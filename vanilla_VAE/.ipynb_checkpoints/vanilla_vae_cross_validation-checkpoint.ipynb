{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/keras-team/keras/blob/master/examples/variational_autoencoder.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # Rather than Torch, for example\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Lambda, Layer, Add, Multiply, BatchNormalization\n",
    "from keras import initializers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.objectives import binary_crossentropy\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n",
    "import random\n",
    "import scipy\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import multivariate_normal\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the data, make sure it's numeric\n",
    "X = pd.read_csv(\"aline_imputed.csv\")\n",
    "#X = X.iloc[:,4:]  # We don't include the patient, hospital, or ICU stay ID's because they're meaningless in this context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'icu_los_day', u'hospital_los_day', u'hosp_exp_flag', u'icu_exp_flag',\n",
       "       u'day_28_flag', u'chf_flag', u'afib_flag', u'renal_flag', u'liver_flag',\n",
       "       u'copd_flag', u'cad_flag', u'stroke_flag', u'malignancy_flag',\n",
       "       u'respfail_flag', u'endocarditis_flag', u'ards_flag',\n",
       "       u'pneumonia_flag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_variables = X.columns[65:]\n",
    "outcome_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into a train/test fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottyf/anaconda/envs/deeplearning/lib/python2.7/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Set the train/test size\n",
    "X_model_input = X.drop(outcome_variables, axis=1)\n",
    "X_train, X_test = sklearn.model_selection.train_test_split(X_model_input, train_size=0.8)\n",
    "\n",
    "# Convert your inputs to numpy arrays (Keras doesn't play nice with pandas dataframes)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a decoder, generator and decoder+generator VAE on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_vae_model(X_train, X_test, latent_dimensions, intermediate_dimensions):\n",
    "    \n",
    "    #Hyperparameters of interest\n",
    "    intermediate_dim = intermediate_dimensions\n",
    "    latent_dim = latent_dimensions\n",
    "    \n",
    "    # Other hyperparameters\n",
    "    original_dim = X_test.shape[1]  # Calculated automatically\n",
    "    batch_size = 1000  # This might affect the learning rate, but shouldn't affect the overall model outcome\n",
    "    n_epochs = 2000  # Not as important when we use the early stopping method (as we do in this method)\n",
    "    epsilon_std = 1.0  # This shouldn't significantly change the model performance, as the z_log_sigma will adjust to accommodate\n",
    "    \n",
    "    # The Encoder, from the original data to the latent dimensions\n",
    "    inputs = Input(shape=(original_dim,))\n",
    "    hidden = Dense(intermediate_dim, activation='relu', kernel_initializer=initializers.he_normal(seed=None))(inputs)\n",
    "    bn = BatchNormalization()(hidden)\n",
    "    z_mean = Dense(latent_dim, activation='linear', kernel_initializer=initializers.he_normal(seed=None))(bn)\n",
    "    z_log_sigma = Dense(latent_dim, activation='linear', kernel_initializer=initializers.Zeros())(bn)\n",
    "    \n",
    "    # The sampler\n",
    "    def sample_z(args):\n",
    "        z_mean, z_log_sigma = args\n",
    "        eps = K.random_normal(shape=(K.shape(inputs)[0], latent_dim),\n",
    "                             mean=0., stddev=1.)\n",
    "        return z_mean + K.exp(z_log_sigma / 2) * eps  # Element-wise product of SD with gaussian noise, + mean vector\n",
    "\n",
    "    z = Lambda(sample_z, output_shape=(latent_dim,))([z_mean, z_log_sigma])\n",
    "    \n",
    "    # The Decoder\n",
    "    decoder_h = Dense(intermediate_dim, activation='relu', kernel_initializer=initializers.he_normal(seed=None))  # We don't specify the inputs because we'll use...\n",
    "    decoder_bn = BatchNormalization()\n",
    "    decoder_mean = Dense(original_dim, activation='linear', kernel_initializer=initializers.he_normal(seed=None))  # ...the same layers again for the generator model below\n",
    "    decoder_log_sigma = Dense(original_dim, activation='linear', kernel_initializer=initializers.Zeros())\n",
    "    h_decoded = decoder_h(z)\n",
    "    bn_decoded = decoder_bn(h_decoded)\n",
    "    output_decoded_mean = decoder_mean(bn_decoded)  # Our output is a mean vector (point estimate) and...\n",
    "    output_decoded_log_sigma = decoder_log_sigma(bn_decoded)  # ...a log_sigma, or log_variance vector...\n",
    "                                                            # which quantifies our certainty about the point estimate\n",
    "    # The end-to-end autoencoder\n",
    "    vae = Model(inputs, output_decoded_mean)\n",
    "\n",
    "    # An encoder, from inputs to the latent space\n",
    "    encoder = Model(inputs, z_mean)\n",
    "\n",
    "    # A generator, from the latent space to the reconstructed inputs\n",
    "    generator_input = Input(shape=(latent_dim,))\n",
    "    generator_h_decoded = decoder_h(generator_input)\n",
    "    generator_bn_decoded = decoder_bn(generator_h_decoded)\n",
    "    generator_output_decoded_mean = decoder_mean(generator_bn_decoded)\n",
    "    generator_output_decoded_log_sigma = decoder_log_sigma(generator_bn_decoded)\n",
    "    generator = Model(generator_input, [generator_output_decoded_mean, generator_output_decoded_log_sigma])\n",
    "    \n",
    "    def vae_loss(y_true, y_pred):\n",
    "        \"\"\" Calculate loss = reconstruction loss + KL loss for each data in minibatch \"\"\"\n",
    "        # -E[log P(X|z)]    \n",
    "        reconstruction_loss = neg_log_likelihood(y_true, y_pred)\n",
    "    \n",
    "        # D_KL(Q(z|X) || P(z|X)); calculate in closed form as both dist. are Gaussian\n",
    "        kl_loss = KL_divergence_loss(y_true, y_pred)\n",
    "    \n",
    "        return reconstruction_loss + kl_loss\n",
    "    \n",
    "    def neg_log_likelihood(y_true, y_pred):\n",
    "        \"\"\" Calculate a proper negative log-likelihood where NLL = -log p(y_pred | mu=y_true, sigma=output_decoded_log_sigma)\"\"\"\n",
    "        negative_log_likelihood = (1./2.) * \\\n",
    "                        (\n",
    "                            K.int_shape(inputs)[1] * K.log(2. * np.pi) + \\\n",
    "                            K.sum(output_decoded_log_sigma, axis=-1, keepdims=True) + \\\n",
    "                            K.sum(\n",
    "                                K.square(y_true - y_pred) * (1. / K.exp(output_decoded_log_sigma)), \n",
    "                                axis=-1, keepdims=True\n",
    "                            )\n",
    "                        )\n",
    "        return negative_log_likelihood\n",
    "    \n",
    "    # An alternative loss function... should give similar results as the above, but isn't a proper NLL per-se\n",
    "    def squared_difference_loss(y_true, y_pred):\n",
    "        \"\"\" Calculate a naive reconstruction loss, i.e. ||y_true - y_pred||^2 \"\"\"\n",
    "        return K.sum(K.square(y_true - y_pred), axis=-1)  # TODO! This isn't strictly speaking the NLL, but it's a half decent approximation for now\n",
    "\n",
    "    def KL_divergence_loss(y_true, y_pred):\n",
    "        \"\"\" Calculate the KL Divergence portion of the loss, i.e. D_KL(Q(z|X) || P(z|X)) \"\"\"\n",
    "        return 0.5 * K.sum(K.exp(z_log_sigma) + K.square(z_mean) - 1. - z_log_sigma, axis=-1)\n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999)\n",
    "    \n",
    "    vae.compile(optimizer=adam, \n",
    "                loss=vae_loss, \n",
    "                metrics=[squared_difference_loss, \n",
    "                         KL_divergence_loss, \n",
    "                         neg_log_likelihood\n",
    "                        ]\n",
    "               )\n",
    "    \n",
    "    #define an early stopping callback criterion so that we don't overfit\n",
    "    earlystop = keras.callbacks.EarlyStopping(monitor='val_loss',  # The quantity to be monitored\n",
    "                                             min_delta=0.01,  # Minimum change in the monitored quantity in order to qualify\n",
    "                                                                # as an improvement (if an absolute change of less than min_delta occurs,\n",
    "                                                                # will not count as no improvement)\n",
    "                                             patience=10,  # The number of epochs with no improvement after which training will be stopped\n",
    "                                             verbose=0,  # Verbosity mode\n",
    "                                             mode='min')  # Training will stop when the quantity monitored has stopped decreasing\n",
    "    \n",
    "    callbacks_list = [earlystop]\n",
    "    \n",
    "    history = vae.fit(X_train,\n",
    "                      X_train,\n",
    "                      shuffle=True,\n",
    "                      epochs=n_epochs,\n",
    "                      verbose=2,\n",
    "                      batch_size=batch_size,\n",
    "#                      callbacks=callbacks_list,\n",
    "                      validation_split=0.3)\n",
    "    \n",
    "    X_test_encoded = encoder.predict(X_test)  # We take our test data directly from data-space to latent variable\n",
    "    X_test_decoded_mean, X_test_decoded_log_sigma = generator.predict(X_test_encoded)  # space to calculate the\n",
    "    \n",
    "    # marginal log likelihood of the data under our fully-trained model (i.e. we don't add noise)\n",
    "    test_nll = (1./2.) * \\\n",
    "               (\n",
    "                   X_test.shape[1] * np.log(2. * np.pi) + \\\n",
    "                   np.sum(X_test_decoded_log_sigma, axis=-1, keepdims=True) + \\\n",
    "                   np.sum(\n",
    "                       np.square(X_test - X_test_decoded_mean) * (1. / np.exp(X_test_decoded_log_sigma)), \n",
    "                       axis=-1, keepdims=True\n",
    "                   )\n",
    "               )\n",
    "    \n",
    "    return np.mean(test_nll), vae, encoder, generator, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29329 samples, validate on 12570 samples\n",
      "Epoch 1/20\n",
      " - 9s - loss: 98.4148 - squared_difference_loss: 72.3830 - KL_divergence_loss: 2.4923 - neg_log_likelihood: 95.9225 - val_loss: 96.1323 - val_squared_difference_loss: 65.1811 - val_KL_divergence_loss: 3.8108 - val_neg_log_likelihood: 92.3216\n",
      "Epoch 2/20\n",
      " - 1s - loss: 86.7020 - squared_difference_loss: 49.9021 - KL_divergence_loss: 2.0199 - neg_log_likelihood: 84.6821 - val_loss: 89.8543 - val_squared_difference_loss: 51.1603 - val_KL_divergence_loss: 4.5431 - val_neg_log_likelihood: 85.3112\n",
      "Epoch 3/20\n",
      " - 1s - loss: 85.5179 - squared_difference_loss: 46.4424 - KL_divergence_loss: 2.5657 - neg_log_likelihood: 82.9522 - val_loss: 88.0750 - val_squared_difference_loss: 48.2348 - val_KL_divergence_loss: 4.2266 - val_neg_log_likelihood: 83.8484\n",
      "Epoch 4/20\n",
      " - 1s - loss: 85.0371 - squared_difference_loss: 45.1469 - KL_divergence_loss: 2.7327 - neg_log_likelihood: 82.3045 - val_loss: 86.8459 - val_squared_difference_loss: 46.4059 - val_KL_divergence_loss: 3.9120 - val_neg_log_likelihood: 82.9340\n",
      "Epoch 5/20\n",
      " - 1s - loss: 84.6757 - squared_difference_loss: 44.1416 - KL_divergence_loss: 2.8739 - neg_log_likelihood: 81.8018 - val_loss: 86.2282 - val_squared_difference_loss: 45.3790 - val_KL_divergence_loss: 3.8077 - val_neg_log_likelihood: 82.4205\n",
      "Epoch 6/20\n",
      " - 1s - loss: 84.4066 - squared_difference_loss: 43.3816 - KL_divergence_loss: 2.9848 - neg_log_likelihood: 81.4218 - val_loss: 85.9186 - val_squared_difference_loss: 44.9129 - val_KL_divergence_loss: 3.7311 - val_neg_log_likelihood: 82.1874\n",
      "Epoch 7/20\n",
      " - 1s - loss: 84.1873 - squared_difference_loss: 42.6994 - KL_divergence_loss: 3.1066 - neg_log_likelihood: 81.0807 - val_loss: 85.5807 - val_squared_difference_loss: 44.2993 - val_KL_divergence_loss: 3.7001 - val_neg_log_likelihood: 81.8806\n",
      "Epoch 8/20\n",
      " - 1s - loss: 83.9825 - squared_difference_loss: 42.1928 - KL_divergence_loss: 3.1551 - neg_log_likelihood: 80.8274 - val_loss: 85.3689 - val_squared_difference_loss: 43.7374 - val_KL_divergence_loss: 3.7692 - val_neg_log_likelihood: 81.5997\n",
      "Epoch 9/20\n",
      " - 1s - loss: 83.8560 - squared_difference_loss: 41.7782 - KL_divergence_loss: 3.2359 - neg_log_likelihood: 80.6201 - val_loss: 85.0635 - val_squared_difference_loss: 43.4472 - val_KL_divergence_loss: 3.6089 - val_neg_log_likelihood: 81.4546\n",
      "Epoch 10/20\n",
      " - 1s - loss: 83.6817 - squared_difference_loss: 41.3864 - KL_divergence_loss: 3.2575 - neg_log_likelihood: 80.4242 - val_loss: 84.9112 - val_squared_difference_loss: 43.1401 - val_KL_divergence_loss: 3.6101 - val_neg_log_likelihood: 81.3010\n",
      "Epoch 11/20\n",
      " - 1s - loss: 83.6101 - squared_difference_loss: 41.1215 - KL_divergence_loss: 3.3183 - neg_log_likelihood: 80.2918 - val_loss: 84.8867 - val_squared_difference_loss: 43.1271 - val_KL_divergence_loss: 3.5921 - val_neg_log_likelihood: 81.2945\n",
      "Epoch 12/20\n",
      " - 1s - loss: 83.5193 - squared_difference_loss: 40.9201 - KL_divergence_loss: 3.3282 - neg_log_likelihood: 80.1910 - val_loss: 84.9641 - val_squared_difference_loss: 43.3120 - val_KL_divergence_loss: 3.5771 - val_neg_log_likelihood: 81.3870\n",
      "Epoch 13/20\n",
      " - 1s - loss: 83.4522 - squared_difference_loss: 40.7885 - KL_divergence_loss: 3.3270 - neg_log_likelihood: 80.1252 - val_loss: 84.6841 - val_squared_difference_loss: 42.7240 - val_KL_divergence_loss: 3.5912 - val_neg_log_likelihood: 81.0930\n",
      "Epoch 14/20\n",
      " - 1s - loss: 83.4184 - squared_difference_loss: 40.6031 - KL_divergence_loss: 3.3858 - neg_log_likelihood: 80.0325 - val_loss: 84.4147 - val_squared_difference_loss: 42.0865 - val_KL_divergence_loss: 3.6404 - val_neg_log_likelihood: 80.7743\n",
      "Epoch 15/20\n",
      " - 1s - loss: 83.3801 - squared_difference_loss: 40.5139 - KL_divergence_loss: 3.3921 - neg_log_likelihood: 79.9879 - val_loss: 84.3692 - val_squared_difference_loss: 42.0299 - val_KL_divergence_loss: 3.6232 - val_neg_log_likelihood: 80.7460\n",
      "Epoch 16/20\n",
      " - 1s - loss: 83.3368 - squared_difference_loss: 40.4562 - KL_divergence_loss: 3.3777 - neg_log_likelihood: 79.9591 - val_loss: 84.2760 - val_squared_difference_loss: 41.9647 - val_KL_divergence_loss: 3.5626 - val_neg_log_likelihood: 80.7133\n",
      "Epoch 17/20\n",
      " - 1s - loss: 83.2609 - squared_difference_loss: 40.2238 - KL_divergence_loss: 3.4180 - neg_log_likelihood: 79.8429 - val_loss: 84.0434 - val_squared_difference_loss: 41.6641 - val_KL_divergence_loss: 3.4804 - val_neg_log_likelihood: 80.5631\n",
      "Epoch 18/20\n",
      " - 1s - loss: 83.2198 - squared_difference_loss: 40.1565 - KL_divergence_loss: 3.4106 - neg_log_likelihood: 79.8092 - val_loss: 83.8506 - val_squared_difference_loss: 41.1642 - val_KL_divergence_loss: 3.5375 - val_neg_log_likelihood: 80.3131\n",
      "Epoch 19/20\n",
      " - 1s - loss: 83.1455 - squared_difference_loss: 40.0182 - KL_divergence_loss: 3.4054 - neg_log_likelihood: 79.7401 - val_loss: 83.8334 - val_squared_difference_loss: 41.1633 - val_KL_divergence_loss: 3.5208 - val_neg_log_likelihood: 80.3127\n",
      "Epoch 20/20\n",
      " - 1s - loss: 83.1474 - squared_difference_loss: 39.9922 - KL_divergence_loss: 3.4203 - neg_log_likelihood: 79.7271 - val_loss: 83.6116 - val_squared_difference_loss: 40.4451 - val_KL_divergence_loss: 3.6581 - val_neg_log_likelihood: 79.9536\n"
     ]
    }
   ],
   "source": [
    "n_z = 4 # Number of units in the latent variable representation\n",
    "n_h = 20 # Number of hidden units in encoder/decoder\n",
    "test_err, vae, encoder, generator, history = evaluate_vae_model(X_train, X_test, n_z, n_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Train Loss & Validation Loss vs. Number of Epochs to see our model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFNCAYAAAD7De1wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd8XNWd///XR71bxbKt4kpzxbJxTDWYEpbQDFkgdELo\n2Q2bEDawSb4Jm/Jbks0SwiZLFkIIEIJDSChLCSFAKAkx2MYYsA3GDVRcJFuWLNmSRnN+f9w70khW\ns6TRzGjez8djHnPn3jt3ztUY3nPOPedcc84hIiIi8Skp2gUQERGRwVOQi4iIxDEFuYiISBxTkIuI\niMQxBbmIiEgcU5CLiIjEMQW5iESdmd1gZtvMbI+ZFcVAeRabWWW0yyEyEApySShm9kcz+04P65eY\n2VYzSwlbd5uZOTM7stu+nzezdj90wh+lvXymM7ODh/9sosvMTjez3/jLD5rZ2YM8TipwB3Cqcy7H\nOVfXbfsU/2/Y/e/9uaGfhUj8U5BLonkAuNTMrNv6y4CHnXMBAH/75cBO/7m7N/zQCX9UR7TksecI\nYHnY8spBHmc8kAG8389++d3+3r8d5OeJjCoKckk0TwBFwKLQCjMrAM4EHgzbbxFQAtwIXGhmacNd\nEDNLMrNvmtkWM9vu12rH+NsyzOzXZlZnZvVm9paZjfe3fd7MNppZo5ltMrNLejh2qZntNbPCsHXz\nzKzWzFLN7GAze8XMdvvrBhOKC4AVZpYNFDrnem2KNrN0M7vTzKr9x53+ukOBD/zd6s3spQMthJn9\nysx+bmYv+H+TV8xsctj2Y/y/327/+ZiwbYVmdr9fpl1m9kS3Y3/V/25qzOzKsPWnm9ka//OqzOzm\nAy23yHBRkEtCcc7tBR6lay37AmCdc+6dsHVXAP/n7wtwVgSK83n/cSIwDcgBfhr2+WOAiXg/PK4H\n9vqheRfwGedcLnAMsKr7gf3WgTeAfwxbfTHwmHOuDfgu8CegACgH/nughTazD8ysHu/Hz1PANmCs\n/4Pjf3t52zeAo4AKYC6wEPimc+5DYJa/T75z7qSBlqObS/DOaSze3+Nhv6yFwDN4f7MivCb8Z8Ku\nwz8EZPllGAf8OOyYE/C+gzLgKuBn/o8+gPuA6/zvYDZwwD9ARIaNc04PPRLqARwH1AMZ/uu/Al8J\n254FNADn+K//F3gybPvngYB/jNBjQx+f54CDe1j/IvDFsNeHAW1ACvAF4G/A4d3ek+1/3j8Cmf2c\n59XAS/6yAZ8Ax/uvHwTuAcoH+Tc8BXjcX74HOL+f/TcAp4e9/gdgs788xf8bpfTy3tD2+m6PGf72\nXwFLw/bPAdrxfgRdBrzZ7Xhv+N9hCRAECnr4zMXA3vAyAduBo/zlj4HrgLxo/3vWQw/VyCXhOOde\nB2qBc8zsILza4W/CdjkXL6if9V8/DHzGzIrD9vm7cy4/7HHQIIpSCmwJe70FL8TH49UUnweW+s2+\nPzSzVOdcE/A5vBp6jZk9Y2bTezn+74GjzawEOB4vtF7zt30NL9zfNLP3zewLAymwX456vFruqf7y\nVcC9Zrb1AM+1x86BfRjb7W++NmzbJ6EF59wevL4NpT18buizy/CCfqdzblcvn1fn/D4Tvma8Hwng\n/ZA6HdjiN+UffYDnIjJsFOSSqB7Ea16/FHjeObctbNsVeP/D/tgPp98BqXhN08OpGpgc9noS3g+I\nbc65NufcvzvnZuI1n5/plxfn3PPOuU/j1SjXAff2dHA/oP6EF/wX49Vanb9tq3PuGudcKV7N8n8G\n0rPeOfc151w+sAk4GDgBr+NfvnNuwgGe63B2DpwYWjCzHKDQP373zw19dhVe+BeaWf6Bfphz7i3n\n3BK85vgn6LwEIzLiFOSSqB7Eax6+Bq8nOwBmVgacjBecFXRe0/0BPfdeH6g0vwNb6JEMPAJ8xcym\n+uHz/wG/dc4FzOxEM5vj79eA1+QeNLPx5g2VywZagD14Ne3e/MYv93mEtTqY2flmVu6/3IXXdN3X\ncTqYWS6Q65yrAebT2XO9L48A3zSzYjMbC3wL+PVAPm+ATjez4/xOid/FazH5BK9V5VAzu9jMUvwh\nazOBp/3yP4f3I6bA7wR4fH8fZGZpZnaJmY1xXn+DBgb4txOJBAW5JCTn3Ga8a9DZeB22Qi4DVjnn\n/uTXWrc657bidZY63Mxm+/sdbfuPa/5UHx/5Pt4119DjSuCXeE3or+LVcPcBX/L3nwA8hhcSa4FX\n/H2TgJvwapo78WrEN/TxuU8BhwBbXdfOfJ8ClpnZHn+ff3HObQTwm9r36wkfZh6dHezmAyv62Dfk\ne3iBvxp4F2+o2vcG8L5w9d3+3jeFbfsN8G28v8kReC0tOG9M+pnAV4E6vEsKZzrnav33XYb3I2kd\n3jXwLw+wLJcBm82sAe8yR19/L5GIMr+lTUQkLpnZr4BK59w3o10WkWhQjVxERCSOKchFRETimJrW\nRURE4phq5CIiInFMQS4iIhLHUvrfJfrGjh3rpkyZEu1iiIiIjIgVK1bUOueK+98zToJ8ypQpLF8+\nkDknRERE4p+ZdZ9auFdqWhcREYljCnIREZE4piAXERGJY3FxjVxERPrW1tZGZWUl+/bti3ZR5ABk\nZGRQXl5OamrqoI+hIBcRGQUqKyvJzc1lypQpmFm0iyMD4Jyjrq6OyspKpk6dOujjqGldRGQU2Ldv\nH0VFRQrxOGJmFBUVDbkVRUEuIjJKKMTjz3B8ZwpyEREZsrq6OioqKqioqGDChAmUlZV1vG5tbR3Q\nMa688ko++OCDAX/mL37xC7785YHeQn700jVyEREZsqKiIlatWgXAbbfdRk5ODjfffHOXfZxzOOdI\nSuq5Dnn//fdHvJyjUcLVyN+r2s0jb34c7WKIiCSEjz76iJkzZ3LJJZcwa9YsampquPbaa1mwYAGz\nZs3iO9/5Tse+xx13HKtWrSIQCJCfn8+tt97K3LlzOfroo9m+ffuAP/PXv/41c+bMYfbs2Xz9618H\nIBAIcNlll3Wsv+uuuwD48Y9/zMyZMzn88MO59NJLh/fkR0jC1chfWLONu15azz/OLyctJeF+x4iI\njLh169bx4IMPsmDBAgBuv/12CgsLCQQCnHjiiZx33nnMnDmzy3t2797NCSecwO23385NN93EL3/5\nS2699dZ+P6uyspJvfvObLF++nDFjxnDKKafw9NNPU1xcTG1tLe+++y4A9fX1APzwhz9ky5YtpKWl\ndayLNwkX5OUFmTgHNbv3MrkoO9rFEREZdv/+f++zprphWI85szSPb581a1DvPeiggzpCHOCRRx7h\nvvvuIxAIUF1dzZo1a/YL8szMTD7zmc8AcMQRR/Daa68N6LOWLVvGSSedxNixYwG4+OKLefXVV7nl\nllv44IMPuPHGGznjjDM49dRTAZg1axaXXnopS5Ys4ZxzzhnU+UVbwlVJywuyAKjctTfKJRERSQzZ\n2Z2VpvXr1/OTn/yEl156idWrV3Paaaf1OPwqLS2tYzk5OZlAIDCkMhQVFbF69WoWLVrEz372M667\n7joAnn/+ea6//nreeustFi5cSHt7+5A+JxoSskYOUKUgF5FRarA155HQ0NBAbm4ueXl51NTU8Pzz\nz3PaaacN2/GPPPJIbr75Zurq6hgzZgxLly7l5ptvZseOHWRkZHD++edzyCGHcPXVV9Pe3k5lZSUn\nnXQSxx13HBMnTqS5uZnc3NxhK89ISLggnzAmgySDyl3N0S6KiEjCmT9/PjNnzmT69OlMnjyZY489\ndkjHu++++3jsscc6Xi9fvpzvfve7LF68GOccZ511FmeccQYrV67kqquuwjmHmfGDH/yAQCDAxRdf\nTGNjI8FgkJtvvjnuQhzAnHPRLkO/FixY4IbzfuTH3v4SR04t5I7PVQzbMUVEomnt2rXMmDEj2sWQ\nQejpuzOzFc65Bb28pYuEu0YOUFaQqWvkIiIyKiRkkJcXZKppXURERoUEDfIstjbsozUQjHZRRERE\nhiRBgzyToIOtu3XfXhERiW8JG+SgnusiIhL/EjLIJ2pSGBERGSUSMsg7xpLXK8hFRIbDiSeeyPPP\nP99l3Z133skNN9zQ5/tycnIAqK6u5rzzzutxn8WLF9PfEOQ777yT5ubOVtbTTz99WOZOv+222/jR\nj3405ONEUkIGeWpyEhPyMtS0LiIyTC666CKWLl3aZd3SpUu56KKLBvT+0tLSLhO7HKjuQf7ss8+S\nn58/6OPFk4QMcvB6rqtpXURkeJx33nk888wztLa2ArB582aqq6tZtGgRe/bs4eSTT2b+/PnMmTOH\nJ598cr/3b968mdmzZwOwd+9eLrzwQmbMmMG5557L3r2d/6++4YYbOm6B+u1vfxuAu+66i+rqak48\n8UROPPFEAKZMmUJtbS0Ad9xxB7Nnz2b27NnceeedHZ83Y8YMrrnmGmbNmsWpp57a5XP609Mxm5qa\nOOOMM5g7dy6zZ8/mt7/9LQC33nprx61Su9+jfThEbIpWMzsM+G3YqmnAt4AH/fVTgM3ABc65XZEq\nR2/KCzJZtmnnSH+siMioVFhYyMKFC3nuuedYsmQJS5cu5YILLsDMyMjI4PHHHycvL4/a2lqOOuoo\nzj77bMysx2PdfffdZGVlsXbtWlavXs38+fM7tn3/+9+nsLCQ9vZ2Tj75ZFavXs2NN97IHXfcwcsv\nv9xx17OQFStWcP/997Ns2TKccxx55JGccMIJFBQUsH79eh555BHuvfdeLrjgAn7/+98P6J7kvR1z\n48aNlJaW8swzzwDerVjr6up4/PHHWbduHWYWkVulRizInXMfABUAZpYMVAGPA7cCLzrnbjezW/3X\nt0SqHL0pL8jkiVV7aWsPkpqcsA0TIjIaPXcrbH13eI85YQ585vY+dwk1r4eC/L777gPAOcfXv/51\nXn31VZKSkqiqqmLbtm1MmDChx+O8+uqr3HjjjQAcfvjhHH744R3bHn30Ue655x4CgQA1NTWsWbOm\ny/buXn/9dc4999yOO7B99rOf5bXXXuPss89m6tSpVFR4U3UfccQRbN68eUB/it6Oedppp/HVr36V\nW265hTPPPJNFixYRCATIyMjgqquu4swzz+TMM88c0GcciJFKsJOBDc65LcAS4AF//QNAVG4AW16Q\npbHkIiLDaMmSJbz44ousXLmS5uZmjjjiCAAefvhhduzYwYoVK1i1ahXjx4/v8dal/dm0aRM/+tGP\nePHFF1m9ejVnnHHGoI4Tkp6e3rE8HLdKPfTQQ1m5ciVz5szhm9/8Jt/5zndISUnhzTff5LzzzuPp\np58e1ju9hYzU3c8uBB7xl8c752r85a3A+BEqQxehseSf7GpmYmFWNIogIhIZ/dScIyUnJ4cTTzyR\nL3zhC106ue3evZtx48aRmprKyy+/zJYtW/o8zvHHH89vfvMbTjrpJN577z1Wr14NeLdAzc7OZsyY\nMWzbto3nnnuOxYsXA5Cbm0tjY+N+TeuLFi3i85//PLfeeivOOR5//HEeeuihIZ1nb8esrq6msLCQ\nSy+9lPz8fH7xi1+wZ88empubOf300zn22GOZNm3akD67JxEPcjNLA84G/q37NuecM7Meb79mZtcC\n1wJMmjRp2MtVrrHkIiLD7qKLLuLcc8/t0oP9kksu4ayzzmLOnDksWLCA6dOn93mMG264gSuvvJIZ\nM2YwY8aMjpr93LlzmTdvHtOnT2fixIldboF67bXXctppp1FaWsrLL7/csX7+/Pl8/vOfZ+HChQBc\nffXVzJs3b8DN6ADf+973Ojq0AVRWVvZ4zOeff55//dd/JSkpidTUVO6++24aGxtZsmQJ+/btwznH\nHXfcMeDPHaiI38bUzJYA/+ScO9V//QGw2DlXY2YlwF+cc4f1dYzhvo0pQGsgyPT/9xz/fNIh3PTp\nQ4f12CIiI023MY1f8XAb04vobFYHeAq4wl++Ath/HMIISEtJYnxeBlWqkYuISByLaJCbWTbwaeAP\nYatvBz5tZuuBU/zXUaHbmYqISLyL6DVy51wTUNRtXR1eL/aoKy/I4k2NJRcRkTiW0AOoywsy2dqw\nj0C77ksuIvEv0n2eZPgNx3eW8EHeHnTUaCy5iMS5jIwM6urqFOZxxDlHXV0dGRkZQzrOSI0jj0nh\nQ9A0llxE4ll5eTmVlZXs2LEj2kWRA5CRkUF5efmQjpHgQe5NCuN1eCvqe2cRkRiWmprK1KlTo10M\niYKEblovGZOJmSaFERGR+JXQQZ6W4t2XvKpeQS4iIvEpoYMcoCxfY8lFRCR+JXyQe5PCqEYuIiLx\nSUFekEXNbo0lFxGR+KQg98eSb23QWHIREYk/CnLdzlREROKYgrxjLLmCXERE4k/CB3lJfoY/llw9\n10VEJP4kfJCnpyQzPjdDNXIREYlLCR/k4DWvVynIRUQkDinIgbKCTCrr1bQuIiLxR0GOVyOvqddY\nchERiT8KcrwhaIGgY1tjS7SLIiIickAU5IQNQdup5nUREYkvCnI0KYyIiMQvBTlQmp8BKMhFRCT+\nKMjxx5LnpWtSGBERiTsKcl95QZZq5CIiEncU5L6y/Eyq6hXkIiISXxTkvvKCTKrr99IedNEuioiI\nyIApyH0dY8l1X3IREYkjCnKfbmcqIiLxSEHu6wxy9VwXEZH4oSD3learRi4iIvEnokFuZvlm9piZ\nrTOztWZ2tJndZmZVZrbKf5weyTIMVEZqMuNyNZZcRETiS6Rr5D8B/uicmw7MBdb663/snKvwH89G\nuAxdffIm/PUnPW4qL8hUjVxEROJKxILczMYAxwP3ATjnWp1z9ZH6vAHb+Aq88C3Y17DfJk0KIyIi\n8SaSNfKpwA7gfjN728x+YWbZ/rYvmdlqM/ulmRVEsAz7K63wnreu3m9TWUEmNbs1llxEROJHJIM8\nBZgP3O2cmwc0AbcCdwPTgAqgBvivnt5sZtea2XIzW75jx47hK1WJH+TVq/bbVF6QSVu7Y3ujxpKL\niEh8iGSQVwKVzrll/uvHgPnOuW3OuXbnXBC4F1jY05udc/c45xY45xYUFxcPX6lyiiGvDGp6CnLd\nzlREROJLxILcObcV+MTMDvNXnQysMbOSsN3OBd6LVBl6VVLRa40cNJZcRETiR0qEj/8l4GEzSwM2\nAlcCd5lZBeCAzcB1ES7D/kor4INnoaUR0nM7VpeFxpLvVI1cRETiQ0SD3Dm3CljQbfVlkfzMASnx\nf0fUrIYpx3aszkhNpjg3XU3rIiISNxJzZrdQz/Xqt/fbVF6QSWW9mtZFRCQ+JGaQ54zrs8ObauQi\nIhIvEjPIoc8Ob9X1ewlqLLmIiMSBxA3y0gqo+8jr8BamLD80lrwlSgUTEREZuMQN8vAOb2E0BE1E\nROJJ4gZ5qMNbt+vkmhRGRETiSeIGec44yC3d7zq5auQiIhJPEjfIwauVd6uRZ6QmMzZHY8lFRCQ+\nJHaQl1RA7fr9OrzpvuQiIhIvEjvIS3vv8KamdRERiQeJHeQlvXd4q67fp7HkIiIS8xI7yHPH99rh\nrbU9yI49GksuIiKxLbGDHHrs8FamnusiIhInFOQ9dHib2BHk6vAmIiKxTUEe6vC29d2OVWX5mhRG\nRETig4I81OEt7Dp5ZloyY3PS1LQuIiIxT0GeOx5yS/a7N3mZbmcqIiJxQEEOXq18vyFomhRGRERi\nn4IcoHTefh3eygsyqdql+5KLiEhsU5BDjx3eyguyNJZcRERinoIceuzwVq4haCIiEgcU5NDZ4S3s\nOnl5viaFERGR2KcgDymp6FIjL1ONXERE4oCCPKS0Amo/hJY9AGSlpVCUnaYgFxGRmKYgDykJdXjr\nvKWpbmcqIiKxTkEeUtpTh7csqlQjFxGRGKYgD8mdADkTunZ4K8iksl5jyUVEJHYpyMOVzttvCFpr\nIEitxpKLiEiMUpCH69bhrbzAvwtavZrXRUQkNkU0yM0s38weM7N1ZrbWzI42s0Ize8HM1vvPBZEs\nwwEp6TrDm4agiYhIrIt0jfwnwB+dc9OBucBa4FbgRefcIcCL/uvYEOrw5l8nL9OkMCIiEuMiFuRm\nNgY4HrgPwDnX6pyrB5YAD/i7PQCcE6kyHLBQhzf/Onl2egqFGksuIiIxLJI18qnADuB+M3vbzH5h\nZtnAeOdcjb/PVmB8BMtw4EorutybXLczFRGRWBbJIE8B5gN3O+fmAU10a0Z3zjmgx7FdZnatmS03\ns+U7duyIYDG7Kene4U2TwoiISOyKZJBXApXOuWX+68fwgn2bmZUA+M/be3qzc+4e59wC59yC4uLi\nCBazm263NA1NCuP95hAREYktEQty59xW4BMzO8xfdTKwBngKuMJfdwXwZKTKMCglXTu8lRdk0hLQ\nfclFRCQ2pUT4+F8CHjazNGAjcCXej4dHzewqYAtwQYTLcGDySrp0eAu/L/m43IxolkxERGQ/EQ1y\n59wqYEEPm06O5OcOWWlFWI3cmxSmatde5k+KnSHvIiIioJndehbq8NbaFDaWXD3XRUQk9ijIe1Ja\nAS4IW98lOz2FgqxU9VwXEZGYpCDvSajDmz+evLwgSzVyERGJSQrynuSVQM74Lh3eVCMXEZFYpCDv\nTUlFlyFolRpLLiIiMUhB3pvSeR0d3soLsmgJBKnd0xrtUomIiHShIO9NWIe3zrHkal4XEZHYoiDv\nTUeHt1UdY8nV4U1ERGKNgrw3oQ5vNaso82vkVfUKchERiS0DmtnNzKYCs/yXa5xzGyNXpBhSUgHV\nq8hJTyFfY8lFRCQG9RnkZpYH/AJvmtVV/uoKM1sBXOWca4hw+aKrtAI+esHv8Kb7kouISOzpr2n9\nLrw7lh3snPusc+6zwEHAu8BPI124qCsJ6/CWr0lhREQk9vQX5Mc6525zzgVDK5znO8DRkS1aDCgN\n7/DmTQqjseQiIhJLhtLZzYatFLEqtwSyx0GNF+T72oLUNWksuYiIxI7+gvxvZvYtM+sS2mb2/4A3\nIlesGGHmTQyjIWgiIhKj+gvyLwFzgI/M7Pf+YyMwF/jniJcuFpRWQO0HTMz1mtTVc11ERGJJn73W\n/V7p55vZQcBMf/XXnHMbIl6yWOF3eCtv8U5ZNXIREYkl/Y4jN7MUYKNzboOZTQSONLM859zbkS9e\nDPA7vGXXvUd+1lSqFOQiIhJD+mxaN7NrgO3AFn/5ReA8YKmZ3TIC5Yu+UIe36rcpy9ftTEVEJLb0\nVyP/Mt648VxgLTDZOVdrZlnAW8APIly+6DPzauXVqygvuJqNO5qiXSIREZEO/XV2a3XO7XLOfQx8\n5JyrBXDONQOJMw6rxOvwNjXPdF9yERGJKf3VyDPNbB5e4Kf5y+Y/MiJduJjh39J0TsrH7G1LY2dT\nK0U56dEulYiISL9BXgPc4S9vDVsObUsMpfMAOCjwETCTyl17FeQiIhIT+ht+dmJv28zsyOEvTozy\nO7xNaFpHKMjnTsyPdqlERESGNEXr74atFLHO7/CWu+t9QJPCiIhI7NBc6wNVUkFy7QeMzwhSVa+x\n5CIiEhuGEuSJ1XXb7/B2XG6NZncTEZGY0ec1cjP7P3oObAOKIlKiWFXizfC2IG0L9+86LMqFERER\n8fTXa/1Hg9w2+uSVQnYxM9jYMZa8203hRERERlx/Qf62f+OU/ZjZpP4ObmabgUagHQg45xaY2W3A\nNcAOf7evO+eeHXCJo8UMSiqYVPMhza3t7GpuozA7LdqlEhGRBNffNfK/hBbM7MVu254Y4Gec6Jyr\ncM4tCFv3Y39dRVyEeEhpBQVNG8mgRT3XRUQkJvQX5OFtx4V9bEsMpfMwgsy0LerwJiIiMaG/IHe9\nLPf0urf3/9nMVpjZtWHrv2Rmq83sl2ZWMJCCxgS/w9vspE2qkYuISEzo7xr5ODO7Ca/2HVrGf108\ngOMf55yrMrNxwAtmtg64G/guXsh/F/gv4Avd3+gH/7UAkyb1ezl+ZPgd3uY3bWGlauQiIhID+quR\n34t3C9OcsOXQ61/0d3DnXJX/vB14HFjonNvmnGt3zgX9Yy7s5b33OOcWOOcWFBcP5DfDCPA7vFUk\nbaJKQS4iIjGgv7nW/32wBzazbCDJOdfoL58KfMfMSpxzoRuunAu8N9jPiIrSCiZ99CI7du6KdklE\nRET6nRDmW31sds657/axfTzwuD/WOgX4jXPuj2b2kJlV4DWtbwauO7AiR1lJBUkEyalfh3Of1lhy\nERGJqv6ukTf1sC4buApvZrdeg9w5txGY28P6yw6kgDGn1OvwdnD7R9Q3t1GgseQiIhJF/TWt/1do\n2cxygX8BrgSW4nVSSzx5ZbSkFzInsInKXXsV5CIiElX93jTFzArN7HvAarzgn++cu8XvwJZ4zGgd\nN1dD0EREJCb0GeRm9p/AW3jTrM5xzt3mnEv4Xl6p5fM5xKqoqU34P4WIiERZfzXyrwKlwDeBajNr\n8B+NZtbjHOyJIGPSfFIsSHvN6mgXRUREElx/18iHcr/y0cvv8JZV+y5wYXTLIiIiCU1BPRh5ZTQk\n5VO8Z220SyIiIglOQT4YZmzLmc6UlvU4N5Ap50VERCJDQT5IewpnM41KdjckbFcBERGJAQryQXIl\nFaRYkLoNK6NdFBERSWAK8kHKnnIEAC0fr4hySUREJJEpyAdpQvnB1Lo8krdpCJqIiESPgnyQ8rJS\nWcc0xtS/H+2iiIhIAlOQD5KZ8UnGoRTv3Qhtuje5iIhEh4J8CHaOmUUyQdgaX7dUFxGR0UNBPgSt\n4+YA4KrfjnJJREQkUSnIhyB33BTqXC5tlQpyERGJDgX5EJQXZvFecCrtVQpyERGJDgX5EJQXZPGu\nm0r6rg/V4U1ERKJCQT4E5QWZvBucRpJrh20ahiYiIiNPQT4EYzJT2ZB6iPdCHd5ERCQKFORDYGak\n5JfTmDQGqldFuzgiIpKAFORDVF6YxQdJB0GNglxEREaegnyIyguyWBmYDNvXqsObiIiMOAX5EJUX\nZLKidTK4ds3wJiIiI05BPkRl+ZmsCB5GMDkDnv4K7N0V7SKJiEgCUZAPUXlBFrWMYeUxP4PaD+DX\n50FLY7SLJSIiCUJBPkTlBZkAvJN+BJz/K28Y2m8+B63N0S2YiIgkBAX5EOVnpZKdlkzlrmaYfgZ8\n9h7Y8jelVwN7AAAgAElEQVT47SUQaIl28UREZJRTkA+RmVFekEXlLr/H+pzzYMlPYcNL8Lsrob0t\nugUUEZFRLaJBbmabzexdM1tlZsv9dYVm9oKZrfefCyJZhpFQXpDZGeQA8y6F038EHzwDj18Hwfbo\nFU5EREa1kaiRn+icq3DOLfBf3wq86Jw7BHjRfx3XvCDvdk184TVwyr/De7+H/7sRgsHoFE5EREa1\nlCh85hJgsb/8APAX4JYolGPYlBdk0bgvwO69bYzJTO3ccNyXoa0ZXvkBpGbBZ34IZtErqIiIjDqR\nDnIH/NnM2oH/dc7dA4x3ztX427cC4yNchogr83uuV+3a2zXIARb/G7Q2wRs/9cL8lNsU5iIiMmwi\nHeTHOeeqzGwc8IKZrQvf6JxzZuZ6eqOZXQtcCzBp0qQIF3NoQkPQ3qvazczSvK4bzeDU73nTt/71\nTkjLhhO+FoVSiojIaBTRa+TOuSr/eTvwOLAQ2GZmJQD+8/Ze3nuPc26Bc25BcXFxJIs5ZDNK8phV\nmsd3n17Dhh179t/BzOv8NvdiePn78LefjnwhRURkVIpYkJtZtpnlhpaBU4H3gKeAK/zdrgCejFQZ\nRkpqchL3XL6AtJQkrnlwOQ37ehhylpQEZ/83zDwH/vQNeOu+kS+oiIiMOpGskY8HXjezd4A3gWec\nc38Ebgc+bWbrgVP813GvLD+T/7lkPh/XNfPlpatoD/ZwxSA5BT57Lxx6GjxzE6x6ZOQLKiIio0rE\ngtw5t9E5N9d/zHLOfd9fX+ecO9k5d4hz7hTn3M5IlWGkHTmtiG+fNZOX1m3njhc+6HmnlDQ4/wGY\nthie/CK8//hIFlFEREYZzew2zC49ajIXfmoiP3t5A8+srul5p9QMuPA3MPFI+P3V8MEfR7aQIiIy\naijIh5mZ8e9LZjF/Uj43/+4d1lQ39LxjWjZc/ChMmAOPXg4bXh7ZgoqIyKigII+A9JRkfn7pEeRl\npnDtQ8vZ2dTa844ZeXDpH6DoYFh6MWx5Y2QLKiIicU9BHiHj8jL438sWsL2xhX96eCVt7b1M0ZpV\nCJc/AXll8PD5ULVyZAsqIiJxTUEeQRUT8/mPc+fwxsY6vv/M2t53zBkHlz/phfqvPwvb3h+5QoqI\nSFxTkEfYPx5RzheOncqv/raZR5d/0vuOY8rgiqcgJRMeXAK160eukCIiErcU5CPg66dP59iDi/jm\n4+/x9se7et+xYIoX5gAPnA27No9E8UREJI4pyEdASnISP71oPuPHpHPdQyvY1rCv953HHgKXPeHd\nNe2Bs2F31cgVVERE4o6CfIQUZKdx7+UL2NMS4Ppfr6Al0N77zhNmw2V/gOadcM9iWBP3s9iKiEiE\nKMhH0PQJefzX+XN5++N6/t8T7+Fcjzd+85QdAV/4I+RO8MaZP3o57Onx/jIiIpLAFOQj7DNzSvjS\nSQfz6PJKHnxjS987T5gN17wEJ3/Lm/3tZwvhnaXQ1w8AERFJKAryKPjKKYdyyoxxfOfpNbyxoa7v\nnZNTYdFX4frXYeyh8Ph13njz3ZUjU1gREYlpCvIoSEoyfvy5CqYUZfHFh1fwyc7m/t9UfChc+Ryc\n9gPY8lf42VGw/JcQ7GWiGRERSQgK8ijJzUjl3ssXEAg6rn1oBc2tgf7flJQMR10PN/wNyubB01+B\nB8+GnRsjX2AREYlJCvIomlacw39fNI91Wxv42mOr++78Fq5wKlz+FJx1F9S8A/9zDPztpxDsoye8\niIiMSgryKFt82Di+9g/TeXp1DXe/smHgbzSDI66AL/4dpp0Af/oG3HcqbO9jKlgRERl1FOQx4PoT\npnHW3FL+8/kPeHndAQ4xG1MGFy2Fz/7Ca2L/3+Phlf+E9rbIFFZERGKKgjwGmBk//MfDmTEhjxsf\neZsNO/Yc6AHg8PPhn96E6WfCy9+De06E6lWRKbCIiMQMBXmMyExL5p7LjyA1JYlrHlxOw75B1Khz\niuH8++FzD0PTdrj3JPjzbdDWx5SwIiIS1xTkMaS8IIv/uWQ+H9c185WlqwgGBznxy4wz4Z+WwdyL\n4PUfw8+Pg4//PryFFRGRmKAgjzFHTSviW2fN5MV127njhQ8Hf6DMAjjnZ3DpHyDQAr88DZ67BVoO\nsNleRERimoI8Bl121GQ+t2AiP335Ix76+xYC7UOY9OXgk+GLf4NPXQ3Lfg53Hw0f/VnTvIqIjBI2\n4LHLUbRgwQK3fPnyaBdjRLUE2rn8vjdZtmknkwqzuGbRVM5fMJGM1OTBH3TzX+GpL8HODVB0MMy9\nEA7/HORPGr6Ci4jIkJnZCufcggHtqyCPXe1BxwtrtvHzVzaw6pN6irLTuOKYKVx+9GTys9IGd9C2\nvfDu7+Cd38KW1711UxZ5oT7jbMjIG74TEBGRQVGQjzLOOd7ctJOfv7KBlz/YQVZaMp/71ESuXjSN\nsvzMwR941xZY/Si884hXS0/JhOlneJ3kpi2G5JThOgURETkACvJRbN3WBu55dSNPrarGAWfPLeW6\nE6YxfcIQatLOQeVyL9Df+z3sq4ec8TDnfC/UJ8wetvKLiEj/FOQJoKp+L798fROPvPkxza3tLD6s\nmOtPOIgjpxZiZoM/cKAF1v/Ju+/5h3+EYADGz/Ga3uecD7njh+8kRESkRwryBFLf3Mqv/76F+/+6\nmbqmVuZOzOeGE6bx6ZkTSE4aQqADNNXB+3/waupVK8CS4KCTvVA/7HRIyxqekxARkS4U5AloX1s7\nj62o5N7XNrKlrplpY7O55vhpnDuvbGg93UN2fAirl3qd5BoqIS0XZi3xmt4nHQNJGskoIjJcYirI\nzSwZWA5UOefONLPbgGuAHf4uX3fOPdvXMRTkA9cedPzxva38/JUNvFu1m7E56Vx57BQuPWoyYzJT\nh/4BwaDX2/2dpbDmSWjdA2MmweEXwORjYNwMyC3x5n8XEZFBibUgvwlYAOSFBfke59yPBnoMBfmB\nc87xxoY6fv7qRl79cAfZaclcfOQkrjpuGhPGZAzPh7Q2wbpnvFDf+DI4f+Ka9DFQfBiMmw7F/kMB\nLyIyYDET5GZWDjwAfB+4SUEeHe9X7+aeVzfy9OoakgzOmlvK+UdM5MiphSQN9Tp6SPNO2PY+7Fjn\nPbavgx1robmuc59QwBcf5gV7KOTzShXwIiJhYinIHwP+A8gFbg4L8iuB3XhN7l91zu3q6zgK8uHx\nyc5m7nt9E79b/glNre2Ujsng7Ioyzp1XxmETciPzoU21sH1tt4BfB821nfuk5/kB79fciw+D4hkK\neBFJWDER5GZ2JnC6c+6LZraYziAfD9QCDvguUOKc+0IP778WuBZg0qRJR2zZsiUi5UxEe1vbeWHt\nNp54u4pXPtxBe9AxoySPc+eVcvbcsuFreu9LU60f7KGQ/8Bb7h7w42dD+QIo/5T3yCuJfNlERKIs\nVoL8P4DLgACQAeQBf3DOXRq2zxTgaedcnzOOqEYeOXV7Wnh6dQ2Pv13Fqk/qMYNjDirinIoyTps9\ngdyMYeggdyBCAR+qvdesgpp3oL3V255X3jXYS+ZC6gj88BARGUExEeRdPqRrjbzEOVfjr/8KcKRz\n7sK+3q8gHxmbapt4clUVT7xdxea6ZtJTkjhl5njOrSjj+EOLSUuJ0hCzQAtsfRcq3+p81H/sbUtK\nhZLDO4O9fAHkT1aTvIjEtVgP8oeACrym9c3AdaFg742CfGQ551j1ST1PvF3F/62uYWdTKwVZqZx5\neCnnzCtj/qT8oc0eNxwat4UF+3KoXgltzd627OLOUC//FJTOh/Sc6JZXROQAxFyQD5WCPHra2oO8\ntn4Hj79dzZ/e30pLIMikwizOmVfGORWlTCuOkYBsD8D2NZ3BXvkm1H3kbbMkGDcrrEl+ARQdokls\nRCRmKcglIhr3tfH8+14nub9uqMU5mDsxn3MrSjlzbiljc9KjXcSumnd6U8t21NxXQMtub1tajnd9\nvaQCSiugdB4UHqRwF5GYoCCXiNvWsI+nVlXz+NtVrKlpIDnJmD8pn+MOLmbRoWM5vGwMKckxForB\nINSt90K9epXXkW7ruxDY521Py/Wut5fO6wx4hbuIRIGCXEbUh9saeWpVNa+u38G7VbtxDnIzUjj2\noLEcd8hYjj+kmElFMXqDlfaA10O+ZpUX7tVvw7b3uoX73M5ae0kFFE5TuItIRCnIJWp2NbXy1w21\nvL6+ltfW11JVvxeASYVZLDpkLIsOGcvRB40dnnnfI6W9zRvXXv12Z8BvfRfaW7zt6Xl+s/xcL9xL\n50HBVIW7iAwbBbnEBOccm2qbeM0P9Tc21NLU2k6SedfWFx08lkWHFlMxMZ/UWGuG7669zau5h2rt\nNatg63th4T4GCiZ7s9HlToBc/zn8dVahhsWJyIAoyCUmtbUHWfVJPa99uIPXPqrlnU/qCTrISU/h\nqGlFHTX2qWOzoz+8bSDa27zZ6EKT1tR/DI010FDTdYa6kOQ0P9RLvEdvoZ+WPfLnIiIxRUEucWF3\ncxtvbKzl1fW1vLZ+B5/s9Jrhy/IzWXSId339mIPGUpidFuWSDkKgFfZshcat0FDtBXwo5MOX25r2\nf2/6GD/YS7yQzws9ymBMmfecWaDavcgopiCXuLSlLtQMv4O/baijcV8AgEPH57BwaiFHTi3iyKmF\njMsbRVOy7mvwwr6xumvIh4K+odr7QRC6RWxISkZnuIcHfcdyOWQVxe51+2AQWhpgXz3srfee9+3u\nXA49J6X4/RDmw9hDY/d8RIaZglziXqA9yDuVu/n7xjqWbdrJis07aWptB2Dq2GwWTin0wn1aIeUF\nMdojfri0B6BpuxfqDVVdn3f7z43VEAx0fV9ymt+E3y3sc8d7AYl5k+WY+cthzz2uS9p/XfgxWvf0\nHcrhzy0N+/84CWfJkJnvTc/busdbl5brjR4oO8J/zPfORy0TMgopyGXUCbQHeb+6gTc37WTZpp28\ntXknu/e2AV5TvFdj98I9bq6xD6dgEJp2hAV9dc/Loc55IyE5DTLyvUDOGBO23N/zGG/CHrPOsf9V\nK/zHSm8EQdD77skZ3xnqpfO958yCkTtHkQhRkMuoFww6PtjW6Ad7HW9u2kntHu8OacW56V2C/dBx\nuSQlJViw98Q5aK6DPdsg2A44b50L+st0rsNf37Hsetg/fJ2DtKyuoZyaGZnacqDFGzEQCvfqlVD7\nYef2woO61tonzPHKIhJHFOSScJxzbKxtYtnGnby5yWuOr9ntTeqSn5XKp6Z4wX7k1CJmlOTG3qxz\nMjT7dnvDAkO19qqV3uUG8C4jjJ8VFu5HwNjDdL1dYpqCXBKec47KXXtZtmknyzbW8ebmnWyp8+6O\nlp2WzGETcplRksf0kjxmTMjlsAm5I3/vdYmshmo/1P1ae9XbnXPtp4/xbp4z8UiYdKQX7um50S2v\nSBgFuUgPtu7ex7JNdazcsou1WxtZW9PQ0TMeYGJhJtMn5DHDD/fpJXlMLsxSs/xoEQzCzg3e3fE+\nWQafvOndMQ/nddgbP8sL9olHwcSFkD9JHekkahTkIgPgnKN69z7W1TSwtqaBtVsbWVfTwKbaJoL+\nfxaZqaHau1+Dn5DHYRNyY3uKWRm4fbvDgn2ZtxzqJZ8zwautT/QfEw6HlDic00DikoJcZAj2tbXz\n4bZG1tU0snarH/I1jR295MHrKT+jJLejBj+9JJfJhVm69h7vgu1eLf3jv3s19k+WQf0Wb1tKhtcz\nfuLCznDPLopueWXUUpCLDDPnHNsaWvyae4MX8jUNbKxtot2vvqcmGxMLs5g2NpupY7OZOjaHqWOz\nmVaczbjc9MQbEjdaNG7tbIr/ZJk3335o+FvRwX6o+03xSamQnOo/p3hD8ELLHdv89aH91OlOeqAg\nFxkh+9ra+Wj7HtZtbWTjjj1sqm3qeLQEOic8yUpLZkpRNlOLs8OCPptpY3MYk6Vm+rjSts/rId8R\n7n/3hvUNliV1hnzHj4DwwPdDv2O5p/Wpvezb03I6ZI/1JwoqUSe/GKUgF4myYNBR07CPTTua2FS7\nh41hAV+5a29HLR6gMDutI9i9cM9mythsphRlk5mWHMWzkAFxDnZu9CbkaW/zauvtbWHLAf+51V8X\nGMB+3d7THr7c2vtyMGzf7jP99SY9r/MmPqFHx4yA/nNWkTr+jTAFuUgMaw0E+WRXsx/yTX7Ie7X5\nbQ1dZ14rGZPB5KIsphRlM7komylFWUwuymZyURbZ6SlROgOJC8Fgtx8Dfui37Qub8re6c4rfBn++\n/57m9u+Y7reXoA/d0S9Z/yaHy4EEuf7qIiMsLSWJg4pzOKg4Z79tTS2Bjpr7Zv95y85m/rx2W8fM\ndSFjc9I7gn1KURaTx/rPhdlqrhfv2ntSOqSk77+t+NDe39cxt3+NN7Vvo/8cuolP9dvQ8AwE9nV9\nX3I6jJsO42fDuJnecL7xsyGneHjPS/ajGrlInGjc18aWumbvsbOJLbXNbK5rYktdM1sbuv5PNT8r\ntUsNPvy5MDtNHe9kaJyDvbs6b9HbUAV1H8G2973Hnm2d+2YXd4Z6KOCLp0PqKLqLYQSoaV0kwext\nbefjnc1s8YN9c9hzdf1ewi7Jk52WzPi8DMbmpjMuN53i0CPHex6Xm0FxbjqF2WkkazIcGYym2s5Q\n3x56XttZi7dkKDrID/iwkNckPB0U5CLSoTUQpHJXc0ewf7yzme2NLexobKHWf25s2b9jVJJBUU54\nwIeFvh/84/K80M9OS1YtX/oWbPc6BYYCPhTyuzZ37pOe59fa/Zp70cH+LXcHagD/Bi0Jig+DrMID\nPYMRpSAXkQPS3BqgtrGVHXv2saOxpSPoOx57Wtje0ELtnhYCwf3/n5GZmkxhdhr5Wan+I438zFQK\nsrx1Y8KW88PWpWoCHWlp9Grr4QG/7f3OefEjwry74k09HqaeAJOPjrlheApyEYmIYNBRv7fND/t9\nHUG/vbGFXc2t1De3UR963ust95D7HXLTUxiT1S3kMzt/DORlpJCTnkJWegrZaclkpaWQnd75nJmq\nloBRyTnvuvvOTfj31+1//4Fqb/NuorPpVW8ugPZWr6m/bL4X7FMWeZP8pGUNuvjDQUEuIjEhGHQ0\ntgTY3dzmBf3esKD31+3e29b1R8DeNnbvbRvQ/5vNICs1udegz0rz13fbnpfhtQjkZXrPY7JSyU1P\n0Y+CRNO21wvzTa95wV61Aly7N9yufCFMXeSFe9mCEZ9nX0EuInEtGHQ07PMCvbm1nebWAE0t3Z5b\n22lu8Z/72d7UEujxkkC4JKMz2DO7BX0fj7xM70eA7pI3CrQ0evPsb3rFC/eadwAHKZkw6Si/Kf54\nKKmI+Jh5BbmISDetgSDNrQEa9wU6fiQ0+LX/8EfD3kDYcuf6vn4IhFoG0lOTSU9JIj0liYyO5WTS\nU5O6LfvbwpfD3+M/p6UkkZacREqSkZKcRGqykeo/pyQlkZqSRKq/LSXZOvZNTjK1LgyHvbtg819h\ns19j377GW5+WC1OO9Zrhpx7v9bof5jnzNSGMiEg3aSlJpKWkkZ914E2kzjmaW9v3C/3wsG9ubacl\n0E5LW5CWQNBbDgTZ19bOnpYAdXs617UEgrS0tbMvEKQ1EOy/AIOQ5od7SlIo/DvDfkxWKkXZaRRm\np1GUk96xXJidxtic9I7ljNQEnyI4swBmnOk9APbs6Az1Ta/Ch3/s3O+w0+Gc/4lKMSMe5GaWDCwH\nqpxzZ5pZIfBbYAqwGbjAObcr0uUQERksMyM7PYXs9BRK8zOH9djBoKO1PSz8u/0QCLQ72tqDtLWH\nLQcdAX9dW7u3HPCPE/Bft+633tvW0h5kd3Mblbv2srpyNzubWnttbchOS6bID/Yegz8njbHZ6RTm\npJGTnkJ6iveDYdTOP5BTDLM/6z0Adld1Bnty9GZTjHjTupndBCwA8vwg/yGw0zl3u5ndChQ4527p\n6xhqWhcRiQznHA37AtTtaWFnUyt1Ta3e856WjuWdTa3U7mllZ5O3T1t7//0NUpO9ywKpKZ2XBEKX\nClKTu67rvm9on7SUJO8HVFqy/0Mqmey0zpEMOene+lCnxpRRNJwxZprWzawcOAP4PnCTv3oJsNhf\nfgD4C9BnkIuISGSYWUfHvWkDmBbdOW8kQp0f7HV7vPBvagnQFtZ60BoI0hpqNQh461vDWhFC2/e0\nBHrcp9W/BNHc2j7gc8lITSI7LaWj9aT7D4DQckqS12qQZN75h5aTzPwHHf0Muuxn5k1h37GfkZzU\n+Tc8alrREL6JwYt00/qdwNeA8JH2451zNf7yVmB8T280s2uBawEmTZoUyTKKiMgAmRl5GankZaQy\ndWx2xD8vGHQ0t3kjEPa0BGhu9focNIWNSPAe7TS1Bjpe7/FHL9Q3t1K5q/N9za3tXW4jPFxmluTx\n7L8sGvbjDkTEgtzMzgS2O+dWmNninvZxzjkz6/Ev6py7B7gHvKb1SJVTRERiV1KSkZPuNaePG6Zj\nOucIOgg6R3vQ4Ry0O0fQOVywczkY7GM/52gPdm7LSI1es34ka+THAmeb2elABpBnZr8GtplZiXOu\nxsxKgO0RLIOIiEgXXjM5JGOMho75EfsJ4Zz7N+dcuXNuCnAh8JJz7lLgKeAKf7crgCcjVQYREZHR\nLhptAbcDnzaz9cAp/msREREZhBGZEMY59xe83uk45+qAk0fic0VEREa70TPoTkREJAEpyEVEROKY\nglxERCSOKchFRETimIJcREQkjinIRURE4piCXEREJI5F/Damw8HMdgBbhvGQY4HaYTxerBiN56Vz\nih+j8bxG4znB6Dyv0XZOk51zA7gfXZwE+XAzs+UDvc9rPBmN56Vzih+j8bxG4znB6Dyv0XhOA6Wm\ndRERkTimIBcREYljiRrk90S7ABEyGs9L5xQ/RuN5jcZzgtF5XqPxnAYkIa+Ri4iIjBaJWiMXEREZ\nFUZ1kJvZaWb2gZl9ZGa39rDdzOwuf/tqM5sfjXIOlJlNNLOXzWyNmb1vZv/Swz6LzWy3ma3yH9+K\nRlkPlJltNrN3/TIv72F7vH1Xh4V9B6vMrMHMvtxtn7j4rszsl2a23czeC1tXaGYvmNl6/7mgl/f2\n+d9gtPRyTv9pZuv8f1+Pm1l+L+/t899qNPVyXreZWVXYv7PTe3lvPH1Xvw07n81mtqqX98bsdzWs\nnHOj8gEkAxuAaUAa8A4ws9s+pwPPAQYcBSyLdrn7OacSYL6/nAt82MM5LQaejnZZB3Fum4GxfWyP\nq++qW9mTga1440Lj7rsCjgfmA++FrfshcKu/fCvwg17Ou8//BmPsnE4FUvzlH/R0Tv62Pv+txuB5\n3Qbc3M/74uq76rb9v4Bvxdt3NZyP0VwjXwh85Jzb6JxrBZYCS7rtswR40Hn+DuSbWclIF3SgnHM1\nzrmV/nIjsBYoi26pRkxcfVfdnAxscM4N56RGI8Y59yqws9vqJcAD/vIDwDk9vHUg/w1GRU/n5Jz7\nk3Mu4L/8O1A+4gUbol6+q4GIq+8qxMwMuAB4ZEQLFWNGc5CXAZ+Eva5k/9AbyD4xycymAPOAZT1s\nPsZvHnzOzGaNaMEGzwF/NrMVZnZtD9vj9rsCLqT3/9HE43cFMN45V+MvbwXG97BPPH9nX8BrAepJ\nf/9WY9GX/H9nv+zlMki8fleLgG3OufW9bI/H7+qAjeYgH7XMLAf4PfBl51xDt80rgUnOucOB/wae\nGOnyDdJxzrkK4DPAP5nZ8dEu0HAwszTgbOB3PWyO1++qC+e1YY6a4S9m9g0gADzcyy7x9m/1brwm\n8wqgBq8perS4iL5r4/H2XQ3KaA7yKmBi2Otyf92B7hNTzCwVL8Qfds79oft251yDc26Pv/wskGpm\nY0e4mAfMOVflP28HHsdr6gsXd9+V7zPASufctu4b4vW78m0LXdrwn7f3sE/cfWdm9nngTOAS/wfK\nfgbwbzWmOOe2OefanXNB4F56Lm88flcpwGeB3/a2T7x9V4M1moP8LeAQM5vq14ouBJ7qts9TwOV+\nj+ijgN1hzYUxx78edB+w1jl3Ry/7TPD3w8wW4n3HdSNXygNnZtlmlhtaxut09F633eLquwrTa40h\nHr+rME8BV/jLVwBP9rDPQP4bjBlmdhrwNeBs51xzL/sM5N9qTOnWl+Rcei5vXH1XvlOAdc65yp42\nxuN3NWjR7m0XyQdeT+cP8XpjfsNfdz1wvb9swM/87e8CC6Jd5n7O5zi8JszVwCr/cXq3c/pn4H28\nXqd/B46JdrkHcF7T/PK+45c97r8rv8zZeME8Jmxd3H1XeD9EaoA2vGunVwFFwIvAeuDPQKG/bynw\nbNh79/tvMBYevZzTR3jXiUP/bf28+zn19m81Vh69nNdD/n8zq/HCuSTevyt//a9C/y2F7Rs339Vw\nPjSzm4iISBwbzU3rIiIio56CXEREJI4pyEVEROKYglxERCSOKchFRETimIJcZBQxs/8wsxPN7Bwz\n+7coleEvZrYgGp8tkogU5CKjy5F4Y9JPAF6NcllEZAQoyEVGAf9e2quBTwFvAFcDd1sP9zg3s2Iz\n+72ZveU/jvXX32ZmD5nZG+bdZ/waf735x3/Pv7fz58KOdYu/7h0zuz3sY843szfN7EMzW+TvO8tf\nt8q/gcchEfyTiCSMlGgXQESGzjn3r2b2KHA5cBPwF+fcsb3s/hPgx865181sEvA8MMPfdjje/d6z\ngbfN7BngaLwbbswFxgJvmdmr/rolwJHOuWYzKwz7jBTn3EIzOx34Nt50mtcDP3HOPexPA5o8bH8A\nkQSmIBcZPebjTUc5He9e9b05BZjpT/MOkOffUQ/gSefcXmCvmb2Md5OJ44BHnHPteDdLeQWv5n8C\ncL/z5yV3zoXfMzp0Q58VwBR/+Q3gG2ZWDvzB9X7rSRE5AApykThnZhV4806XA7VAlrfaVgFH+8Ec\nLgk4yjm3r9txYP/bkQ52DucW/7kd//8zzrnfmNky4AzgWTO7zjn30iCPLyI+XSMXiXPOuVXOu+fy\nh92xJ0gAAADtSURBVMBM4CXgH5xzFT2EOMCfgC+FXvg/BEKWmFmGmRUBi/HuivUa8DkzSzazYuB4\n4E3gBeBKM8vyjxPetL4fM5sGbHTO3YV3t7TDB3XCItKFglxkFPADdpfz7jk93Tm3po/dbwQW+B3O\n1uBduw5ZDbyM1/P9u865arz7OK/Ga7Z/Cfiac26rc+6PeHfTWu7X/m/up5gXAO/5+84GHjzgExWR\n/ejuZyICeL3WgT3OuR9FuywiMnCqkYuIiMQx1chFRETimGrkIiIicUxBLiIiEscU5CIiInFMQS4i\nIhLHFOQiIiJxTEEuIiISx/5/Ah6v1bT52gYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13f5f8110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "ax.plot(history.history['squared_difference_loss'], label='Train Loss')\n",
    "ax.plot(history.history['val_squared_difference_loss'], label='Validation Loss')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "ax.set_ylabel('NELBO')\n",
    "ax.set_xlabel('# epochs')\n",
    "\n",
    "plt.title('VAE Loss vs. # of Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent Var Num = 5\n",
      "Hidden Var Num = 10\n",
      "Simulation #1: VAE with 5 Latent Variable(s) and 10 Hidden Variable(s)...\n",
      "\tEvaluating model on Fold 1\n",
      "Train on 29507 samples, validate on 12647 samples\n",
      "Epoch 1/2000\n",
      "29507/29507 [==============================] - 15s 504us/step - loss: 13826036.5687 - squared_difference_loss: 61.8729 - KL_divergence_loss: 13825975.5781 - neg_log_likelihood: 82644940162782442101756374548480.0000 - val_loss: 115010290.6445 - val_squared_difference_loss: 55.7680 - val_KL_divergence_loss: 115010239.1035 - val_neg_log_likelihood: inf\n",
      "Epoch 2/2000\n",
      "29507/29507 [==============================] - 1s 36us/step - loss: 87010.5522 - squared_difference_loss: 53.5744 - KL_divergence_loss: 86956.9948 - neg_log_likelihood: inf - val_loss: 87988745.2863 - val_squared_difference_loss: 79.5232 - val_KL_divergence_loss: 87988664.2004 - val_neg_log_likelihood: inf\n",
      "Epoch 3/2000\n",
      "29507/29507 [==============================] - 1s 22us/step - loss: 405438.1167 - squared_difference_loss: 46.9794 - KL_divergence_loss: 405391.2402 - neg_log_likelihood: 348156418841405019961850786217984.0000 - val_loss: 169995858.4946 - val_squared_difference_loss: 54.2441 - val_KL_divergence_loss: 169995818.2313 - val_neg_log_likelihood: inf\n",
      "Epoch 4/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 378811.6863 - squared_difference_loss: 42.7070 - KL_divergence_loss: 378769.1318 - neg_log_likelihood: 47611478788283191542908190720.0000 - val_loss: 299407713.7791 - val_squared_difference_loss: 12645.6085 - val_KL_divergence_loss: 299395062.5259 - val_neg_log_likelihood: inf\n",
      "Epoch 5/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 641011.5536 - squared_difference_loss: 38.4712 - KL_divergence_loss: 640973.2322 - neg_log_likelihood: 152113509289277239342558871552.0000 - val_loss: 435201146.7627 - val_squared_difference_loss: 485.2764 - val_KL_divergence_loss: 435200681.1641 - val_neg_log_likelihood: inf\n",
      "Epoch 6/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 212900.8493 - squared_difference_loss: 35.8487 - KL_divergence_loss: 212865.0965 - neg_log_likelihood: 21135172871869889073840652288.0000 - val_loss: 609532301.4483 - val_squared_difference_loss: 57.1871 - val_KL_divergence_loss: 609532240.3563 - val_neg_log_likelihood: inf\n",
      "Epoch 7/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 736755.1949 - squared_difference_loss: 33.0988 - KL_divergence_loss: 736722.1885 - neg_log_likelihood: 443505582722025748164509696.0000 - val_loss: 771149046.6541 - val_squared_difference_loss: 2211.9929 - val_KL_divergence_loss: 771146840.4120 - val_neg_log_likelihood: inf\n",
      "Epoch 8/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 1567701.2959 - squared_difference_loss: 31.4291 - KL_divergence_loss: 1567669.7164 - neg_log_likelihood: 35647022746936043170298150780928.0000 - val_loss: 557060574.7993 - val_squared_difference_loss: 8998.3828 - val_KL_divergence_loss: 557051567.3512 - val_neg_log_likelihood: inf\n",
      "Epoch 9/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 286298.8067 - squared_difference_loss: 29.7766 - KL_divergence_loss: 286269.1765 - neg_log_likelihood: 504084947640068756179665666703360.0000 - val_loss: 494319390.2364 - val_squared_difference_loss: 28.4418 - val_KL_divergence_loss: 494319370.2035 - val_neg_log_likelihood: inf\n",
      "Epoch 10/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 653371.3803 - squared_difference_loss: 28.1572 - KL_divergence_loss: 653343.3704 - neg_log_likelihood: 194647859591602720623139259154432.0000 - val_loss: 501065966.0393 - val_squared_difference_loss: 253.2003 - val_KL_divergence_loss: 501065703.1047 - val_neg_log_likelihood: inf\n",
      "Epoch 11/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18101.7913 - squared_difference_loss: 27.1510 - KL_divergence_loss: 18074.6127 - neg_log_likelihood: 28152577138167540175507795476480.0000 - val_loss: 446781134.7742 - val_squared_difference_loss: 3874.1465 - val_KL_divergence_loss: 446777268.6797 - val_neg_log_likelihood: inf\n",
      "Epoch 12/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 43150.7671 - squared_difference_loss: 26.2578 - KL_divergence_loss: 43124.6121 - neg_log_likelihood: 3694505024492400790195291553792.0000 - val_loss: 455130191.5990 - val_squared_difference_loss: 25698.8277 - val_KL_divergence_loss: 455104504.7903 - val_neg_log_likelihood: inf\n",
      "Epoch 13/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 167504.4845 - squared_difference_loss: 25.4552 - KL_divergence_loss: 167479.1352 - neg_log_likelihood: 3775321571784006730522283737088.0000 - val_loss: 436996169.4889 - val_squared_difference_loss: 1265.8858 - val_KL_divergence_loss: 436994934.9101 - val_neg_log_likelihood: inf\n",
      "Epoch 14/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 23349.4528 - squared_difference_loss: 24.8602 - KL_divergence_loss: 23324.5817 - neg_log_likelihood: 476258427572846453323022204928.0000 - val_loss: 423849212.7539 - val_squared_difference_loss: 150.4527 - val_KL_divergence_loss: 423849071.2646 - val_neg_log_likelihood: inf\n",
      "Epoch 15/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 77257.3539 - squared_difference_loss: 24.1422 - KL_divergence_loss: 77233.3309 - neg_log_likelihood: 1392748853958180766192186163200.0000 - val_loss: 410684600.7245 - val_squared_difference_loss: 1295.3002 - val_KL_divergence_loss: 410683285.2332 - val_neg_log_likelihood: inf\n",
      "Epoch 16/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 167732.8160 - squared_difference_loss: 23.8817 - KL_divergence_loss: 167708.9245 - neg_log_likelihood: 1481986043570603099894579200.0000 - val_loss: 378674243.0142 - val_squared_difference_loss: 34726.9457 - val_KL_divergence_loss: 378639528.2792 - val_neg_log_likelihood: inf\n",
      "Epoch 17/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 155231.2037 - squared_difference_loss: 23.3074 - KL_divergence_loss: 155208.0577 - neg_log_likelihood: 147196934705272892658401935360.0000 - val_loss: 344218953.9391 - val_squared_difference_loss: 3724.7236 - val_KL_divergence_loss: 344215209.4349 - val_neg_log_likelihood: inf\n",
      "Epoch 18/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 48265.2739 - squared_difference_loss: 23.1545 - KL_divergence_loss: 48242.1377 - neg_log_likelihood: 168135754415781454463794937856.0000 - val_loss: 337729425.1771 - val_squared_difference_loss: 10914.3451 - val_KL_divergence_loss: 337718515.0250 - val_neg_log_likelihood: inf\n",
      "Epoch 19/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 179112.9757 - squared_difference_loss: 22.8830 - KL_divergence_loss: 179090.1912 - neg_log_likelihood: 200644209973923049648422912.0000 - val_loss: 308364427.5617 - val_squared_difference_loss: 11837.5926 - val_KL_divergence_loss: 308352586.2831 - val_neg_log_likelihood: inf\n",
      "Epoch 20/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 92742.5024 - squared_difference_loss: 22.5695 - KL_divergence_loss: 92720.0879 - neg_log_likelihood: 66490856548871670017810235392.0000 - val_loss: 285436711.9144 - val_squared_difference_loss: 240.9256 - val_KL_divergence_loss: 285436469.2540 - val_neg_log_likelihood: inf\n",
      "Epoch 21/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 30815.7446 - squared_difference_loss: 22.3448 - KL_divergence_loss: 30793.4267 - neg_log_likelihood: 15628015738489912689596301312.0000 - val_loss: 271307422.1435 - val_squared_difference_loss: 756.2059 - val_KL_divergence_loss: 271306673.4708 - val_neg_log_likelihood: inf3\n",
      "Epoch 22/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 45610.7959 - squared_difference_loss: 22.1888 - KL_divergence_loss: 45588.6048 - neg_log_likelihood: 22016903167032307789949042688.0000 - val_loss: 258545389.2245 - val_squared_difference_loss: 1772.4237 - val_KL_divergence_loss: 258543628.4561 - val_neg_log_likelihood: inf\n",
      "Epoch 23/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 54312.5288 - squared_difference_loss: 22.0124 - KL_divergence_loss: 54290.6188 - neg_log_likelihood: 50907468447099377418240.0000 - val_loss: 242370946.7943 - val_squared_difference_loss: 6237.2799 - val_KL_divergence_loss: 242364712.5536 - val_neg_log_likelihood: inf\n",
      "Epoch 24/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 62894.9606 - squared_difference_loss: 21.8030 - KL_divergence_loss: 62873.1643 - neg_log_likelihood: 1696318617611737214484480.0000 - val_loss: 229395168.5501 - val_squared_difference_loss: 1458.2823 - val_KL_divergence_loss: 229393711.2842 - val_neg_log_likelihood: inf\n",
      "Epoch 25/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 157531.1368 - squared_difference_loss: 21.6132 - KL_divergence_loss: 157509.6536 - neg_log_likelihood: 8295946756621527416832.0000 - val_loss: 216437971.0394 - val_squared_difference_loss: 429.8049 - val_KL_divergence_loss: 216437546.2571 - val_neg_log_likelihood: inf\n",
      "Epoch 26/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 27215.8352 - squared_difference_loss: 21.4879 - KL_divergence_loss: 27194.4015 - neg_log_likelihood: 10220323649438623989760.0000 - val_loss: 199396667.7837 - val_squared_difference_loss: 19438.8938 - val_KL_divergence_loss: 199377215.5475 - val_neg_log_likelihood: inf\n",
      "Epoch 27/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 49644.8597 - squared_difference_loss: 21.3609 - KL_divergence_loss: 49623.5151 - neg_log_likelihood: 6116225547466331652096.0000 - val_loss: 188649297.4649 - val_squared_difference_loss: 4323.5190 - val_KL_divergence_loss: 188644966.0272 - val_neg_log_likelihood: inf\n",
      "Epoch 28/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 9792.2144 - squared_difference_loss: 21.2594 - KL_divergence_loss: 9770.9474 - neg_log_likelihood: 8067034691772273917952.0000 - val_loss: 188002925.1225 - val_squared_difference_loss: 31048.5500 - val_KL_divergence_loss: 187971874.3093 - val_neg_log_likelihood: inf\n",
      "Epoch 29/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 160355.8463 - squared_difference_loss: 21.1490 - KL_divergence_loss: 160334.8338 - neg_log_likelihood: 48291434749480665088000.0000 - val_loss: 163422658.0315 - val_squared_difference_loss: 1316.4223 - val_KL_divergence_loss: 163421342.6686 - val_neg_log_likelihood: inf\n",
      "Epoch 30/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 80549.1389 - squared_difference_loss: 21.0992 - KL_divergence_loss: 80528.0706 - neg_log_likelihood: 204898750629093258035200.0000 - val_loss: 149243774.5866 - val_squared_difference_loss: 15164.9682 - val_KL_divergence_loss: 149228613.7266 - val_neg_log_likelihood: inf\n",
      "Epoch 31/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 6384.1624 - squared_difference_loss: 21.0900 - KL_divergence_loss: 6363.0665 - neg_log_likelihood: 278299474272687030272.0000 - val_loss: 143744557.8976 - val_squared_difference_loss: 2390.6903 - val_KL_divergence_loss: 143742169.7069 - val_neg_log_likelihood: inf\n",
      "Epoch 32/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 28331.9997 - squared_difference_loss: 20.9948 - KL_divergence_loss: 28311.0550 - neg_log_likelihood: 109624306045896933376.0000 - val_loss: 143148458.4711 - val_squared_difference_loss: 548.9686 - val_KL_divergence_loss: 143147902.1576 - val_neg_log_likelihood: inf\n",
      "Epoch 33/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 16503.3380 - squared_difference_loss: 20.8933 - KL_divergence_loss: 16482.4490 - neg_log_likelihood: 921058336915938168799232.0000 - val_loss: 139707739.5250 - val_squared_difference_loss: 9927.1883 - val_KL_divergence_loss: 139697811.1839 - val_neg_log_likelihood: inf\n",
      "Epoch 34/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 76707.6484 - squared_difference_loss: 20.8441 - KL_divergence_loss: 76686.9441 - neg_log_likelihood: 41457360408712959376752640.0000 - val_loss: 128470749.3528 - val_squared_difference_loss: 5331.6447 - val_KL_divergence_loss: 128465426.0865 - val_neg_log_likelihood: inf\n",
      "Epoch 35/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 134967.7834 - squared_difference_loss: 20.8383 - KL_divergence_loss: 134946.9564 - neg_log_likelihood: 23370443554402718449664.0000 - val_loss: 121128392.1674 - val_squared_difference_loss: 270.2003 - val_KL_divergence_loss: 121128129.3654 - val_neg_log_likelihood: inf\n",
      "Epoch 36/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 53547.0375 - squared_difference_loss: 20.7630 - KL_divergence_loss: 53526.3761 - neg_log_likelihood: 793569248855521624064.0000 - val_loss: 106652565.3286 - val_squared_difference_loss: 53348.5789 - val_KL_divergence_loss: 106599228.1496 - val_neg_log_likelihood: inf\n",
      "Epoch 37/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 27309.3330 - squared_difference_loss: 20.7176 - KL_divergence_loss: 27288.6429 - neg_log_likelihood: 679016461156979441664.0000 - val_loss: 101037685.2173 - val_squared_difference_loss: 978.9874 - val_KL_divergence_loss: 101036713.9839 - val_neg_log_likelihood: inf\n",
      "Epoch 38/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 11782.6333 - squared_difference_loss: 20.6384 - KL_divergence_loss: 11762.0015 - neg_log_likelihood: 239646444635130494976.0000 - val_loss: 97131719.9867 - val_squared_difference_loss: 486.5741 - val_KL_divergence_loss: 97131234.5962 - val_neg_log_likelihood: inf\n",
      "Epoch 39/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15279.3104 - squared_difference_loss: 20.6698 - KL_divergence_loss: 15258.6435 - neg_log_likelihood: 1408853630971837415424.0000 - val_loss: 96422720.8455 - val_squared_difference_loss: 295.3634 - val_KL_divergence_loss: 96422427.7322 - val_neg_log_likelihood: inf\n",
      "Epoch 40/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 7690.1351 - squared_difference_loss: 20.6208 - KL_divergence_loss: 7669.5052 - neg_log_likelihood: 1324928392129024360448.0000 - val_loss: 94563412.1953 - val_squared_difference_loss: 1453.7119 - val_KL_divergence_loss: 94561965.3064 - val_neg_log_likelihood: inf\n",
      "Epoch 41/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 141872.1978 - squared_difference_loss: 20.5605 - KL_divergence_loss: 141851.6675 - neg_log_likelihood: 2949548187421539565568.0000 - val_loss: 77611676.1563 - val_squared_difference_loss: 76326.0763 - val_KL_divergence_loss: 77535354.2603 - val_neg_log_likelihood: inf\n",
      "Epoch 42/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 34623.2436 - squared_difference_loss: 20.5802 - KL_divergence_loss: 34602.6653 - neg_log_likelihood: 398675274562174582784.0000 - val_loss: 73045387.4079 - val_squared_difference_loss: 64.3226 - val_KL_divergence_loss: 73045327.0866 - val_neg_log_likelihood: inf\n",
      "Epoch 43/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 36929.2048 - squared_difference_loss: 20.5318 - KL_divergence_loss: 36908.6607 - neg_log_likelihood: 11653235821495290900527448064.0000 - val_loss: 68726580.2658 - val_squared_difference_loss: 1641.6641 - val_KL_divergence_loss: 68724935.9303 - val_neg_log_likelihood: inf\n",
      "Epoch 44/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 14198.7129 - squared_difference_loss: 20.4998 - KL_divergence_loss: 14178.2085 - neg_log_likelihood: 56773973269546819584.0000 - val_loss: 66704863.3209 - val_squared_difference_loss: 159.3560 - val_KL_divergence_loss: 66704706.8140 - val_neg_log_likelihood: inf\n",
      "Epoch 45/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 14258.6838 - squared_difference_loss: 20.4283 - KL_divergence_loss: 14238.2562 - neg_log_likelihood: 49497122926085865472.0000 - val_loss: 66233744.2959 - val_squared_difference_loss: 2425.7641 - val_KL_divergence_loss: 66231320.7195 - val_neg_log_likelihood: inf\n",
      "Epoch 46/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 14us/step - loss: 11719.4135 - squared_difference_loss: 20.4573 - KL_divergence_loss: 11698.9544 - neg_log_likelihood: 116546193209279332352.0000 - val_loss: 66193812.3463 - val_squared_difference_loss: 1391.2857 - val_KL_divergence_loss: 66192426.1545 - val_neg_log_likelihood: inf\n",
      "Epoch 47/2000\n",
      "29507/29507 [==============================] - 1s 19us/step - loss: 36770.9894 - squared_difference_loss: 20.4628 - KL_divergence_loss: 36750.5927 - neg_log_likelihood: 3235466584693178852442112.0000 - val_loss: 63023662.4153 - val_squared_difference_loss: 57.3591 - val_KL_divergence_loss: 63023607.1625 - val_neg_log_likelihood: inf\n",
      "Epoch 48/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 60839.8840 - squared_difference_loss: 20.3932 - KL_divergence_loss: 60819.5669 - neg_log_likelihood: 321612497542969622528.0000 - val_loss: 58283104.0549 - val_squared_difference_loss: 1096.7599 - val_KL_divergence_loss: 58282006.3353 - val_neg_log_likelihood: inf\n",
      "Epoch 49/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 21315.4756 - squared_difference_loss: 20.3693 - KL_divergence_loss: 21295.1144 - neg_log_likelihood: 13429584296135099794063360.0000 - val_loss: 55631360.9385 - val_squared_difference_loss: 10416.6592 - val_KL_divergence_loss: 55620946.8918 - val_neg_log_likelihood: inf\n",
      "Epoch 50/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 46963.8708 - squared_difference_loss: 20.4514 - KL_divergence_loss: 46943.4386 - neg_log_likelihood: 21118082600203832134729728.0000 - val_loss: 52094922.8702 - val_squared_difference_loss: 983.0874 - val_KL_divergence_loss: 52093941.5428 - val_neg_log_likelihood: inf\n",
      "Epoch 51/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 3350.9687 - squared_difference_loss: 20.2865 - KL_divergence_loss: 3330.6811 - neg_log_likelihood: 573125522573678568538112.0000 - val_loss: 51434550.3672 - val_squared_difference_loss: 12189.2463 - val_KL_divergence_loss: 51422360.1003 - val_neg_log_likelihood: inf\n",
      "Epoch 52/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 6384.4444 - squared_difference_loss: 20.2483 - KL_divergence_loss: 6364.1889 - neg_log_likelihood: 4617736302023068672.0000 - val_loss: 50309476.7119 - val_squared_difference_loss: 7075.4039 - val_KL_divergence_loss: 50302402.6243 - val_neg_log_likelihood: inf\n",
      "Epoch 53/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 4725.8842 - squared_difference_loss: 20.2278 - KL_divergence_loss: 4705.6520 - neg_log_likelihood: 223329960221039034368.0000 - val_loss: 49680920.8810 - val_squared_difference_loss: 3136.8656 - val_KL_divergence_loss: 49677783.8392 - val_neg_log_likelihood: inf\n",
      "Epoch 54/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 33515.5312 - squared_difference_loss: 20.2080 - KL_divergence_loss: 33495.3327 - neg_log_likelihood: 21661847671743512576.0000 - val_loss: 47730165.8142 - val_squared_difference_loss: 1758.6185 - val_KL_divergence_loss: 47728410.2577 - val_neg_log_likelihood: inf\n",
      "Epoch 55/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 8616.1622 - squared_difference_loss: 20.1167 - KL_divergence_loss: 8596.0360 - neg_log_likelihood: 4135683441166650880.0000 - val_loss: 47199120.0051 - val_squared_difference_loss: 25.6144 - val_KL_divergence_loss: 47199095.1796 - val_neg_log_likelihood: inf\n",
      "Epoch 56/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 30950.4648 - squared_difference_loss: 20.1563 - KL_divergence_loss: 30930.3252 - neg_log_likelihood: 93169167517319151616.0000 - val_loss: 45304072.5891 - val_squared_difference_loss: 1179.8552 - val_KL_divergence_loss: 45302888.9120 - val_neg_log_likelihood: inf\n",
      "Epoch 57/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17347.6725 - squared_difference_loss: 20.1738 - KL_divergence_loss: 17327.5072 - neg_log_likelihood: 33209326407381544960.0000 - val_loss: 42650536.1488 - val_squared_difference_loss: 79.2577 - val_KL_divergence_loss: 42650455.6813 - val_neg_log_likelihood: inf\n",
      "Epoch 58/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 30808.1076 - squared_difference_loss: 20.0774 - KL_divergence_loss: 30788.1001 - neg_log_likelihood: 79629978793434775552.0000 - val_loss: 39789625.0789 - val_squared_difference_loss: 412.4220 - val_KL_divergence_loss: 39789215.7340 - val_neg_log_likelihood: inf\n",
      "Epoch 59/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 54224.5709 - squared_difference_loss: 20.0617 - KL_divergence_loss: 54204.6022 - neg_log_likelihood: 6322884024821923971072.0000 - val_loss: 36882639.1584 - val_squared_difference_loss: 129.3975 - val_KL_divergence_loss: 36882510.7115 - val_neg_log_likelihood: inf\n",
      "Epoch 60/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 10183.6103 - squared_difference_loss: 20.0515 - KL_divergence_loss: 10163.5500 - neg_log_likelihood: 401043413856527646720.0000 - val_loss: 35199818.1958 - val_squared_difference_loss: 5863.4190 - val_KL_divergence_loss: 35193956.2204 - val_neg_log_likelihood: inf\n",
      "Epoch 61/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 34670.7169 - squared_difference_loss: 19.9519 - KL_divergence_loss: 34650.8320 - neg_log_likelihood: 1039642143918081.5000 - val_loss: 33054500.2779 - val_squared_difference_loss: 197.8453 - val_KL_divergence_loss: 33054303.5638 - val_neg_log_likelihood: inf\n",
      "Epoch 62/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 12930.9245 - squared_difference_loss: 20.0447 - KL_divergence_loss: 12910.8741 - neg_log_likelihood: 2591353150310334464.0000 - val_loss: 30675611.3854 - val_squared_difference_loss: 48.0199 - val_KL_divergence_loss: 30675566.5421 - val_neg_log_likelihood: inf\n",
      "Epoch 63/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 4680.7969 - squared_difference_loss: 19.9140 - KL_divergence_loss: 4660.8748 - neg_log_likelihood: 272834131865213376.0000 - val_loss: 30357980.3715 - val_squared_difference_loss: 679.5276 - val_KL_divergence_loss: 30357302.9678 - val_neg_log_likelihood: inf\n",
      "Epoch 64/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 6917.4049 - squared_difference_loss: 19.9370 - KL_divergence_loss: 6897.4612 - neg_log_likelihood: 8141239144068946944.0000 - val_loss: 30080362.9261 - val_squared_difference_loss: 7293.2030 - val_KL_divergence_loss: 30073068.9900 - val_neg_log_likelihood: inf\n",
      "Epoch 65/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 10141.1577 - squared_difference_loss: 19.8319 - KL_divergence_loss: 10121.3106 - neg_log_likelihood: 47096871444325595086848.0000 - val_loss: 29633644.8776 - val_squared_difference_loss: 481.9373 - val_KL_divergence_loss: 29633164.9993 - val_neg_log_likelihood: inf\n",
      "Epoch 66/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 5853.9423 - squared_difference_loss: 19.8298 - KL_divergence_loss: 5834.1019 - neg_log_likelihood: 1579721832437856768.0000 - val_loss: 28901764.1700 - val_squared_difference_loss: 837.3347 - val_KL_divergence_loss: 28900927.5870 - val_neg_log_likelihood: inf\n",
      "Epoch 67/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 6719.4323 - squared_difference_loss: 19.7825 - KL_divergence_loss: 6699.6378 - neg_log_likelihood: 23604385791305707520.0000 - val_loss: 29126397.4147 - val_squared_difference_loss: 31060.6384 - val_KL_divergence_loss: 29095339.5884 - val_neg_log_likelihood: inf\n",
      "Epoch 68/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 44666.5342 - squared_difference_loss: 19.7779 - KL_divergence_loss: 44646.8770 - neg_log_likelihood: 736978026100507279360.0000 - val_loss: 27829232.0260 - val_squared_difference_loss: 34.2761 - val_KL_divergence_loss: 27829200.0371 - val_neg_log_likelihood: inf\n",
      "Epoch 69/2000\n",
      "29507/29507 [==============================] - 1s 20us/step - loss: 4381.5213 - squared_difference_loss: 19.6983 - KL_divergence_loss: 4361.8182 - neg_log_likelihood: 1392366385683991166451712.0000 - val_loss: 26483830.2099 - val_squared_difference_loss: 427.9194 - val_KL_divergence_loss: 26483403.5963 - val_neg_log_likelihood: inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 14096.9865 - squared_difference_loss: 19.7483 - KL_divergence_loss: 14077.2432 - neg_log_likelihood: 4027770880735797087043584.0000 - val_loss: 26187407.9231 - val_squared_difference_loss: 60.1746 - val_KL_divergence_loss: 26187350.7579 - val_neg_log_likelihood: inf\n",
      "Epoch 71/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 22343.4394 - squared_difference_loss: 19.7234 - KL_divergence_loss: 22323.7573 - neg_log_likelihood: 32063937920620799945867264.0000 - val_loss: 24686307.2319 - val_squared_difference_loss: 4622.2974 - val_KL_divergence_loss: 24681687.8221 - val_neg_log_likelihood: inf\n",
      "Epoch 72/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 8274.7218 - squared_difference_loss: 19.6629 - KL_divergence_loss: 8255.0427 - neg_log_likelihood: 5460160113686973465493504.0000 - val_loss: 24127134.4761 - val_squared_difference_loss: 1507.2530 - val_KL_divergence_loss: 24125627.2773 - val_neg_log_likelihood: inf\n",
      "Epoch 73/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 4466.5616 - squared_difference_loss: 19.5657 - KL_divergence_loss: 4446.9917 - neg_log_likelihood: 2304527037063801864192.0000 - val_loss: 23641425.9687 - val_squared_difference_loss: 200.4337 - val_KL_divergence_loss: 23641226.9690 - val_neg_log_likelihood: inf\n",
      "Epoch 74/2000\n",
      "29507/29507 [==============================] - 1s 21us/step - loss: 8117.6024 - squared_difference_loss: 19.5336 - KL_divergence_loss: 8098.0571 - neg_log_likelihood: 52231815848318410752.0000 - val_loss: 23337816.6159 - val_squared_difference_loss: 1366.0924 - val_KL_divergence_loss: 23336451.1876 - val_neg_log_likelihood: inf\n",
      "Epoch 75/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 2685.8134 - squared_difference_loss: 19.6548 - KL_divergence_loss: 2666.1559 - neg_log_likelihood: 313260073054222891876352.0000 - val_loss: 21678258.4911 - val_squared_difference_loss: 124.6840 - val_KL_divergence_loss: 21678132.8926 - val_neg_log_likelihood: inf\n",
      "Epoch 76/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 7021.2970 - squared_difference_loss: 19.5381 - KL_divergence_loss: 7001.7530 - neg_log_likelihood: 29959097663811584000.0000 - val_loss: 21233122.6293 - val_squared_difference_loss: 9037.1099 - val_KL_divergence_loss: 21224083.0681 - val_neg_log_likelihood: inf\n",
      "Epoch 77/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 5269.0685 - squared_difference_loss: 19.5026 - KL_divergence_loss: 5249.5614 - neg_log_likelihood: 714504214130269618176.0000 - val_loss: 21338379.7492 - val_squared_difference_loss: 6138.4715 - val_KL_divergence_loss: 21332239.9460 - val_neg_log_likelihood: inf\n",
      "Epoch 78/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 35633.2638 - squared_difference_loss: 19.5522 - KL_divergence_loss: 35613.7747 - neg_log_likelihood: 164439725772763824128.0000 - val_loss: 19917293.3449 - val_squared_difference_loss: 14998.1456 - val_KL_divergence_loss: 19902293.8244 - val_neg_log_likelihood: inf\n",
      "Epoch 79/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 14538.8809 - squared_difference_loss: 19.3157 - KL_divergence_loss: 14519.5631 - neg_log_likelihood: 5154056698824943616.0000 - val_loss: 19595705.4109 - val_squared_difference_loss: 21.1146 - val_KL_divergence_loss: 19595683.7351 - val_neg_log_likelihood: inf\n",
      "Epoch 80/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 8404.4030 - squared_difference_loss: 19.3947 - KL_divergence_loss: 8385.0020 - neg_log_likelihood: 13955350922542225408.0000 - val_loss: 18542856.4792 - val_squared_difference_loss: 1343.7361 - val_KL_divergence_loss: 18541512.6922 - val_neg_log_likelihood: inf\n",
      "Epoch 81/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 3436.2843 - squared_difference_loss: 19.2790 - KL_divergence_loss: 3417.0032 - neg_log_likelihood: 586947675110517632.0000 - val_loss: 18642689.0171 - val_squared_difference_loss: 1354.9053 - val_KL_divergence_loss: 18641332.6663 - val_neg_log_likelihood: inf\n",
      "Epoch 82/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 3198.0412 - squared_difference_loss: 19.2808 - KL_divergence_loss: 3178.7572 - neg_log_likelihood: 11647889669145434112.0000 - val_loss: 18682132.4403 - val_squared_difference_loss: 4211.4434 - val_KL_divergence_loss: 18677919.5905 - val_neg_log_likelihood: inf\n",
      "Epoch 83/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 14948.0549 - squared_difference_loss: 19.3246 - KL_divergence_loss: 14928.7310 - neg_log_likelihood: 25730840551520538624.0000 - val_loss: 18225884.7682 - val_squared_difference_loss: 13001.9474 - val_KL_divergence_loss: 18212882.9987 - val_neg_log_likelihood: inf\n",
      "Epoch 84/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 10093.4653 - squared_difference_loss: 19.2722 - KL_divergence_loss: 10074.1900 - neg_log_likelihood: 306757494190214807552.0000 - val_loss: 17458230.9690 - val_squared_difference_loss: 5489.5118 - val_KL_divergence_loss: 17452740.4613 - val_neg_log_likelihood: inf\n",
      "Epoch 85/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 11642.9567 - squared_difference_loss: 19.1899 - KL_divergence_loss: 11623.7522 - neg_log_likelihood: 107734865906281952.0000 - val_loss: 17138672.3277 - val_squared_difference_loss: 2589.3083 - val_KL_divergence_loss: 17136081.4795 - val_neg_log_likelihood: inf\n",
      "Epoch 86/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 2502.0177 - squared_difference_loss: 19.1779 - KL_divergence_loss: 2482.8375 - neg_log_likelihood: 437057455847432064.0000 - val_loss: 17274378.1050 - val_squared_difference_loss: 669.8389 - val_KL_divergence_loss: 17273707.7772 - val_neg_log_likelihood: inf\n",
      "Epoch 87/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 1309.9171 - squared_difference_loss: 19.1719 - KL_divergence_loss: 1290.7455 - neg_log_likelihood: 51154071952637778984960.0000 - val_loss: 16645312.8306 - val_squared_difference_loss: 166.5730 - val_KL_divergence_loss: 16645146.1632 - val_neg_log_likelihood: inf\n",
      "Epoch 88/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 6868.8918 - squared_difference_loss: 19.1129 - KL_divergence_loss: 6849.7612 - neg_log_likelihood: 9207288792396100608.0000 - val_loss: 16659655.0791 - val_squared_difference_loss: 9873.9902 - val_KL_divergence_loss: 16649779.9453 - val_neg_log_likelihood: inf\n",
      "Epoch 89/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 4531.3354 - squared_difference_loss: 19.0099 - KL_divergence_loss: 4512.3233 - neg_log_likelihood: 11808073248580758.0000 - val_loss: 16227955.6410 - val_squared_difference_loss: 145.8422 - val_KL_divergence_loss: 16227808.0336 - val_neg_log_likelihood: inf\n",
      "Epoch 90/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 13331.6864 - squared_difference_loss: 19.1111 - KL_divergence_loss: 13312.5777 - neg_log_likelihood: 4113422597286876160.0000 - val_loss: 15352742.9343 - val_squared_difference_loss: 1821.2553 - val_KL_divergence_loss: 15350920.2753 - val_neg_log_likelihood: inf\n",
      "Epoch 91/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 2380.8065 - squared_difference_loss: 19.0427 - KL_divergence_loss: 2361.7601 - neg_log_likelihood: 32690132677926940672.0000 - val_loss: 14992406.1143 - val_squared_difference_loss: 431.2988 - val_KL_divergence_loss: 14991975.1864 - val_neg_log_likelihood: inf\n",
      "Epoch 92/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 8246.6030 - squared_difference_loss: 19.0685 - KL_divergence_loss: 8227.5261 - neg_log_likelihood: 83532251017377660928.0000 - val_loss: 14216641.4270 - val_squared_difference_loss: 161.8605 - val_KL_divergence_loss: 14216478.6117 - val_neg_log_likelihood: inf\n",
      "Epoch 93/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 4913.3843 - squared_difference_loss: 18.9316 - KL_divergence_loss: 4894.4456 - neg_log_likelihood: 46778473505624539136.0000 - val_loss: 14142832.3395 - val_squared_difference_loss: 49.8576 - val_KL_divergence_loss: 14142782.1634 - val_neg_log_likelihood: inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 1856.1964 - squared_difference_loss: 18.9501 - KL_divergence_loss: 1837.2466 - neg_log_likelihood: 6011703735256497152.0000 - val_loss: 14444683.6997 - val_squared_difference_loss: 1684.0680 - val_KL_divergence_loss: 14442999.1341 - val_neg_log_likelihood: inf\n",
      "Epoch 95/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 10716.1565 - squared_difference_loss: 18.9321 - KL_divergence_loss: 10697.2281 - neg_log_likelihood: 42994267860464784392585216.0000 - val_loss: 13837324.6953 - val_squared_difference_loss: 846.2167 - val_KL_divergence_loss: 13836476.3001 - val_neg_log_likelihood: inf\n",
      "Epoch 96/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 5384.6659 - squared_difference_loss: 18.9162 - KL_divergence_loss: 5365.7335 - neg_log_likelihood: 11754146378696747271585792.0000 - val_loss: 13450293.3448 - val_squared_difference_loss: 3141.0312 - val_KL_divergence_loss: 13447151.0029 - val_neg_log_likelihood: inf\n",
      "Epoch 97/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 4032.7272 - squared_difference_loss: 18.9447 - KL_divergence_loss: 4013.7801 - neg_log_likelihood: 7502325269720480768.0000 - val_loss: 13403495.9750 - val_squared_difference_loss: 5344.1069 - val_KL_divergence_loss: 13398149.8719 - val_neg_log_likelihood: inf\n",
      "Epoch 98/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 8142.6778 - squared_difference_loss: 18.8811 - KL_divergence_loss: 8123.7818 - neg_log_likelihood: 6996917829155573760.0000 - val_loss: 13044019.6845 - val_squared_difference_loss: 1933.3025 - val_KL_divergence_loss: 13042085.6798 - val_neg_log_likelihood: inf\n",
      "Epoch 99/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 8265.5023 - squared_difference_loss: 18.7793 - KL_divergence_loss: 8246.7131 - neg_log_likelihood: 329639467316418176.0000 - val_loss: 12944239.2089 - val_squared_difference_loss: 732.7203 - val_KL_divergence_loss: 12943504.6444 - val_neg_log_likelihood: inf\n",
      "Epoch 100/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 41892.6774 - squared_difference_loss: 18.7832 - KL_divergence_loss: 41873.9783 - neg_log_likelihood: 2518075270107652.5000 - val_loss: 11655330.6693 - val_squared_difference_loss: 547.4719 - val_KL_divergence_loss: 11654782.2019 - val_neg_log_likelihood: inf\n",
      "Epoch 101/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 6433.9462 - squared_difference_loss: 18.7443 - KL_divergence_loss: 6415.1885 - neg_log_likelihood: 9136992653383822.0000 - val_loss: 10839250.2438 - val_squared_difference_loss: 1345.3654 - val_KL_divergence_loss: 10837904.8018 - val_neg_log_likelihood: inf\n",
      "Epoch 102/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 5556.4524 - squared_difference_loss: 18.7969 - KL_divergence_loss: 5537.6510 - neg_log_likelihood: 160840467977606080.0000 - val_loss: 10774248.2074 - val_squared_difference_loss: 1181.2954 - val_KL_divergence_loss: 10773068.6608 - val_neg_log_likelihood: inf\n",
      "Epoch 103/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 3599.0482 - squared_difference_loss: 18.7659 - KL_divergence_loss: 3580.2803 - neg_log_likelihood: 25224020150866400.0000 - val_loss: 10415778.7903 - val_squared_difference_loss: 9290.5173 - val_KL_divergence_loss: 10406489.2262 - val_neg_log_likelihood: inf\n",
      "Epoch 104/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 5243.2760 - squared_difference_loss: 18.7069 - KL_divergence_loss: 5224.5484 - neg_log_likelihood: 105683865448648832.0000 - val_loss: 10371087.2801 - val_squared_difference_loss: 23263.4321 - val_KL_divergence_loss: 10347825.1428 - val_neg_log_likelihood: inf\n",
      "Epoch 105/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 11175.8181 - squared_difference_loss: 18.8384 - KL_divergence_loss: 11156.9801 - neg_log_likelihood: 8259433813174932480.0000 - val_loss: 9844902.4012 - val_squared_difference_loss: 23.7940 - val_KL_divergence_loss: 9844879.8158 - val_neg_log_likelihood: inf\n",
      "Epoch 106/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 6661.5187 - squared_difference_loss: 18.7603 - KL_divergence_loss: 6642.7592 - neg_log_likelihood: 52364865364239695872.0000 - val_loss: 9557667.1107 - val_squared_difference_loss: 449.6733 - val_KL_divergence_loss: 9557218.1167 - val_neg_log_likelihood: inf\n",
      "Epoch 107/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 2645.5740 - squared_difference_loss: 18.7792 - KL_divergence_loss: 2626.7904 - neg_log_likelihood: 2851385212478780928.0000 - val_loss: 9343617.0688 - val_squared_difference_loss: 75.4374 - val_KL_divergence_loss: 9343542.3044 - val_neg_log_likelihood: inf\n",
      "Epoch 108/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 3942.5721 - squared_difference_loss: 18.6802 - KL_divergence_loss: 3923.8853 - neg_log_likelihood: 15885789782744406.0000 - val_loss: 9279418.1898 - val_squared_difference_loss: 77.8026 - val_KL_divergence_loss: 9279341.0517 - val_neg_log_likelihood: inf\n",
      "Epoch 109/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 3449.0023 - squared_difference_loss: 18.7323 - KL_divergence_loss: 3430.2702 - neg_log_likelihood: 2162765846020883712.0000 - val_loss: 9150590.9592 - val_squared_difference_loss: 20059.2523 - val_KL_divergence_loss: 9130533.2043 - val_neg_log_likelihood: inf\n",
      "Epoch 110/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 2082.9610 - squared_difference_loss: 18.6369 - KL_divergence_loss: 2064.3202 - neg_log_likelihood: 201611788777204096.0000 - val_loss: 8907769.0603 - val_squared_difference_loss: 131.5273 - val_KL_divergence_loss: 8907637.6650 - val_neg_log_likelihood: inf\n",
      "Epoch 111/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 1662.0726 - squared_difference_loss: 18.6610 - KL_divergence_loss: 1643.4115 - neg_log_likelihood: 13082938704344702976.0000 - val_loss: 8735808.7816 - val_squared_difference_loss: 4522.4001 - val_KL_divergence_loss: 8731286.9047 - val_neg_log_likelihood: inf\n",
      "Epoch 112/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 3961.2606 - squared_difference_loss: 18.7104 - KL_divergence_loss: 3942.5435 - neg_log_likelihood: 2768621139315908096.0000 - val_loss: 8498380.8148 - val_squared_difference_loss: 5810.2400 - val_KL_divergence_loss: 8492572.1073 - val_neg_log_likelihood: inf\n",
      "Epoch 113/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17947.9206 - squared_difference_loss: 18.5870 - KL_divergence_loss: 17929.3302 - neg_log_likelihood: 452690507425808576.0000 - val_loss: 8224075.4028 - val_squared_difference_loss: 350.6457 - val_KL_divergence_loss: 8223725.8594 - val_neg_log_likelihood: inf\n",
      "Epoch 114/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 5100.0910 - squared_difference_loss: 18.5876 - KL_divergence_loss: 5081.5032 - neg_log_likelihood: 28672094306651414200320.0000 - val_loss: 7789810.2107 - val_squared_difference_loss: 7194.9181 - val_KL_divergence_loss: 7782615.8389 - val_neg_log_likelihood: inf\n",
      "Epoch 115/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 2547.5427 - squared_difference_loss: 18.4923 - KL_divergence_loss: 2529.0472 - neg_log_likelihood: 268976366798596512.0000 - val_loss: 7663249.4135 - val_squared_difference_loss: 1100.2742 - val_KL_divergence_loss: 7662149.7781 - val_neg_log_likelihood: inf\n",
      "Epoch 116/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 1152.6403 - squared_difference_loss: 18.5552 - KL_divergence_loss: 1134.0849 - neg_log_likelihood: 7444813056976731.0000 - val_loss: 7661337.4935 - val_squared_difference_loss: 240.6536 - val_KL_divergence_loss: 7661097.5701 - val_neg_log_likelihood: inf\n",
      "Epoch 117/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 8927.0242 - squared_difference_loss: 18.5598 - KL_divergence_loss: 8908.4638 - neg_log_likelihood: 339788580233313.9375 - val_loss: 7442067.5004 - val_squared_difference_loss: 1319.1193 - val_KL_divergence_loss: 7440749.1643 - val_neg_log_likelihood: inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 4953.0984 - squared_difference_loss: 18.5166 - KL_divergence_loss: 4934.5738 - neg_log_likelihood: 466688525777618624.0000 - val_loss: 7382618.6642 - val_squared_difference_loss: 1420.2237 - val_KL_divergence_loss: 7381199.0709 - val_neg_log_likelihood: inf\n",
      "Epoch 119/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 2264.1334 - squared_difference_loss: 18.5007 - KL_divergence_loss: 2245.6324 - neg_log_likelihood: 3817044204731514368.0000 - val_loss: 7427992.2683 - val_squared_difference_loss: 1081.2682 - val_KL_divergence_loss: 7426911.8066 - val_neg_log_likelihood: inf\n",
      "Epoch 120/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 5241.9035 - squared_difference_loss: 18.4136 - KL_divergence_loss: 5223.4877 - neg_log_likelihood: 131241912529360.3750 - val_loss: 7090438.7318 - val_squared_difference_loss: 68.7311 - val_KL_divergence_loss: 7090370.4020 - val_neg_log_likelihood: inf\n",
      "Epoch 121/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 1235.7607 - squared_difference_loss: 18.4402 - KL_divergence_loss: 1217.3204 - neg_log_likelihood: 319645443311351168.0000 - val_loss: 6930303.1484 - val_squared_difference_loss: 2315.1525 - val_KL_divergence_loss: 6927988.0108 - val_neg_log_likelihood: inf\n",
      "Epoch 122/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 6662.9572 - squared_difference_loss: 18.4959 - KL_divergence_loss: 6644.4572 - neg_log_likelihood: 297503639176825536.0000 - val_loss: 6760986.3557 - val_squared_difference_loss: 485.8706 - val_KL_divergence_loss: 6760500.6012 - val_neg_log_likelihood: inf\n",
      "Epoch 123/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 11640.2375 - squared_difference_loss: 18.4897 - KL_divergence_loss: 11621.7542 - neg_log_likelihood: 4499547002417894912.0000 - val_loss: 6346647.9926 - val_squared_difference_loss: 48.4218 - val_KL_divergence_loss: 6346599.9736 - val_neg_log_likelihood: inf\n",
      "Epoch 124/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 1875.1428 - squared_difference_loss: 18.3886 - KL_divergence_loss: 1856.7545 - neg_log_likelihood: 440334394875224.3750 - val_loss: 6073389.8030 - val_squared_difference_loss: 1455.3973 - val_KL_divergence_loss: 6071934.9347 - val_neg_log_likelihood: inf\n",
      "Epoch 125/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 4811.8120 - squared_difference_loss: 18.4194 - KL_divergence_loss: 4793.3870 - neg_log_likelihood: 10127935747901798400.0000 - val_loss: 5979799.7607 - val_squared_difference_loss: 49.5846 - val_KL_divergence_loss: 5979750.3733 - val_neg_log_likelihood: inf\n",
      "Epoch 126/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 3910.9456 - squared_difference_loss: 18.3956 - KL_divergence_loss: 3892.5486 - neg_log_likelihood: 107889607808957744.0000 - val_loss: 5810030.1408 - val_squared_difference_loss: 53.6974 - val_KL_divergence_loss: 5809977.0109 - val_neg_log_likelihood: inf\n",
      "Epoch 127/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 2969.7304 - squared_difference_loss: 18.3738 - KL_divergence_loss: 2951.3519 - neg_log_likelihood: 878244583890620288.0000 - val_loss: 5469778.7527 - val_squared_difference_loss: 163.5469 - val_KL_divergence_loss: 5469614.9039 - val_neg_log_likelihood: inf\n",
      "Epoch 128/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 6487.4053 - squared_difference_loss: 18.4776 - KL_divergence_loss: 6468.9128 - neg_log_likelihood: 2075635304712884480.0000 - val_loss: 5355208.8082 - val_squared_difference_loss: 82.0979 - val_KL_divergence_loss: 5355126.7338 - val_neg_log_likelihood: inf\n",
      "Epoch 129/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 1803.7178 - squared_difference_loss: 18.3952 - KL_divergence_loss: 1785.3227 - neg_log_likelihood: 122028255012979472.0000 - val_loss: 5361770.2099 - val_squared_difference_loss: 41.2220 - val_KL_divergence_loss: 5361728.6504 - val_neg_log_likelihood: inf\n",
      "Epoch 130/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 2783.3479 - squared_difference_loss: 18.3413 - KL_divergence_loss: 2765.0040 - neg_log_likelihood: 1646687606951103232.0000 - val_loss: 5366436.0753 - val_squared_difference_loss: 144.2404 - val_KL_divergence_loss: 5366291.4569 - val_neg_log_likelihood: inf\n",
      "Epoch 131/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 4700.4198 - squared_difference_loss: 18.2934 - KL_divergence_loss: 4682.1228 - neg_log_likelihood: 7880059414611348.0000 - val_loss: 5278391.8410 - val_squared_difference_loss: 199.9329 - val_KL_divergence_loss: 5278191.8746 - val_neg_log_likelihood: inf\n",
      "Epoch 132/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 1594.1193 - squared_difference_loss: 18.3298 - KL_divergence_loss: 1575.7897 - neg_log_likelihood: 580671545850745728.0000 - val_loss: 5068979.3476 - val_squared_difference_loss: 687.2864 - val_KL_divergence_loss: 5068291.7084 - val_neg_log_likelihood: inf\n",
      "Epoch 133/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 5472.3347 - squared_difference_loss: 18.3323 - KL_divergence_loss: 5453.9968 - neg_log_likelihood: 50415480259667536.0000 - val_loss: 5006756.3347 - val_squared_difference_loss: 21.8031 - val_KL_divergence_loss: 5006734.0889 - val_neg_log_likelihood: inf\n",
      "Epoch 134/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 7351.3463 - squared_difference_loss: 18.2929 - KL_divergence_loss: 7333.0361 - neg_log_likelihood: 311118345195288768.0000 - val_loss: 4858229.9892 - val_squared_difference_loss: 31.2012 - val_KL_divergence_loss: 4858198.6625 - val_neg_log_likelihood: inf\n",
      "Epoch 135/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 1012.6388 - squared_difference_loss: 18.2776 - KL_divergence_loss: 994.3611 - neg_log_likelihood: 73784423598206528.0000 - val_loss: 4759110.5526 - val_squared_difference_loss: 769.0170 - val_KL_divergence_loss: 4758341.4195 - val_neg_log_likelihood: inf\n",
      "Epoch 136/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 2875.1089 - squared_difference_loss: 18.2680 - KL_divergence_loss: 2856.8395 - neg_log_likelihood: 212024983987703480320.0000 - val_loss: 4645499.9909 - val_squared_difference_loss: 41.7423 - val_KL_divergence_loss: 4645458.0657 - val_neg_log_likelihood: inf\n",
      "Epoch 137/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 2113.2501 - squared_difference_loss: 18.2486 - KL_divergence_loss: 2095.0009 - neg_log_likelihood: 4801543776381288.0000 - val_loss: 4574904.1152 - val_squared_difference_loss: 401.2184 - val_KL_divergence_loss: 4574502.6539 - val_neg_log_likelihood: inf\n",
      "Epoch 138/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 2589.0187 - squared_difference_loss: 18.2507 - KL_divergence_loss: 2570.7638 - neg_log_likelihood: 31968727945855625068544.0000 - val_loss: 4479763.0643 - val_squared_difference_loss: 645.2494 - val_KL_divergence_loss: 4479117.4356 - val_neg_log_likelihood: inf\n",
      "Epoch 139/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 5709.1876 - squared_difference_loss: 18.2416 - KL_divergence_loss: 5690.9369 - neg_log_likelihood: 81990481695140.3594 - val_loss: 4379379.5744 - val_squared_difference_loss: 569.5364 - val_KL_divergence_loss: 4378809.9235 - val_neg_log_likelihood: inf\n",
      "Epoch 140/2000\n",
      "29507/29507 [==============================] - 1s 19us/step - loss: 2212.6737 - squared_difference_loss: 18.2045 - KL_divergence_loss: 2194.4683 - neg_log_likelihood: 8685401992642714.0000 - val_loss: 4311537.4165 - val_squared_difference_loss: 20.6026 - val_KL_divergence_loss: 4311516.9012 - val_neg_log_likelihood: inf\n",
      "Epoch 141/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 3290.1080 - squared_difference_loss: 18.2287 - KL_divergence_loss: 3271.8695 - neg_log_likelihood: 255096677725579.1875 - val_loss: 4225299.8618 - val_squared_difference_loss: 188.4766 - val_KL_divergence_loss: 4225111.4247 - val_neg_log_likelihood: inf\n",
      "Epoch 142/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 1045.7914 - squared_difference_loss: 18.2269 - KL_divergence_loss: 1027.5645 - neg_log_likelihood: 10958998223894.3066 - val_loss: 4135478.2974 - val_squared_difference_loss: 138.5500 - val_KL_divergence_loss: 4135339.6119 - val_neg_log_likelihood: inf\n",
      "Epoch 143/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 499.0350 - squared_difference_loss: 18.1542 - KL_divergence_loss: 480.8805 - neg_log_likelihood: 3716542523923725.5000 - val_loss: 4054463.2446 - val_squared_difference_loss: 19.2976 - val_KL_divergence_loss: 4054443.7911 - val_neg_log_likelihood: inf\n",
      "Epoch 144/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 944.7443 - squared_difference_loss: 18.1845 - KL_divergence_loss: 926.5599 - neg_log_likelihood: 458250117041354.5625 - val_loss: 4013377.4244 - val_squared_difference_loss: 1832.2500 - val_KL_divergence_loss: 4011544.7354 - val_neg_log_likelihood: inf\n",
      "Epoch 145/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 2960.3888 - squared_difference_loss: 18.2188 - KL_divergence_loss: 2942.1645 - neg_log_likelihood: 92888233323064272.0000 - val_loss: 3817028.2611 - val_squared_difference_loss: 21.8244 - val_KL_divergence_loss: 3817006.4877 - val_neg_log_likelihood: inf\n",
      "Epoch 146/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 1118.2390 - squared_difference_loss: 18.1279 - KL_divergence_loss: 1100.1111 - neg_log_likelihood: 103872384073621.5312 - val_loss: 3709665.4572 - val_squared_difference_loss: 3482.4674 - val_KL_divergence_loss: 3706183.1185 - val_neg_log_likelihood: inf\n",
      "Epoch 147/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 222.7860 - squared_difference_loss: 18.1471 - KL_divergence_loss: 204.6388 - neg_log_likelihood: 7547743795762.5488 - val_loss: 3798620.5010 - val_squared_difference_loss: 6734.6738 - val_KL_divergence_loss: 3791885.6233 - val_neg_log_likelihood: inf\n",
      "Epoch 148/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 1599.2803 - squared_difference_loss: 18.1290 - KL_divergence_loss: 1581.1507 - neg_log_likelihood: 30787372935352744.0000 - val_loss: 3792203.6174 - val_squared_difference_loss: 1900.8232 - val_KL_divergence_loss: 3790302.4791 - val_neg_log_likelihood: inf\n",
      "Epoch 149/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 4011.7089 - squared_difference_loss: 18.1340 - KL_divergence_loss: 3993.5740 - neg_log_likelihood: 808870231520131.6250 - val_loss: 3811848.2063 - val_squared_difference_loss: 944.0160 - val_KL_divergence_loss: 3810903.8501 - val_neg_log_likelihood: inf\n",
      "Epoch 150/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 2880.2861 - squared_difference_loss: 18.1180 - KL_divergence_loss: 2862.1648 - neg_log_likelihood: 14936676429733325204094976.0000 - val_loss: 3695028.5394 - val_squared_difference_loss: 4729.7048 - val_KL_divergence_loss: 3690298.7873 - val_neg_log_likelihood: inf\n",
      "Epoch 151/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 8331.7059 - squared_difference_loss: 18.2092 - KL_divergence_loss: 8313.4980 - neg_log_likelihood: 189436258158809382912.0000 - val_loss: 3528053.3969 - val_squared_difference_loss: 30.9263 - val_KL_divergence_loss: 3528022.2505 - val_neg_log_likelihood: inf\n",
      "Epoch 152/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 1263.6409 - squared_difference_loss: 18.1265 - KL_divergence_loss: 1245.5143 - neg_log_likelihood: 45138404745444728.0000 - val_loss: 3447454.5532 - val_squared_difference_loss: 1577.2273 - val_KL_divergence_loss: 3445877.5118 - val_neg_log_likelihood: inf\n",
      "Epoch 153/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 1489.8098 - squared_difference_loss: 18.1155 - KL_divergence_loss: 1471.6946 - neg_log_likelihood: 57033929512883536.0000 - val_loss: 3392764.0389 - val_squared_difference_loss: 1000.7568 - val_KL_divergence_loss: 3391763.3914 - val_neg_log_likelihood: inf\n",
      "Epoch 154/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 2253.9973 - squared_difference_loss: 18.1331 - KL_divergence_loss: 2235.8585 - neg_log_likelihood: 257453163604031360.0000 - val_loss: 3407186.9507 - val_squared_difference_loss: 3051.4849 - val_KL_divergence_loss: 3404135.2393 - val_neg_log_likelihood: inf\n",
      "Epoch 155/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 2032.1909 - squared_difference_loss: 18.1560 - KL_divergence_loss: 2014.0337 - neg_log_likelihood: 671375234587914076684288.0000 - val_loss: 3371137.3152 - val_squared_difference_loss: 377.5961 - val_KL_divergence_loss: 3370759.4359 - val_neg_log_likelihood: inf\n",
      "Epoch 156/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 391.4399 - squared_difference_loss: 18.1229 - KL_divergence_loss: 373.3171 - neg_log_likelihood: 3515773656848181248.0000 - val_loss: 3360128.6881 - val_squared_difference_loss: 863.8830 - val_KL_divergence_loss: 3359264.4156 - val_neg_log_likelihood: inf\n",
      "Epoch 157/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 676.1719 - squared_difference_loss: 18.0643 - KL_divergence_loss: 658.1077 - neg_log_likelihood: 16302604793317707776.0000 - val_loss: 3352900.0867 - val_squared_difference_loss: 381.7044 - val_KL_divergence_loss: 3352518.1713 - val_neg_log_likelihood: inf\n",
      "Epoch 158/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 2423.1518 - squared_difference_loss: 18.0474 - KL_divergence_loss: 2405.1030 - neg_log_likelihood: 280009811427697792.0000 - val_loss: 3223043.1800 - val_squared_difference_loss: 3569.2645 - val_KL_divergence_loss: 3219473.7798 - val_neg_log_likelihood: inf\n",
      "Epoch 159/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 2056.6664 - squared_difference_loss: 18.0789 - KL_divergence_loss: 2038.5865 - neg_log_likelihood: 2694431777351563.5000 - val_loss: 3140960.8410 - val_squared_difference_loss: 43.8571 - val_KL_divergence_loss: 3140916.8058 - val_neg_log_likelihood: inf\n",
      "Epoch 160/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 5318.0658 - squared_difference_loss: 18.0709 - KL_divergence_loss: 5299.9790 - neg_log_likelihood: 15216875372140332.0000 - val_loss: 2986072.7750 - val_squared_difference_loss: 782.5821 - val_KL_divergence_loss: 2985289.8215 - val_neg_log_likelihood: inf\n",
      "Epoch 161/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 2853.7267 - squared_difference_loss: 18.0713 - KL_divergence_loss: 2835.6538 - neg_log_likelihood: 6577201603805101.0000 - val_loss: 2929101.3043 - val_squared_difference_loss: 41.9698 - val_KL_divergence_loss: 2929059.4973 - val_neg_log_likelihood: inf\n",
      "Epoch 162/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 979.7015 - squared_difference_loss: 18.1007 - KL_divergence_loss: 961.6007 - neg_log_likelihood: 612581739655358.6250 - val_loss: 2771419.0860 - val_squared_difference_loss: 71.5782 - val_KL_divergence_loss: 2771347.4622 - val_neg_log_likelihood: inf\n",
      "Epoch 163/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 1577.8746 - squared_difference_loss: 18.0327 - KL_divergence_loss: 1559.8412 - neg_log_likelihood: 3916696284427226.5000 - val_loss: 2789333.7351 - val_squared_difference_loss: 30.0444 - val_KL_divergence_loss: 2789303.3511 - val_neg_log_likelihood: inf\n",
      "Epoch 164/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 1739.4309 - squared_difference_loss: 18.0500 - KL_divergence_loss: 1721.3766 - neg_log_likelihood: 816646201952715264.0000 - val_loss: 2808334.6184 - val_squared_difference_loss: 969.6549 - val_KL_divergence_loss: 2807364.9649 - val_neg_log_likelihood: inf\n",
      "Epoch 165/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 1509.6166 - squared_difference_loss: 18.0475 - KL_divergence_loss: 1491.5658 - neg_log_likelihood: 800172765361833.5000 - val_loss: 2678440.8972 - val_squared_difference_loss: 607.0084 - val_KL_divergence_loss: 2677834.2714 - val_neg_log_likelihood: inf\n",
      "Epoch 166/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 13us/step - loss: 953.0210 - squared_difference_loss: 18.0855 - KL_divergence_loss: 934.9358 - neg_log_likelihood: 7138528745903629.0000 - val_loss: 2604043.8088 - val_squared_difference_loss: 3248.7143 - val_KL_divergence_loss: 2600795.2506 - val_neg_log_likelihood: inf\n",
      "Epoch 167/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 660.5420 - squared_difference_loss: 18.0253 - KL_divergence_loss: 642.5167 - neg_log_likelihood: 36485555179818.2891 - val_loss: 2486090.0658 - val_squared_difference_loss: 804.7836 - val_KL_divergence_loss: 2485285.3167 - val_neg_log_likelihood: inf\n",
      "Epoch 168/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 4686.3030 - squared_difference_loss: 17.9970 - KL_divergence_loss: 4668.3020 - neg_log_likelihood: 131007571162327.7812 - val_loss: 2383132.0418 - val_squared_difference_loss: 558.1163 - val_KL_divergence_loss: 2382574.0881 - val_neg_log_likelihood: inf\n",
      "Epoch 169/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 1124.2158 - squared_difference_loss: 18.0025 - KL_divergence_loss: 1106.2138 - neg_log_likelihood: 25497931464998076.0000 - val_loss: 2401344.0885 - val_squared_difference_loss: 386.3065 - val_KL_divergence_loss: 2400958.0941 - val_neg_log_likelihood: inf\n",
      "Epoch 170/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 1117.8056 - squared_difference_loss: 17.9684 - KL_divergence_loss: 1099.8372 - neg_log_likelihood: 4834104524475.4014 - val_loss: 2410980.1218 - val_squared_difference_loss: 55.1909 - val_KL_divergence_loss: 2410925.2654 - val_neg_log_likelihood: inf\n",
      "Epoch 171/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 1095.9538 - squared_difference_loss: 17.9879 - KL_divergence_loss: 1077.9661 - neg_log_likelihood: 146822821381711.4688 - val_loss: 2431100.4501 - val_squared_difference_loss: 38.5082 - val_KL_divergence_loss: 2431062.0475 - val_neg_log_likelihood: inf\n",
      "Epoch 172/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 2390.0359 - squared_difference_loss: 18.0037 - KL_divergence_loss: 2372.0307 - neg_log_likelihood: 11209361024751.5176 - val_loss: 2363713.0120 - val_squared_difference_loss: 85.2636 - val_KL_divergence_loss: 2363627.9858 - val_neg_log_likelihood: inf\n",
      "Epoch 173/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 6865.7632 - squared_difference_loss: 18.0092 - KL_divergence_loss: 6847.7465 - neg_log_likelihood: 29632561805531790799011840.0000 - val_loss: 2261298.8269 - val_squared_difference_loss: 26.1591 - val_KL_divergence_loss: 2261273.0239 - val_neg_log_likelihood: inf\n",
      "Epoch 174/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 2171.3728 - squared_difference_loss: 17.9838 - KL_divergence_loss: 2153.3875 - neg_log_likelihood: 315642992396509.1250 - val_loss: 2120564.5052 - val_squared_difference_loss: 47.0743 - val_KL_divergence_loss: 2120517.7990 - val_neg_log_likelihood: inf\n",
      "Epoch 175/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 2877.8250 - squared_difference_loss: 18.0407 - KL_divergence_loss: 2859.7845 - neg_log_likelihood: 25100799465531822080.0000 - val_loss: 2055397.6913 - val_squared_difference_loss: 107.2859 - val_KL_divergence_loss: 2055290.8106 - val_neg_log_likelihood: inf\n",
      "Epoch 176/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 2320.1924 - squared_difference_loss: 17.9450 - KL_divergence_loss: 2302.2469 - neg_log_likelihood: 15512077846225.3262 - val_loss: 2015962.5839 - val_squared_difference_loss: 288.8058 - val_KL_divergence_loss: 2015674.0550 - val_neg_log_likelihood: inf\n",
      "Epoch 177/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 998.0704 - squared_difference_loss: 17.9632 - KL_divergence_loss: 980.1070 - neg_log_likelihood: 23716688776906.1953 - val_loss: 1957321.5265 - val_squared_difference_loss: 293.6762 - val_KL_divergence_loss: 1957028.1706 - val_neg_log_likelihood: inf\n",
      "Epoch 178/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 1355.0351 - squared_difference_loss: 17.9555 - KL_divergence_loss: 1337.0802 - neg_log_likelihood: 22664467280356.3008 - val_loss: 1895387.7084 - val_squared_difference_loss: 19.0101 - val_KL_divergence_loss: 1895369.0485 - val_neg_log_likelihood: 55730161706707118366503469056.0000\n",
      "Epoch 179/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 5091.8347 - squared_difference_loss: 17.9523 - KL_divergence_loss: 5073.8778 - neg_log_likelihood: 6604281787840952532992.0000 - val_loss: 1809616.0692 - val_squared_difference_loss: 494.2347 - val_KL_divergence_loss: 1809122.2151 - val_neg_log_likelihood: inf\n",
      "Epoch 180/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 3119.9295 - squared_difference_loss: 17.9972 - KL_divergence_loss: 3101.9291 - neg_log_likelihood: 483723031466862656.0000 - val_loss: 1735112.1498 - val_squared_difference_loss: 3995.6685 - val_KL_divergence_loss: 1731116.6941 - val_neg_log_likelihood: inf\n",
      "Epoch 181/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 2009.5657 - squared_difference_loss: 17.9818 - KL_divergence_loss: 1991.5826 - neg_log_likelihood: 20277903601467708.0000 - val_loss: 1682023.1436 - val_squared_difference_loss: 388.1661 - val_KL_divergence_loss: 1681635.2603 - val_neg_log_likelihood: inf\n",
      "Epoch 182/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 1444.6192 - squared_difference_loss: 18.0416 - KL_divergence_loss: 1426.5740 - neg_log_likelihood: 8564868994763817984.0000 - val_loss: 1672446.7664 - val_squared_difference_loss: 74.2487 - val_KL_divergence_loss: 1672372.7076 - val_neg_log_likelihood: inf\n",
      "Epoch 183/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 1834.5822 - squared_difference_loss: 17.8986 - KL_divergence_loss: 1816.6820 - neg_log_likelihood: 95894547172588.3125 - val_loss: 1632612.1272 - val_squared_difference_loss: 224.4823 - val_KL_divergence_loss: 1632387.9175 - val_neg_log_likelihood: inf\n",
      "Epoch 184/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 1321.6216 - squared_difference_loss: 17.9458 - KL_divergence_loss: 1303.6762 - neg_log_likelihood: 3426439403610479.5000 - val_loss: 1574299.8001 - val_squared_difference_loss: 1400.5232 - val_KL_divergence_loss: 1572899.5841 - val_neg_log_likelihood: inf\n",
      "Epoch 185/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 1249.3833 - squared_difference_loss: 17.8903 - KL_divergence_loss: 1231.4931 - neg_log_likelihood: 817992744397.8965 - val_loss: 1547598.9014 - val_squared_difference_loss: 28.9399 - val_KL_divergence_loss: 1547570.1800 - val_neg_log_likelihood: inf\n",
      "Epoch 186/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 1873.7885 - squared_difference_loss: 17.8858 - KL_divergence_loss: 1855.9022 - neg_log_likelihood: 17750200314326488.0000 - val_loss: 1535251.4226 - val_squared_difference_loss: 702.0860 - val_KL_divergence_loss: 1534549.7094 - val_neg_log_likelihood: inf\n",
      "Epoch 187/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 2142.9893 - squared_difference_loss: 17.8574 - KL_divergence_loss: 2125.1281 - neg_log_likelihood: 38279759452250.8984 - val_loss: 1469799.3857 - val_squared_difference_loss: 135.7358 - val_KL_divergence_loss: 1469663.9958 - val_neg_log_likelihood: inf\n",
      "Epoch 188/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 711.3278 - squared_difference_loss: 17.9053 - KL_divergence_loss: 693.4228 - neg_log_likelihood: 543008637742.5016 - val_loss: 1468158.0149 - val_squared_difference_loss: 469.0892 - val_KL_divergence_loss: 1467689.1979 - val_neg_log_likelihood: inf\n",
      "Epoch 189/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 2662.6650 - squared_difference_loss: 17.8718 - KL_divergence_loss: 2644.7902 - neg_log_likelihood: 4614446636616.6211 - val_loss: 1421081.4822 - val_squared_difference_loss: 246.1636 - val_KL_divergence_loss: 1420835.6516 - val_neg_log_likelihood: inf\n",
      "Epoch 190/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 1530.0010 - squared_difference_loss: 17.8907 - KL_divergence_loss: 1512.1060 - neg_log_likelihood: 130667887253697424.0000 - val_loss: 1385277.1995 - val_squared_difference_loss: 180.9131 - val_KL_divergence_loss: 1385096.6161 - val_neg_log_likelihood: inf\n",
      "Epoch 191/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 698.6847 - squared_difference_loss: 17.8832 - KL_divergence_loss: 680.8015 - neg_log_likelihood: 65146208758594216.0000 - val_loss: 1339641.7981 - val_squared_difference_loss: 419.0000 - val_KL_divergence_loss: 1339222.9227 - val_neg_log_likelihood: inf\n",
      "Epoch 192/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 214.0655 - squared_difference_loss: 17.8228 - KL_divergence_loss: 196.2428 - neg_log_likelihood: 97437857322.7255 - val_loss: 1328162.7956 - val_squared_difference_loss: 25.2499 - val_KL_divergence_loss: 1328137.5155 - val_neg_log_likelihood: inf\n",
      "Epoch 193/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 496.0411 - squared_difference_loss: 17.8661 - KL_divergence_loss: 478.1751 - neg_log_likelihood: 121680290534350.5469 - val_loss: 1335819.3089 - val_squared_difference_loss: 16503.1514 - val_KL_divergence_loss: 1319316.2797 - val_neg_log_likelihood: inf\n",
      "Epoch 194/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 622.9352 - squared_difference_loss: 17.8627 - KL_divergence_loss: 605.0725 - neg_log_likelihood: 6999908335550385152.0000 - val_loss: 1310264.5519 - val_squared_difference_loss: 20.8800 - val_KL_divergence_loss: 1310243.7820 - val_neg_log_likelihood: inf\n",
      "Epoch 195/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 1140.7994 - squared_difference_loss: 17.8930 - KL_divergence_loss: 1122.9064 - neg_log_likelihood: 723596247109.9294 - val_loss: 1287642.2426 - val_squared_difference_loss: 117.4377 - val_KL_divergence_loss: 1287524.8877 - val_neg_log_likelihood: inf\n",
      "Epoch 196/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 302.5897 - squared_difference_loss: 17.8468 - KL_divergence_loss: 284.7430 - neg_log_likelihood: 499500962585.7984 - val_loss: 1255825.8016 - val_squared_difference_loss: 232.1242 - val_KL_divergence_loss: 1255593.7558 - val_neg_log_likelihood: inf\n",
      "Epoch 197/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 1178.6421 - squared_difference_loss: 17.8778 - KL_divergence_loss: 1160.7645 - neg_log_likelihood: 1059078483398.5927 - val_loss: 1186488.9482 - val_squared_difference_loss: 508.3835 - val_KL_divergence_loss: 1185980.7492 - val_neg_log_likelihood: inf\n",
      "Epoch 198/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 494.5343 - squared_difference_loss: 17.8611 - KL_divergence_loss: 476.6732 - neg_log_likelihood: 133026856990589.4219 - val_loss: 1197778.0603 - val_squared_difference_loss: 659.4229 - val_KL_divergence_loss: 1197118.7162 - val_neg_log_likelihood: inf\n",
      "Epoch 199/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 2194.4976 - squared_difference_loss: 17.8471 - KL_divergence_loss: 2176.6486 - neg_log_likelihood: 497392534412.2660 - val_loss: 1160069.4984 - val_squared_difference_loss: 592.2694 - val_KL_divergence_loss: 1159477.2885 - val_neg_log_likelihood: inf\n",
      "Epoch 200/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 1347.6615 - squared_difference_loss: 17.8558 - KL_divergence_loss: 1329.8057 - neg_log_likelihood: 3172413113188735488.0000 - val_loss: 1168831.4215 - val_squared_difference_loss: 668.3260 - val_KL_divergence_loss: 1168163.1933 - val_neg_log_likelihood: inf\n",
      "Epoch 201/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 461.2946 - squared_difference_loss: 17.7660 - KL_divergence_loss: 443.5286 - neg_log_likelihood: 935784909157.0520 - val_loss: 1101850.7431 - val_squared_difference_loss: 324.8199 - val_KL_divergence_loss: 1101526.0539 - val_neg_log_likelihood: inf\n",
      "Epoch 202/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 1835.9483 - squared_difference_loss: 17.8270 - KL_divergence_loss: 1818.1185 - neg_log_likelihood: 13412921565239.0684 - val_loss: 1096110.8134 - val_squared_difference_loss: 85.8976 - val_KL_divergence_loss: 1096025.0953 - val_neg_log_likelihood: inf\n",
      "Epoch 203/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 1047.1777 - squared_difference_loss: 17.8018 - KL_divergence_loss: 1029.3758 - neg_log_likelihood: 59111995318340.5781 - val_loss: 1086891.1035 - val_squared_difference_loss: 19.1260 - val_KL_divergence_loss: 1086872.0593 - val_neg_log_likelihood: inf\n",
      "Epoch 204/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 756.0856 - squared_difference_loss: 17.7846 - KL_divergence_loss: 738.3010 - neg_log_likelihood: 1135761274733.7715 - val_loss: 1090695.4368 - val_squared_difference_loss: 21.2341 - val_KL_divergence_loss: 1090674.3653 - val_neg_log_likelihood: inf\n",
      "Epoch 205/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 1123.4842 - squared_difference_loss: 17.8281 - KL_divergence_loss: 1105.6567 - neg_log_likelihood: 282452160244740352.0000 - val_loss: 1071646.5667 - val_squared_difference_loss: 70.1530 - val_KL_divergence_loss: 1071576.5733 - val_neg_log_likelihood: inf\n",
      "Epoch 206/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 1159.2522 - squared_difference_loss: 17.7883 - KL_divergence_loss: 1141.4636 - neg_log_likelihood: 567066490088203.0000 - val_loss: 1010211.9883 - val_squared_difference_loss: 121.1605 - val_KL_divergence_loss: 1010091.0060 - val_neg_log_likelihood: inf\n",
      "Epoch 207/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 907.3806 - squared_difference_loss: 17.8022 - KL_divergence_loss: 889.5787 - neg_log_likelihood: 273548183587042787328.0000 - val_loss: 996220.4407 - val_squared_difference_loss: 469.9558 - val_KL_divergence_loss: 995750.6357 - val_neg_log_likelihood: inf\n",
      "Epoch 208/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 838.5525 - squared_difference_loss: 17.8071 - KL_divergence_loss: 820.7455 - neg_log_likelihood: 28758287492158.5586 - val_loss: 1003799.9629 - val_squared_difference_loss: 488.6108 - val_KL_divergence_loss: 1003311.4777 - val_neg_log_likelihood: inf\n",
      "Epoch 209/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 317.0256 - squared_difference_loss: 17.7196 - KL_divergence_loss: 299.3060 - neg_log_likelihood: 3189469485460.9590 - val_loss: 1006825.0999 - val_squared_difference_loss: 1278.1337 - val_KL_divergence_loss: 1005547.0559 - val_neg_log_likelihood: inf\n",
      "Epoch 210/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 1295.9593 - squared_difference_loss: 17.7606 - KL_divergence_loss: 1278.1992 - neg_log_likelihood: 2607474269093.5869 - val_loss: 989476.1862 - val_squared_difference_loss: 587.8253 - val_KL_divergence_loss: 988888.4716 - val_neg_log_likelihood: inf\n",
      "Epoch 211/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 301.9763 - squared_difference_loss: 17.7399 - KL_divergence_loss: 284.2364 - neg_log_likelihood: 4127465367089442.5000 - val_loss: 944224.4849 - val_squared_difference_loss: 85.7097 - val_KL_divergence_loss: 944138.9391 - val_neg_log_likelihood: inf\n",
      "Epoch 212/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 532.6565 - squared_difference_loss: 17.7384 - KL_divergence_loss: 514.9177 - neg_log_likelihood: 6798974261048.3359 - val_loss: 937952.3213 - val_squared_difference_loss: 27.1063 - val_KL_divergence_loss: 937925.3026 - val_neg_log_likelihood: inf\n",
      "Epoch 213/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 962.3622 - squared_difference_loss: 17.7285 - KL_divergence_loss: 944.6343 - neg_log_likelihood: 8439714779094173.0000 - val_loss: 934544.7060 - val_squared_difference_loss: 58.4575 - val_KL_divergence_loss: 934486.3798 - val_neg_log_likelihood: inf\n",
      "Epoch 214/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 13us/step - loss: 611.0116 - squared_difference_loss: 17.6856 - KL_divergence_loss: 593.3258 - neg_log_likelihood: 443689448124.3786 - val_loss: 912000.7553 - val_squared_difference_loss: 587.4008 - val_KL_divergence_loss: 911413.4356 - val_neg_log_likelihood: inf\n",
      "Epoch 215/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 1212.2817 - squared_difference_loss: 17.7136 - KL_divergence_loss: 1194.5682 - neg_log_likelihood: 9574896852324.3535 - val_loss: 899600.1360 - val_squared_difference_loss: 225.9061 - val_KL_divergence_loss: 899374.3408 - val_neg_log_likelihood: inf\n",
      "Epoch 216/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 546.3671 - squared_difference_loss: 17.6753 - KL_divergence_loss: 528.6919 - neg_log_likelihood: 1717274979108.8079 - val_loss: 881888.3853 - val_squared_difference_loss: 448.6016 - val_KL_divergence_loss: 881439.8446 - val_neg_log_likelihood: inf\n",
      "Epoch 217/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 2146.7580 - squared_difference_loss: 17.6904 - KL_divergence_loss: 2129.0667 - neg_log_likelihood: 22672375667.0547 - val_loss: 810012.3258 - val_squared_difference_loss: 65.5202 - val_KL_divergence_loss: 809946.9196 - val_neg_log_likelihood: inf\n",
      "Epoch 218/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 449.3009 - squared_difference_loss: 17.7072 - KL_divergence_loss: 431.5935 - neg_log_likelihood: 113575212482043.7656 - val_loss: 805221.4959 - val_squared_difference_loss: 3830.3027 - val_KL_divergence_loss: 801391.3375 - val_neg_log_likelihood: inf\n",
      "Epoch 219/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 890.1958 - squared_difference_loss: 17.6737 - KL_divergence_loss: 872.5221 - neg_log_likelihood: 2408859465.4814 - val_loss: 758746.2273 - val_squared_difference_loss: 158.4716 - val_KL_divergence_loss: 758587.8590 - val_neg_log_likelihood: inf\n",
      "Epoch 220/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 379.2371 - squared_difference_loss: 17.6790 - KL_divergence_loss: 361.5581 - neg_log_likelihood: 932024399.5174 - val_loss: 740799.0031 - val_squared_difference_loss: 1046.9040 - val_KL_divergence_loss: 739752.1468 - val_neg_log_likelihood: inf\n",
      "Epoch 221/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 718.0877 - squared_difference_loss: 17.6282 - KL_divergence_loss: 700.4594 - neg_log_likelihood: 116787573336530.4062 - val_loss: 722219.3942 - val_squared_difference_loss: 182.7267 - val_KL_divergence_loss: 722036.7728 - val_neg_log_likelihood: inf\n",
      "Epoch 222/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 802.3478 - squared_difference_loss: 17.6440 - KL_divergence_loss: 784.7042 - neg_log_likelihood: 1610861662190.3655 - val_loss: 724272.4626 - val_squared_difference_loss: 2143.7436 - val_KL_divergence_loss: 722128.7743 - val_neg_log_likelihood: inf\n",
      "Epoch 223/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 951.0970 - squared_difference_loss: 17.6266 - KL_divergence_loss: 933.4705 - neg_log_likelihood: 37288752715834.7656 - val_loss: 707322.4784 - val_squared_difference_loss: 740.2291 - val_KL_divergence_loss: 706582.2498 - val_neg_log_likelihood: inf\n",
      "Epoch 224/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 1098.9764 - squared_difference_loss: 17.6550 - KL_divergence_loss: 1081.3214 - neg_log_likelihood: 629938256427.5471 - val_loss: 700192.3900 - val_squared_difference_loss: 571.3140 - val_KL_divergence_loss: 699621.0441 - val_neg_log_likelihood: inf\n",
      "Epoch 225/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 534.1363 - squared_difference_loss: 17.6200 - KL_divergence_loss: 516.5162 - neg_log_likelihood: 240456115878.9008 - val_loss: 679945.2004 - val_squared_difference_loss: 24.3908 - val_KL_divergence_loss: 679920.8377 - val_neg_log_likelihood: inf\n",
      "Epoch 226/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 799.3642 - squared_difference_loss: 17.6250 - KL_divergence_loss: 781.7387 - neg_log_likelihood: 1894020139387.0303 - val_loss: 680824.5226 - val_squared_difference_loss: 427.4145 - val_KL_divergence_loss: 680397.1064 - val_neg_log_likelihood: inf\n",
      "Epoch 227/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 584.6407 - squared_difference_loss: 17.6605 - KL_divergence_loss: 566.9802 - neg_log_likelihood: 385925415225.4009 - val_loss: 678889.0180 - val_squared_difference_loss: 1666.4408 - val_KL_divergence_loss: 677222.7445 - val_neg_log_likelihood: inf\n",
      "Epoch 228/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 1279.7084 - squared_difference_loss: 17.6559 - KL_divergence_loss: 1262.0461 - neg_log_likelihood: 15247443296522579968.0000 - val_loss: 660988.6588 - val_squared_difference_loss: 84.8197 - val_KL_divergence_loss: 660904.0083 - val_neg_log_likelihood: inf\n",
      "Epoch 229/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 659.5455 - squared_difference_loss: 17.5952 - KL_divergence_loss: 641.9506 - neg_log_likelihood: 458110079561.7872 - val_loss: 657129.4138 - val_squared_difference_loss: 1313.4543 - val_KL_divergence_loss: 655816.1649 - val_neg_log_likelihood: inf\n",
      "Epoch 230/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 421.4939 - squared_difference_loss: 17.6218 - KL_divergence_loss: 403.8722 - neg_log_likelihood: 35069211754292.6680 - val_loss: 642550.3357 - val_squared_difference_loss: 1733.5373 - val_KL_divergence_loss: 640816.9459 - val_neg_log_likelihood: inf\n",
      "Epoch 231/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 226.5402 - squared_difference_loss: 17.6094 - KL_divergence_loss: 208.9308 - neg_log_likelihood: 36856360750849.1562 - val_loss: 623145.5224 - val_squared_difference_loss: 190.5179 - val_KL_divergence_loss: 622955.1922 - val_neg_log_likelihood: inf\n",
      "Epoch 232/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 655.2328 - squared_difference_loss: 17.6189 - KL_divergence_loss: 637.6140 - neg_log_likelihood: 425241246.8617 - val_loss: 631381.3008 - val_squared_difference_loss: 507.4686 - val_KL_divergence_loss: 630873.9708 - val_neg_log_likelihood: inf\n",
      "Epoch 233/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 519.7558 - squared_difference_loss: 17.6388 - KL_divergence_loss: 502.1168 - neg_log_likelihood: 37459729919626.6484 - val_loss: 598414.3821 - val_squared_difference_loss: 1269.0987 - val_KL_divergence_loss: 597145.4580 - val_neg_log_likelihood: inf\n",
      "Epoch 234/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 418.9013 - squared_difference_loss: 17.5565 - KL_divergence_loss: 401.3447 - neg_log_likelihood: 8049476511368842.0000 - val_loss: 575201.8516 - val_squared_difference_loss: 3342.5921 - val_KL_divergence_loss: 571859.4655 - val_neg_log_likelihood: inf\n",
      "Epoch 235/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 395.1460 - squared_difference_loss: 17.5722 - KL_divergence_loss: 377.5739 - neg_log_likelihood: 687429814757.6288 - val_loss: 575757.9518 - val_squared_difference_loss: 19.3201 - val_KL_divergence_loss: 575738.8456 - val_neg_log_likelihood: inf\n",
      "Epoch 236/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 579.1481 - squared_difference_loss: 17.5740 - KL_divergence_loss: 561.5738 - neg_log_likelihood: 12311907641.8601 - val_loss: 578966.0828 - val_squared_difference_loss: 4595.0586 - val_KL_divergence_loss: 574371.2181 - val_neg_log_likelihood: inf\n",
      "Epoch 237/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 841.3424 - squared_difference_loss: 17.5430 - KL_divergence_loss: 823.7996 - neg_log_likelihood: 3428485298.6215 - val_loss: 562237.0198 - val_squared_difference_loss: 418.7989 - val_KL_divergence_loss: 561818.4365 - val_neg_log_likelihood: inf\n",
      "Epoch 238/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 792.1951 - squared_difference_loss: 17.5298 - KL_divergence_loss: 774.6652 - neg_log_likelihood: 47225640784.0549 - val_loss: 555825.7855 - val_squared_difference_loss: 22.8893 - val_KL_divergence_loss: 555803.0752 - val_neg_log_likelihood: inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 692.5274 - squared_difference_loss: 17.5690 - KL_divergence_loss: 674.9589 - neg_log_likelihood: 2258775765175.0630 - val_loss: 548428.9296 - val_squared_difference_loss: 1394.8639 - val_KL_divergence_loss: 547034.2471 - val_neg_log_likelihood: inf\n",
      "Epoch 240/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 279.7215 - squared_difference_loss: 17.5563 - KL_divergence_loss: 262.1653 - neg_log_likelihood: 7082162152.5782 - val_loss: 535667.0045 - val_squared_difference_loss: 505.7229 - val_KL_divergence_loss: 535161.4828 - val_neg_log_likelihood: inf\n",
      "Epoch 241/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 332.2875 - squared_difference_loss: 17.5372 - KL_divergence_loss: 314.7503 - neg_log_likelihood: 64777688332.9442 - val_loss: 522432.0708 - val_squared_difference_loss: 44.8198 - val_KL_divergence_loss: 522387.4332 - val_neg_log_likelihood: inf\n",
      "Epoch 242/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 592.4581 - squared_difference_loss: 17.5785 - KL_divergence_loss: 574.8792 - neg_log_likelihood: 20267573833.7495 - val_loss: 505355.5788 - val_squared_difference_loss: 40.8124 - val_KL_divergence_loss: 505314.9665 - val_neg_log_likelihood: inf\n",
      "Epoch 243/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 895.9325 - squared_difference_loss: 17.5448 - KL_divergence_loss: 878.3874 - neg_log_likelihood: 378381544566.7306 - val_loss: 490511.2957 - val_squared_difference_loss: 57.3560 - val_KL_divergence_loss: 490454.1446 - val_neg_log_likelihood: inf\n",
      "Epoch 244/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 665.6539 - squared_difference_loss: 17.5394 - KL_divergence_loss: 648.1144 - neg_log_likelihood: 5471441833.7162 - val_loss: 465620.4739 - val_squared_difference_loss: 36.3123 - val_KL_divergence_loss: 465584.3625 - val_neg_log_likelihood: inf\n",
      "Epoch 245/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 634.6590 - squared_difference_loss: 17.5697 - KL_divergence_loss: 617.0895 - neg_log_likelihood: 729292757300.4094 - val_loss: 437366.0628 - val_squared_difference_loss: 497.8538 - val_KL_divergence_loss: 436868.3778 - val_neg_log_likelihood: inf\n",
      "Epoch 246/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 966.0671 - squared_difference_loss: 17.6014 - KL_divergence_loss: 948.4660 - neg_log_likelihood: 2858071584110841432113152.0000 - val_loss: 425714.6196 - val_squared_difference_loss: 1634.2729 - val_KL_divergence_loss: 424080.4992 - val_neg_log_likelihood: inf\n",
      "Epoch 247/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 369.2657 - squared_difference_loss: 17.5865 - KL_divergence_loss: 351.6793 - neg_log_likelihood: 1407023831431557.5000 - val_loss: 415491.0103 - val_squared_difference_loss: 25.6645 - val_KL_divergence_loss: 415465.4740 - val_neg_log_likelihood: inf\n",
      "Epoch 248/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 705.8705 - squared_difference_loss: 17.5156 - KL_divergence_loss: 688.3547 - neg_log_likelihood: 1223565132007501.5000 - val_loss: 398850.7076 - val_squared_difference_loss: 156.8531 - val_KL_divergence_loss: 398694.0203 - val_neg_log_likelihood: inf\n",
      "Epoch 249/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 1138.0380 - squared_difference_loss: 17.6034 - KL_divergence_loss: 1120.4348 - neg_log_likelihood: 1268897057325191936.0000 - val_loss: 382128.5270 - val_squared_difference_loss: 815.5221 - val_KL_divergence_loss: 381313.1797 - val_neg_log_likelihood: inf\n",
      "Epoch 250/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 189.6541 - squared_difference_loss: 17.4916 - KL_divergence_loss: 172.1625 - neg_log_likelihood: 72655396526.8371 - val_loss: 378174.4356 - val_squared_difference_loss: 1008.8832 - val_KL_divergence_loss: 377165.6566 - val_neg_log_likelihood: inf\n",
      "Epoch 251/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 152.3164 - squared_difference_loss: 17.4820 - KL_divergence_loss: 134.8344 - neg_log_likelihood: 14117892373.6487 - val_loss: 375962.4729 - val_squared_difference_loss: 313.8736 - val_KL_divergence_loss: 375648.7186 - val_neg_log_likelihood: inf\n",
      "Epoch 252/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 543.7092 - squared_difference_loss: 17.5475 - KL_divergence_loss: 526.1616 - neg_log_likelihood: 15205903978856250.0000 - val_loss: 369106.6747 - val_squared_difference_loss: 138.9380 - val_KL_divergence_loss: 368967.8982 - val_neg_log_likelihood: inf\n",
      "Epoch 253/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 307.9769 - squared_difference_loss: 17.4910 - KL_divergence_loss: 290.4859 - neg_log_likelihood: 2084868213931.3455 - val_loss: 356568.4167 - val_squared_difference_loss: 4499.2572 - val_KL_divergence_loss: 352069.3513 - val_neg_log_likelihood: inf\n",
      "Epoch 254/2000\n",
      "29507/29507 [==============================] - 1s 19us/step - loss: 152.8538 - squared_difference_loss: 17.5335 - KL_divergence_loss: 135.3202 - neg_log_likelihood: 109560392883183.0312 - val_loss: 354700.0991 - val_squared_difference_loss: 784.3015 - val_KL_divergence_loss: 353915.9525 - val_neg_log_likelihood: inf\n",
      "Epoch 255/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 463.7324 - squared_difference_loss: 17.5014 - KL_divergence_loss: 446.2309 - neg_log_likelihood: 2315907036115.6455 - val_loss: 357124.8867 - val_squared_difference_loss: 2355.6401 - val_KL_divergence_loss: 354769.4269 - val_neg_log_likelihood: inf\n",
      "Epoch 256/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 272.3008 - squared_difference_loss: 17.4698 - KL_divergence_loss: 254.8312 - neg_log_likelihood: 158668718339.6756 - val_loss: 350256.0360 - val_squared_difference_loss: 61.4343 - val_KL_divergence_loss: 350194.7157 - val_neg_log_likelihood: inf\n",
      "Epoch 257/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 679.8182 - squared_difference_loss: 17.4836 - KL_divergence_loss: 662.3346 - neg_log_likelihood: 14377017.8983 - val_loss: 341301.8260 - val_squared_difference_loss: 1049.1924 - val_KL_divergence_loss: 340252.7772 - val_neg_log_likelihood: inf\n",
      "Epoch 258/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 174.0565 - squared_difference_loss: 17.4844 - KL_divergence_loss: 156.5720 - neg_log_likelihood: 43782975480.0882 - val_loss: 332525.5971 - val_squared_difference_loss: 146.1481 - val_KL_divergence_loss: 332379.5996 - val_neg_log_likelihood: inf\n",
      "Epoch 259/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 171.4200 - squared_difference_loss: 17.4360 - KL_divergence_loss: 153.9841 - neg_log_likelihood: 14153980540.9007 - val_loss: 332553.3573 - val_squared_difference_loss: 1141.7508 - val_KL_divergence_loss: 331411.7278 - val_neg_log_likelihood: inf\n",
      "Epoch 260/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 850.8180 - squared_difference_loss: 17.4325 - KL_divergence_loss: 833.3854 - neg_log_likelihood: 3640384251.2800 - val_loss: 320898.8560 - val_squared_difference_loss: 328.6848 - val_KL_divergence_loss: 320570.3066 - val_neg_log_likelihood: inf\n",
      "Epoch 261/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 880.6451 - squared_difference_loss: 17.4264 - KL_divergence_loss: 863.2186 - neg_log_likelihood: 1625769461.9209 - val_loss: 309911.9687 - val_squared_difference_loss: 1485.3117 - val_KL_divergence_loss: 308426.7876 - val_neg_log_likelihood: inf\n",
      "Epoch 262/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 255.1029 - squared_difference_loss: 17.4349 - KL_divergence_loss: 237.6679 - neg_log_likelihood: 6325023.2563 - val_loss: 307108.3022 - val_squared_difference_loss: 214.9005 - val_KL_divergence_loss: 306893.5383 - val_neg_log_likelihood: inf\n",
      "Epoch 263/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 211.7535 - squared_difference_loss: 17.4311 - KL_divergence_loss: 194.3225 - neg_log_likelihood: 34096056535.5070 - val_loss: 303504.5763 - val_squared_difference_loss: 791.4241 - val_KL_divergence_loss: 302713.2813 - val_neg_log_likelihood: inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 264/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 280.6106 - squared_difference_loss: 17.4315 - KL_divergence_loss: 263.1791 - neg_log_likelihood: 1083948976515.6874 - val_loss: 296237.0877 - val_squared_difference_loss: 32.8689 - val_KL_divergence_loss: 296204.3527 - val_neg_log_likelihood: inf\n",
      "Epoch 265/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 304.9176 - squared_difference_loss: 17.4275 - KL_divergence_loss: 287.4902 - neg_log_likelihood: 64465833031.0339 - val_loss: 293452.9916 - val_squared_difference_loss: 1962.9986 - val_KL_divergence_loss: 291490.1382 - val_neg_log_likelihood: inf\n",
      "Epoch 266/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 416.6465 - squared_difference_loss: 17.3900 - KL_divergence_loss: 399.2564 - neg_log_likelihood: 1281006610097.4141 - val_loss: 287988.9617 - val_squared_difference_loss: 1503.3318 - val_KL_divergence_loss: 286485.7770 - val_neg_log_likelihood: inf\n",
      "Epoch 267/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 133.8469 - squared_difference_loss: 17.4240 - KL_divergence_loss: 116.4229 - neg_log_likelihood: 1407373323090.8416 - val_loss: 284704.0292 - val_squared_difference_loss: 230.1608 - val_KL_divergence_loss: 284474.0085 - val_neg_log_likelihood: inf\n",
      "Epoch 268/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 655.1369 - squared_difference_loss: 17.4034 - KL_divergence_loss: 637.7336 - neg_log_likelihood: 322270479.8047 - val_loss: 274743.2755 - val_squared_difference_loss: 20.3748 - val_KL_divergence_loss: 274723.0108 - val_neg_log_likelihood: inf\n",
      "Epoch 269/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 221.0809 - squared_difference_loss: 17.4064 - KL_divergence_loss: 203.6745 - neg_log_likelihood: 1901378802809.9648 - val_loss: 264435.7929 - val_squared_difference_loss: 975.7361 - val_KL_divergence_loss: 263460.1892 - val_neg_log_likelihood: inf\n",
      "Epoch 270/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 163.9823 - squared_difference_loss: 17.4460 - KL_divergence_loss: 146.5362 - neg_log_likelihood: 272592456359.7759 - val_loss: 256889.9476 - val_squared_difference_loss: 46.8740 - val_KL_divergence_loss: 256843.2111 - val_neg_log_likelihood: inf\n",
      "Epoch 271/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 1338.8783 - squared_difference_loss: 17.4338 - KL_divergence_loss: 1321.4434 - neg_log_likelihood: 2093010770106880.7500 - val_loss: 245091.6219 - val_squared_difference_loss: 153.1944 - val_KL_divergence_loss: 244938.5392 - val_neg_log_likelihood: inf\n",
      "Epoch 272/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 95.9313 - squared_difference_loss: 17.3657 - KL_divergence_loss: 78.5655 - neg_log_likelihood: 7977968475.6213 - val_loss: 232872.7717 - val_squared_difference_loss: 17.5839 - val_KL_divergence_loss: 232855.3293 - val_neg_log_likelihood: inf\n",
      "Epoch 273/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 334.1358 - squared_difference_loss: 17.3860 - KL_divergence_loss: 316.7498 - neg_log_likelihood: 78259322481.6667 - val_loss: 225138.3497 - val_squared_difference_loss: 364.7709 - val_KL_divergence_loss: 224773.7229 - val_neg_log_likelihood: inf\n",
      "Epoch 274/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 87.8204 - squared_difference_loss: 17.3460 - KL_divergence_loss: 70.4744 - neg_log_likelihood: 3606028598.6338 - val_loss: 225136.1854 - val_squared_difference_loss: 1426.3443 - val_KL_divergence_loss: 223709.9781 - val_neg_log_likelihood: inf\n",
      "Epoch 275/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 376.8686 - squared_difference_loss: 17.4216 - KL_divergence_loss: 359.4471 - neg_log_likelihood: 22936012621927.1367 - val_loss: 212737.7027 - val_squared_difference_loss: 1292.9676 - val_KL_divergence_loss: 211444.8836 - val_neg_log_likelihood: inf\n",
      "Epoch 276/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 122.0656 - squared_difference_loss: 17.3894 - KL_divergence_loss: 104.6762 - neg_log_likelihood: 40002885945.4161 - val_loss: 209904.1492 - val_squared_difference_loss: 31.5697 - val_KL_divergence_loss: 209872.7030 - val_neg_log_likelihood: inf\n",
      "Epoch 277/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 285.2140 - squared_difference_loss: 17.3944 - KL_divergence_loss: 267.8196 - neg_log_likelihood: 336179005385.9831 - val_loss: 205760.0935 - val_squared_difference_loss: 59.4552 - val_KL_divergence_loss: 205700.7786 - val_neg_log_likelihood: inf\n",
      "Epoch 278/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 464.7677 - squared_difference_loss: 17.3559 - KL_divergence_loss: 447.4115 - neg_log_likelihood: 12432617749.6410 - val_loss: 202059.6261 - val_squared_difference_loss: 48.9705 - val_KL_divergence_loss: 202010.8143 - val_neg_log_likelihood: inf\n",
      "Epoch 279/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 89.5388 - squared_difference_loss: 17.3953 - KL_divergence_loss: 72.1436 - neg_log_likelihood: 388562350.0374 - val_loss: 199942.0822 - val_squared_difference_loss: 26.4418 - val_KL_divergence_loss: 199915.7951 - val_neg_log_likelihood: inf\n",
      "Epoch 280/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 147.9996 - squared_difference_loss: 17.3869 - KL_divergence_loss: 130.6127 - neg_log_likelihood: 4848915740.1136 - val_loss: 197342.7483 - val_squared_difference_loss: 17.3344 - val_KL_divergence_loss: 197325.5403 - val_neg_log_likelihood: 6806605935707.5869\n",
      "Epoch 281/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 181.0271 - squared_difference_loss: 17.3805 - KL_divergence_loss: 163.6466 - neg_log_likelihood: 394629612927.5026 - val_loss: 199042.5159 - val_squared_difference_loss: 3709.9004 - val_KL_divergence_loss: 195332.7650 - val_neg_log_likelihood: inf\n",
      "Epoch 282/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 112.7502 - squared_difference_loss: 17.3685 - KL_divergence_loss: 95.3818 - neg_log_likelihood: 526165440.0348 - val_loss: 196244.1250 - val_squared_difference_loss: 621.1466 - val_KL_divergence_loss: 195623.1183 - val_neg_log_likelihood: inf\n",
      "Epoch 283/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 234.0277 - squared_difference_loss: 17.3657 - KL_divergence_loss: 216.6621 - neg_log_likelihood: 77977867354.3522 - val_loss: 193654.0833 - val_squared_difference_loss: 617.6659 - val_KL_divergence_loss: 193036.5588 - val_neg_log_likelihood: inf\n",
      "Epoch 284/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 218.1907 - squared_difference_loss: 17.3572 - KL_divergence_loss: 200.8335 - neg_log_likelihood: 101774710970.1735 - val_loss: 192674.9502 - val_squared_difference_loss: 40.5206 - val_KL_divergence_loss: 192634.5774 - val_neg_log_likelihood: inf\n",
      "Epoch 285/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 438.3588 - squared_difference_loss: 17.3813 - KL_divergence_loss: 420.9777 - neg_log_likelihood: 31367366442.3814 - val_loss: 188835.5784 - val_squared_difference_loss: 37.2536 - val_KL_divergence_loss: 188798.4433 - val_neg_log_likelihood: inf\n",
      "Epoch 286/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 66.6819 - squared_difference_loss: 17.3557 - KL_divergence_loss: 49.3262 - neg_log_likelihood: 9620624.8839 - val_loss: 189054.0413 - val_squared_difference_loss: 1948.0029 - val_KL_divergence_loss: 187106.1803 - val_neg_log_likelihood: inf\n",
      "Epoch 287/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 605.2041 - squared_difference_loss: 17.3439 - KL_divergence_loss: 587.8599 - neg_log_likelihood: 66121035.5007 - val_loss: 180799.3202 - val_squared_difference_loss: 51.6362 - val_KL_divergence_loss: 180747.8103 - val_neg_log_likelihood: inf\n",
      "Epoch 288/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 265.6963 - squared_difference_loss: 17.3723 - KL_divergence_loss: 248.3241 - neg_log_likelihood: 8422068520.8873 - val_loss: 174895.3828 - val_squared_difference_loss: 80.7503 - val_KL_divergence_loss: 174814.7877 - val_neg_log_likelihood: inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 171.6088 - squared_difference_loss: 17.4111 - KL_divergence_loss: 154.1978 - neg_log_likelihood: 5547090886638.7598 - val_loss: 173016.5794 - val_squared_difference_loss: 592.3930 - val_KL_divergence_loss: 172424.3540 - val_neg_log_likelihood: inf\n",
      "Epoch 290/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 345.5002 - squared_difference_loss: 17.3139 - KL_divergence_loss: 328.1862 - neg_log_likelihood: 38933100627.4063 - val_loss: 167144.6608 - val_squared_difference_loss: 61.2119 - val_KL_divergence_loss: 167083.5626 - val_neg_log_likelihood: inf\n",
      "Epoch 291/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 67.6355 - squared_difference_loss: 17.3975 - KL_divergence_loss: 50.2379 - neg_log_likelihood: 58500658897.9884 - val_loss: 156211.1683 - val_squared_difference_loss: 659.3714 - val_KL_divergence_loss: 155551.9055 - val_neg_log_likelihood: inf\n",
      "Epoch 292/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 258.7791 - squared_difference_loss: 17.3456 - KL_divergence_loss: 241.4335 - neg_log_likelihood: 7694791698213.7764 - val_loss: 153029.5221 - val_squared_difference_loss: 361.6652 - val_KL_divergence_loss: 152667.9733 - val_neg_log_likelihood: inf\n",
      "Epoch 293/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 189.4936 - squared_difference_loss: 17.3605 - KL_divergence_loss: 172.1331 - neg_log_likelihood: 23524052957.8980 - val_loss: 150180.6955 - val_squared_difference_loss: 473.1129 - val_KL_divergence_loss: 149707.6958 - val_neg_log_likelihood: inf\n",
      "Epoch 294/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 83.6448 - squared_difference_loss: 17.3821 - KL_divergence_loss: 66.2628 - neg_log_likelihood: 29457265700623.5703 - val_loss: 151257.5047 - val_squared_difference_loss: 203.0358 - val_KL_divergence_loss: 151054.5882 - val_neg_log_likelihood: inf\n",
      "Epoch 295/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 103.4538 - squared_difference_loss: 17.3282 - KL_divergence_loss: 86.1256 - neg_log_likelihood: 538015784.7048 - val_loss: 149053.4447 - val_squared_difference_loss: 347.9342 - val_KL_divergence_loss: 148705.6328 - val_neg_log_likelihood: inf\n",
      "Epoch 296/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 261.2962 - squared_difference_loss: 17.3780 - KL_divergence_loss: 243.9182 - neg_log_likelihood: 54788411764.2103 - val_loss: 147220.4208 - val_squared_difference_loss: 120.4863 - val_KL_divergence_loss: 147100.0441 - val_neg_log_likelihood: inf\n",
      "Epoch 297/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 131.7972 - squared_difference_loss: 17.3775 - KL_divergence_loss: 114.4197 - neg_log_likelihood: 1343320882.2763 - val_loss: 143334.2435 - val_squared_difference_loss: 368.1864 - val_KL_divergence_loss: 142966.1859 - val_neg_log_likelihood: inf\n",
      "Epoch 298/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 160.9224 - squared_difference_loss: 17.3326 - KL_divergence_loss: 143.5898 - neg_log_likelihood: 847879565.2250 - val_loss: 138059.1434 - val_squared_difference_loss: 414.4316 - val_KL_divergence_loss: 137644.8507 - val_neg_log_likelihood: inf\n",
      "Epoch 299/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 158.9847 - squared_difference_loss: 17.3742 - KL_divergence_loss: 141.6105 - neg_log_likelihood: 452767580355.4753 - val_loss: 137485.0188 - val_squared_difference_loss: 291.4235 - val_KL_divergence_loss: 137193.7159 - val_neg_log_likelihood: inf\n",
      "Epoch 300/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 101.1185 - squared_difference_loss: 17.3849 - KL_divergence_loss: 83.7337 - neg_log_likelihood: 44325108219.5732 - val_loss: 131358.7771 - val_squared_difference_loss: 459.0285 - val_KL_divergence_loss: 130899.8552 - val_neg_log_likelihood: inf\n",
      "Epoch 301/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 188.7843 - squared_difference_loss: 17.3714 - KL_divergence_loss: 171.4130 - neg_log_likelihood: 32489327.0358 - val_loss: 131926.7500 - val_squared_difference_loss: 398.5045 - val_KL_divergence_loss: 131528.3641 - val_neg_log_likelihood: inf\n",
      "Epoch 302/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 255.3270 - squared_difference_loss: 17.3171 - KL_divergence_loss: 238.0098 - neg_log_likelihood: 985422372579970.6250 - val_loss: 128544.9679 - val_squared_difference_loss: 17.5030 - val_KL_divergence_loss: 128527.5988 - val_neg_log_likelihood: inf\n",
      "Epoch 303/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 108.4217 - squared_difference_loss: 17.3379 - KL_divergence_loss: 91.0838 - neg_log_likelihood: 38853917866.6791 - val_loss: 128114.1618 - val_squared_difference_loss: 24.3256 - val_KL_divergence_loss: 128089.9511 - val_neg_log_likelihood: inf\n",
      "Epoch 304/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 129.6942 - squared_difference_loss: 17.2895 - KL_divergence_loss: 112.4047 - neg_log_likelihood: 608650209656.1862 - val_loss: 126523.0034 - val_squared_difference_loss: 162.7522 - val_KL_divergence_loss: 126360.3598 - val_neg_log_likelihood: inf\n",
      "Epoch 305/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 260.1110 - squared_difference_loss: 17.3119 - KL_divergence_loss: 242.7992 - neg_log_likelihood: 2956312301.3120 - val_loss: 120775.6468 - val_squared_difference_loss: 208.4419 - val_KL_divergence_loss: 120567.3232 - val_neg_log_likelihood: inf\n",
      "Epoch 306/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 60.9192 - squared_difference_loss: 17.3358 - KL_divergence_loss: 43.5834 - neg_log_likelihood: 9358597199.1392 - val_loss: 117881.6865 - val_squared_difference_loss: 17.7753 - val_KL_divergence_loss: 117864.0270 - val_neg_log_likelihood: inf\n",
      "Epoch 307/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 189.0345 - squared_difference_loss: 17.2723 - KL_divergence_loss: 171.7621 - neg_log_likelihood: 2121468364.3486 - val_loss: 117478.5830 - val_squared_difference_loss: 71.5227 - val_KL_divergence_loss: 117407.1808 - val_neg_log_likelihood: inf\n",
      "Epoch 308/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 231.9493 - squared_difference_loss: 17.3199 - KL_divergence_loss: 214.6293 - neg_log_likelihood: 87591727.4732 - val_loss: 115558.4224 - val_squared_difference_loss: 607.8895 - val_KL_divergence_loss: 114950.6708 - val_neg_log_likelihood: inf\n",
      "Epoch 309/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 92.8352 - squared_difference_loss: 17.3129 - KL_divergence_loss: 75.5223 - neg_log_likelihood: 2959466129.4280 - val_loss: 115586.2743 - val_squared_difference_loss: 266.4008 - val_KL_divergence_loss: 115319.9808 - val_neg_log_likelihood: inf\n",
      "Epoch 310/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 106.8295 - squared_difference_loss: 17.3506 - KL_divergence_loss: 89.4789 - neg_log_likelihood: 89650.3165 - val_loss: 108627.0089 - val_squared_difference_loss: 298.6053 - val_KL_divergence_loss: 108328.5187 - val_neg_log_likelihood: inf\n",
      "Epoch 311/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 154.3376 - squared_difference_loss: 17.2670 - KL_divergence_loss: 137.0706 - neg_log_likelihood: 167232380991.8188 - val_loss: 110421.7196 - val_squared_difference_loss: 44.3805 - val_KL_divergence_loss: 110377.4779 - val_neg_log_likelihood: inf\n",
      "Epoch 312/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 171.4571 - squared_difference_loss: 17.3178 - KL_divergence_loss: 154.1394 - neg_log_likelihood: 448925964326.2061 - val_loss: 109366.1446 - val_squared_difference_loss: 468.5201 - val_KL_divergence_loss: 108897.7567 - val_neg_log_likelihood: inf\n",
      "Epoch 313/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 160.8747 - squared_difference_loss: 17.2895 - KL_divergence_loss: 143.5853 - neg_log_likelihood: 1425795930396.4915 - val_loss: 105971.1801 - val_squared_difference_loss: 108.4974 - val_KL_divergence_loss: 105862.7927 - val_neg_log_likelihood: inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 314/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 147.8347 - squared_difference_loss: 17.2635 - KL_divergence_loss: 130.5712 - neg_log_likelihood: 6648756609.1367 - val_loss: 109307.8565 - val_squared_difference_loss: 3079.4596 - val_KL_divergence_loss: 106228.5418 - val_neg_log_likelihood: inf\n",
      "Epoch 315/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 91.6502 - squared_difference_loss: 17.2736 - KL_divergence_loss: 74.3766 - neg_log_likelihood: 290584467901.1035 - val_loss: 104179.0277 - val_squared_difference_loss: 21.3879 - val_KL_divergence_loss: 104157.7718 - val_neg_log_likelihood: inf\n",
      "Epoch 316/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 268.2624 - squared_difference_loss: 17.3210 - KL_divergence_loss: 250.9414 - neg_log_likelihood: 35008646.9483 - val_loss: 98459.1092 - val_squared_difference_loss: 948.5538 - val_KL_divergence_loss: 97510.6700 - val_neg_log_likelihood: inf\n",
      "Epoch 317/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 114.2649 - squared_difference_loss: 17.2935 - KL_divergence_loss: 96.9714 - neg_log_likelihood: 3869385238.6396 - val_loss: 95682.0585 - val_squared_difference_loss: 374.5356 - val_KL_divergence_loss: 95307.6425 - val_neg_log_likelihood: inf\n",
      "Epoch 318/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 112.2957 - squared_difference_loss: 17.2858 - KL_divergence_loss: 95.0098 - neg_log_likelihood: 6550646896.9812 - val_loss: 95042.0764 - val_squared_difference_loss: 638.7585 - val_KL_divergence_loss: 94403.4330 - val_neg_log_likelihood: inf\n",
      "Epoch 319/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 84.4432 - squared_difference_loss: 17.2834 - KL_divergence_loss: 67.1598 - neg_log_likelihood: 2094072.4301 - val_loss: 93631.8237 - val_squared_difference_loss: 25.5385 - val_KL_divergence_loss: 93606.4102 - val_neg_log_likelihood: inf\n",
      "Epoch 320/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 60.8664 - squared_difference_loss: 17.3048 - KL_divergence_loss: 43.5617 - neg_log_likelihood: 701418.0727 - val_loss: 93933.9825 - val_squared_difference_loss: 329.7541 - val_KL_divergence_loss: 93604.3539 - val_neg_log_likelihood: inf\n",
      "Epoch 321/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 93.1106 - squared_difference_loss: 17.2532 - KL_divergence_loss: 75.8574 - neg_log_likelihood: 11257396939.2541 - val_loss: 93174.6692 - val_squared_difference_loss: 453.1973 - val_KL_divergence_loss: 92721.5900 - val_neg_log_likelihood: inf\n",
      "Epoch 322/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 231.0959 - squared_difference_loss: 17.2775 - KL_divergence_loss: 213.8183 - neg_log_likelihood: 19224812057.9904 - val_loss: 91160.0343 - val_squared_difference_loss: 84.8404 - val_KL_divergence_loss: 91075.2993 - val_neg_log_likelihood: inf\n",
      "Epoch 323/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 72.8932 - squared_difference_loss: 17.2654 - KL_divergence_loss: 55.6279 - neg_log_likelihood: 365516300.4699 - val_loss: 85237.4621 - val_squared_difference_loss: 36.7021 - val_KL_divergence_loss: 85200.8732 - val_neg_log_likelihood: inf\n",
      "Epoch 324/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 80.2712 - squared_difference_loss: 17.2392 - KL_divergence_loss: 63.0320 - neg_log_likelihood: 1173414909.0075 - val_loss: 82484.2098 - val_squared_difference_loss: 396.8547 - val_KL_divergence_loss: 82087.4268 - val_neg_log_likelihood: inf\n",
      "Epoch 325/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 96.2828 - squared_difference_loss: 17.2353 - KL_divergence_loss: 79.0475 - neg_log_likelihood: 1476708699.7615 - val_loss: 82099.5378 - val_squared_difference_loss: 157.1484 - val_KL_divergence_loss: 81942.4583 - val_neg_log_likelihood: inf\n",
      "Epoch 326/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 275.7011 - squared_difference_loss: 17.2986 - KL_divergence_loss: 258.4024 - neg_log_likelihood: 60925360716864.1719 - val_loss: 81455.9226 - val_squared_difference_loss: 427.3747 - val_KL_divergence_loss: 81028.6241 - val_neg_log_likelihood: inf\n",
      "Epoch 327/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 98.7462 - squared_difference_loss: 17.2892 - KL_divergence_loss: 81.4570 - neg_log_likelihood: 1281796323.7336 - val_loss: 78942.6010 - val_squared_difference_loss: 300.3980 - val_KL_divergence_loss: 78642.2787 - val_neg_log_likelihood: inf\n",
      "Epoch 328/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 121.7491 - squared_difference_loss: 17.2339 - KL_divergence_loss: 104.5153 - neg_log_likelihood: 254736547.1483 - val_loss: 76362.6872 - val_squared_difference_loss: 96.3029 - val_KL_divergence_loss: 76266.4613 - val_neg_log_likelihood: inf\n",
      "Epoch 329/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 83.8726 - squared_difference_loss: 17.2471 - KL_divergence_loss: 66.6256 - neg_log_likelihood: 3775472297.1983 - val_loss: 75283.3714 - val_squared_difference_loss: 448.6943 - val_KL_divergence_loss: 74834.7569 - val_neg_log_likelihood: inf\n",
      "Epoch 330/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 160.0330 - squared_difference_loss: 17.2564 - KL_divergence_loss: 142.7766 - neg_log_likelihood: 4235792692440.0684 - val_loss: 72467.1645 - val_squared_difference_loss: 59.8750 - val_KL_divergence_loss: 72407.3667 - val_neg_log_likelihood: inf\n",
      "Epoch 331/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 175.4070 - squared_difference_loss: 17.2023 - KL_divergence_loss: 158.2047 - neg_log_likelihood: 48006061.1841 - val_loss: 71327.2532 - val_squared_difference_loss: 66.9186 - val_KL_divergence_loss: 71260.4221 - val_neg_log_likelihood: inf\n",
      "Epoch 332/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 128.3413 - squared_difference_loss: 17.2341 - KL_divergence_loss: 111.1072 - neg_log_likelihood: 30224430386.8755 - val_loss: 68524.4712 - val_squared_difference_loss: 17.3015 - val_KL_divergence_loss: 68507.2499 - val_neg_log_likelihood: inf\n",
      "Epoch 333/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 98.3165 - squared_difference_loss: 17.2127 - KL_divergence_loss: 81.1038 - neg_log_likelihood: 27151174656.1675 - val_loss: 67037.6827 - val_squared_difference_loss: 134.4990 - val_KL_divergence_loss: 66903.2599 - val_neg_log_likelihood: inf\n",
      "Epoch 334/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 75.5624 - squared_difference_loss: 17.2430 - KL_divergence_loss: 58.3194 - neg_log_likelihood: 586568495.8610 - val_loss: 66409.6402 - val_squared_difference_loss: 282.7950 - val_KL_divergence_loss: 66126.9376 - val_neg_log_likelihood: inf\n",
      "Epoch 335/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 142.3172 - squared_difference_loss: 17.2234 - KL_divergence_loss: 125.0938 - neg_log_likelihood: 781190093.3277 - val_loss: 63004.4142 - val_squared_difference_loss: 16.9640 - val_KL_divergence_loss: 62987.5419 - val_neg_log_likelihood: 50569694108766032.0000\n",
      "Epoch 336/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 360.0615 - squared_difference_loss: 17.1900 - KL_divergence_loss: 342.8714 - neg_log_likelihood: 1459549663.0524 - val_loss: 59673.8915 - val_squared_difference_loss: 632.4929 - val_KL_divergence_loss: 59041.4877 - val_neg_log_likelihood: inf\n",
      "Epoch 337/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 96.9406 - squared_difference_loss: 17.2332 - KL_divergence_loss: 79.7074 - neg_log_likelihood: 708694375.0974 - val_loss: 62809.3705 - val_squared_difference_loss: 186.8709 - val_KL_divergence_loss: 62622.5829 - val_neg_log_likelihood: inf\n",
      "Epoch 338/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 88.5867 - squared_difference_loss: 17.1370 - KL_divergence_loss: 71.4497 - neg_log_likelihood: 197508321.2293 - val_loss: 65145.6948 - val_squared_difference_loss: 26.9856 - val_KL_divergence_loss: 65118.7913 - val_neg_log_likelihood: inf\n",
      "Epoch 339/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 89.4881 - squared_difference_loss: 17.1194 - KL_divergence_loss: 72.3687 - neg_log_likelihood: 54046742.7544 - val_loss: 66377.9349 - val_squared_difference_loss: 281.7963 - val_KL_divergence_loss: 66096.2205 - val_neg_log_likelihood: inf\n",
      "Epoch 340/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 91.2999 - squared_difference_loss: 17.1382 - KL_divergence_loss: 74.1617 - neg_log_likelihood: 12953871.6758 - val_loss: 66140.1926 - val_squared_difference_loss: 42.3166 - val_KL_divergence_loss: 66097.9605 - val_neg_log_likelihood: inf\n",
      "Epoch 341/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 49.5366 - squared_difference_loss: 17.0992 - KL_divergence_loss: 32.4374 - neg_log_likelihood: 470660683.9877 - val_loss: 63569.2439 - val_squared_difference_loss: 72.6448 - val_KL_divergence_loss: 63496.6877 - val_neg_log_likelihood: inf\n",
      "Epoch 342/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 75.9441 - squared_difference_loss: 17.0741 - KL_divergence_loss: 58.8700 - neg_log_likelihood: 14462648399.6954 - val_loss: 67045.2957 - val_squared_difference_loss: 3723.2120 - val_KL_divergence_loss: 63322.1736 - val_neg_log_likelihood: inf\n",
      "Epoch 343/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 172.3127 - squared_difference_loss: 17.0954 - KL_divergence_loss: 155.2172 - neg_log_likelihood: 43126406384.6634 - val_loss: 60473.3444 - val_squared_difference_loss: 20.6224 - val_KL_divergence_loss: 60452.7960 - val_neg_log_likelihood: inf\n",
      "Epoch 344/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 114.9731 - squared_difference_loss: 17.0663 - KL_divergence_loss: 97.9068 - neg_log_likelihood: 1148966051.6397 - val_loss: 58927.3061 - val_squared_difference_loss: 398.4939 - val_KL_divergence_loss: 58528.8992 - val_neg_log_likelihood: inf\n",
      "Epoch 345/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 53.5230 - squared_difference_loss: 17.0726 - KL_divergence_loss: 36.4505 - neg_log_likelihood: 19812824388.9876 - val_loss: 55125.0482 - val_squared_difference_loss: 28.5656 - val_KL_divergence_loss: 55096.5504 - val_neg_log_likelihood: inf\n",
      "Epoch 346/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 103.3099 - squared_difference_loss: 17.0592 - KL_divergence_loss: 86.2507 - neg_log_likelihood: 200635375600.2708 - val_loss: 53779.6965 - val_squared_difference_loss: 125.4763 - val_KL_divergence_loss: 53654.3070 - val_neg_log_likelihood: inf\n",
      "Epoch 347/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 80.2673 - squared_difference_loss: 17.0159 - KL_divergence_loss: 63.2513 - neg_log_likelihood: 10401402945.2882 - val_loss: 52979.1429 - val_squared_difference_loss: 200.2358 - val_KL_divergence_loss: 52778.9835 - val_neg_log_likelihood: inf\n",
      "Epoch 348/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 85.0537 - squared_difference_loss: 17.0399 - KL_divergence_loss: 68.0138 - neg_log_likelihood: 48267894041.5871 - val_loss: 52554.9895 - val_squared_difference_loss: 118.3899 - val_KL_divergence_loss: 52436.6903 - val_neg_log_likelihood: inf\n",
      "Epoch 349/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 98.8111 - squared_difference_loss: 17.0675 - KL_divergence_loss: 81.7436 - neg_log_likelihood: 153734415791.1367 - val_loss: 51334.8609 - val_squared_difference_loss: 217.8409 - val_KL_divergence_loss: 51117.1055 - val_neg_log_likelihood: inf\n",
      "Epoch 350/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 58.3109 - squared_difference_loss: 17.0350 - KL_divergence_loss: 41.2760 - neg_log_likelihood: 1174058371.4338 - val_loss: 49692.0109 - val_squared_difference_loss: 60.6243 - val_KL_divergence_loss: 49631.4662 - val_neg_log_likelihood: inf\n",
      "Epoch 351/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 56.3716 - squared_difference_loss: 17.0642 - KL_divergence_loss: 39.3073 - neg_log_likelihood: 1659612834.0484 - val_loss: 49447.5402 - val_squared_difference_loss: 528.2289 - val_KL_divergence_loss: 48919.3970 - val_neg_log_likelihood: inf\n",
      "Epoch 352/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 62.2907 - squared_difference_loss: 17.0654 - KL_divergence_loss: 45.2253 - neg_log_likelihood: 813918170.1142 - val_loss: 47652.2518 - val_squared_difference_loss: 16.7777 - val_KL_divergence_loss: 47635.5475 - val_neg_log_likelihood: 142754821649621.8750\n",
      "Epoch 353/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 46.1001 - squared_difference_loss: 17.0272 - KL_divergence_loss: 29.0729 - neg_log_likelihood: 53331050.9183 - val_loss: 47174.0719 - val_squared_difference_loss: 46.6963 - val_KL_divergence_loss: 47127.4729 - val_neg_log_likelihood: inf\n",
      "Epoch 354/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 40.3363 - squared_difference_loss: 17.0289 - KL_divergence_loss: 23.3074 - neg_log_likelihood: 3218012795.1758 - val_loss: 46000.6685 - val_squared_difference_loss: 129.7780 - val_KL_divergence_loss: 45870.9716 - val_neg_log_likelihood: inf\n",
      "Epoch 355/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 54.3216 - squared_difference_loss: 17.0010 - KL_divergence_loss: 37.3206 - neg_log_likelihood: 106280418069.2148 - val_loss: 46122.1793 - val_squared_difference_loss: 237.2672 - val_KL_divergence_loss: 45884.9927 - val_neg_log_likelihood: inf\n",
      "Epoch 356/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 96.1301 - squared_difference_loss: 16.9841 - KL_divergence_loss: 79.1460 - neg_log_likelihood: 33618091386.5349 - val_loss: 43782.9853 - val_squared_difference_loss: 101.4037 - val_KL_divergence_loss: 43681.6699 - val_neg_log_likelihood: inf\n",
      "Epoch 357/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 78.6033 - squared_difference_loss: 16.9887 - KL_divergence_loss: 61.6146 - neg_log_likelihood: 2653430229838.3931 - val_loss: 42537.4591 - val_squared_difference_loss: 196.1055 - val_KL_divergence_loss: 42341.4346 - val_neg_log_likelihood: inf\n",
      "Epoch 358/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 124.8280 - squared_difference_loss: 16.9671 - KL_divergence_loss: 107.8608 - neg_log_likelihood: 813532012.8016 - val_loss: 40774.8265 - val_squared_difference_loss: 181.0495 - val_KL_divergence_loss: 40593.7980 - val_neg_log_likelihood: inf\n",
      "Epoch 359/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 42.6798 - squared_difference_loss: 16.9664 - KL_divergence_loss: 25.7134 - neg_log_likelihood: 192116761927.5977 - val_loss: 42508.2459 - val_squared_difference_loss: 3210.1852 - val_KL_divergence_loss: 39298.1478 - val_neg_log_likelihood: inf\n",
      "Epoch 360/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 101.9518 - squared_difference_loss: 17.0225 - KL_divergence_loss: 84.9293 - neg_log_likelihood: 88849917696.5723 - val_loss: 37706.6806 - val_squared_difference_loss: 129.6393 - val_KL_divergence_loss: 37577.0439 - val_neg_log_likelihood: inf\n",
      "Epoch 361/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 50.3684 - squared_difference_loss: 16.9539 - KL_divergence_loss: 33.4144 - neg_log_likelihood: 19680127771.5141 - val_loss: 37063.5259 - val_squared_difference_loss: 31.8880 - val_KL_divergence_loss: 37031.6474 - val_neg_log_likelihood: inf\n",
      "Epoch 362/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 68.9016 - squared_difference_loss: 16.9832 - KL_divergence_loss: 51.9183 - neg_log_likelihood: 19388596966.3676 - val_loss: 35333.5067 - val_squared_difference_loss: 45.0509 - val_KL_divergence_loss: 35288.4507 - val_neg_log_likelihood: inf\n",
      "Epoch 363/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 49.7728 - squared_difference_loss: 16.9743 - KL_divergence_loss: 32.7985 - neg_log_likelihood: 151880336388.3955 - val_loss: 35125.5879 - val_squared_difference_loss: 54.1920 - val_KL_divergence_loss: 35071.4128 - val_neg_log_likelihood: inf\n",
      "Epoch 364/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 13us/step - loss: 60.7953 - squared_difference_loss: 16.9839 - KL_divergence_loss: 43.8115 - neg_log_likelihood: 13640883859.5641 - val_loss: 33666.5814 - val_squared_difference_loss: 50.8544 - val_KL_divergence_loss: 33615.7424 - val_neg_log_likelihood: inf\n",
      "Epoch 365/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 87.2683 - squared_difference_loss: 16.9719 - KL_divergence_loss: 70.2964 - neg_log_likelihood: 7964898707.4716 - val_loss: 31012.4162 - val_squared_difference_loss: 97.6920 - val_KL_divergence_loss: 30914.7391 - val_neg_log_likelihood: inf\n",
      "Epoch 366/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 81.1934 - squared_difference_loss: 16.9574 - KL_divergence_loss: 64.2361 - neg_log_likelihood: 742942995.5677 - val_loss: 29283.3549 - val_squared_difference_loss: 16.7448 - val_KL_divergence_loss: 29266.6257 - val_neg_log_likelihood: 6990523952.0635\n",
      "Epoch 367/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 73.1906 - squared_difference_loss: 16.8952 - KL_divergence_loss: 56.2954 - neg_log_likelihood: 1067553355.1875 - val_loss: 27958.8590 - val_squared_difference_loss: 35.6731 - val_KL_divergence_loss: 27923.1941 - val_neg_log_likelihood: inf\n",
      "Epoch 368/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 47.9810 - squared_difference_loss: 16.8858 - KL_divergence_loss: 31.0952 - neg_log_likelihood: 182751050.6342 - val_loss: 26524.5148 - val_squared_difference_loss: 251.9562 - val_KL_divergence_loss: 26272.5659 - val_neg_log_likelihood: inf\n",
      "Epoch 369/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 49.6648 - squared_difference_loss: 16.8940 - KL_divergence_loss: 32.7708 - neg_log_likelihood: 790178843936.2379 - val_loss: 25785.0499 - val_squared_difference_loss: 18.3371 - val_KL_divergence_loss: 25766.7146 - val_neg_log_likelihood: inf\n",
      "Epoch 370/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 46.5086 - squared_difference_loss: 16.8779 - KL_divergence_loss: 29.6307 - neg_log_likelihood: 8006395.8388 - val_loss: 24476.6247 - val_squared_difference_loss: 228.0815 - val_KL_divergence_loss: 24248.5582 - val_neg_log_likelihood: inf\n",
      "Epoch 371/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 55.2689 - squared_difference_loss: 16.8632 - KL_divergence_loss: 38.4056 - neg_log_likelihood: 83443242277.0169 - val_loss: 24530.0860 - val_squared_difference_loss: 105.6622 - val_KL_divergence_loss: 24424.4259 - val_neg_log_likelihood: inf\n",
      "Epoch 372/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 53.9456 - squared_difference_loss: 16.8432 - KL_divergence_loss: 37.1024 - neg_log_likelihood: 3247612136256.2671 - val_loss: 23614.2249 - val_squared_difference_loss: 56.1703 - val_KL_divergence_loss: 23558.0656 - val_neg_log_likelihood: inf\n",
      "Epoch 373/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 79.7291 - squared_difference_loss: 16.8005 - KL_divergence_loss: 62.9286 - neg_log_likelihood: 26965475053.2546 - val_loss: 23502.3657 - val_squared_difference_loss: 549.2079 - val_KL_divergence_loss: 22953.1534 - val_neg_log_likelihood: inf\n",
      "Epoch 374/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 88.3806 - squared_difference_loss: 16.8133 - KL_divergence_loss: 71.5674 - neg_log_likelihood: 7839884397077.3535 - val_loss: 21907.0287 - val_squared_difference_loss: 255.1707 - val_KL_divergence_loss: 21651.8754 - val_neg_log_likelihood: inf\n",
      "Epoch 375/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 68.9914 - squared_difference_loss: 16.7924 - KL_divergence_loss: 52.1990 - neg_log_likelihood: 2636624.5536 - val_loss: 20776.3321 - val_squared_difference_loss: 45.7800 - val_KL_divergence_loss: 20730.5282 - val_neg_log_likelihood: inf\n",
      "Epoch 376/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 62.7675 - squared_difference_loss: 16.7690 - KL_divergence_loss: 45.9985 - neg_log_likelihood: 689470832208.6929 - val_loss: 20109.0218 - val_squared_difference_loss: 19.5738 - val_KL_divergence_loss: 20089.4284 - val_neg_log_likelihood: inf\n",
      "Epoch 377/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 55.6677 - squared_difference_loss: 16.7717 - KL_divergence_loss: 38.8960 - neg_log_likelihood: 67859444816920.6250 - val_loss: 19866.3632 - val_squared_difference_loss: 27.6367 - val_KL_divergence_loss: 19838.7017 - val_neg_log_likelihood: inf\n",
      "Epoch 378/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 30.8202 - squared_difference_loss: 16.7891 - KL_divergence_loss: 14.0311 - neg_log_likelihood: 57320487919.7721 - val_loss: 19622.4047 - val_squared_difference_loss: 58.8506 - val_KL_divergence_loss: 19563.5302 - val_neg_log_likelihood: inf\n",
      "Epoch 379/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 39.2938 - squared_difference_loss: 16.7493 - KL_divergence_loss: 22.5445 - neg_log_likelihood: 7293917624287.6914 - val_loss: 19601.8466 - val_squared_difference_loss: 221.6090 - val_KL_divergence_loss: 19380.2161 - val_neg_log_likelihood: inf\n",
      "Epoch 380/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 72.5168 - squared_difference_loss: 16.7133 - KL_divergence_loss: 55.8035 - neg_log_likelihood: 10009502254201.6484 - val_loss: 18477.1543 - val_squared_difference_loss: 222.0537 - val_KL_divergence_loss: 18255.0864 - val_neg_log_likelihood: inf\n",
      "Epoch 381/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 61.8968 - squared_difference_loss: 16.7489 - KL_divergence_loss: 45.1479 - neg_log_likelihood: 374115575976.9876 - val_loss: 18393.9842 - val_squared_difference_loss: 1086.8537 - val_KL_divergence_loss: 17307.1082 - val_neg_log_likelihood: inf\n",
      "Epoch 382/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 52.1695 - squared_difference_loss: 16.7600 - KL_divergence_loss: 35.4095 - neg_log_likelihood: 53114035875.2707 - val_loss: 16461.0277 - val_squared_difference_loss: 22.7316 - val_KL_divergence_loss: 16438.2734 - val_neg_log_likelihood: inf\n",
      "Epoch 383/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 52.7659 - squared_difference_loss: 16.6936 - KL_divergence_loss: 36.0722 - neg_log_likelihood: 19079744.7964 - val_loss: 15892.7461 - val_squared_difference_loss: 161.1984 - val_KL_divergence_loss: 15731.5274 - val_neg_log_likelihood: inf\n",
      "Epoch 384/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 35.8385 - squared_difference_loss: 16.7125 - KL_divergence_loss: 19.1261 - neg_log_likelihood: 2977983975.1367 - val_loss: 15504.6347 - val_squared_difference_loss: 16.9511 - val_KL_divergence_loss: 15487.6569 - val_neg_log_likelihood: inf\n",
      "Epoch 385/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 68.2931 - squared_difference_loss: 16.7019 - KL_divergence_loss: 51.5912 - neg_log_likelihood: 4982227272508.1670 - val_loss: 13727.1577 - val_squared_difference_loss: 24.1662 - val_KL_divergence_loss: 13702.9627 - val_neg_log_likelihood: inf\n",
      "Epoch 386/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 35.6238 - squared_difference_loss: 16.7263 - KL_divergence_loss: 18.8975 - neg_log_likelihood: 225388617.8812 - val_loss: 12948.8486 - val_squared_difference_loss: 87.9603 - val_KL_divergence_loss: 12860.8605 - val_neg_log_likelihood: inf\n",
      "Epoch 387/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 36.8512 - squared_difference_loss: 16.7386 - KL_divergence_loss: 20.1126 - neg_log_likelihood: 2801085902962.6719 - val_loss: 12807.7584 - val_squared_difference_loss: 29.6639 - val_KL_divergence_loss: 12778.0711 - val_neg_log_likelihood: inf\n",
      "Epoch 388/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 34.2688 - squared_difference_loss: 16.7036 - KL_divergence_loss: 17.5651 - neg_log_likelihood: 4900018594.5286 - val_loss: 12613.9816 - val_squared_difference_loss: 50.2726 - val_KL_divergence_loss: 12563.6858 - val_neg_log_likelihood: inf\n",
      "Epoch 389/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 40.8318 - squared_difference_loss: 16.6837 - KL_divergence_loss: 24.1481 - neg_log_likelihood: 4049089.6803 - val_loss: 12491.1616 - val_squared_difference_loss: 73.0454 - val_KL_divergence_loss: 12418.0928 - val_neg_log_likelihood: inf\n",
      "Epoch 390/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 47.8582 - squared_difference_loss: 16.6627 - KL_divergence_loss: 31.1955 - neg_log_likelihood: 1879692669949.9573 - val_loss: 11994.1489 - val_squared_difference_loss: 85.0034 - val_KL_divergence_loss: 11909.1208 - val_neg_log_likelihood: inf\n",
      "Epoch 391/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 38.3799 - squared_difference_loss: 16.6692 - KL_divergence_loss: 21.7108 - neg_log_likelihood: 236649233466.5173 - val_loss: 11554.9653 - val_squared_difference_loss: 28.9554 - val_KL_divergence_loss: 11525.9861 - val_neg_log_likelihood: inf\n",
      "Epoch 392/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 39.0787 - squared_difference_loss: 16.6726 - KL_divergence_loss: 22.4061 - neg_log_likelihood: 115317108.3811 - val_loss: 11417.6176 - val_squared_difference_loss: 20.2728 - val_KL_divergence_loss: 11397.3246 - val_neg_log_likelihood: inf\n",
      "Epoch 393/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 41.8810 - squared_difference_loss: 16.6854 - KL_divergence_loss: 25.1956 - neg_log_likelihood: 120257383651077.1875 - val_loss: 11294.4757 - val_squared_difference_loss: 434.6833 - val_KL_divergence_loss: 10859.7665 - val_neg_log_likelihood: inf\n",
      "Epoch 394/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 29.1402 - squared_difference_loss: 16.6653 - KL_divergence_loss: 12.4750 - neg_log_likelihood: 1954837314.4225 - val_loss: 11035.7424 - val_squared_difference_loss: 366.4613 - val_KL_divergence_loss: 10669.2635 - val_neg_log_likelihood: inf\n",
      "Epoch 395/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 37.2924 - squared_difference_loss: 16.6930 - KL_divergence_loss: 20.5995 - neg_log_likelihood: 48335266.2047 - val_loss: 10260.9683 - val_squared_difference_loss: 16.2584 - val_KL_divergence_loss: 10244.6997 - val_neg_log_likelihood: 17104561027192627200.0000\n",
      "Epoch 396/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 23.7556 - squared_difference_loss: 16.6541 - KL_divergence_loss: 7.1015 - neg_log_likelihood: 7073171.1222 - val_loss: 10373.9877 - val_squared_difference_loss: 246.5580 - val_KL_divergence_loss: 10127.4176 - val_neg_log_likelihood: inf\n",
      "Epoch 397/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 38.1723 - squared_difference_loss: 16.6403 - KL_divergence_loss: 21.5320 - neg_log_likelihood: 218018100664.8358 - val_loss: 12238.8567 - val_squared_difference_loss: 2368.8759 - val_KL_divergence_loss: 9869.9604 - val_neg_log_likelihood: inf\n",
      "Epoch 398/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 27.3587 - squared_difference_loss: 16.6264 - KL_divergence_loss: 10.7324 - neg_log_likelihood: 1189758.7165 - val_loss: 9365.4544 - val_squared_difference_loss: 44.6233 - val_KL_divergence_loss: 9320.8178 - val_neg_log_likelihood: inf\n",
      "Epoch 399/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 30.6368 - squared_difference_loss: 16.6578 - KL_divergence_loss: 13.9790 - neg_log_likelihood: 11763942397.2295 - val_loss: 9513.9193 - val_squared_difference_loss: 394.2794 - val_KL_divergence_loss: 9119.6268 - val_neg_log_likelihood: inf\n",
      "Epoch 400/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 31.7007 - squared_difference_loss: 16.6678 - KL_divergence_loss: 15.0329 - neg_log_likelihood: 80792659.1510 - val_loss: 8930.6070 - val_squared_difference_loss: 16.3616 - val_KL_divergence_loss: 8914.2315 - val_neg_log_likelihood: 158802470779640676352.0000\n",
      "Epoch 401/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 31.2571 - squared_difference_loss: 16.6322 - KL_divergence_loss: 14.6250 - neg_log_likelihood: 7559863636.5026 - val_loss: 9190.0836 - val_squared_difference_loss: 439.6526 - val_KL_divergence_loss: 8750.4162 - val_neg_log_likelihood: inf\n",
      "Epoch 402/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 30.4250 - squared_difference_loss: 16.6501 - KL_divergence_loss: 13.7749 - neg_log_likelihood: 1557177109.2866 - val_loss: 8742.5828 - val_squared_difference_loss: 236.2191 - val_KL_divergence_loss: 8506.3504 - val_neg_log_likelihood: inf\n",
      "Epoch 403/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 40.2044 - squared_difference_loss: 16.6241 - KL_divergence_loss: 23.5804 - neg_log_likelihood: 5222035.6932 - val_loss: 8311.5108 - val_squared_difference_loss: 146.3150 - val_KL_divergence_loss: 8165.1887 - val_neg_log_likelihood: inf\n",
      "Epoch 404/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 29.0237 - squared_difference_loss: 16.6236 - KL_divergence_loss: 12.4001 - neg_log_likelihood: 79873591.0590 - val_loss: 8019.2399 - val_squared_difference_loss: 171.5767 - val_KL_divergence_loss: 7847.6505 - val_neg_log_likelihood: inf\n",
      "Epoch 405/2000\n",
      "29507/29507 [==============================] - 1s 19us/step - loss: 26.0043 - squared_difference_loss: 16.6194 - KL_divergence_loss: 9.3849 - neg_log_likelihood: 6174105.8115 - val_loss: 7813.8124 - val_squared_difference_loss: 54.1790 - val_KL_divergence_loss: 7759.6203 - val_neg_log_likelihood: inf\n",
      "Epoch 406/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 23.5490 - squared_difference_loss: 16.6173 - KL_divergence_loss: 6.9317 - neg_log_likelihood: 4937981764.7073 - val_loss: 7747.5866 - val_squared_difference_loss: 29.9858 - val_KL_divergence_loss: 7717.5884 - val_neg_log_likelihood: inf\n",
      "Epoch 407/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 32.7530 - squared_difference_loss: 16.6205 - KL_divergence_loss: 16.1325 - neg_log_likelihood: 3293753997.9285 - val_loss: 7532.0058 - val_squared_difference_loss: 18.3081 - val_KL_divergence_loss: 7513.6873 - val_neg_log_likelihood: inf\n",
      "Epoch 408/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 26.1896 - squared_difference_loss: 16.6278 - KL_divergence_loss: 9.5618 - neg_log_likelihood: 2890277027.4025 - val_loss: 7583.0157 - val_squared_difference_loss: 207.1377 - val_KL_divergence_loss: 7375.8653 - val_neg_log_likelihood: inf\n",
      "Epoch 409/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 27.8387 - squared_difference_loss: 16.6099 - KL_divergence_loss: 11.2288 - neg_log_likelihood: 4374249.8056 - val_loss: 7124.8592 - val_squared_difference_loss: 66.5303 - val_KL_divergence_loss: 7058.3164 - val_neg_log_likelihood: inf\n",
      "Epoch 410/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 34.8818 - squared_difference_loss: 16.5859 - KL_divergence_loss: 18.2959 - neg_log_likelihood: 1249237244.8595 - val_loss: 6996.3754 - val_squared_difference_loss: 48.8152 - val_KL_divergence_loss: 6947.5482 - val_neg_log_likelihood: inf\n",
      "Epoch 411/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 30.5743 - squared_difference_loss: 16.5670 - KL_divergence_loss: 14.0073 - neg_log_likelihood: 185565061.9163 - val_loss: 6899.1146 - val_squared_difference_loss: 20.5616 - val_KL_divergence_loss: 6878.5423 - val_neg_log_likelihood: inf\n",
      "Epoch 412/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 35.8657 - squared_difference_loss: 16.5893 - KL_divergence_loss: 19.2764 - neg_log_likelihood: 24373183.7014 - val_loss: 6680.0693 - val_squared_difference_loss: 88.4590 - val_KL_divergence_loss: 6591.5953 - val_neg_log_likelihood: inf\n",
      "Epoch 413/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 23.5130 - squared_difference_loss: 16.5935 - KL_divergence_loss: 6.9195 - neg_log_likelihood: 486319779.8879 - val_loss: 6578.8319 - val_squared_difference_loss: 125.3750 - val_KL_divergence_loss: 6453.4443 - val_neg_log_likelihood: inf\n",
      "Epoch 414/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 13us/step - loss: 33.0212 - squared_difference_loss: 16.6046 - KL_divergence_loss: 16.4166 - neg_log_likelihood: 199064926549.2679 - val_loss: 6293.8975 - val_squared_difference_loss: 18.3241 - val_KL_divergence_loss: 6275.5632 - val_neg_log_likelihood: inf\n",
      "Epoch 415/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 35.7101 - squared_difference_loss: 16.5459 - KL_divergence_loss: 19.1642 - neg_log_likelihood: 18356966.5309 - val_loss: 6008.3551 - val_squared_difference_loss: 68.2446 - val_KL_divergence_loss: 5940.0970 - val_neg_log_likelihood: inf\n",
      "Epoch 416/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 29.6646 - squared_difference_loss: 16.5657 - KL_divergence_loss: 13.0989 - neg_log_likelihood: 901740656.8576 - val_loss: 5763.5335 - val_squared_difference_loss: 18.5157 - val_KL_divergence_loss: 5745.0104 - val_neg_log_likelihood: inf\n",
      "Epoch 417/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 23.3797 - squared_difference_loss: 16.5873 - KL_divergence_loss: 6.7923 - neg_log_likelihood: 4515156627.4255 - val_loss: 5758.4132 - val_squared_difference_loss: 16.9472 - val_KL_divergence_loss: 5741.4575 - val_neg_log_likelihood: inf\n",
      "Epoch 418/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 45.6659 - squared_difference_loss: 16.5235 - KL_divergence_loss: 29.1424 - neg_log_likelihood: 149452346.2964 - val_loss: 5592.5656 - val_squared_difference_loss: 23.3679 - val_KL_divergence_loss: 5569.1876 - val_neg_log_likelihood: inf\n",
      "Epoch 419/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 26.7742 - squared_difference_loss: 16.5303 - KL_divergence_loss: 10.2439 - neg_log_likelihood: 1736820913.3859 - val_loss: 5143.6495 - val_squared_difference_loss: 24.4674 - val_KL_divergence_loss: 5119.1768 - val_neg_log_likelihood: inf\n",
      "Epoch 420/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 25.3314 - squared_difference_loss: 16.5278 - KL_divergence_loss: 8.8036 - neg_log_likelihood: 17114587944.4182 - val_loss: 4918.9439 - val_squared_difference_loss: 63.7712 - val_KL_divergence_loss: 4855.1689 - val_neg_log_likelihood: inf\n",
      "Epoch 421/2000\n",
      "29507/29507 [==============================] - 1s 19us/step - loss: 22.6879 - squared_difference_loss: 16.5587 - KL_divergence_loss: 6.1292 - neg_log_likelihood: 2707421830.1796 - val_loss: 4772.9087 - val_squared_difference_loss: 206.8171 - val_KL_divergence_loss: 4566.0839 - val_neg_log_likelihood: inf\n",
      "Epoch 422/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 24.4211 - squared_difference_loss: 16.5486 - KL_divergence_loss: 7.8725 - neg_log_likelihood: 124381066312.0637 - val_loss: 4430.8958 - val_squared_difference_loss: 32.1691 - val_KL_divergence_loss: 4398.7209 - val_neg_log_likelihood: inf\n",
      "Epoch 423/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 28.6873 - squared_difference_loss: 16.5334 - KL_divergence_loss: 12.1538 - neg_log_likelihood: 63819321463.4150 - val_loss: 4241.1292 - val_squared_difference_loss: 81.8873 - val_KL_divergence_loss: 4159.2357 - val_neg_log_likelihood: inf\n",
      "Epoch 424/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 22.6121 - squared_difference_loss: 16.5640 - KL_divergence_loss: 6.0481 - neg_log_likelihood: 13107394.1993 - val_loss: 4265.3720 - val_squared_difference_loss: 243.4134 - val_KL_divergence_loss: 4021.9523 - val_neg_log_likelihood: inf\n",
      "Epoch 425/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 32.5420 - squared_difference_loss: 16.5555 - KL_divergence_loss: 15.9866 - neg_log_likelihood: 5001191.3280 - val_loss: 4020.0379 - val_squared_difference_loss: 52.2106 - val_KL_divergence_loss: 3967.8207 - val_neg_log_likelihood: inf\n",
      "Epoch 426/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 28.7304 - squared_difference_loss: 16.5695 - KL_divergence_loss: 12.1609 - neg_log_likelihood: 47841419280.0361 - val_loss: 4077.0232 - val_squared_difference_loss: 51.5433 - val_KL_divergence_loss: 4025.4732 - val_neg_log_likelihood: inf\n",
      "Epoch 427/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 23.9930 - squared_difference_loss: 16.5186 - KL_divergence_loss: 7.4744 - neg_log_likelihood: 13459424.1216 - val_loss: 4057.5875 - val_squared_difference_loss: 162.5963 - val_KL_divergence_loss: 3894.9847 - val_neg_log_likelihood: inf\n",
      "Epoch 428/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 25.0918 - squared_difference_loss: 16.5343 - KL_divergence_loss: 8.5575 - neg_log_likelihood: 150077907.9241 - val_loss: 3850.5514 - val_squared_difference_loss: 71.8883 - val_KL_divergence_loss: 3778.6578 - val_neg_log_likelihood: inf\n",
      "Epoch 429/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 22.0388 - squared_difference_loss: 16.4874 - KL_divergence_loss: 5.5514 - neg_log_likelihood: 25048787.4335 - val_loss: 3787.5337 - val_squared_difference_loss: 76.0054 - val_KL_divergence_loss: 3711.5225 - val_neg_log_likelihood: inf\n",
      "Epoch 430/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 30.1938 - squared_difference_loss: 16.5391 - KL_divergence_loss: 13.6547 - neg_log_likelihood: 2249311.6979 - val_loss: 3537.9153 - val_squared_difference_loss: 17.3348 - val_KL_divergence_loss: 3520.5760 - val_neg_log_likelihood: inf\n",
      "Epoch 431/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 25.9758 - squared_difference_loss: 16.5161 - KL_divergence_loss: 9.4597 - neg_log_likelihood: 18336760.7229 - val_loss: 3503.3658 - val_squared_difference_loss: 151.0442 - val_KL_divergence_loss: 3352.3142 - val_neg_log_likelihood: inf\n",
      "Epoch 432/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 21.9689 - squared_difference_loss: 16.5331 - KL_divergence_loss: 5.4358 - neg_log_likelihood: 2563630.2471 - val_loss: 3177.1566 - val_squared_difference_loss: 26.0662 - val_KL_divergence_loss: 3151.0847 - val_neg_log_likelihood: inf\n",
      "Epoch 433/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 26.5218 - squared_difference_loss: 16.5008 - KL_divergence_loss: 10.0210 - neg_log_likelihood: 48351332.3779 - val_loss: 3056.1254 - val_squared_difference_loss: 109.8068 - val_KL_divergence_loss: 2946.3129 - val_neg_log_likelihood: inf\n",
      "Epoch 434/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 28.9423 - squared_difference_loss: 16.5189 - KL_divergence_loss: 12.4234 - neg_log_likelihood: 169125732103.1360 - val_loss: 3006.0575 - val_squared_difference_loss: 169.9009 - val_KL_divergence_loss: 2836.1499 - val_neg_log_likelihood: inf\n",
      "Epoch 435/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 23.3244 - squared_difference_loss: 16.5092 - KL_divergence_loss: 6.8152 - neg_log_likelihood: 4376660.9889 - val_loss: 2691.4857 - val_squared_difference_loss: 17.2484 - val_KL_divergence_loss: 2674.2324 - val_neg_log_likelihood: inf\n",
      "Epoch 436/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 22.2669 - squared_difference_loss: 16.5228 - KL_divergence_loss: 5.7441 - neg_log_likelihood: 43462.1964 - val_loss: 2666.4792 - val_squared_difference_loss: 103.0416 - val_KL_divergence_loss: 2563.4403 - val_neg_log_likelihood: inf\n",
      "Epoch 437/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 22.5096 - squared_difference_loss: 16.5079 - KL_divergence_loss: 6.0017 - neg_log_likelihood: 572376.8902 - val_loss: 2555.5865 - val_squared_difference_loss: 75.7113 - val_KL_divergence_loss: 2479.8779 - val_neg_log_likelihood: inf\n",
      "Epoch 438/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 23.7552 - squared_difference_loss: 16.4958 - KL_divergence_loss: 7.2594 - neg_log_likelihood: 3178441.3606 - val_loss: 2395.2393 - val_squared_difference_loss: 47.1079 - val_KL_divergence_loss: 2348.1336 - val_neg_log_likelihood: inf\n",
      "Epoch 439/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 25.0868 - squared_difference_loss: 16.5034 - KL_divergence_loss: 8.5834 - neg_log_likelihood: 61223377.8979 - val_loss: 2242.0979 - val_squared_difference_loss: 16.8883 - val_KL_divergence_loss: 2225.2130 - val_neg_log_likelihood: inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 440/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 23.6956 - squared_difference_loss: 16.5125 - KL_divergence_loss: 7.1831 - neg_log_likelihood: 507274814.6488 - val_loss: 2255.5804 - val_squared_difference_loss: 35.8895 - val_KL_divergence_loss: 2219.6945 - val_neg_log_likelihood: inf\n",
      "Epoch 441/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 23.5836 - squared_difference_loss: 16.4770 - KL_divergence_loss: 7.1065 - neg_log_likelihood: 4603900.9255 - val_loss: 2126.5805 - val_squared_difference_loss: 24.8909 - val_KL_divergence_loss: 2101.6920 - val_neg_log_likelihood: inf\n",
      "Epoch 442/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 24.7982 - squared_difference_loss: 16.4799 - KL_divergence_loss: 8.3183 - neg_log_likelihood: 1891467983.9251 - val_loss: 1998.6778 - val_squared_difference_loss: 18.7728 - val_KL_divergence_loss: 1979.9068 - val_neg_log_likelihood: inf\n",
      "Epoch 443/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 22.6680 - squared_difference_loss: 16.4653 - KL_divergence_loss: 6.2028 - neg_log_likelihood: 2178728.5761 - val_loss: 1942.7945 - val_squared_difference_loss: 27.1785 - val_KL_divergence_loss: 1915.6179 - val_neg_log_likelihood: inf\n",
      "Epoch 444/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 20.8033 - squared_difference_loss: 16.4662 - KL_divergence_loss: 4.3371 - neg_log_likelihood: 120275990.3431 - val_loss: 1899.5125 - val_squared_difference_loss: 16.9670 - val_KL_divergence_loss: 1882.5482 - val_neg_log_likelihood: inf\n",
      "Epoch 445/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 22.9741 - squared_difference_loss: 16.4637 - KL_divergence_loss: 6.5104 - neg_log_likelihood: 317309.2840 - val_loss: 1837.5490 - val_squared_difference_loss: 26.4004 - val_KL_divergence_loss: 1811.1515 - val_neg_log_likelihood: inf\n",
      "Epoch 446/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 26.5025 - squared_difference_loss: 16.4774 - KL_divergence_loss: 10.0251 - neg_log_likelihood: 18115075.5183 - val_loss: 1765.5801 - val_squared_difference_loss: 19.6894 - val_KL_divergence_loss: 1745.8931 - val_neg_log_likelihood: inf\n",
      "Epoch 447/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 21.9282 - squared_difference_loss: 16.4822 - KL_divergence_loss: 5.4459 - neg_log_likelihood: 61769250.0419 - val_loss: 1741.3192 - val_squared_difference_loss: 20.1149 - val_KL_divergence_loss: 1721.2067 - val_neg_log_likelihood: inf\n",
      "Epoch 448/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 21.7827 - squared_difference_loss: 16.4418 - KL_divergence_loss: 5.3409 - neg_log_likelihood: 1224542.1351 - val_loss: 1739.0282 - val_squared_difference_loss: 31.1676 - val_KL_divergence_loss: 1707.8637 - val_neg_log_likelihood: inf\n",
      "Epoch 449/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 22.6593 - squared_difference_loss: 16.4474 - KL_divergence_loss: 6.2119 - neg_log_likelihood: 201460446.4390 - val_loss: 1668.9785 - val_squared_difference_loss: 16.2329 - val_KL_divergence_loss: 1652.7490 - val_neg_log_likelihood: inf\n",
      "Epoch 450/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 21.3887 - squared_difference_loss: 16.4622 - KL_divergence_loss: 4.9264 - neg_log_likelihood: 679776.5532 - val_loss: 1604.5022 - val_squared_difference_loss: 16.6335 - val_KL_divergence_loss: 1587.8715 - val_neg_log_likelihood: inf\n",
      "Epoch 451/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 27.1444 - squared_difference_loss: 16.4672 - KL_divergence_loss: 10.6772 - neg_log_likelihood: 16966719.6011 - val_loss: 1463.2763 - val_squared_difference_loss: 16.1698 - val_KL_divergence_loss: 1447.1093 - val_neg_log_likelihood: 297436478424857088.0000\n",
      "Epoch 452/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 21.5777 - squared_difference_loss: 16.5168 - KL_divergence_loss: 5.0609 - neg_log_likelihood: 55377075.4037 - val_loss: 1377.3340 - val_squared_difference_loss: 24.3515 - val_KL_divergence_loss: 1352.9860 - val_neg_log_likelihood: inf\n",
      "Epoch 453/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 21.8534 - squared_difference_loss: 16.4820 - KL_divergence_loss: 5.3713 - neg_log_likelihood: 8699430.8779 - val_loss: 1247.3765 - val_squared_difference_loss: 23.8054 - val_KL_divergence_loss: 1223.5706 - val_neg_log_likelihood: inf\n",
      "Epoch 454/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 21.3095 - squared_difference_loss: 16.4612 - KL_divergence_loss: 4.8483 - neg_log_likelihood: 322617.6027 - val_loss: 1205.9025 - val_squared_difference_loss: 23.0128 - val_KL_divergence_loss: 1182.8896 - val_neg_log_likelihood: inf\n",
      "Epoch 455/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 20.9688 - squared_difference_loss: 16.4370 - KL_divergence_loss: 4.5318 - neg_log_likelihood: 884611846.3326 - val_loss: 1156.1225 - val_squared_difference_loss: 16.6953 - val_KL_divergence_loss: 1139.4261 - val_neg_log_likelihood: inf\n",
      "Epoch 456/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 20.1341 - squared_difference_loss: 16.4161 - KL_divergence_loss: 3.7180 - neg_log_likelihood: 2451034.6710 - val_loss: 1115.0804 - val_squared_difference_loss: 16.7348 - val_KL_divergence_loss: 1098.3447 - val_neg_log_likelihood: inf\n",
      "Epoch 457/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 21.3204 - squared_difference_loss: 16.4220 - KL_divergence_loss: 4.8983 - neg_log_likelihood: 462247.6857 - val_loss: 1083.2202 - val_squared_difference_loss: 16.4597 - val_KL_divergence_loss: 1066.7597 - val_neg_log_likelihood: inf\n",
      "Epoch 458/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 22.5060 - squared_difference_loss: 16.4704 - KL_divergence_loss: 6.0356 - neg_log_likelihood: 2703589.1664 - val_loss: 1080.8900 - val_squared_difference_loss: 34.7015 - val_KL_divergence_loss: 1046.1881 - val_neg_log_likelihood: inf\n",
      "Epoch 459/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 21.4366 - squared_difference_loss: 16.4125 - KL_divergence_loss: 5.0241 - neg_log_likelihood: 21047755.5259 - val_loss: 1048.7915 - val_squared_difference_loss: 30.6865 - val_KL_divergence_loss: 1018.1040 - val_neg_log_likelihood: inf\n",
      "Epoch 460/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 20.6285 - squared_difference_loss: 16.4580 - KL_divergence_loss: 4.1705 - neg_log_likelihood: 118889.9959 - val_loss: 1158.2962 - val_squared_difference_loss: 191.1580 - val_KL_divergence_loss: 967.1373 - val_neg_log_likelihood: inf\n",
      "Epoch 461/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 21.0496 - squared_difference_loss: 16.4405 - KL_divergence_loss: 4.6090 - neg_log_likelihood: 33202016.6086 - val_loss: 940.3901 - val_squared_difference_loss: 16.6099 - val_KL_divergence_loss: 923.7796 - val_neg_log_likelihood: inf\n",
      "Epoch 462/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 23.3964 - squared_difference_loss: 16.4756 - KL_divergence_loss: 6.9207 - neg_log_likelihood: 15823235.0942 - val_loss: 884.8242 - val_squared_difference_loss: 26.1955 - val_KL_divergence_loss: 858.6280 - val_neg_log_likelihood: inf\n",
      "Epoch 463/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 24.3067 - squared_difference_loss: 16.4927 - KL_divergence_loss: 7.8140 - neg_log_likelihood: 550398.5206 - val_loss: 816.0219 - val_squared_difference_loss: 25.3500 - val_KL_divergence_loss: 790.6711 - val_neg_log_likelihood: inf\n",
      "Epoch 464/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 23.6902 - squared_difference_loss: 16.4244 - KL_divergence_loss: 7.2658 - neg_log_likelihood: 75034219.9234 - val_loss: 800.4142 - val_squared_difference_loss: 19.0449 - val_KL_divergence_loss: 781.3684 - val_neg_log_likelihood: inf\n",
      "Epoch 465/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 20.9810 - squared_difference_loss: 16.3805 - KL_divergence_loss: 4.6005 - neg_log_likelihood: 2629853.8751 - val_loss: 733.4784 - val_squared_difference_loss: 18.1148 - val_KL_divergence_loss: 715.3630 - val_neg_log_likelihood: inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 21.6341 - squared_difference_loss: 16.4414 - KL_divergence_loss: 5.1928 - neg_log_likelihood: 3906509.1897 - val_loss: 675.9080 - val_squared_difference_loss: 35.1150 - val_KL_divergence_loss: 640.7931 - val_neg_log_likelihood: inf\n",
      "Epoch 467/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 20.8389 - squared_difference_loss: 16.4147 - KL_divergence_loss: 4.4242 - neg_log_likelihood: 1852550.6481 - val_loss: 630.8492 - val_squared_difference_loss: 25.8503 - val_KL_divergence_loss: 604.9989 - val_neg_log_likelihood: inf\n",
      "Epoch 468/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 21.4451 - squared_difference_loss: 16.4171 - KL_divergence_loss: 5.0280 - neg_log_likelihood: 19067593.3110 - val_loss: 604.6682 - val_squared_difference_loss: 29.4357 - val_KL_divergence_loss: 575.2324 - val_neg_log_likelihood: inf\n",
      "Epoch 469/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 20.1257 - squared_difference_loss: 16.4131 - KL_divergence_loss: 3.7125 - neg_log_likelihood: 576709.9998 - val_loss: 556.1282 - val_squared_difference_loss: 20.5754 - val_KL_divergence_loss: 535.5526 - val_neg_log_likelihood: inf\n",
      "Epoch 470/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 20.9099 - squared_difference_loss: 16.4036 - KL_divergence_loss: 4.5063 - neg_log_likelihood: 3746149.3078 - val_loss: 519.9355 - val_squared_difference_loss: 26.9740 - val_KL_divergence_loss: 492.9616 - val_neg_log_likelihood: inf\n",
      "Epoch 471/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 20.8332 - squared_difference_loss: 16.3946 - KL_divergence_loss: 4.4386 - neg_log_likelihood: 4521362.8889 - val_loss: 478.7258 - val_squared_difference_loss: 16.9884 - val_KL_divergence_loss: 461.7373 - val_neg_log_likelihood: inf\n",
      "Epoch 472/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 20.5720 - squared_difference_loss: 16.4038 - KL_divergence_loss: 4.1681 - neg_log_likelihood: 15026842.2056 - val_loss: 462.9192 - val_squared_difference_loss: 17.0063 - val_KL_divergence_loss: 445.9130 - val_neg_log_likelihood: inf\n",
      "Epoch 473/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 20.5778 - squared_difference_loss: 16.4370 - KL_divergence_loss: 4.1408 - neg_log_likelihood: 1244096.2657 - val_loss: 436.5059 - val_squared_difference_loss: 17.5215 - val_KL_divergence_loss: 418.9846 - val_neg_log_likelihood: inf\n",
      "Epoch 474/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 20.4760 - squared_difference_loss: 16.4144 - KL_divergence_loss: 4.0616 - neg_log_likelihood: 687341.7220 - val_loss: 420.4639 - val_squared_difference_loss: 29.2054 - val_KL_divergence_loss: 391.2585 - val_neg_log_likelihood: inf\n",
      "Epoch 475/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 19.9841 - squared_difference_loss: 16.3997 - KL_divergence_loss: 3.5844 - neg_log_likelihood: 1406929.6353 - val_loss: 517.2067 - val_squared_difference_loss: 141.2676 - val_KL_divergence_loss: 375.9390 - val_neg_log_likelihood: inf\n",
      "Epoch 476/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 19.7884 - squared_difference_loss: 16.3567 - KL_divergence_loss: 3.4317 - neg_log_likelihood: 6628270.8331 - val_loss: 382.5762 - val_squared_difference_loss: 16.1895 - val_KL_divergence_loss: 366.3868 - val_neg_log_likelihood: 294804705598933163407572992.0000\n",
      "Epoch 477/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 19.9813 - squared_difference_loss: 16.3569 - KL_divergence_loss: 3.6244 - neg_log_likelihood: 19937403.3730 - val_loss: 381.4835 - val_squared_difference_loss: 36.7850 - val_KL_divergence_loss: 344.6985 - val_neg_log_likelihood: inf\n",
      "Epoch 478/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 20.5285 - squared_difference_loss: 16.3714 - KL_divergence_loss: 4.1571 - neg_log_likelihood: 2172059.3089 - val_loss: 354.9223 - val_squared_difference_loss: 20.5768 - val_KL_divergence_loss: 334.3455 - val_neg_log_likelihood: inf\n",
      "Epoch 479/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 20.8359 - squared_difference_loss: 16.3725 - KL_divergence_loss: 4.4634 - neg_log_likelihood: 1525270.3792 - val_loss: 338.4873 - val_squared_difference_loss: 16.0137 - val_KL_divergence_loss: 322.4735 - val_neg_log_likelihood: 14730097.3007\n",
      "Epoch 480/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 20.4153 - squared_difference_loss: 16.3661 - KL_divergence_loss: 4.0492 - neg_log_likelihood: 4314922.8383 - val_loss: 317.0971 - val_squared_difference_loss: 15.9818 - val_KL_divergence_loss: 301.1154 - val_neg_log_likelihood: 344690.5808\n",
      "Epoch 481/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 19.5879 - squared_difference_loss: 16.3272 - KL_divergence_loss: 3.2606 - neg_log_likelihood: 84779979.9121 - val_loss: 339.9763 - val_squared_difference_loss: 45.8809 - val_KL_divergence_loss: 294.0954 - val_neg_log_likelihood: inf\n",
      "Epoch 482/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 20.5062 - squared_difference_loss: 16.3603 - KL_divergence_loss: 4.1459 - neg_log_likelihood: 31176799.4391 - val_loss: 345.2107 - val_squared_difference_loss: 62.7132 - val_KL_divergence_loss: 282.4975 - val_neg_log_likelihood: inf\n",
      "Epoch 483/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 19.6776 - squared_difference_loss: 16.3504 - KL_divergence_loss: 3.3272 - neg_log_likelihood: 231249.4854 - val_loss: 311.9842 - val_squared_difference_loss: 47.8904 - val_KL_divergence_loss: 264.0939 - val_neg_log_likelihood: inf\n",
      "Epoch 484/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 20.1049 - squared_difference_loss: 16.3174 - KL_divergence_loss: 3.7875 - neg_log_likelihood: 2346545.1538 - val_loss: 263.5791 - val_squared_difference_loss: 15.9813 - val_KL_divergence_loss: 247.5977 - val_neg_log_likelihood: 11246826385470.8359\n",
      "Epoch 485/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 20.1765 - squared_difference_loss: 16.3292 - KL_divergence_loss: 3.8473 - neg_log_likelihood: 36513493.2307 - val_loss: 251.8330 - val_squared_difference_loss: 16.4973 - val_KL_divergence_loss: 235.3357 - val_neg_log_likelihood: inf\n",
      "Epoch 486/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 19.8028 - squared_difference_loss: 16.3470 - KL_divergence_loss: 3.4558 - neg_log_likelihood: 73061.6878 - val_loss: 262.7577 - val_squared_difference_loss: 34.6392 - val_KL_divergence_loss: 228.1184 - val_neg_log_likelihood: inf\n",
      "Epoch 487/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 20.2776 - squared_difference_loss: 16.3412 - KL_divergence_loss: 3.9365 - neg_log_likelihood: 2223318.4629 - val_loss: 232.7599 - val_squared_difference_loss: 16.0371 - val_KL_divergence_loss: 216.7228 - val_neg_log_likelihood: 130287263420410469810176.0000\n",
      "Epoch 488/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 19.9308 - squared_difference_loss: 16.3459 - KL_divergence_loss: 3.5850 - neg_log_likelihood: 534901.2412 - val_loss: 216.4297 - val_squared_difference_loss: 15.9986 - val_KL_divergence_loss: 200.4311 - val_neg_log_likelihood: 1315945169848349491200.0000\n",
      "Epoch 489/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 19.8757 - squared_difference_loss: 16.3052 - KL_divergence_loss: 3.5705 - neg_log_likelihood: 10099637.5125 - val_loss: 202.9376 - val_squared_difference_loss: 15.9270 - val_KL_divergence_loss: 187.0105 - val_neg_log_likelihood: 190661933930555.5938\n",
      "Epoch 490/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 20.1386 - squared_difference_loss: 16.3265 - KL_divergence_loss: 3.8121 - neg_log_likelihood: 1003759.6213 - val_loss: 192.7234 - val_squared_difference_loss: 16.0784 - val_KL_divergence_loss: 176.6449 - val_neg_log_likelihood: 70109237829019098752560922624.0000\n",
      "Epoch 491/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 19.5155 - squared_difference_loss: 16.2866 - KL_divergence_loss: 3.2289 - neg_log_likelihood: 1641256.6716 - val_loss: 182.6467 - val_squared_difference_loss: 17.5122 - val_KL_divergence_loss: 165.1346 - val_neg_log_likelihood: inf\n",
      "Epoch 492/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 19.8738 - squared_difference_loss: 16.2658 - KL_divergence_loss: 3.6080 - neg_log_likelihood: 13726224.2806 - val_loss: 175.7176 - val_squared_difference_loss: 19.7223 - val_KL_divergence_loss: 155.9953 - val_neg_log_likelihood: inf\n",
      "Epoch 493/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 19.7478 - squared_difference_loss: 16.3055 - KL_divergence_loss: 3.4423 - neg_log_likelihood: 11442832.2262 - val_loss: 224.4029 - val_squared_difference_loss: 76.6602 - val_KL_divergence_loss: 147.7427 - val_neg_log_likelihood: inf\n",
      "Epoch 494/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 19.5579 - squared_difference_loss: 16.2941 - KL_divergence_loss: 3.2638 - neg_log_likelihood: 294503.4953 - val_loss: 153.1189 - val_squared_difference_loss: 16.1180 - val_KL_divergence_loss: 137.0009 - val_neg_log_likelihood: inf\n",
      "Epoch 495/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 20.0438 - squared_difference_loss: 16.2624 - KL_divergence_loss: 3.7814 - neg_log_likelihood: 175300.0325 - val_loss: 149.8266 - val_squared_difference_loss: 16.5832 - val_KL_divergence_loss: 133.2433 - val_neg_log_likelihood: inf\n",
      "Epoch 496/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 19.7106 - squared_difference_loss: 16.2781 - KL_divergence_loss: 3.4325 - neg_log_likelihood: 553249.5141 - val_loss: 142.4712 - val_squared_difference_loss: 15.9537 - val_KL_divergence_loss: 126.5175 - val_neg_log_likelihood: 4509546672164120557518848.0000\n",
      "Epoch 497/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 19.5442 - squared_difference_loss: 16.2541 - KL_divergence_loss: 3.2901 - neg_log_likelihood: 74647401.7560 - val_loss: 180.9202 - val_squared_difference_loss: 61.0830 - val_KL_divergence_loss: 119.8373 - val_neg_log_likelihood: inf\n",
      "Epoch 498/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 19.4281 - squared_difference_loss: 16.2441 - KL_divergence_loss: 3.1840 - neg_log_likelihood: 518542.1111 - val_loss: 133.2276 - val_squared_difference_loss: 16.1035 - val_KL_divergence_loss: 117.1241 - val_neg_log_likelihood: 118166317449044935127335683751936.0000\n",
      "Epoch 499/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 19.3602 - squared_difference_loss: 16.2088 - KL_divergence_loss: 3.1514 - neg_log_likelihood: 107360.2045 - val_loss: 130.1389 - val_squared_difference_loss: 15.9165 - val_KL_divergence_loss: 114.2225 - val_neg_log_likelihood: 705829918819277471744.0000\n",
      "Epoch 500/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 19.3533 - squared_difference_loss: 16.2321 - KL_divergence_loss: 3.1212 - neg_log_likelihood: 603175.7104 - val_loss: 133.1861 - val_squared_difference_loss: 20.4535 - val_KL_divergence_loss: 112.7325 - val_neg_log_likelihood: inf\n",
      "Epoch 501/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 19.4245 - squared_difference_loss: 16.1961 - KL_divergence_loss: 3.2284 - neg_log_likelihood: 782881.2278 - val_loss: 132.5148 - val_squared_difference_loss: 21.3445 - val_KL_divergence_loss: 111.1702 - val_neg_log_likelihood: inf\n",
      "Epoch 502/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 19.4412 - squared_difference_loss: 16.2118 - KL_divergence_loss: 3.2294 - neg_log_likelihood: 1346296.5134 - val_loss: 122.8936 - val_squared_difference_loss: 16.0136 - val_KL_divergence_loss: 106.8800 - val_neg_log_likelihood: 31652913915549145153709015040.0000\n",
      "Epoch 503/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 19.3291 - squared_difference_loss: 16.1978 - KL_divergence_loss: 3.1313 - neg_log_likelihood: 155206.4835 - val_loss: 124.5487 - val_squared_difference_loss: 19.5147 - val_KL_divergence_loss: 105.0340 - val_neg_log_likelihood: inf\n",
      "Epoch 504/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 19.3271 - squared_difference_loss: 16.1678 - KL_divergence_loss: 3.1593 - neg_log_likelihood: 813245.0164 - val_loss: 129.7799 - val_squared_difference_loss: 26.3163 - val_KL_divergence_loss: 103.4636 - val_neg_log_likelihood: inf\n",
      "Epoch 505/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 19.5462 - squared_difference_loss: 16.1337 - KL_divergence_loss: 3.4125 - neg_log_likelihood: 653649.7654 - val_loss: 119.1157 - val_squared_difference_loss: 18.8548 - val_KL_divergence_loss: 100.2608 - val_neg_log_likelihood: inf\n",
      "Epoch 506/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 19.3605 - squared_difference_loss: 16.1495 - KL_divergence_loss: 3.2110 - neg_log_likelihood: 1670474.6406 - val_loss: 123.0258 - val_squared_difference_loss: 22.6647 - val_KL_divergence_loss: 100.3612 - val_neg_log_likelihood: inf\n",
      "Epoch 507/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 19.2670 - squared_difference_loss: 16.1142 - KL_divergence_loss: 3.1528 - neg_log_likelihood: 5659138.7603 - val_loss: 113.8007 - val_squared_difference_loss: 16.1315 - val_KL_divergence_loss: 97.6691 - val_neg_log_likelihood: inf\n",
      "Epoch 508/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 19.5666 - squared_difference_loss: 16.1289 - KL_divergence_loss: 3.4377 - neg_log_likelihood: 2154443.4324 - val_loss: 104.5302 - val_squared_difference_loss: 16.0150 - val_KL_divergence_loss: 88.5153 - val_neg_log_likelihood: 21793035326286564590367115575296.0000\n",
      "Epoch 509/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 19.3730 - squared_difference_loss: 16.1328 - KL_divergence_loss: 3.2402 - neg_log_likelihood: 11870389.1574 - val_loss: 97.2962 - val_squared_difference_loss: 15.8535 - val_KL_divergence_loss: 81.4426 - val_neg_log_likelihood: 341523254248446252548096.0000\n",
      "Epoch 510/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 19.3104 - squared_difference_loss: 16.1099 - KL_divergence_loss: 3.2005 - neg_log_likelihood: 996205.7518 - val_loss: 96.9301 - val_squared_difference_loss: 18.2614 - val_KL_divergence_loss: 78.6687 - val_neg_log_likelihood: inf\n",
      "Epoch 511/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 19.4491 - squared_difference_loss: 16.1195 - KL_divergence_loss: 3.3296 - neg_log_likelihood: 181251.7824 - val_loss: 93.0008 - val_squared_difference_loss: 16.6260 - val_KL_divergence_loss: 76.3748 - val_neg_log_likelihood: inf\n",
      "Epoch 512/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 19.4655 - squared_difference_loss: 16.1150 - KL_divergence_loss: 3.3505 - neg_log_likelihood: 5275019.5455 - val_loss: 103.3687 - val_squared_difference_loss: 29.6486 - val_KL_divergence_loss: 73.7201 - val_neg_log_likelihood: inf\n",
      "Epoch 513/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 19.2227 - squared_difference_loss: 16.0788 - KL_divergence_loss: 3.1439 - neg_log_likelihood: 464637.5160 - val_loss: 86.0578 - val_squared_difference_loss: 16.2889 - val_KL_divergence_loss: 69.7688 - val_neg_log_likelihood: inf\n",
      "Epoch 514/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 19.1154 - squared_difference_loss: 16.0604 - KL_divergence_loss: 3.0550 - neg_log_likelihood: 54608949.6603 - val_loss: 81.6225 - val_squared_difference_loss: 15.9196 - val_KL_divergence_loss: 65.7030 - val_neg_log_likelihood: 34705351240651666006067904512.0000\n",
      "Epoch 515/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 19.2531 - squared_difference_loss: 16.0492 - KL_divergence_loss: 3.2039 - neg_log_likelihood: 96621812.5933 - val_loss: 81.4362 - val_squared_difference_loss: 15.8155 - val_KL_divergence_loss: 65.6207 - val_neg_log_likelihood: 46079374509987933542416384.0000\n",
      "Epoch 516/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 14us/step - loss: 19.4841 - squared_difference_loss: 16.0149 - KL_divergence_loss: 3.4691 - neg_log_likelihood: 1571775.4847 - val_loss: 98.4551 - val_squared_difference_loss: 32.8194 - val_KL_divergence_loss: 65.6357 - val_neg_log_likelihood: inf\n",
      "Epoch 517/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 19.3131 - squared_difference_loss: 16.0472 - KL_divergence_loss: 3.2659 - neg_log_likelihood: 1705256.3603 - val_loss: 78.3282 - val_squared_difference_loss: 15.6615 - val_KL_divergence_loss: 62.6667 - val_neg_log_likelihood: 5481582164825248.0000\n",
      "Epoch 518/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 19.3433 - squared_difference_loss: 16.0131 - KL_divergence_loss: 3.3302 - neg_log_likelihood: 355427.9667 - val_loss: 73.4650 - val_squared_difference_loss: 15.7284 - val_KL_divergence_loss: 57.7366 - val_neg_log_likelihood: 3567112354780615168.0000\n",
      "Epoch 519/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 19.2072 - squared_difference_loss: 15.9939 - KL_divergence_loss: 3.2134 - neg_log_likelihood: 3437947.5463 - val_loss: 76.1206 - val_squared_difference_loss: 20.8245 - val_KL_divergence_loss: 55.2961 - val_neg_log_likelihood: inf\n",
      "Epoch 520/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 19.1096 - squared_difference_loss: 15.9625 - KL_divergence_loss: 3.1470 - neg_log_likelihood: 1018101.4743 - val_loss: 71.6250 - val_squared_difference_loss: 15.8498 - val_KL_divergence_loss: 55.7752 - val_neg_log_likelihood: 99771254765184447784675482533888.0000\n",
      "Epoch 521/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 19.0743 - squared_difference_loss: 15.9194 - KL_divergence_loss: 3.1549 - neg_log_likelihood: 207470.3618 - val_loss: 74.4080 - val_squared_difference_loss: 18.9321 - val_KL_divergence_loss: 55.4759 - val_neg_log_likelihood: inf\n",
      "Epoch 522/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 19.1926 - squared_difference_loss: 15.9276 - KL_divergence_loss: 3.2649 - neg_log_likelihood: 2117545.2800 - val_loss: 69.9620 - val_squared_difference_loss: 15.6161 - val_KL_divergence_loss: 54.3458 - val_neg_log_likelihood: 2159029323187933.7500\n",
      "Epoch 523/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 19.1120 - squared_difference_loss: 15.8882 - KL_divergence_loss: 3.2237 - neg_log_likelihood: 490027.9388 - val_loss: 67.9953 - val_squared_difference_loss: 16.6888 - val_KL_divergence_loss: 51.3065 - val_neg_log_likelihood: inf\n",
      "Epoch 524/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 19.0000 - squared_difference_loss: 15.8814 - KL_divergence_loss: 3.1185 - neg_log_likelihood: 624729.3190 - val_loss: 86.0887 - val_squared_difference_loss: 35.1186 - val_KL_divergence_loss: 50.9701 - val_neg_log_likelihood: inf\n",
      "Epoch 525/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 18.9818 - squared_difference_loss: 15.8637 - KL_divergence_loss: 3.1182 - neg_log_likelihood: 1002642.2196 - val_loss: 66.2230 - val_squared_difference_loss: 15.5663 - val_KL_divergence_loss: 50.6568 - val_neg_log_likelihood: 45525337660702.1719\n",
      "Epoch 526/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 19.0736 - squared_difference_loss: 15.8629 - KL_divergence_loss: 3.2107 - neg_log_likelihood: 737885.9068 - val_loss: 67.2938 - val_squared_difference_loss: 15.9354 - val_KL_divergence_loss: 51.3584 - val_neg_log_likelihood: 6723323704740048890029609582592.0000\n",
      "Epoch 527/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 19.0535 - squared_difference_loss: 15.8214 - KL_divergence_loss: 3.2321 - neg_log_likelihood: 5007821.7588 - val_loss: 71.4715 - val_squared_difference_loss: 22.3061 - val_KL_divergence_loss: 49.1654 - val_neg_log_likelihood: inf\n",
      "Epoch 528/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 19.0764 - squared_difference_loss: 15.8361 - KL_divergence_loss: 3.2403 - neg_log_likelihood: 2250636.5860 - val_loss: 68.0422 - val_squared_difference_loss: 19.4076 - val_KL_divergence_loss: 48.6346 - val_neg_log_likelihood: inf\n",
      "Epoch 529/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 19.0996 - squared_difference_loss: 15.8546 - KL_divergence_loss: 3.2450 - neg_log_likelihood: 776605.6987 - val_loss: 81.0642 - val_squared_difference_loss: 34.4836 - val_KL_divergence_loss: 46.5805 - val_neg_log_likelihood: inf\n",
      "Epoch 530/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.9607 - squared_difference_loss: 15.7984 - KL_divergence_loss: 3.1623 - neg_log_likelihood: 193888.0279 - val_loss: 72.6150 - val_squared_difference_loss: 29.3586 - val_KL_divergence_loss: 43.2564 - val_neg_log_likelihood: inf\n",
      "Epoch 531/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 18.9405 - squared_difference_loss: 15.7765 - KL_divergence_loss: 3.1640 - neg_log_likelihood: 1764105.4219 - val_loss: 58.2027 - val_squared_difference_loss: 15.6324 - val_KL_divergence_loss: 42.5702 - val_neg_log_likelihood: 840564524383301979584069632.0000\n",
      "Epoch 532/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.9829 - squared_difference_loss: 15.7927 - KL_divergence_loss: 3.1902 - neg_log_likelihood: 94945.0340 - val_loss: 57.6153 - val_squared_difference_loss: 15.4805 - val_KL_divergence_loss: 42.1348 - val_neg_log_likelihood: 71717345830826852352.0000\n",
      "Epoch 533/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.9678 - squared_difference_loss: 15.7460 - KL_divergence_loss: 3.2219 - neg_log_likelihood: 598143.4924 - val_loss: 56.4747 - val_squared_difference_loss: 15.4460 - val_KL_divergence_loss: 41.0287 - val_neg_log_likelihood: 247480001345295.8125\n",
      "Epoch 534/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 19.0677 - squared_difference_loss: 15.7624 - KL_divergence_loss: 3.3052 - neg_log_likelihood: 2965185.1200 - val_loss: 55.9366 - val_squared_difference_loss: 16.1702 - val_KL_divergence_loss: 39.7664 - val_neg_log_likelihood: inf\n",
      "Epoch 535/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.9731 - squared_difference_loss: 15.7502 - KL_divergence_loss: 3.2228 - neg_log_likelihood: 795235.3032 - val_loss: 53.3521 - val_squared_difference_loss: 15.4336 - val_KL_divergence_loss: 37.9185 - val_neg_log_likelihood: 953898539547593088.0000\n",
      "Epoch 536/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.8865 - squared_difference_loss: 15.7119 - KL_divergence_loss: 3.1746 - neg_log_likelihood: 547034.9672 - val_loss: 53.2380 - val_squared_difference_loss: 15.5148 - val_KL_divergence_loss: 37.7232 - val_neg_log_likelihood: 391678250106234011648.0000\n",
      "Epoch 537/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 18.9829 - squared_difference_loss: 15.7031 - KL_divergence_loss: 3.2798 - neg_log_likelihood: 141253.3282 - val_loss: 52.5872 - val_squared_difference_loss: 15.4372 - val_KL_divergence_loss: 37.1500 - val_neg_log_likelihood: 183031112233972498432.0000\n",
      "Epoch 538/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.8494 - squared_difference_loss: 15.7049 - KL_divergence_loss: 3.1445 - neg_log_likelihood: 89629316.7690 - val_loss: 51.5559 - val_squared_difference_loss: 15.4966 - val_KL_divergence_loss: 36.0592 - val_neg_log_likelihood: 30392556618650546176.0000\n",
      "Epoch 539/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.8525 - squared_difference_loss: 15.6670 - KL_divergence_loss: 3.1855 - neg_log_likelihood: 3578835.8990 - val_loss: 52.1384 - val_squared_difference_loss: 15.4032 - val_KL_divergence_loss: 36.7352 - val_neg_log_likelihood: 289612097387824448.0000\n",
      "Epoch 540/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 19.0841 - squared_difference_loss: 15.7283 - KL_divergence_loss: 3.3558 - neg_log_likelihood: 709815.4098 - val_loss: 51.6105 - val_squared_difference_loss: 16.0871 - val_KL_divergence_loss: 35.5234 - val_neg_log_likelihood: inf\n",
      "Epoch 541/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.8977 - squared_difference_loss: 15.6799 - KL_divergence_loss: 3.2178 - neg_log_likelihood: 11981892.6785 - val_loss: 50.5633 - val_squared_difference_loss: 15.7588 - val_KL_divergence_loss: 34.8045 - val_neg_log_likelihood: inf\n",
      "Epoch 542/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.9093 - squared_difference_loss: 15.6252 - KL_divergence_loss: 3.2841 - neg_log_likelihood: 91664832.5970 - val_loss: 48.7860 - val_squared_difference_loss: 15.3492 - val_KL_divergence_loss: 33.4369 - val_neg_log_likelihood: 2689634215180.3564\n",
      "Epoch 543/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.9374 - squared_difference_loss: 15.6725 - KL_divergence_loss: 3.2649 - neg_log_likelihood: 28364503.0977 - val_loss: 46.6433 - val_squared_difference_loss: 15.8168 - val_KL_divergence_loss: 30.8265 - val_neg_log_likelihood: inf\n",
      "Epoch 544/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.9794 - squared_difference_loss: 15.6239 - KL_divergence_loss: 3.3555 - neg_log_likelihood: 2498993.0291 - val_loss: 45.0347 - val_squared_difference_loss: 16.4146 - val_KL_divergence_loss: 28.6201 - val_neg_log_likelihood: inf\n",
      "Epoch 545/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.7815 - squared_difference_loss: 15.6509 - KL_divergence_loss: 3.1306 - neg_log_likelihood: 1254289.1748 - val_loss: 42.5667 - val_squared_difference_loss: 15.3374 - val_KL_divergence_loss: 27.2293 - val_neg_log_likelihood: 112393045002958127104.0000\n",
      "Epoch 546/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 18.9957 - squared_difference_loss: 15.6517 - KL_divergence_loss: 3.3439 - neg_log_likelihood: 1642889.6892 - val_loss: 42.8722 - val_squared_difference_loss: 15.3445 - val_KL_divergence_loss: 27.5277 - val_neg_log_likelihood: 2093892329494305570816.0000\n",
      "Epoch 547/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.8701 - squared_difference_loss: 15.6108 - KL_divergence_loss: 3.2593 - neg_log_likelihood: 19457878.9469 - val_loss: 41.4289 - val_squared_difference_loss: 15.5595 - val_KL_divergence_loss: 25.8694 - val_neg_log_likelihood: 6021972202271833354928128.0000\n",
      "Epoch 548/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.7994 - squared_difference_loss: 15.5697 - KL_divergence_loss: 3.2297 - neg_log_likelihood: 3920800.9114 - val_loss: 49.8054 - val_squared_difference_loss: 23.5238 - val_KL_divergence_loss: 26.2815 - val_neg_log_likelihood: inf\n",
      "Epoch 549/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 18.9142 - squared_difference_loss: 15.6206 - KL_divergence_loss: 3.2936 - neg_log_likelihood: 8676030.7352 - val_loss: 50.6326 - val_squared_difference_loss: 24.1661 - val_KL_divergence_loss: 26.4665 - val_neg_log_likelihood: inf\n",
      "Epoch 550/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.7791 - squared_difference_loss: 15.5856 - KL_divergence_loss: 3.1935 - neg_log_likelihood: 6552983.4852 - val_loss: 45.3397 - val_squared_difference_loss: 18.8203 - val_KL_divergence_loss: 26.5195 - val_neg_log_likelihood: inf\n",
      "Epoch 551/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.8969 - squared_difference_loss: 15.5698 - KL_divergence_loss: 3.3271 - neg_log_likelihood: 1329168.4119 - val_loss: 44.4234 - val_squared_difference_loss: 17.3736 - val_KL_divergence_loss: 27.0498 - val_neg_log_likelihood: inf\n",
      "Epoch 552/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.8833 - squared_difference_loss: 15.5783 - KL_divergence_loss: 3.3051 - neg_log_likelihood: 2193617.5946 - val_loss: 41.5396 - val_squared_difference_loss: 16.9417 - val_KL_divergence_loss: 24.5979 - val_neg_log_likelihood: inf\n",
      "Epoch 553/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 18.7870 - squared_difference_loss: 15.5223 - KL_divergence_loss: 3.2647 - neg_log_likelihood: 269722739.3774 - val_loss: 39.6065 - val_squared_difference_loss: 16.4810 - val_KL_divergence_loss: 23.1254 - val_neg_log_likelihood: inf\n",
      "Epoch 554/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.6821 - squared_difference_loss: 15.5337 - KL_divergence_loss: 3.1485 - neg_log_likelihood: 27864676.6738 - val_loss: 38.2011 - val_squared_difference_loss: 15.3628 - val_KL_divergence_loss: 22.8384 - val_neg_log_likelihood: 223340435944007714996224.0000\n",
      "Epoch 555/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.7551 - squared_difference_loss: 15.5106 - KL_divergence_loss: 3.2445 - neg_log_likelihood: 1116521.8421 - val_loss: 43.2034 - val_squared_difference_loss: 19.4618 - val_KL_divergence_loss: 23.7417 - val_neg_log_likelihood: inf\n",
      "Epoch 556/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 18.7557 - squared_difference_loss: 15.5184 - KL_divergence_loss: 3.2373 - neg_log_likelihood: 142367259757.6658 - val_loss: 39.0706 - val_squared_difference_loss: 15.2577 - val_KL_divergence_loss: 23.8128 - val_neg_log_likelihood: 1047042877513565.3750\n",
      "Epoch 557/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.8254 - squared_difference_loss: 15.5266 - KL_divergence_loss: 3.2988 - neg_log_likelihood: 2895441.6121 - val_loss: 38.5258 - val_squared_difference_loss: 15.4010 - val_KL_divergence_loss: 23.1248 - val_neg_log_likelihood: 390814751557256151040.0000\n",
      "Epoch 558/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.6671 - squared_difference_loss: 15.4396 - KL_divergence_loss: 3.2275 - neg_log_likelihood: 16874796.3989 - val_loss: 39.2241 - val_squared_difference_loss: 15.4281 - val_KL_divergence_loss: 23.7961 - val_neg_log_likelihood: 2277568828885284159488.0000\n",
      "Epoch 559/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 18.7310 - squared_difference_loss: 15.4716 - KL_divergence_loss: 3.2595 - neg_log_likelihood: 7309299.4775 - val_loss: 44.0938 - val_squared_difference_loss: 21.0149 - val_KL_divergence_loss: 23.0789 - val_neg_log_likelihood: inf\n",
      "Epoch 560/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.7514 - squared_difference_loss: 15.4860 - KL_divergence_loss: 3.2654 - neg_log_likelihood: 3555499.0642 - val_loss: 37.8627 - val_squared_difference_loss: 15.2175 - val_KL_divergence_loss: 22.6452 - val_neg_log_likelihood: 143245267565.8453\n",
      "Epoch 561/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.6398 - squared_difference_loss: 15.4422 - KL_divergence_loss: 3.1976 - neg_log_likelihood: 12647950.6191 - val_loss: 38.5860 - val_squared_difference_loss: 16.4592 - val_KL_divergence_loss: 22.1268 - val_neg_log_likelihood: inf\n",
      "Epoch 562/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 18.5957 - squared_difference_loss: 15.4226 - KL_divergence_loss: 3.1731 - neg_log_likelihood: 14796601.2560 - val_loss: 37.7068 - val_squared_difference_loss: 15.3407 - val_KL_divergence_loss: 22.3661 - val_neg_log_likelihood: 3403393505423247710512742400.0000\n",
      "Epoch 563/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.5835 - squared_difference_loss: 15.3759 - KL_divergence_loss: 3.2077 - neg_log_likelihood: 23920040.5697 - val_loss: 37.9951 - val_squared_difference_loss: 15.0503 - val_KL_divergence_loss: 22.9447 - val_neg_log_likelihood: 97937827500.7903\n",
      "Epoch 564/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.5680 - squared_difference_loss: 15.3953 - KL_divergence_loss: 3.1727 - neg_log_likelihood: 15530352.1523 - val_loss: 38.9394 - val_squared_difference_loss: 15.4472 - val_KL_divergence_loss: 23.4922 - val_neg_log_likelihood: 10010325164659075915134427147010048.0000\n",
      "Epoch 565/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 18.6264 - squared_difference_loss: 15.4279 - KL_divergence_loss: 3.1984 - neg_log_likelihood: 380554.7993 - val_loss: 39.2253 - val_squared_difference_loss: 15.9319 - val_KL_divergence_loss: 23.2934 - val_neg_log_likelihood: 1476980612959608365795696481140736.0000\n",
      "Epoch 566/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.6450 - squared_difference_loss: 15.3765 - KL_divergence_loss: 3.2685 - neg_log_likelihood: 241825789.8678 - val_loss: 38.9024 - val_squared_difference_loss: 15.2206 - val_KL_divergence_loss: 23.6818 - val_neg_log_likelihood: 2445740728373625344.0000\n",
      "Epoch 567/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.5539 - squared_difference_loss: 15.3380 - KL_divergence_loss: 3.2159 - neg_log_likelihood: 19135659.2363 - val_loss: 39.0719 - val_squared_difference_loss: 15.1759 - val_KL_divergence_loss: 23.8960 - val_neg_log_likelihood: 850145738750932700626944.0000\n",
      "Epoch 568/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 18.5899 - squared_difference_loss: 15.3721 - KL_divergence_loss: 3.2178 - neg_log_likelihood: 6637161.9009 - val_loss: 40.5693 - val_squared_difference_loss: 16.1567 - val_KL_divergence_loss: 24.4126 - val_neg_log_likelihood: inf\n",
      "Epoch 569/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.4774 - squared_difference_loss: 15.3144 - KL_divergence_loss: 3.1630 - neg_log_likelihood: 2314777.1627 - val_loss: 60.5074 - val_squared_difference_loss: 35.8086 - val_KL_divergence_loss: 24.6988 - val_neg_log_likelihood: inf\n",
      "Epoch 570/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.6050 - squared_difference_loss: 15.3179 - KL_divergence_loss: 3.2870 - neg_log_likelihood: 13898796.6255 - val_loss: 42.1124 - val_squared_difference_loss: 17.6790 - val_KL_divergence_loss: 24.4334 - val_neg_log_likelihood: inf\n",
      "Epoch 571/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.5633 - squared_difference_loss: 15.3284 - KL_divergence_loss: 3.2348 - neg_log_likelihood: 14733061.4342 - val_loss: 48.8315 - val_squared_difference_loss: 25.4465 - val_KL_divergence_loss: 23.3850 - val_neg_log_likelihood: inf\n",
      "Epoch 572/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.5643 - squared_difference_loss: 15.3177 - KL_divergence_loss: 3.2466 - neg_log_likelihood: 20120911.4083 - val_loss: 38.1076 - val_squared_difference_loss: 15.1114 - val_KL_divergence_loss: 22.9962 - val_neg_log_likelihood: 3801507703046.2573\n",
      "Epoch 573/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.5187 - squared_difference_loss: 15.3072 - KL_divergence_loss: 3.2115 - neg_log_likelihood: 46544866.5753 - val_loss: 44.3085 - val_squared_difference_loss: 21.9068 - val_KL_divergence_loss: 22.4017 - val_neg_log_likelihood: inf\n",
      "Epoch 574/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.5519 - squared_difference_loss: 15.2978 - KL_divergence_loss: 3.2541 - neg_log_likelihood: 13823667.5163 - val_loss: 37.7384 - val_squared_difference_loss: 15.2980 - val_KL_divergence_loss: 22.4404 - val_neg_log_likelihood: 842121754778377859660809364307968.0000\n",
      "Epoch 575/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 18.5010 - squared_difference_loss: 15.3210 - KL_divergence_loss: 3.1800 - neg_log_likelihood: 2343654856.3781 - val_loss: 37.0771 - val_squared_difference_loss: 15.0309 - val_KL_divergence_loss: 22.0463 - val_neg_log_likelihood: 5016771640773.8506\n",
      "Epoch 576/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.5010 - squared_difference_loss: 15.2486 - KL_divergence_loss: 3.2525 - neg_log_likelihood: 444899963.9276 - val_loss: 38.0124 - val_squared_difference_loss: 16.2355 - val_KL_divergence_loss: 21.7769 - val_neg_log_likelihood: 2504304638387956883245587371130880.0000\n",
      "Epoch 577/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.5528 - squared_difference_loss: 15.2725 - KL_divergence_loss: 3.2803 - neg_log_likelihood: 37081348.7225 - val_loss: 36.9091 - val_squared_difference_loss: 16.5778 - val_KL_divergence_loss: 20.3312 - val_neg_log_likelihood: inf\n",
      "Epoch 578/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 18.5487 - squared_difference_loss: 15.3161 - KL_divergence_loss: 3.2326 - neg_log_likelihood: 3596205184.0029 - val_loss: 35.5132 - val_squared_difference_loss: 16.0242 - val_KL_divergence_loss: 19.4890 - val_neg_log_likelihood: inf\n",
      "Epoch 579/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.4505 - squared_difference_loss: 15.2790 - KL_divergence_loss: 3.1715 - neg_log_likelihood: 9241719.0716 - val_loss: 34.3814 - val_squared_difference_loss: 15.0935 - val_KL_divergence_loss: 19.2879 - val_neg_log_likelihood: 43281517621424488.0000\n",
      "Epoch 580/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 18.4727 - squared_difference_loss: 15.2532 - KL_divergence_loss: 3.2195 - neg_log_likelihood: 8319454.7468 - val_loss: 38.6987 - val_squared_difference_loss: 18.0041 - val_KL_divergence_loss: 20.6946 - val_neg_log_likelihood: inf\n",
      "Epoch 581/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 18.6232 - squared_difference_loss: 15.2806 - KL_divergence_loss: 3.3427 - neg_log_likelihood: 59218648.8016 - val_loss: 35.9198 - val_squared_difference_loss: 15.2150 - val_KL_divergence_loss: 20.7048 - val_neg_log_likelihood: 155831911259805912662016.0000\n",
      "Epoch 582/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.4600 - squared_difference_loss: 15.2592 - KL_divergence_loss: 3.2009 - neg_log_likelihood: 8044324.6370 - val_loss: 39.7591 - val_squared_difference_loss: 19.7261 - val_KL_divergence_loss: 20.0331 - val_neg_log_likelihood: inf\n",
      "Epoch 583/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.5502 - squared_difference_loss: 15.2112 - KL_divergence_loss: 3.3390 - neg_log_likelihood: 159459164.6771 - val_loss: 35.1201 - val_squared_difference_loss: 15.0493 - val_KL_divergence_loss: 20.0709 - val_neg_log_likelihood: 4683467106204997632.0000\n",
      "Epoch 584/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 18.4634 - squared_difference_loss: 15.2253 - KL_divergence_loss: 3.2380 - neg_log_likelihood: 76358136.6752 - val_loss: 34.6713 - val_squared_difference_loss: 16.4725 - val_KL_divergence_loss: 18.1989 - val_neg_log_likelihood: inf\n",
      "Epoch 585/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.4708 - squared_difference_loss: 15.2572 - KL_divergence_loss: 3.2136 - neg_log_likelihood: 4754628.0920 - val_loss: 31.9121 - val_squared_difference_loss: 15.0266 - val_KL_divergence_loss: 16.8855 - val_neg_log_likelihood: 252749333448580896.0000\n",
      "Epoch 586/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.4778 - squared_difference_loss: 15.2216 - KL_divergence_loss: 3.2562 - neg_log_likelihood: 9221872.5486 - val_loss: 32.9117 - val_squared_difference_loss: 15.9175 - val_KL_divergence_loss: 16.9942 - val_neg_log_likelihood: 12842159548407413720821298024677376.0000\n",
      "Epoch 587/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 18.4904 - squared_difference_loss: 15.2225 - KL_divergence_loss: 3.2679 - neg_log_likelihood: 439506941.1211 - val_loss: 32.0763 - val_squared_difference_loss: 14.9824 - val_KL_divergence_loss: 17.0940 - val_neg_log_likelihood: 63764219953429807104.0000\n",
      "Epoch 588/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.4584 - squared_difference_loss: 15.1376 - KL_divergence_loss: 3.3208 - neg_log_likelihood: 15630015.0321 - val_loss: 31.7733 - val_squared_difference_loss: 15.4298 - val_KL_divergence_loss: 16.3435 - val_neg_log_likelihood: 46055517868407354019545088.0000\n",
      "Epoch 589/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.3770 - squared_difference_loss: 15.1787 - KL_divergence_loss: 3.1983 - neg_log_likelihood: 37158802.7751 - val_loss: 34.2101 - val_squared_difference_loss: 18.3756 - val_KL_divergence_loss: 15.8345 - val_neg_log_likelihood: inf\n",
      "Epoch 590/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 18.3766 - squared_difference_loss: 15.1631 - KL_divergence_loss: 3.2135 - neg_log_likelihood: 49794589.2485 - val_loss: 31.5854 - val_squared_difference_loss: 15.5303 - val_KL_divergence_loss: 16.0552 - val_neg_log_likelihood: 57477237944711134446918565888.0000\n",
      "Epoch 591/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.3099 - squared_difference_loss: 15.1171 - KL_divergence_loss: 3.1928 - neg_log_likelihood: 4751261.6521 - val_loss: 34.5279 - val_squared_difference_loss: 18.2193 - val_KL_divergence_loss: 16.3086 - val_neg_log_likelihood: inf\n",
      "Epoch 592/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.3243 - squared_difference_loss: 15.1609 - KL_divergence_loss: 3.1635 - neg_log_likelihood: 28827730.4036 - val_loss: 32.6953 - val_squared_difference_loss: 16.0732 - val_KL_divergence_loss: 16.6221 - val_neg_log_likelihood: inf\n",
      "Epoch 593/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.3202 - squared_difference_loss: 15.1071 - KL_divergence_loss: 3.2131 - neg_log_likelihood: 23571826.0179 - val_loss: 32.1968 - val_squared_difference_loss: 15.2005 - val_KL_divergence_loss: 16.9963 - val_neg_log_likelihood: 4219621255368691555882998127656960.0000\n",
      "Epoch 594/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.3707 - squared_difference_loss: 15.1118 - KL_divergence_loss: 3.2589 - neg_log_likelihood: 20360628.1715 - val_loss: 31.7420 - val_squared_difference_loss: 15.0719 - val_KL_divergence_loss: 16.6701 - val_neg_log_likelihood: 106177437869203914752.0000\n",
      "Epoch 595/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.2605 - squared_difference_loss: 15.0916 - KL_divergence_loss: 3.1689 - neg_log_likelihood: 12680983.2972 - val_loss: 31.3662 - val_squared_difference_loss: 14.8608 - val_KL_divergence_loss: 16.5054 - val_neg_log_likelihood: 19612576348316315648.0000\n",
      "Epoch 596/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 18.2877 - squared_difference_loss: 15.0994 - KL_divergence_loss: 3.1883 - neg_log_likelihood: 4873782.5395 - val_loss: 33.0828 - val_squared_difference_loss: 15.9596 - val_KL_divergence_loss: 17.1232 - val_neg_log_likelihood: inf\n",
      "Epoch 597/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.3245 - squared_difference_loss: 15.0812 - KL_divergence_loss: 3.2433 - neg_log_likelihood: 22041805.8505 - val_loss: 31.5756 - val_squared_difference_loss: 14.8034 - val_KL_divergence_loss: 16.7721 - val_neg_log_likelihood: 27063801429329.9648\n",
      "Epoch 598/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.3278 - squared_difference_loss: 15.1001 - KL_divergence_loss: 3.2277 - neg_log_likelihood: 30517545.1570 - val_loss: 31.3803 - val_squared_difference_loss: 14.8626 - val_KL_divergence_loss: 16.5177 - val_neg_log_likelihood: 8461022874228073472.0000\n",
      "Epoch 599/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 18.3964 - squared_difference_loss: 15.1125 - KL_divergence_loss: 3.2838 - neg_log_likelihood: 8144469.1325 - val_loss: 33.2824 - val_squared_difference_loss: 17.5273 - val_KL_divergence_loss: 15.7551 - val_neg_log_likelihood: inf\n",
      "Epoch 600/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 18.2695 - squared_difference_loss: 15.0458 - KL_divergence_loss: 3.2236 - neg_log_likelihood: 61244006.6190 - val_loss: 31.8439 - val_squared_difference_loss: 16.7617 - val_KL_divergence_loss: 15.0822 - val_neg_log_likelihood: inf\n",
      "Epoch 601/2000\n",
      "29507/29507 [==============================] - 1s 19us/step - loss: 18.3849 - squared_difference_loss: 15.0993 - KL_divergence_loss: 3.2856 - neg_log_likelihood: 4477057636.4320 - val_loss: 29.3839 - val_squared_difference_loss: 14.9188 - val_KL_divergence_loss: 14.4651 - val_neg_log_likelihood: 7284650628204736512.0000\n",
      "Epoch 602/2000\n",
      "29507/29507 [==============================] - 1s 19us/step - loss: 18.3140 - squared_difference_loss: 15.1037 - KL_divergence_loss: 3.2103 - neg_log_likelihood: 37593317.5574 - val_loss: 33.2474 - val_squared_difference_loss: 19.3928 - val_KL_divergence_loss: 13.8546 - val_neg_log_likelihood: inf\n",
      "Epoch 603/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 18.1954 - squared_difference_loss: 15.0279 - KL_divergence_loss: 3.1675 - neg_log_likelihood: 9192783.9895 - val_loss: 28.9442 - val_squared_difference_loss: 15.0016 - val_KL_divergence_loss: 13.9426 - val_neg_log_likelihood: 54201979111350052721149882662912.0000\n",
      "Epoch 604/2000\n",
      "29507/29507 [==============================] - 1s 19us/step - loss: 18.1937 - squared_difference_loss: 15.0350 - KL_divergence_loss: 3.1587 - neg_log_likelihood: 12028865.1863 - val_loss: 30.0981 - val_squared_difference_loss: 16.0749 - val_KL_divergence_loss: 14.0232 - val_neg_log_likelihood: inf\n",
      "Epoch 605/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 18.2338 - squared_difference_loss: 15.0332 - KL_divergence_loss: 3.2005 - neg_log_likelihood: 15519989.5504 - val_loss: 30.0574 - val_squared_difference_loss: 15.6792 - val_KL_divergence_loss: 14.3782 - val_neg_log_likelihood: 29202046996827143197649304289280.0000\n",
      "Epoch 606/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.1972 - squared_difference_loss: 15.0042 - KL_divergence_loss: 3.1930 - neg_log_likelihood: 142535991.4225 - val_loss: 29.1182 - val_squared_difference_loss: 14.9138 - val_KL_divergence_loss: 14.2044 - val_neg_log_likelihood: 159407090269241921187434463232.0000\n",
      "Epoch 607/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 18.1665 - squared_difference_loss: 14.9812 - KL_divergence_loss: 3.1854 - neg_log_likelihood: 211616215.5361 - val_loss: 29.2429 - val_squared_difference_loss: 15.0172 - val_KL_divergence_loss: 14.2257 - val_neg_log_likelihood: 11153993340210417588606798397440.0000\n",
      "Epoch 608/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 18.2646 - squared_difference_loss: 15.0375 - KL_divergence_loss: 3.2270 - neg_log_likelihood: 20049656.6617 - val_loss: 28.9670 - val_squared_difference_loss: 15.0834 - val_KL_divergence_loss: 13.8836 - val_neg_log_likelihood: inf\n",
      "Epoch 609/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 18.2525 - squared_difference_loss: 15.0116 - KL_divergence_loss: 3.2409 - neg_log_likelihood: 64659188.5172 - val_loss: 28.4573 - val_squared_difference_loss: 15.1553 - val_KL_divergence_loss: 13.3019 - val_neg_log_likelihood: 109375551791745843200.0000\n",
      "Epoch 610/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 18.1461 - squared_difference_loss: 14.9584 - KL_divergence_loss: 3.1876 - neg_log_likelihood: 5450482.9483 - val_loss: 28.5924 - val_squared_difference_loss: 15.4117 - val_KL_divergence_loss: 13.1808 - val_neg_log_likelihood: inf\n",
      "Epoch 611/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.1646 - squared_difference_loss: 15.0074 - KL_divergence_loss: 3.1571 - neg_log_likelihood: 1470229.3140 - val_loss: 32.0274 - val_squared_difference_loss: 18.3239 - val_KL_divergence_loss: 13.7034 - val_neg_log_likelihood: inf\n",
      "Epoch 612/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 18.1941 - squared_difference_loss: 14.9579 - KL_divergence_loss: 3.2362 - neg_log_likelihood: 11206978.8272 - val_loss: 29.4911 - val_squared_difference_loss: 14.9539 - val_KL_divergence_loss: 14.5373 - val_neg_log_likelihood: 75495040878143265226932732559360.0000\n",
      "Epoch 613/2000\n",
      "29507/29507 [==============================] - 1s 19us/step - loss: 18.1634 - squared_difference_loss: 14.9533 - KL_divergence_loss: 3.2101 - neg_log_likelihood: 206993024.5890 - val_loss: 31.6998 - val_squared_difference_loss: 17.1311 - val_KL_divergence_loss: 14.5686 - val_neg_log_likelihood: inf\n",
      "Epoch 614/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 18.1634 - squared_difference_loss: 14.9556 - KL_divergence_loss: 3.2078 - neg_log_likelihood: 23153229.9115 - val_loss: 29.6566 - val_squared_difference_loss: 15.0141 - val_KL_divergence_loss: 14.6425 - val_neg_log_likelihood: inf\n",
      "Epoch 615/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 18.0934 - squared_difference_loss: 14.9138 - KL_divergence_loss: 3.1795 - neg_log_likelihood: 108198296.6406 - val_loss: 31.9081 - val_squared_difference_loss: 17.1291 - val_KL_divergence_loss: 14.7791 - val_neg_log_likelihood: inf\n",
      "Epoch 616/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.1704 - squared_difference_loss: 14.9809 - KL_divergence_loss: 3.1895 - neg_log_likelihood: 127755554.6460 - val_loss: 29.6702 - val_squared_difference_loss: 14.7090 - val_KL_divergence_loss: 14.9612 - val_neg_log_likelihood: 60938195487098288.0000\n",
      "Epoch 617/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.1366 - squared_difference_loss: 14.9044 - KL_divergence_loss: 3.2322 - neg_log_likelihood: 101080457.5293 - val_loss: 29.1933 - val_squared_difference_loss: 14.7116 - val_KL_divergence_loss: 14.4817 - val_neg_log_likelihood: 690547638903081.7500\n",
      "Epoch 618/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.0850 - squared_difference_loss: 14.9048 - KL_divergence_loss: 3.1802 - neg_log_likelihood: 7682421.1789 - val_loss: 37.1247 - val_squared_difference_loss: 22.3326 - val_KL_divergence_loss: 14.7920 - val_neg_log_likelihood: inf\n",
      "Epoch 619/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.1232 - squared_difference_loss: 14.9198 - KL_divergence_loss: 3.2034 - neg_log_likelihood: 58222971.7800 - val_loss: 29.7840 - val_squared_difference_loss: 14.8864 - val_KL_divergence_loss: 14.8976 - val_neg_log_likelihood: 932552608467534336.0000\n",
      "Epoch 620/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.1536 - squared_difference_loss: 14.9489 - KL_divergence_loss: 3.2047 - neg_log_likelihood: 56840871.3350 - val_loss: 29.7782 - val_squared_difference_loss: 15.4616 - val_KL_divergence_loss: 14.3166 - val_neg_log_likelihood: inf\n",
      "Epoch 621/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.0737 - squared_difference_loss: 14.8776 - KL_divergence_loss: 3.1962 - neg_log_likelihood: 64325580.2788 - val_loss: 28.4918 - val_squared_difference_loss: 14.7537 - val_KL_divergence_loss: 13.7381 - val_neg_log_likelihood: 428340923698142974574592.0000\n",
      "Epoch 622/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 18.1004 - squared_difference_loss: 14.8927 - KL_divergence_loss: 3.2077 - neg_log_likelihood: 36939844.0981 - val_loss: 28.5364 - val_squared_difference_loss: 14.6547 - val_KL_divergence_loss: 13.8817 - val_neg_log_likelihood: 1632806868621500.0000\n",
      "Epoch 623/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.1239 - squared_difference_loss: 14.9177 - KL_divergence_loss: 3.2062 - neg_log_likelihood: 8846449.1321 - val_loss: 29.0854 - val_squared_difference_loss: 15.2699 - val_KL_divergence_loss: 13.8155 - val_neg_log_likelihood: inf\n",
      "Epoch 624/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.1389 - squared_difference_loss: 14.9133 - KL_divergence_loss: 3.2256 - neg_log_likelihood: 15045241.2164 - val_loss: 27.5847 - val_squared_difference_loss: 14.6096 - val_KL_divergence_loss: 12.9751 - val_neg_log_likelihood: 1529705566017139.7500\n",
      "Epoch 625/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 18.0074 - squared_difference_loss: 14.8305 - KL_divergence_loss: 3.1770 - neg_log_likelihood: 68716635.1336 - val_loss: 27.6568 - val_squared_difference_loss: 14.6281 - val_KL_divergence_loss: 13.0288 - val_neg_log_likelihood: 54368428108.5789\n",
      "Epoch 626/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 18.1085 - squared_difference_loss: 14.8627 - KL_divergence_loss: 3.2459 - neg_log_likelihood: 9478652.1629 - val_loss: 27.7126 - val_squared_difference_loss: 14.6500 - val_KL_divergence_loss: 13.0625 - val_neg_log_likelihood: 37429513649058.2578\n",
      "Epoch 627/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 18.0285 - squared_difference_loss: 14.8360 - KL_divergence_loss: 3.1925 - neg_log_likelihood: 68220091.0496 - val_loss: 28.3110 - val_squared_difference_loss: 15.5922 - val_KL_divergence_loss: 12.7189 - val_neg_log_likelihood: inf\n",
      "Epoch 628/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 18.0316 - squared_difference_loss: 14.8669 - KL_divergence_loss: 3.1647 - neg_log_likelihood: 1446350317.5644 - val_loss: 35.9106 - val_squared_difference_loss: 22.6855 - val_KL_divergence_loss: 13.2250 - val_neg_log_likelihood: inf\n",
      "Epoch 629/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.9932 - squared_difference_loss: 14.8329 - KL_divergence_loss: 3.1603 - neg_log_likelihood: 39144291.0179 - val_loss: 28.3688 - val_squared_difference_loss: 14.7033 - val_KL_divergence_loss: 13.6655 - val_neg_log_likelihood: 9491736325655763185207083008.0000\n",
      "Epoch 630/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 18.0369 - squared_difference_loss: 14.8361 - KL_divergence_loss: 3.2008 - neg_log_likelihood: 1716898021069.3486 - val_loss: 28.9677 - val_squared_difference_loss: 14.8521 - val_KL_divergence_loss: 14.1156 - val_neg_log_likelihood: 705172869379693084672.0000\n",
      "Epoch 631/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 18.0960 - squared_difference_loss: 14.8711 - KL_divergence_loss: 3.2249 - neg_log_likelihood: 284543384.5791 - val_loss: 28.3762 - val_squared_difference_loss: 14.6398 - val_KL_divergence_loss: 13.7364 - val_neg_log_likelihood: 669088721994205.5000\n",
      "Epoch 632/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 18.0175 - squared_difference_loss: 14.8520 - KL_divergence_loss: 3.1654 - neg_log_likelihood: 4330970.9903 - val_loss: 28.3451 - val_squared_difference_loss: 14.6848 - val_KL_divergence_loss: 13.6603 - val_neg_log_likelihood: 15840099181730383872.0000\n",
      "Epoch 633/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 18.0021 - squared_difference_loss: 14.8185 - KL_divergence_loss: 3.1836 - neg_log_likelihood: 97159133.1615 - val_loss: 28.7322 - val_squared_difference_loss: 15.1217 - val_KL_divergence_loss: 13.6105 - val_neg_log_likelihood: inf\n",
      "Epoch 634/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 18.0464 - squared_difference_loss: 14.8090 - KL_divergence_loss: 3.2373 - neg_log_likelihood: 27960499.9368 - val_loss: 38.2642 - val_squared_difference_loss: 24.8766 - val_KL_divergence_loss: 13.3876 - val_neg_log_likelihood: inf\n",
      "Epoch 635/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.9302 - squared_difference_loss: 14.7883 - KL_divergence_loss: 3.1419 - neg_log_likelihood: 3899689.1222 - val_loss: 28.1071 - val_squared_difference_loss: 14.6070 - val_KL_divergence_loss: 13.5001 - val_neg_log_likelihood: 129560636993.1528\n",
      "Epoch 636/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 18.0163 - squared_difference_loss: 14.8338 - KL_divergence_loss: 3.1825 - neg_log_likelihood: 59201555.7286 - val_loss: 28.3606 - val_squared_difference_loss: 15.0212 - val_KL_divergence_loss: 13.3394 - val_neg_log_likelihood: inf\n",
      "Epoch 637/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 18.0108 - squared_difference_loss: 14.8087 - KL_divergence_loss: 3.2021 - neg_log_likelihood: 47391185.1437 - val_loss: 28.5833 - val_squared_difference_loss: 15.4132 - val_KL_divergence_loss: 13.1701 - val_neg_log_likelihood: inf\n",
      "Epoch 638/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.9520 - squared_difference_loss: 14.7975 - KL_divergence_loss: 3.1546 - neg_log_likelihood: 13785789.2820 - val_loss: 27.9150 - val_squared_difference_loss: 14.5835 - val_KL_divergence_loss: 13.3315 - val_neg_log_likelihood: 8889992682.6889\n",
      "Epoch 639/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 18.0372 - squared_difference_loss: 14.8305 - KL_divergence_loss: 3.2067 - neg_log_likelihood: 44244300.5715 - val_loss: 29.4694 - val_squared_difference_loss: 15.8400 - val_KL_divergence_loss: 13.6294 - val_neg_log_likelihood: inf\n",
      "Epoch 640/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.9021 - squared_difference_loss: 14.7301 - KL_divergence_loss: 3.1721 - neg_log_likelihood: 44101106.4691 - val_loss: 28.0961 - val_squared_difference_loss: 14.5638 - val_KL_divergence_loss: 13.5323 - val_neg_log_likelihood: 4739014917022061568.0000\n",
      "Epoch 641/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.9464 - squared_difference_loss: 14.7532 - KL_divergence_loss: 3.1932 - neg_log_likelihood: 85805835.7695 - val_loss: 27.8694 - val_squared_difference_loss: 14.6322 - val_KL_divergence_loss: 13.2371 - val_neg_log_likelihood: 542329238357.1763\n",
      "Epoch 642/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.9644 - squared_difference_loss: 14.7636 - KL_divergence_loss: 3.2009 - neg_log_likelihood: 6370135.0034 - val_loss: 27.1134 - val_squared_difference_loss: 14.5436 - val_KL_divergence_loss: 12.5698 - val_neg_log_likelihood: 53155578448.9094\n",
      "Epoch 643/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.8854 - squared_difference_loss: 14.7194 - KL_divergence_loss: 3.1660 - neg_log_likelihood: 32090862.6812 - val_loss: 27.9014 - val_squared_difference_loss: 15.4652 - val_KL_divergence_loss: 12.4361 - val_neg_log_likelihood: inf\n",
      "Epoch 644/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.9248 - squared_difference_loss: 14.7194 - KL_divergence_loss: 3.2054 - neg_log_likelihood: 6175522.2899 - val_loss: 26.6168 - val_squared_difference_loss: 14.5917 - val_KL_divergence_loss: 12.0251 - val_neg_log_likelihood: 157640141943321165824.0000\n",
      "Epoch 645/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.9455 - squared_difference_loss: 14.7619 - KL_divergence_loss: 3.1836 - neg_log_likelihood: 100830925.6767 - val_loss: 26.1492 - val_squared_difference_loss: 14.6805 - val_KL_divergence_loss: 11.4687 - val_neg_log_likelihood: 21538441876728956388701819109376.0000\n",
      "Epoch 646/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 17.9584 - squared_difference_loss: 14.7699 - KL_divergence_loss: 3.1885 - neg_log_likelihood: 28368709.6067 - val_loss: 27.1166 - val_squared_difference_loss: 15.8618 - val_KL_divergence_loss: 11.2548 - val_neg_log_likelihood: inf\n",
      "Epoch 647/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.8955 - squared_difference_loss: 14.7097 - KL_divergence_loss: 3.1858 - neg_log_likelihood: 80940737.1813 - val_loss: 27.2429 - val_squared_difference_loss: 15.7505 - val_KL_divergence_loss: 11.4924 - val_neg_log_likelihood: 243958661705686520730715724709888.0000\n",
      "Epoch 648/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.9240 - squared_difference_loss: 14.7218 - KL_divergence_loss: 3.2022 - neg_log_likelihood: 143867825.8989 - val_loss: 25.6242 - val_squared_difference_loss: 14.6624 - val_KL_divergence_loss: 10.9618 - val_neg_log_likelihood: 16706814127943660339200.0000\n",
      "Epoch 649/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.9166 - squared_difference_loss: 14.7195 - KL_divergence_loss: 3.1971 - neg_log_likelihood: 35266888.2927 - val_loss: 27.1205 - val_squared_difference_loss: 16.5696 - val_KL_divergence_loss: 10.5510 - val_neg_log_likelihood: inf\n",
      "Epoch 650/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.9116 - squared_difference_loss: 14.7389 - KL_divergence_loss: 3.1727 - neg_log_likelihood: 10636307.4364 - val_loss: 24.3434 - val_squared_difference_loss: 14.5206 - val_KL_divergence_loss: 9.8228 - val_neg_log_likelihood: 736156184465.1592\n",
      "Epoch 651/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.9091 - squared_difference_loss: 14.7396 - KL_divergence_loss: 3.1695 - neg_log_likelihood: 5299316.7760 - val_loss: 28.2349 - val_squared_difference_loss: 18.5749 - val_KL_divergence_loss: 9.6600 - val_neg_log_likelihood: inf\n",
      "Epoch 652/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.8719 - squared_difference_loss: 14.6771 - KL_divergence_loss: 3.1948 - neg_log_likelihood: 46386122.7310 - val_loss: 25.7471 - val_squared_difference_loss: 16.0564 - val_KL_divergence_loss: 9.6907 - val_neg_log_likelihood: 865271047533250423200898609053696.0000\n",
      "Epoch 653/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.8870 - squared_difference_loss: 14.7107 - KL_divergence_loss: 3.1764 - neg_log_likelihood: 862156911.0623 - val_loss: 36.9535 - val_squared_difference_loss: 27.4166 - val_KL_divergence_loss: 9.5369 - val_neg_log_likelihood: inf\n",
      "Epoch 654/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.8868 - squared_difference_loss: 14.6863 - KL_divergence_loss: 3.2005 - neg_log_likelihood: 63601966.9680 - val_loss: 25.1621 - val_squared_difference_loss: 15.6356 - val_KL_divergence_loss: 9.5264 - val_neg_log_likelihood: inf\n",
      "Epoch 655/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.8702 - squared_difference_loss: 14.6782 - KL_divergence_loss: 3.1920 - neg_log_likelihood: 47148056.0330 - val_loss: 31.9594 - val_squared_difference_loss: 22.5863 - val_KL_divergence_loss: 9.3731 - val_neg_log_likelihood: inf\n",
      "Epoch 656/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.8421 - squared_difference_loss: 14.6731 - KL_divergence_loss: 3.1690 - neg_log_likelihood: 60749613.6557 - val_loss: 24.1497 - val_squared_difference_loss: 14.8196 - val_KL_divergence_loss: 9.3301 - val_neg_log_likelihood: 5179519530423060267008.0000\n",
      "Epoch 657/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.8956 - squared_difference_loss: 14.6894 - KL_divergence_loss: 3.2061 - neg_log_likelihood: 387962964.6580 - val_loss: 23.9225 - val_squared_difference_loss: 14.5499 - val_KL_divergence_loss: 9.3726 - val_neg_log_likelihood: 6807290366786292154368.0000\n",
      "Epoch 658/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.8525 - squared_difference_loss: 14.6472 - KL_divergence_loss: 3.2054 - neg_log_likelihood: 133249878.3441 - val_loss: 24.1774 - val_squared_difference_loss: 14.8054 - val_KL_divergence_loss: 9.3720 - val_neg_log_likelihood: inf\n",
      "Epoch 659/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.7995 - squared_difference_loss: 14.6243 - KL_divergence_loss: 3.1752 - neg_log_likelihood: 461225664.3734 - val_loss: 23.8800 - val_squared_difference_loss: 14.6004 - val_KL_divergence_loss: 9.2796 - val_neg_log_likelihood: 15357990137273727497264955392.0000\n",
      "Epoch 660/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.8243 - squared_difference_loss: 14.6484 - KL_divergence_loss: 3.1759 - neg_log_likelihood: 43253186.6549 - val_loss: 24.0984 - val_squared_difference_loss: 14.8274 - val_KL_divergence_loss: 9.2709 - val_neg_log_likelihood: 2972539382120917237760.0000\n",
      "Epoch 661/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.8257 - squared_difference_loss: 14.6230 - KL_divergence_loss: 3.2027 - neg_log_likelihood: 521668019.4192 - val_loss: 27.6116 - val_squared_difference_loss: 18.7171 - val_KL_divergence_loss: 8.8945 - val_neg_log_likelihood: inf\n",
      "Epoch 662/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.7428 - squared_difference_loss: 14.5877 - KL_divergence_loss: 3.1551 - neg_log_likelihood: 20496175.7572 - val_loss: 23.6120 - val_squared_difference_loss: 14.8301 - val_KL_divergence_loss: 8.7819 - val_neg_log_likelihood: 877893798080160922075136.0000\n",
      "Epoch 663/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.7906 - squared_difference_loss: 14.6145 - KL_divergence_loss: 3.1761 - neg_log_likelihood: 58070449.3093 - val_loss: 23.0284 - val_squared_difference_loss: 14.4131 - val_KL_divergence_loss: 8.6153 - val_neg_log_likelihood: 620807025790193792.0000\n",
      "Epoch 664/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.8208 - squared_difference_loss: 14.6202 - KL_divergence_loss: 3.2006 - neg_log_likelihood: 21730685.2307 - val_loss: 23.2859 - val_squared_difference_loss: 14.7357 - val_KL_divergence_loss: 8.5501 - val_neg_log_likelihood: inf\n",
      "Epoch 665/2000\n",
      "29507/29507 [==============================] - 1s 19us/step - loss: 17.7664 - squared_difference_loss: 14.5706 - KL_divergence_loss: 3.1958 - neg_log_likelihood: 41902908.5594 - val_loss: 23.1617 - val_squared_difference_loss: 14.5154 - val_KL_divergence_loss: 8.6464 - val_neg_log_likelihood: 6174496886431576.0000\n",
      "Epoch 666/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 1s 18us/step - loss: 17.7945 - squared_difference_loss: 14.5919 - KL_divergence_loss: 3.2026 - neg_log_likelihood: 36283574.1354 - val_loss: 23.2642 - val_squared_difference_loss: 14.7828 - val_KL_divergence_loss: 8.4815 - val_neg_log_likelihood: 7598622710956674777088.0000\n",
      "Epoch 667/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.8194 - squared_difference_loss: 14.6386 - KL_divergence_loss: 3.1808 - neg_log_likelihood: 167562665.0240 - val_loss: 22.9396 - val_squared_difference_loss: 14.8496 - val_KL_divergence_loss: 8.0900 - val_neg_log_likelihood: 807482993835857231740928.0000\n",
      "Epoch 668/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.8314 - squared_difference_loss: 14.6006 - KL_divergence_loss: 3.2307 - neg_log_likelihood: 22931405.5326 - val_loss: 21.7711 - val_squared_difference_loss: 14.4263 - val_KL_divergence_loss: 7.3448 - val_neg_log_likelihood: 87005782623.0029\n",
      "Epoch 669/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.7746 - squared_difference_loss: 14.5882 - KL_divergence_loss: 3.1863 - neg_log_likelihood: 544978141.8872 - val_loss: 25.7089 - val_squared_difference_loss: 18.7290 - val_KL_divergence_loss: 6.9799 - val_neg_log_likelihood: inf\n",
      "Epoch 670/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.7681 - squared_difference_loss: 14.5702 - KL_divergence_loss: 3.1978 - neg_log_likelihood: 53190416.3110 - val_loss: 21.2984 - val_squared_difference_loss: 14.4439 - val_KL_divergence_loss: 6.8545 - val_neg_log_likelihood: 39366468726291352.0000\n",
      "Epoch 671/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.7737 - squared_difference_loss: 14.5843 - KL_divergence_loss: 3.1893 - neg_log_likelihood: 135302574.4739 - val_loss: 28.0148 - val_squared_difference_loss: 21.3997 - val_KL_divergence_loss: 6.6151 - val_neg_log_likelihood: inf\n",
      "Epoch 672/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.7392 - squared_difference_loss: 14.5473 - KL_divergence_loss: 3.1919 - neg_log_likelihood: 223638472.6349 - val_loss: 20.9271 - val_squared_difference_loss: 14.5272 - val_KL_divergence_loss: 6.3999 - val_neg_log_likelihood: 667617933698421566621089792.0000\n",
      "Epoch 673/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.7800 - squared_difference_loss: 14.6035 - KL_divergence_loss: 3.1765 - neg_log_likelihood: 57110777.5019 - val_loss: 20.6739 - val_squared_difference_loss: 14.3339 - val_KL_divergence_loss: 6.3400 - val_neg_log_likelihood: 31114776984863832.0000\n",
      "Epoch 674/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.7115 - squared_difference_loss: 14.5422 - KL_divergence_loss: 3.1693 - neg_log_likelihood: 49448517.0481 - val_loss: 20.6256 - val_squared_difference_loss: 14.3907 - val_KL_divergence_loss: 6.2349 - val_neg_log_likelihood: 120673126931156281851904.0000\n",
      "Epoch 675/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.7020 - squared_difference_loss: 14.5300 - KL_divergence_loss: 3.1720 - neg_log_likelihood: 1085714281.4619 - val_loss: 20.7504 - val_squared_difference_loss: 14.4750 - val_KL_divergence_loss: 6.2754 - val_neg_log_likelihood: 3978225299984991064674243969024.0000\n",
      "Epoch 676/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.7009 - squared_difference_loss: 14.5336 - KL_divergence_loss: 3.1674 - neg_log_likelihood: 21490650.2480 - val_loss: 20.8802 - val_squared_difference_loss: 14.4887 - val_KL_divergence_loss: 6.3915 - val_neg_log_likelihood: inf\n",
      "Epoch 677/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.7276 - squared_difference_loss: 14.5447 - KL_divergence_loss: 3.1829 - neg_log_likelihood: 3386784861.4899 - val_loss: 21.7264 - val_squared_difference_loss: 15.1923 - val_KL_divergence_loss: 6.5340 - val_neg_log_likelihood: 890790217039202504591540224.0000\n",
      "Epoch 678/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.7366 - squared_difference_loss: 14.5396 - KL_divergence_loss: 3.1970 - neg_log_likelihood: 769323109.8027 - val_loss: 21.6542 - val_squared_difference_loss: 14.7664 - val_KL_divergence_loss: 6.8878 - val_neg_log_likelihood: 35765140407585383383040.0000\n",
      "Epoch 679/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.7095 - squared_difference_loss: 14.5329 - KL_divergence_loss: 3.1766 - neg_log_likelihood: 56117622.8986 - val_loss: 21.2960 - val_squared_difference_loss: 14.4703 - val_KL_divergence_loss: 6.8257 - val_neg_log_likelihood: 4103841549089974.5000\n",
      "Epoch 680/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.7087 - squared_difference_loss: 14.5081 - KL_divergence_loss: 3.2006 - neg_log_likelihood: 11958366.5057 - val_loss: 21.2869 - val_squared_difference_loss: 14.3958 - val_KL_divergence_loss: 6.8911 - val_neg_log_likelihood: 34346634203.2058\n",
      "Epoch 681/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.6824 - squared_difference_loss: 14.5249 - KL_divergence_loss: 3.1575 - neg_log_likelihood: 51919904.3906 - val_loss: 21.6412 - val_squared_difference_loss: 14.5437 - val_KL_divergence_loss: 7.0975 - val_neg_log_likelihood: inf\n",
      "Epoch 682/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.7057 - squared_difference_loss: 14.5286 - KL_divergence_loss: 3.1771 - neg_log_likelihood: 46094915.5284 - val_loss: 21.8270 - val_squared_difference_loss: 14.4893 - val_KL_divergence_loss: 7.3376 - val_neg_log_likelihood: 96459443740303792.0000\n",
      "Epoch 683/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.6817 - squared_difference_loss: 14.5036 - KL_divergence_loss: 3.1780 - neg_log_likelihood: 85436485.3707 - val_loss: 22.9765 - val_squared_difference_loss: 15.2652 - val_KL_divergence_loss: 7.7113 - val_neg_log_likelihood: 4729072713756997095889305600.0000\n",
      "Epoch 684/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.6608 - squared_difference_loss: 14.4686 - KL_divergence_loss: 3.1922 - neg_log_likelihood: 163033767349.3316 - val_loss: 22.6482 - val_squared_difference_loss: 14.8818 - val_KL_divergence_loss: 7.7664 - val_neg_log_likelihood: 7915959295627667439616.0000\n",
      "Epoch 685/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.6750 - squared_difference_loss: 14.4799 - KL_divergence_loss: 3.1951 - neg_log_likelihood: 61781429.1943 - val_loss: 24.0981 - val_squared_difference_loss: 16.5343 - val_KL_divergence_loss: 7.5638 - val_neg_log_likelihood: inf\n",
      "Epoch 686/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.6687 - squared_difference_loss: 14.4890 - KL_divergence_loss: 3.1798 - neg_log_likelihood: 8772788.1295 - val_loss: 21.6587 - val_squared_difference_loss: 14.2718 - val_KL_divergence_loss: 7.3869 - val_neg_log_likelihood: 3837902776.1389\n",
      "Epoch 687/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.6819 - squared_difference_loss: 14.4852 - KL_divergence_loss: 3.1966 - neg_log_likelihood: 140863093.5260 - val_loss: 21.9898 - val_squared_difference_loss: 14.3314 - val_KL_divergence_loss: 7.6583 - val_neg_log_likelihood: 346405667604448352927744.0000\n",
      "Epoch 688/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.6293 - squared_difference_loss: 14.4447 - KL_divergence_loss: 3.1846 - neg_log_likelihood: 12063010.7252 - val_loss: 22.7865 - val_squared_difference_loss: 15.0171 - val_KL_divergence_loss: 7.7695 - val_neg_log_likelihood: 63109912726347617333673984.0000\n",
      "Epoch 689/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.6571 - squared_difference_loss: 14.4688 - KL_divergence_loss: 3.1883 - neg_log_likelihood: 100788554.3055 - val_loss: 22.5272 - val_squared_difference_loss: 14.6003 - val_KL_divergence_loss: 7.9269 - val_neg_log_likelihood: inf\n",
      "Epoch 690/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.6432 - squared_difference_loss: 14.4478 - KL_divergence_loss: 3.1955 - neg_log_likelihood: 680484487.5904 - val_loss: 22.1615 - val_squared_difference_loss: 14.2971 - val_KL_divergence_loss: 7.8644 - val_neg_log_likelihood: 218048460298.2046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 691/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.6109 - squared_difference_loss: 14.4189 - KL_divergence_loss: 3.1920 - neg_log_likelihood: 7084861225.7549 - val_loss: 22.9218 - val_squared_difference_loss: 15.2251 - val_KL_divergence_loss: 7.6967 - val_neg_log_likelihood: inf\n",
      "Epoch 692/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.5936 - squared_difference_loss: 14.4183 - KL_divergence_loss: 3.1754 - neg_log_likelihood: 8007035.2079 - val_loss: 21.9705 - val_squared_difference_loss: 14.2377 - val_KL_divergence_loss: 7.7328 - val_neg_log_likelihood: 3300099385.5715\n",
      "Epoch 693/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.7141 - squared_difference_loss: 14.5070 - KL_divergence_loss: 3.2071 - neg_log_likelihood: 29716504.1911 - val_loss: 22.9816 - val_squared_difference_loss: 15.2788 - val_KL_divergence_loss: 7.7028 - val_neg_log_likelihood: inf\n",
      "Epoch 694/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.6578 - squared_difference_loss: 14.4563 - KL_divergence_loss: 3.2015 - neg_log_likelihood: 310080600.6017 - val_loss: 21.7472 - val_squared_difference_loss: 14.4256 - val_KL_divergence_loss: 7.3216 - val_neg_log_likelihood: 91876768991927.2656\n",
      "Epoch 695/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.6085 - squared_difference_loss: 14.4101 - KL_divergence_loss: 3.1984 - neg_log_likelihood: 143729606.5522 - val_loss: 31.9616 - val_squared_difference_loss: 25.1651 - val_KL_divergence_loss: 6.7965 - val_neg_log_likelihood: inf\n",
      "Epoch 696/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.6374 - squared_difference_loss: 14.4459 - KL_divergence_loss: 3.1915 - neg_log_likelihood: 58193372.7552 - val_loss: 20.7308 - val_squared_difference_loss: 14.2414 - val_KL_divergence_loss: 6.4894 - val_neg_log_likelihood: 128853118867.9802\n",
      "Epoch 697/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.6549 - squared_difference_loss: 14.4464 - KL_divergence_loss: 3.2085 - neg_log_likelihood: 327367636.9017 - val_loss: 20.6977 - val_squared_difference_loss: 14.2237 - val_KL_divergence_loss: 6.4740 - val_neg_log_likelihood: 7255615331.9056\n",
      "Epoch 698/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.5895 - squared_difference_loss: 14.4192 - KL_divergence_loss: 3.1703 - neg_log_likelihood: 304640973.4611 - val_loss: 23.3505 - val_squared_difference_loss: 16.9918 - val_KL_divergence_loss: 6.3587 - val_neg_log_likelihood: 11245035029096949302924201382903808.0000\n",
      "Epoch 699/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.5827 - squared_difference_loss: 14.4015 - KL_divergence_loss: 3.1812 - neg_log_likelihood: 554707123.2177 - val_loss: 20.6052 - val_squared_difference_loss: 14.2480 - val_KL_divergence_loss: 6.3572 - val_neg_log_likelihood: 7532155178352334864384.0000\n",
      "Epoch 700/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 17.5817 - squared_difference_loss: 14.3942 - KL_divergence_loss: 3.1875 - neg_log_likelihood: 545293875.1005 - val_loss: 20.6092 - val_squared_difference_loss: 14.2253 - val_KL_divergence_loss: 6.3840 - val_neg_log_likelihood: 142136753180376736.0000\n",
      "Epoch 701/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.6214 - squared_difference_loss: 14.4329 - KL_divergence_loss: 3.1885 - neg_log_likelihood: 50038021.1907 - val_loss: 21.9903 - val_squared_difference_loss: 15.9013 - val_KL_divergence_loss: 6.0891 - val_neg_log_likelihood: 363144087083609048665804773523456.0000\n",
      "Epoch 702/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.5661 - squared_difference_loss: 14.3800 - KL_divergence_loss: 3.1861 - neg_log_likelihood: 44896515.2557 - val_loss: 21.1334 - val_squared_difference_loss: 15.1222 - val_KL_divergence_loss: 6.0113 - val_neg_log_likelihood: 206855740742750538911711232.0000\n",
      "Epoch 703/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.6049 - squared_difference_loss: 14.4139 - KL_divergence_loss: 3.1910 - neg_log_likelihood: 26500188.6430 - val_loss: 20.4083 - val_squared_difference_loss: 14.3672 - val_KL_divergence_loss: 6.0410 - val_neg_log_likelihood: inf\n",
      "Epoch 704/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.5557 - squared_difference_loss: 14.3418 - KL_divergence_loss: 3.2139 - neg_log_likelihood: 13760438.7314 - val_loss: 23.6734 - val_squared_difference_loss: 17.7197 - val_KL_divergence_loss: 5.9536 - val_neg_log_likelihood: inf\n",
      "Epoch 705/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.5630 - squared_difference_loss: 14.3600 - KL_divergence_loss: 3.2031 - neg_log_likelihood: 268239429.6366 - val_loss: 20.2972 - val_squared_difference_loss: 14.1717 - val_KL_divergence_loss: 6.1255 - val_neg_log_likelihood: 9846815210.2786\n",
      "Epoch 706/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.5418 - squared_difference_loss: 14.3532 - KL_divergence_loss: 3.1887 - neg_log_likelihood: 46930835.9192 - val_loss: 20.3654 - val_squared_difference_loss: 14.2014 - val_KL_divergence_loss: 6.1640 - val_neg_log_likelihood: 2115782508.1672\n",
      "Epoch 707/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.5194 - squared_difference_loss: 14.3263 - KL_divergence_loss: 3.1932 - neg_log_likelihood: 5562211501.8992 - val_loss: 24.2095 - val_squared_difference_loss: 17.8769 - val_KL_divergence_loss: 6.3326 - val_neg_log_likelihood: inf\n",
      "Epoch 708/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 17.5592 - squared_difference_loss: 14.3651 - KL_divergence_loss: 3.1942 - neg_log_likelihood: 521765758.3581 - val_loss: 20.5983 - val_squared_difference_loss: 14.3793 - val_KL_divergence_loss: 6.2190 - val_neg_log_likelihood: 5520472232521634.0000\n",
      "Epoch 709/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.5774 - squared_difference_loss: 14.3530 - KL_divergence_loss: 3.2244 - neg_log_likelihood: 19551293589116.4062 - val_loss: 19.9967 - val_squared_difference_loss: 14.1883 - val_KL_divergence_loss: 5.8083 - val_neg_log_likelihood: 36631306932.8415\n",
      "Epoch 710/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.5904 - squared_difference_loss: 14.3843 - KL_divergence_loss: 3.2061 - neg_log_likelihood: 21056873.8991 - val_loss: 19.8212 - val_squared_difference_loss: 14.1851 - val_KL_divergence_loss: 5.6360 - val_neg_log_likelihood: 6159964101178.8848\n",
      "Epoch 711/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.5043 - squared_difference_loss: 14.3435 - KL_divergence_loss: 3.1609 - neg_log_likelihood: 20412612.7795 - val_loss: 19.7741 - val_squared_difference_loss: 14.1976 - val_KL_divergence_loss: 5.5765 - val_neg_log_likelihood: 13829593666595406.0000\n",
      "Epoch 712/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.4910 - squared_difference_loss: 14.3080 - KL_divergence_loss: 3.1830 - neg_log_likelihood: 31575494.5562 - val_loss: 19.9353 - val_squared_difference_loss: 14.2551 - val_KL_divergence_loss: 5.6802 - val_neg_log_likelihood: 1733520668046837208188700327936.0000\n",
      "Epoch 713/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.5567 - squared_difference_loss: 14.3414 - KL_divergence_loss: 3.2153 - neg_log_likelihood: 11709292.5838 - val_loss: 19.9936 - val_squared_difference_loss: 14.2447 - val_KL_divergence_loss: 5.7489 - val_neg_log_likelihood: 784419736833849.1250\n",
      "Epoch 714/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 17.5145 - squared_difference_loss: 14.3177 - KL_divergence_loss: 3.1968 - neg_log_likelihood: 102909168.8833 - val_loss: 19.9505 - val_squared_difference_loss: 14.2835 - val_KL_divergence_loss: 5.6670 - val_neg_log_likelihood: 11327497631520374348840960.0000\n",
      "Epoch 715/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.5264 - squared_difference_loss: 14.3183 - KL_divergence_loss: 3.2081 - neg_log_likelihood: 124143889.1393 - val_loss: 19.8642 - val_squared_difference_loss: 14.2857 - val_KL_divergence_loss: 5.5784 - val_neg_log_likelihood: 65382961004023704.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 716/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.5133 - squared_difference_loss: 14.3085 - KL_divergence_loss: 3.2048 - neg_log_likelihood: 35145386.7280 - val_loss: 19.7683 - val_squared_difference_loss: 14.2787 - val_KL_divergence_loss: 5.4896 - val_neg_log_likelihood: 1770051697297031368399013281792.0000\n",
      "Epoch 717/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.5067 - squared_difference_loss: 14.2974 - KL_divergence_loss: 3.2093 - neg_log_likelihood: 800286447.1737 - val_loss: 19.6349 - val_squared_difference_loss: 14.1772 - val_KL_divergence_loss: 5.4577 - val_neg_log_likelihood: 2803798359656.7524\n",
      "Epoch 718/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.4673 - squared_difference_loss: 14.2639 - KL_divergence_loss: 3.2034 - neg_log_likelihood: 173127919.7084 - val_loss: 19.5253 - val_squared_difference_loss: 14.1709 - val_KL_divergence_loss: 5.3545 - val_neg_log_likelihood: 79581408096.9629\n",
      "Epoch 719/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.4633 - squared_difference_loss: 14.2759 - KL_divergence_loss: 3.1873 - neg_log_likelihood: 38350347.7528 - val_loss: 19.7861 - val_squared_difference_loss: 14.4799 - val_KL_divergence_loss: 5.3062 - val_neg_log_likelihood: 14317658019885015040.0000\n",
      "Epoch 720/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.5057 - squared_difference_loss: 14.2995 - KL_divergence_loss: 3.2062 - neg_log_likelihood: 58079776.3833 - val_loss: 19.3979 - val_squared_difference_loss: 14.1729 - val_KL_divergence_loss: 5.2250 - val_neg_log_likelihood: 3190182784771310219585126400.0000\n",
      "Epoch 721/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.4561 - squared_difference_loss: 14.2570 - KL_divergence_loss: 3.1991 - neg_log_likelihood: 239131625.1438 - val_loss: 19.3224 - val_squared_difference_loss: 14.1833 - val_KL_divergence_loss: 5.1391 - val_neg_log_likelihood: 18261421388475.5039\n",
      "Epoch 722/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 17.4375 - squared_difference_loss: 14.2357 - KL_divergence_loss: 3.2019 - neg_log_likelihood: 162243185.2682 - val_loss: 19.4199 - val_squared_difference_loss: 14.2824 - val_KL_divergence_loss: 5.1376 - val_neg_log_likelihood: 5681713111499364660568838440484864.0000\n",
      "Epoch 723/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.5055 - squared_difference_loss: 14.3167 - KL_divergence_loss: 3.1888 - neg_log_likelihood: 29184423.8265 - val_loss: 19.9367 - val_squared_difference_loss: 14.6667 - val_KL_divergence_loss: 5.2700 - val_neg_log_likelihood: 29250488937817485344768.0000\n",
      "Epoch 724/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.4767 - squared_difference_loss: 14.2758 - KL_divergence_loss: 3.2010 - neg_log_likelihood: 165487164.4350 - val_loss: 19.6070 - val_squared_difference_loss: 14.3261 - val_KL_divergence_loss: 5.2809 - val_neg_log_likelihood: 1299578920914107702556400960929792.0000\n",
      "Epoch 725/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 17.4963 - squared_difference_loss: 14.2752 - KL_divergence_loss: 3.2212 - neg_log_likelihood: 171389447.1892 - val_loss: 19.2254 - val_squared_difference_loss: 14.0963 - val_KL_divergence_loss: 5.1291 - val_neg_log_likelihood: 4355743861.4847\n",
      "Epoch 726/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.4808 - squared_difference_loss: 14.2632 - KL_divergence_loss: 3.2176 - neg_log_likelihood: 86729239.9613 - val_loss: 19.9885 - val_squared_difference_loss: 14.9568 - val_KL_divergence_loss: 5.0317 - val_neg_log_likelihood: 144873280412000261918162944.0000\n",
      "Epoch 727/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 17.4524 - squared_difference_loss: 14.2457 - KL_divergence_loss: 3.2067 - neg_log_likelihood: 16690478.5714 - val_loss: 19.0588 - val_squared_difference_loss: 14.1064 - val_KL_divergence_loss: 4.9524 - val_neg_log_likelihood: 13548453699560189952.0000\n",
      "Epoch 728/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.4640 - squared_difference_loss: 14.2516 - KL_divergence_loss: 3.2124 - neg_log_likelihood: 129263682.2537 - val_loss: 19.3425 - val_squared_difference_loss: 14.3535 - val_KL_divergence_loss: 4.9891 - val_neg_log_likelihood: 222002412791811424.0000\n",
      "Epoch 729/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.4326 - squared_difference_loss: 14.2199 - KL_divergence_loss: 3.2128 - neg_log_likelihood: 90576637.4015 - val_loss: 19.0464 - val_squared_difference_loss: 14.1871 - val_KL_divergence_loss: 4.8593 - val_neg_log_likelihood: 34161369870611040075916509184.0000\n",
      "Epoch 730/2000\n",
      "29507/29507 [==============================] - 1s 19us/step - loss: 17.4276 - squared_difference_loss: 14.2330 - KL_divergence_loss: 3.1946 - neg_log_likelihood: 65726993.5084 - val_loss: 18.9375 - val_squared_difference_loss: 14.1620 - val_KL_divergence_loss: 4.7755 - val_neg_log_likelihood: 3150546612590.3296\n",
      "Epoch 731/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.4723 - squared_difference_loss: 14.2560 - KL_divergence_loss: 3.2163 - neg_log_likelihood: 2658240108.7261 - val_loss: 18.9178 - val_squared_difference_loss: 14.1217 - val_KL_divergence_loss: 4.7960 - val_neg_log_likelihood: 10286644434703294464.0000\n",
      "Epoch 732/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.4320 - squared_difference_loss: 14.2300 - KL_divergence_loss: 3.2020 - neg_log_likelihood: 249701811.4583 - val_loss: 18.8137 - val_squared_difference_loss: 14.0773 - val_KL_divergence_loss: 4.7364 - val_neg_log_likelihood: 268838895656093088.0000\n",
      "Epoch 733/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 17.4782 - squared_difference_loss: 14.2478 - KL_divergence_loss: 3.2304 - neg_log_likelihood: 94113364874.3052 - val_loss: 19.0106 - val_squared_difference_loss: 14.3092 - val_KL_divergence_loss: 4.7014 - val_neg_log_likelihood: inf\n",
      "Epoch 734/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.4192 - squared_difference_loss: 14.1968 - KL_divergence_loss: 3.2223 - neg_log_likelihood: 269078904.5294 - val_loss: 18.5905 - val_squared_difference_loss: 14.0450 - val_KL_divergence_loss: 4.5456 - val_neg_log_likelihood: 431519795495.6096\n",
      "Epoch 735/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.4385 - squared_difference_loss: 14.2318 - KL_divergence_loss: 3.2066 - neg_log_likelihood: 4402077118.0004 - val_loss: 18.6572 - val_squared_difference_loss: 14.1306 - val_KL_divergence_loss: 4.5266 - val_neg_log_likelihood: 25251549157154498445049856.0000\n",
      "Epoch 736/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.4494 - squared_difference_loss: 14.2515 - KL_divergence_loss: 3.1979 - neg_log_likelihood: 359835126.4800 - val_loss: 18.5346 - val_squared_difference_loss: 14.0930 - val_KL_divergence_loss: 4.4417 - val_neg_log_likelihood: 136277630089.7188\n",
      "Epoch 737/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.4224 - squared_difference_loss: 14.2219 - KL_divergence_loss: 3.2005 - neg_log_likelihood: 2301286085.1486 - val_loss: 19.6725 - val_squared_difference_loss: 15.3621 - val_KL_divergence_loss: 4.3104 - val_neg_log_likelihood: 13611382349545828356456448.0000\n",
      "Epoch 738/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.3387 - squared_difference_loss: 14.1416 - KL_divergence_loss: 3.1971 - neg_log_likelihood: 95561516.3998 - val_loss: 19.2702 - val_squared_difference_loss: 14.9309 - val_KL_divergence_loss: 4.3393 - val_neg_log_likelihood: 79476757188434689261568.0000\n",
      "Epoch 739/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.4430 - squared_difference_loss: 14.2285 - KL_divergence_loss: 3.2145 - neg_log_likelihood: 36137679.5761 - val_loss: 18.4562 - val_squared_difference_loss: 14.1074 - val_KL_divergence_loss: 4.3488 - val_neg_log_likelihood: 649247558960.3900\n",
      "Epoch 740/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.4255 - squared_difference_loss: 14.2203 - KL_divergence_loss: 3.2053 - neg_log_likelihood: 45251798.8758 - val_loss: 18.6338 - val_squared_difference_loss: 14.1902 - val_KL_divergence_loss: 4.4436 - val_neg_log_likelihood: 125138106426404.7188\n",
      "Epoch 741/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.4287 - squared_difference_loss: 14.1960 - KL_divergence_loss: 3.2327 - neg_log_likelihood: 32925721701.2572 - val_loss: 20.3481 - val_squared_difference_loss: 16.0034 - val_KL_divergence_loss: 4.3447 - val_neg_log_likelihood: 2382475336309493972994860515328.0000\n",
      "Epoch 742/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.4001 - squared_difference_loss: 14.1921 - KL_divergence_loss: 3.2079 - neg_log_likelihood: 10389284.8078 - val_loss: 18.7633 - val_squared_difference_loss: 14.4295 - val_KL_divergence_loss: 4.3338 - val_neg_log_likelihood: inf\n",
      "Epoch 743/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.3662 - squared_difference_loss: 14.1657 - KL_divergence_loss: 3.2005 - neg_log_likelihood: 859151345.6436 - val_loss: 18.4164 - val_squared_difference_loss: 14.0371 - val_KL_divergence_loss: 4.3793 - val_neg_log_likelihood: 113396844145.2242\n",
      "Epoch 744/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 17.3913 - squared_difference_loss: 14.1789 - KL_divergence_loss: 3.2124 - neg_log_likelihood: 16568133946.2265 - val_loss: 20.6702 - val_squared_difference_loss: 16.3287 - val_KL_divergence_loss: 4.3415 - val_neg_log_likelihood: 9770648784902363462366889246720.0000\n",
      "Epoch 745/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.4213 - squared_difference_loss: 14.2050 - KL_divergence_loss: 3.2164 - neg_log_likelihood: 86908084.5007 - val_loss: 18.4970 - val_squared_difference_loss: 14.2164 - val_KL_divergence_loss: 4.2805 - val_neg_log_likelihood: 42258793031283693812212285046784.0000\n",
      "Epoch 746/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.3996 - squared_difference_loss: 14.2047 - KL_divergence_loss: 3.1949 - neg_log_likelihood: 594708690.9069 - val_loss: 18.3059 - val_squared_difference_loss: 14.0060 - val_KL_divergence_loss: 4.2999 - val_neg_log_likelihood: 224114854239384956305408.0000\n",
      "Epoch 747/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.3578 - squared_difference_loss: 14.1428 - KL_divergence_loss: 3.2150 - neg_log_likelihood: 36699607.6669 - val_loss: 18.2758 - val_squared_difference_loss: 14.0033 - val_KL_divergence_loss: 4.2725 - val_neg_log_likelihood: 62907153657.8050\n",
      "Epoch 748/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 17.3993 - squared_difference_loss: 14.1916 - KL_divergence_loss: 3.2077 - neg_log_likelihood: 117264355.6918 - val_loss: 18.3048 - val_squared_difference_loss: 14.0734 - val_KL_divergence_loss: 4.2314 - val_neg_log_likelihood: 393802528848.3422\n",
      "Epoch 749/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.4040 - squared_difference_loss: 14.1794 - KL_divergence_loss: 3.2245 - neg_log_likelihood: 527901777.4330 - val_loss: 18.1521 - val_squared_difference_loss: 14.0308 - val_KL_divergence_loss: 4.1213 - val_neg_log_likelihood: 3558535114251128.5000\n",
      "Epoch 750/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.3671 - squared_difference_loss: 14.1601 - KL_divergence_loss: 3.2070 - neg_log_likelihood: 155465721.4466 - val_loss: 19.5007 - val_squared_difference_loss: 15.3751 - val_KL_divergence_loss: 4.1256 - val_neg_log_likelihood: 38444300492836734583894441984.0000\n",
      "Epoch 751/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 17.3363 - squared_difference_loss: 14.1221 - KL_divergence_loss: 3.2143 - neg_log_likelihood: 97540524.5108 - val_loss: 18.1859 - val_squared_difference_loss: 14.0525 - val_KL_divergence_loss: 4.1333 - val_neg_log_likelihood: 311617354322392745221554176.0000\n",
      "Epoch 752/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.3323 - squared_difference_loss: 14.1290 - KL_divergence_loss: 3.2033 - neg_log_likelihood: 2738153673.8001 - val_loss: 18.1270 - val_squared_difference_loss: 13.9858 - val_KL_divergence_loss: 4.1412 - val_neg_log_likelihood: 128521340315.1195\n",
      "Epoch 753/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.3379 - squared_difference_loss: 14.1139 - KL_divergence_loss: 3.2240 - neg_log_likelihood: 726411355.3421 - val_loss: 21.3160 - val_squared_difference_loss: 17.1721 - val_KL_divergence_loss: 4.1439 - val_neg_log_likelihood: inf\n",
      "Epoch 754/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.3452 - squared_difference_loss: 14.1301 - KL_divergence_loss: 3.2151 - neg_log_likelihood: 34072278.3951 - val_loss: 18.1434 - val_squared_difference_loss: 14.0192 - val_KL_divergence_loss: 4.1241 - val_neg_log_likelihood: 817458084914934491119616.0000\n",
      "Epoch 755/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.3393 - squared_difference_loss: 14.1051 - KL_divergence_loss: 3.2342 - neg_log_likelihood: 50483437.4350 - val_loss: 18.0840 - val_squared_difference_loss: 13.9700 - val_KL_divergence_loss: 4.1140 - val_neg_log_likelihood: 249713987241527.9375\n",
      "Epoch 756/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.3934 - squared_difference_loss: 14.1754 - KL_divergence_loss: 3.2181 - neg_log_likelihood: 206468594.6155 - val_loss: 18.1755 - val_squared_difference_loss: 14.0850 - val_KL_divergence_loss: 4.0905 - val_neg_log_likelihood: 23279052432476.1680\n",
      "Epoch 757/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.3668 - squared_difference_loss: 14.1588 - KL_divergence_loss: 3.2080 - neg_log_likelihood: 96050137.4854 - val_loss: 18.0128 - val_squared_difference_loss: 13.9164 - val_KL_divergence_loss: 4.0964 - val_neg_log_likelihood: 499316644197.1539\n",
      "Epoch 758/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.3078 - squared_difference_loss: 14.0832 - KL_divergence_loss: 3.2247 - neg_log_likelihood: 1016789811.5520 - val_loss: 18.1559 - val_squared_difference_loss: 14.0852 - val_KL_divergence_loss: 4.0707 - val_neg_log_likelihood: 18044673007962.7266\n",
      "Epoch 759/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.2907 - squared_difference_loss: 14.0788 - KL_divergence_loss: 3.2119 - neg_log_likelihood: 76242151.5319 - val_loss: 18.0065 - val_squared_difference_loss: 13.9286 - val_KL_divergence_loss: 4.0779 - val_neg_log_likelihood: 50509882015.2997\n",
      "Epoch 760/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 17.3194 - squared_difference_loss: 14.1012 - KL_divergence_loss: 3.2182 - neg_log_likelihood: 75533287.0334 - val_loss: 19.3343 - val_squared_difference_loss: 15.3394 - val_KL_divergence_loss: 3.9949 - val_neg_log_likelihood: 71519253445058880373522432.0000\n",
      "Epoch 761/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.3714 - squared_difference_loss: 14.1334 - KL_divergence_loss: 3.2381 - neg_log_likelihood: 122064846.4685 - val_loss: 18.2088 - val_squared_difference_loss: 14.2316 - val_KL_divergence_loss: 3.9772 - val_neg_log_likelihood: inf\n",
      "Epoch 762/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.3329 - squared_difference_loss: 14.1145 - KL_divergence_loss: 3.2184 - neg_log_likelihood: 191904491.0230 - val_loss: 18.0696 - val_squared_difference_loss: 14.1930 - val_KL_divergence_loss: 3.8766 - val_neg_log_likelihood: inf\n",
      "Epoch 763/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 17.2989 - squared_difference_loss: 14.0796 - KL_divergence_loss: 3.2194 - neg_log_likelihood: 536578623.5577 - val_loss: 17.9027 - val_squared_difference_loss: 14.0605 - val_KL_divergence_loss: 3.8422 - val_neg_log_likelihood: 1905332666403274232506995441664.0000\n",
      "Epoch 764/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.3198 - squared_difference_loss: 14.0801 - KL_divergence_loss: 3.2397 - neg_log_likelihood: 115981560.2131 - val_loss: 17.7539 - val_squared_difference_loss: 13.9499 - val_KL_divergence_loss: 3.8039 - val_neg_log_likelihood: 11557017404808402944.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 765/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.2609 - squared_difference_loss: 14.0578 - KL_divergence_loss: 3.2031 - neg_log_likelihood: 285677312.6170 - val_loss: 19.5280 - val_squared_difference_loss: 15.7189 - val_KL_divergence_loss: 3.8091 - val_neg_log_likelihood: 128650351572570243586128389079040.0000\n",
      "Epoch 766/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.2816 - squared_difference_loss: 14.0711 - KL_divergence_loss: 3.2105 - neg_log_likelihood: 450101594.9111 - val_loss: 17.7097 - val_squared_difference_loss: 13.8642 - val_KL_divergence_loss: 3.8454 - val_neg_log_likelihood: 913869536018.7296\n",
      "Epoch 767/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.2932 - squared_difference_loss: 14.0714 - KL_divergence_loss: 3.2219 - neg_log_likelihood: 9358112023.9024 - val_loss: 18.0617 - val_squared_difference_loss: 14.2593 - val_KL_divergence_loss: 3.8024 - val_neg_log_likelihood: inf\n",
      "Epoch 768/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.3137 - squared_difference_loss: 14.0877 - KL_divergence_loss: 3.2260 - neg_log_likelihood: 77923243.7407 - val_loss: 18.8361 - val_squared_difference_loss: 15.0075 - val_KL_divergence_loss: 3.8286 - val_neg_log_likelihood: 2420120165760225664565248.0000\n",
      "Epoch 769/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.2784 - squared_difference_loss: 14.0615 - KL_divergence_loss: 3.2169 - neg_log_likelihood: 189986892.1770 - val_loss: 18.3606 - val_squared_difference_loss: 14.5100 - val_KL_divergence_loss: 3.8506 - val_neg_log_likelihood: 214651944793996460032.0000\n",
      "Epoch 770/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.2978 - squared_difference_loss: 14.0695 - KL_divergence_loss: 3.2282 - neg_log_likelihood: 226523126.1319 - val_loss: 17.7247 - val_squared_difference_loss: 13.8398 - val_KL_divergence_loss: 3.8849 - val_neg_log_likelihood: 48885905298.9866\n",
      "Epoch 771/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.2361 - squared_difference_loss: 14.0007 - KL_divergence_loss: 3.2354 - neg_log_likelihood: 123764507.5264 - val_loss: 17.7022 - val_squared_difference_loss: 13.8274 - val_KL_divergence_loss: 3.8748 - val_neg_log_likelihood: 63856728649.0575\n",
      "Epoch 772/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.2326 - squared_difference_loss: 14.0231 - KL_divergence_loss: 3.2095 - neg_log_likelihood: 81030524.6190 - val_loss: 17.9944 - val_squared_difference_loss: 14.1236 - val_KL_divergence_loss: 3.8708 - val_neg_log_likelihood: inf\n",
      "Epoch 773/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.2408 - squared_difference_loss: 14.0250 - KL_divergence_loss: 3.2158 - neg_log_likelihood: 75589951.4870 - val_loss: 20.3144 - val_squared_difference_loss: 16.4488 - val_KL_divergence_loss: 3.8656 - val_neg_log_likelihood: 427322424504951242527146650894336.0000\n",
      "Epoch 774/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.2412 - squared_difference_loss: 14.0251 - KL_divergence_loss: 3.2162 - neg_log_likelihood: 101195870.1873 - val_loss: 17.9176 - val_squared_difference_loss: 14.1004 - val_KL_divergence_loss: 3.8172 - val_neg_log_likelihood: 24163373418256045885136234872832.0000\n",
      "Epoch 775/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.2986 - squared_difference_loss: 14.0685 - KL_divergence_loss: 3.2302 - neg_log_likelihood: 252152411.1001 - val_loss: 17.8851 - val_squared_difference_loss: 14.0627 - val_KL_divergence_loss: 3.8224 - val_neg_log_likelihood: 61293167271468615838182898925568.0000\n",
      "Epoch 776/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.2584 - squared_difference_loss: 14.0282 - KL_divergence_loss: 3.2302 - neg_log_likelihood: 265015727.8159 - val_loss: 17.6876 - val_squared_difference_loss: 13.8929 - val_KL_divergence_loss: 3.7947 - val_neg_log_likelihood: 12986446988879213887488.0000\n",
      "Epoch 777/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.2466 - squared_difference_loss: 14.0340 - KL_divergence_loss: 3.2126 - neg_log_likelihood: 587740435.1502 - val_loss: 18.5543 - val_squared_difference_loss: 14.7708 - val_KL_divergence_loss: 3.7835 - val_neg_log_likelihood: 93649449541581420888064.0000\n",
      "Epoch 778/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.2278 - squared_difference_loss: 14.0053 - KL_divergence_loss: 3.2224 - neg_log_likelihood: 166258324.9047 - val_loss: 17.8157 - val_squared_difference_loss: 14.0720 - val_KL_divergence_loss: 3.7437 - val_neg_log_likelihood: inf\n",
      "Epoch 779/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.2727 - squared_difference_loss: 14.0462 - KL_divergence_loss: 3.2265 - neg_log_likelihood: 134306750.8563 - val_loss: 17.5458 - val_squared_difference_loss: 13.8553 - val_KL_divergence_loss: 3.6905 - val_neg_log_likelihood: 8449090332104.1553\n",
      "Epoch 780/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.2188 - squared_difference_loss: 13.9928 - KL_divergence_loss: 3.2260 - neg_log_likelihood: 3618971182.4975 - val_loss: 18.5046 - val_squared_difference_loss: 14.8328 - val_KL_divergence_loss: 3.6719 - val_neg_log_likelihood: 1399206031131870211604480.0000\n",
      "Epoch 781/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.2450 - squared_difference_loss: 14.0191 - KL_divergence_loss: 3.2259 - neg_log_likelihood: 23263577.3488 - val_loss: 17.5131 - val_squared_difference_loss: 13.8255 - val_KL_divergence_loss: 3.6876 - val_neg_log_likelihood: 3001339266.1321\n",
      "Epoch 782/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.2500 - squared_difference_loss: 14.0039 - KL_divergence_loss: 3.2461 - neg_log_likelihood: 414717418.1934 - val_loss: 17.5131 - val_squared_difference_loss: 13.8169 - val_KL_divergence_loss: 3.6962 - val_neg_log_likelihood: 1687184046237.0229\n",
      "Epoch 783/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.2807 - squared_difference_loss: 14.0532 - KL_divergence_loss: 3.2275 - neg_log_likelihood: 171864797.5164 - val_loss: 17.4868 - val_squared_difference_loss: 13.7917 - val_KL_divergence_loss: 3.6950 - val_neg_log_likelihood: 48840823915.3832\n",
      "Epoch 784/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.2207 - squared_difference_loss: 13.9981 - KL_divergence_loss: 3.2226 - neg_log_likelihood: 9993985003.5014 - val_loss: 17.6814 - val_squared_difference_loss: 13.9527 - val_KL_divergence_loss: 3.7287 - val_neg_log_likelihood: 5520182443088700708995021576077312.0000\n",
      "Epoch 785/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.2180 - squared_difference_loss: 13.9891 - KL_divergence_loss: 3.2289 - neg_log_likelihood: 1205099525.6714 - val_loss: 18.0483 - val_squared_difference_loss: 14.3445 - val_KL_divergence_loss: 3.7039 - val_neg_log_likelihood: 155669485745197184.0000\n",
      "Epoch 786/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.2260 - squared_difference_loss: 13.9988 - KL_divergence_loss: 3.2272 - neg_log_likelihood: 37025227.5509 - val_loss: 17.8171 - val_squared_difference_loss: 14.0540 - val_KL_divergence_loss: 3.7630 - val_neg_log_likelihood: 42980144266313.8906\n",
      "Epoch 787/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.2627 - squared_difference_loss: 14.0016 - KL_divergence_loss: 3.2610 - neg_log_likelihood: 134616866.5692 - val_loss: 17.7104 - val_squared_difference_loss: 14.0033 - val_KL_divergence_loss: 3.7071 - val_neg_log_likelihood: 690774420267.4457\n",
      "Epoch 788/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.1908 - squared_difference_loss: 13.9697 - KL_divergence_loss: 3.2211 - neg_log_likelihood: 139482606.4284 - val_loss: 17.5698 - val_squared_difference_loss: 13.8117 - val_KL_divergence_loss: 3.7581 - val_neg_log_likelihood: 198291880544.1768\n",
      "Epoch 789/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.2196 - squared_difference_loss: 13.9875 - KL_divergence_loss: 3.2321 - neg_log_likelihood: 2456656708.0654 - val_loss: 17.6695 - val_squared_difference_loss: 13.9083 - val_KL_divergence_loss: 3.7611 - val_neg_log_likelihood: 31664969950.3136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 790/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.2034 - squared_difference_loss: 13.9705 - KL_divergence_loss: 3.2329 - neg_log_likelihood: 93793441.7105 - val_loss: 17.9145 - val_squared_difference_loss: 14.1749 - val_KL_divergence_loss: 3.7396 - val_neg_log_likelihood: 6010771936297525.0000\n",
      "Epoch 791/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.1886 - squared_difference_loss: 13.9488 - KL_divergence_loss: 3.2398 - neg_log_likelihood: 5376296959.2390 - val_loss: 17.6949 - val_squared_difference_loss: 14.0180 - val_KL_divergence_loss: 3.6769 - val_neg_log_likelihood: 231049390282733753235383007576064.0000\n",
      "Epoch 792/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.2117 - squared_difference_loss: 13.9579 - KL_divergence_loss: 3.2537 - neg_log_likelihood: 486760584.6263 - val_loss: 17.4474 - val_squared_difference_loss: 13.8328 - val_KL_divergence_loss: 3.6146 - val_neg_log_likelihood: 382154339103.2088\n",
      "Epoch 793/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.1832 - squared_difference_loss: 13.9377 - KL_divergence_loss: 3.2455 - neg_log_likelihood: 14706198358.0955 - val_loss: 18.5844 - val_squared_difference_loss: 14.9752 - val_KL_divergence_loss: 3.6092 - val_neg_log_likelihood: 51625770648303325675520.0000\n",
      "Epoch 794/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.1805 - squared_difference_loss: 13.9321 - KL_divergence_loss: 3.2484 - neg_log_likelihood: 541574076.4266 - val_loss: 17.9772 - val_squared_difference_loss: 14.4225 - val_KL_divergence_loss: 3.5547 - val_neg_log_likelihood: 45452441584258908160.0000\n",
      "Epoch 795/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.1478 - squared_difference_loss: 13.9067 - KL_divergence_loss: 3.2412 - neg_log_likelihood: 1705593528.9981 - val_loss: 19.4538 - val_squared_difference_loss: 15.8902 - val_KL_divergence_loss: 3.5636 - val_neg_log_likelihood: 63885309173528048841097629138944.0000\n",
      "Epoch 796/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.1978 - squared_difference_loss: 13.9572 - KL_divergence_loss: 3.2405 - neg_log_likelihood: 83669854174.7958 - val_loss: 17.5797 - val_squared_difference_loss: 14.0580 - val_KL_divergence_loss: 3.5217 - val_neg_log_likelihood: inf\n",
      "Epoch 797/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.1223 - squared_difference_loss: 13.8853 - KL_divergence_loss: 3.2369 - neg_log_likelihood: 124354921.3310 - val_loss: 17.3813 - val_squared_difference_loss: 13.8334 - val_KL_divergence_loss: 3.5479 - val_neg_log_likelihood: 121542961919648.2812\n",
      "Epoch 798/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.1636 - squared_difference_loss: 13.9420 - KL_divergence_loss: 3.2216 - neg_log_likelihood: 234786757.4088 - val_loss: 17.3483 - val_squared_difference_loss: 13.7899 - val_KL_divergence_loss: 3.5585 - val_neg_log_likelihood: 3714933797839486.5000\n",
      "Epoch 799/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.1471 - squared_difference_loss: 13.8876 - KL_divergence_loss: 3.2594 - neg_log_likelihood: 1143694739.2799 - val_loss: 17.2587 - val_squared_difference_loss: 13.7436 - val_KL_divergence_loss: 3.5151 - val_neg_log_likelihood: 32466315876212.6562\n",
      "Epoch 800/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.0999 - squared_difference_loss: 13.8647 - KL_divergence_loss: 3.2353 - neg_log_likelihood: 460190277.5755 - val_loss: 17.3222 - val_squared_difference_loss: 13.8294 - val_KL_divergence_loss: 3.4929 - val_neg_log_likelihood: 7953065732216461.0000\n",
      "Epoch 801/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.1450 - squared_difference_loss: 13.8956 - KL_divergence_loss: 3.2494 - neg_log_likelihood: 103989561.9219 - val_loss: 18.0701 - val_squared_difference_loss: 14.5793 - val_KL_divergence_loss: 3.4907 - val_neg_log_likelihood: 12426396759642731446272.0000\n",
      "Epoch 802/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.1480 - squared_difference_loss: 13.9084 - KL_divergence_loss: 3.2396 - neg_log_likelihood: 2666668937.8652 - val_loss: 17.2726 - val_squared_difference_loss: 13.7564 - val_KL_divergence_loss: 3.5162 - val_neg_log_likelihood: 358082977421594.0000\n",
      "Epoch 803/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.1288 - squared_difference_loss: 13.8788 - KL_divergence_loss: 3.2501 - neg_log_likelihood: 1033946063.9076 - val_loss: 17.3729 - val_squared_difference_loss: 13.9137 - val_KL_divergence_loss: 3.4591 - val_neg_log_likelihood: 94787394524004.6406\n",
      "Epoch 804/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.1557 - squared_difference_loss: 13.9151 - KL_divergence_loss: 3.2406 - neg_log_likelihood: 49598856991.4718 - val_loss: 17.2484 - val_squared_difference_loss: 13.7437 - val_KL_divergence_loss: 3.5046 - val_neg_log_likelihood: 254008954579496.5625\n",
      "Epoch 805/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.1281 - squared_difference_loss: 13.8779 - KL_divergence_loss: 3.2502 - neg_log_likelihood: 492219689.5995 - val_loss: 17.6237 - val_squared_difference_loss: 14.1292 - val_KL_divergence_loss: 3.4945 - val_neg_log_likelihood: 2350290565181281280.0000\n",
      "Epoch 806/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.1477 - squared_difference_loss: 13.8823 - KL_divergence_loss: 3.2654 - neg_log_likelihood: 65243155338.2510 - val_loss: 17.2057 - val_squared_difference_loss: 13.7687 - val_KL_divergence_loss: 3.4370 - val_neg_log_likelihood: 10509077587473460.0000\n",
      "Epoch 807/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.1285 - squared_difference_loss: 13.8917 - KL_divergence_loss: 3.2368 - neg_log_likelihood: 588426417.2333 - val_loss: 17.2326 - val_squared_difference_loss: 13.8226 - val_KL_divergence_loss: 3.4100 - val_neg_log_likelihood: 482259228629.7642\n",
      "Epoch 808/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.1344 - squared_difference_loss: 13.8758 - KL_divergence_loss: 3.2586 - neg_log_likelihood: 7374741038.9053 - val_loss: 17.1881 - val_squared_difference_loss: 13.7463 - val_KL_divergence_loss: 3.4419 - val_neg_log_likelihood: 65633584810736607232.0000\n",
      "Epoch 809/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.1046 - squared_difference_loss: 13.8475 - KL_divergence_loss: 3.2571 - neg_log_likelihood: 25474330.6584 - val_loss: 17.5199 - val_squared_difference_loss: 14.1116 - val_KL_divergence_loss: 3.4083 - val_neg_log_likelihood: 2163945817872696064.0000\n",
      "Epoch 810/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.1104 - squared_difference_loss: 13.8444 - KL_divergence_loss: 3.2660 - neg_log_likelihood: 1953197412.1857 - val_loss: 17.1175 - val_squared_difference_loss: 13.7624 - val_KL_divergence_loss: 3.3551 - val_neg_log_likelihood: 840572683776711040.0000\n",
      "Epoch 811/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 17.1222 - squared_difference_loss: 13.8688 - KL_divergence_loss: 3.2534 - neg_log_likelihood: 100826923.8520 - val_loss: 17.0765 - val_squared_difference_loss: 13.6615 - val_KL_divergence_loss: 3.4150 - val_neg_log_likelihood: 35669185895867.4062\n",
      "Epoch 812/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 17.0795 - squared_difference_loss: 13.8225 - KL_divergence_loss: 3.2569 - neg_log_likelihood: 2814221234.0725 - val_loss: 17.0863 - val_squared_difference_loss: 13.6949 - val_KL_divergence_loss: 3.3914 - val_neg_log_likelihood: 20178195809181504.0000\n",
      "Epoch 813/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.1039 - squared_difference_loss: 13.8347 - KL_divergence_loss: 3.2692 - neg_log_likelihood: 253929021.1506 - val_loss: 17.1889 - val_squared_difference_loss: 13.8124 - val_KL_divergence_loss: 3.3766 - val_neg_log_likelihood: 105392284622445.6562\n",
      "Epoch 814/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.1083 - squared_difference_loss: 13.8567 - KL_divergence_loss: 3.2516 - neg_log_likelihood: 180327861.4762 - val_loss: 17.1242 - val_squared_difference_loss: 13.7587 - val_KL_divergence_loss: 3.3654 - val_neg_log_likelihood: 102182223424787.3750\n",
      "Epoch 815/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.1120 - squared_difference_loss: 13.8517 - KL_divergence_loss: 3.2604 - neg_log_likelihood: 642632604.7019 - val_loss: 17.0846 - val_squared_difference_loss: 13.6595 - val_KL_divergence_loss: 3.4251 - val_neg_log_likelihood: 2050377589954975.2500\n",
      "Epoch 816/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 17.0930 - squared_difference_loss: 13.8473 - KL_divergence_loss: 3.2457 - neg_log_likelihood: 299152661.1588 - val_loss: 17.0753 - val_squared_difference_loss: 13.6575 - val_KL_divergence_loss: 3.4178 - val_neg_log_likelihood: 1068775898259429.7500\n",
      "Epoch 817/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 17.1045 - squared_difference_loss: 13.8224 - KL_divergence_loss: 3.2821 - neg_log_likelihood: 122810276.2153 - val_loss: 17.1788 - val_squared_difference_loss: 13.7512 - val_KL_divergence_loss: 3.4276 - val_neg_log_likelihood: 22787164459894510438641393729536.0000\n",
      "Epoch 818/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.0788 - squared_difference_loss: 13.8075 - KL_divergence_loss: 3.2713 - neg_log_likelihood: 247483546.6732 - val_loss: 17.1006 - val_squared_difference_loss: 13.6608 - val_KL_divergence_loss: 3.4398 - val_neg_log_likelihood: 61608624213347.4062\n",
      "Epoch 819/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.0810 - squared_difference_loss: 13.8237 - KL_divergence_loss: 3.2573 - neg_log_likelihood: 144857777.6036 - val_loss: 18.0606 - val_squared_difference_loss: 14.6244 - val_KL_divergence_loss: 3.4362 - val_neg_log_likelihood: 1614556854144975008432128.0000\n",
      "Epoch 820/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.0203 - squared_difference_loss: 13.7487 - KL_divergence_loss: 3.2717 - neg_log_likelihood: 419266172.4298 - val_loss: 17.0493 - val_squared_difference_loss: 13.6315 - val_KL_divergence_loss: 3.4178 - val_neg_log_likelihood: 14308340355462.4375\n",
      "Epoch 821/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.0448 - squared_difference_loss: 13.7695 - KL_divergence_loss: 3.2753 - neg_log_likelihood: 1738122526.7413 - val_loss: 17.0261 - val_squared_difference_loss: 13.6264 - val_KL_divergence_loss: 3.3997 - val_neg_log_likelihood: 378704467922680.3750\n",
      "Epoch 822/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.0630 - squared_difference_loss: 13.7848 - KL_divergence_loss: 3.2782 - neg_log_likelihood: 51392908.4234 - val_loss: 17.2003 - val_squared_difference_loss: 13.8247 - val_KL_divergence_loss: 3.3757 - val_neg_log_likelihood: inf\n",
      "Epoch 823/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.0036 - squared_difference_loss: 13.7518 - KL_divergence_loss: 3.2518 - neg_log_likelihood: 177558304.8580 - val_loss: 17.0727 - val_squared_difference_loss: 13.7309 - val_KL_divergence_loss: 3.3418 - val_neg_log_likelihood: 10201815959992404797292544.0000\n",
      "Epoch 824/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.0018 - squared_difference_loss: 13.7425 - KL_divergence_loss: 3.2593 - neg_log_likelihood: 252589883.8890 - val_loss: 16.9500 - val_squared_difference_loss: 13.6401 - val_KL_divergence_loss: 3.3099 - val_neg_log_likelihood: 428779613241703.5000\n",
      "Epoch 825/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 17.0191 - squared_difference_loss: 13.7639 - KL_divergence_loss: 3.2552 - neg_log_likelihood: 62946027.0690 - val_loss: 17.1039 - val_squared_difference_loss: 13.8033 - val_KL_divergence_loss: 3.3006 - val_neg_log_likelihood: 101485448774815288236038946816.0000\n",
      "Epoch 826/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 16.9983 - squared_difference_loss: 13.7148 - KL_divergence_loss: 3.2836 - neg_log_likelihood: 276312999.0130 - val_loss: 16.9940 - val_squared_difference_loss: 13.6674 - val_KL_divergence_loss: 3.3266 - val_neg_log_likelihood: 2629126627613.7476\n",
      "Epoch 827/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 16.9818 - squared_difference_loss: 13.6902 - KL_divergence_loss: 3.2916 - neg_log_likelihood: 637998714.3305 - val_loss: 16.9655 - val_squared_difference_loss: 13.6658 - val_KL_divergence_loss: 3.2997 - val_neg_log_likelihood: 144375498388.7863\n",
      "Epoch 828/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 16.9904 - squared_difference_loss: 13.7204 - KL_divergence_loss: 3.2700 - neg_log_likelihood: 422492486.4493 - val_loss: 16.9437 - val_squared_difference_loss: 13.6360 - val_KL_divergence_loss: 3.3078 - val_neg_log_likelihood: 151584459466.6174\n",
      "Epoch 829/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 17.0013 - squared_difference_loss: 13.6990 - KL_divergence_loss: 3.3023 - neg_log_likelihood: 28267636790.2960 - val_loss: 16.9629 - val_squared_difference_loss: 13.6840 - val_KL_divergence_loss: 3.2789 - val_neg_log_likelihood: 473404183005550081998848.0000\n",
      "Epoch 830/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.9317 - squared_difference_loss: 13.6532 - KL_divergence_loss: 3.2785 - neg_log_likelihood: 10338361534.1611 - val_loss: 16.9374 - val_squared_difference_loss: 13.6601 - val_KL_divergence_loss: 3.2773 - val_neg_log_likelihood: 3997215013488135168.0000\n",
      "Epoch 831/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 16.9390 - squared_difference_loss: 13.6610 - KL_divergence_loss: 3.2781 - neg_log_likelihood: 251212975.5741 - val_loss: 17.1752 - val_squared_difference_loss: 13.8949 - val_KL_divergence_loss: 3.2802 - val_neg_log_likelihood: 1924047281961442304.0000\n",
      "Epoch 832/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 16.9573 - squared_difference_loss: 13.6653 - KL_divergence_loss: 3.2920 - neg_log_likelihood: 6056462213.6577 - val_loss: 17.2652 - val_squared_difference_loss: 13.9830 - val_KL_divergence_loss: 3.2822 - val_neg_log_likelihood: 11162972328892981248.0000\n",
      "Epoch 833/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.9129 - squared_difference_loss: 13.6243 - KL_divergence_loss: 3.2887 - neg_log_likelihood: 497674423.2940 - val_loss: 16.8818 - val_squared_difference_loss: 13.6288 - val_KL_divergence_loss: 3.2530 - val_neg_log_likelihood: 10503542057946110.0000\n",
      "Epoch 834/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 16.9081 - squared_difference_loss: 13.6289 - KL_divergence_loss: 3.2792 - neg_log_likelihood: 834934151.3077 - val_loss: 16.9261 - val_squared_difference_loss: 13.6327 - val_KL_divergence_loss: 3.2934 - val_neg_log_likelihood: 52181855584661480547549184.0000\n",
      "Epoch 835/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.9053 - squared_difference_loss: 13.5907 - KL_divergence_loss: 3.3145 - neg_log_likelihood: 1573612282.8179 - val_loss: 16.8194 - val_squared_difference_loss: 13.5725 - val_KL_divergence_loss: 3.2469 - val_neg_log_likelihood: 11081349802513.7363\n",
      "Epoch 836/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 16.8501 - squared_difference_loss: 13.5647 - KL_divergence_loss: 3.2854 - neg_log_likelihood: 5834032470.1381 - val_loss: 16.8531 - val_squared_difference_loss: 13.6219 - val_KL_divergence_loss: 3.2312 - val_neg_log_likelihood: 534593922273788.3750\n",
      "Epoch 837/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.8528 - squared_difference_loss: 13.5517 - KL_divergence_loss: 3.3011 - neg_log_likelihood: 11538415727.1499 - val_loss: 16.9908 - val_squared_difference_loss: 13.7543 - val_KL_divergence_loss: 3.2364 - val_neg_log_likelihood: 32675554299537604.0000\n",
      "Epoch 838/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 16.8799 - squared_difference_loss: 13.5700 - KL_divergence_loss: 3.3099 - neg_log_likelihood: 3243743092.5335 - val_loss: 16.9250 - val_squared_difference_loss: 13.6962 - val_KL_divergence_loss: 3.2289 - val_neg_log_likelihood: 24816492909400604.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 839/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.8822 - squared_difference_loss: 13.5585 - KL_divergence_loss: 3.3237 - neg_log_likelihood: 622877192.6545 - val_loss: 16.7398 - val_squared_difference_loss: 13.4589 - val_KL_divergence_loss: 3.2809 - val_neg_log_likelihood: 759425211546.1735\n",
      "Epoch 840/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.8524 - squared_difference_loss: 13.5427 - KL_divergence_loss: 3.3097 - neg_log_likelihood: 13546779790.1915 - val_loss: 17.3053 - val_squared_difference_loss: 14.0225 - val_KL_divergence_loss: 3.2828 - val_neg_log_likelihood: 5309440563272707211264.0000\n",
      "Epoch 841/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.8679 - squared_difference_loss: 13.5401 - KL_divergence_loss: 3.3278 - neg_log_likelihood: 1534160552.9017 - val_loss: 16.7552 - val_squared_difference_loss: 13.4871 - val_KL_divergence_loss: 3.2681 - val_neg_log_likelihood: 29844625743864.9805\n",
      "Epoch 842/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.8407 - squared_difference_loss: 13.5237 - KL_divergence_loss: 3.3170 - neg_log_likelihood: 15600022551.2230 - val_loss: 16.7926 - val_squared_difference_loss: 13.5628 - val_KL_divergence_loss: 3.2298 - val_neg_log_likelihood: 34798913003384.9062\n",
      "Epoch 843/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 16.8131 - squared_difference_loss: 13.4986 - KL_divergence_loss: 3.3145 - neg_log_likelihood: 10859827802.2105 - val_loss: 16.6836 - val_squared_difference_loss: 13.4517 - val_KL_divergence_loss: 3.2319 - val_neg_log_likelihood: 34905860196593.7617\n",
      "Epoch 844/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.8093 - squared_difference_loss: 13.4877 - KL_divergence_loss: 3.3215 - neg_log_likelihood: 11971907000.5078 - val_loss: 17.2186 - val_squared_difference_loss: 14.0006 - val_KL_divergence_loss: 3.2181 - val_neg_log_likelihood: 1536459971109495242752.0000\n",
      "Epoch 845/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 16.8331 - squared_difference_loss: 13.5021 - KL_divergence_loss: 3.3311 - neg_log_likelihood: 7966818461.3458 - val_loss: 16.6580 - val_squared_difference_loss: 13.3932 - val_KL_divergence_loss: 3.2648 - val_neg_log_likelihood: 328020302610082048.0000\n",
      "Epoch 846/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.7816 - squared_difference_loss: 13.4663 - KL_divergence_loss: 3.3153 - neg_log_likelihood: 8609290743.0808 - val_loss: 16.6649 - val_squared_difference_loss: 13.4354 - val_KL_divergence_loss: 3.2295 - val_neg_log_likelihood: 2040707252201.6833\n",
      "Epoch 847/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.7822 - squared_difference_loss: 13.4570 - KL_divergence_loss: 3.3252 - neg_log_likelihood: 402392355.1527 - val_loss: 16.6985 - val_squared_difference_loss: 13.4467 - val_KL_divergence_loss: 3.2519 - val_neg_log_likelihood: 6024785747351961600000.0000\n",
      "Epoch 848/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.8193 - squared_difference_loss: 13.4765 - KL_divergence_loss: 3.3429 - neg_log_likelihood: 1607859728.2296 - val_loss: 16.6141 - val_squared_difference_loss: 13.3762 - val_KL_divergence_loss: 3.2379 - val_neg_log_likelihood: 5213701386445.2812\n",
      "Epoch 849/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.7594 - squared_difference_loss: 13.4162 - KL_divergence_loss: 3.3433 - neg_log_likelihood: 6811462115.6134 - val_loss: 16.6068 - val_squared_difference_loss: 13.3091 - val_KL_divergence_loss: 3.2976 - val_neg_log_likelihood: 810437716843689.6250\n",
      "Epoch 850/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.8042 - squared_difference_loss: 13.4583 - KL_divergence_loss: 3.3459 - neg_log_likelihood: 1194626114.4228 - val_loss: 16.6130 - val_squared_difference_loss: 13.3565 - val_KL_divergence_loss: 3.2565 - val_neg_log_likelihood: 676145358102431360.0000\n",
      "Epoch 851/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.7650 - squared_difference_loss: 13.4315 - KL_divergence_loss: 3.3335 - neg_log_likelihood: 881294265.4918 - val_loss: 16.6657 - val_squared_difference_loss: 13.3513 - val_KL_divergence_loss: 3.3144 - val_neg_log_likelihood: 1358641501341719.2500\n",
      "Epoch 852/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.7809 - squared_difference_loss: 13.4417 - KL_divergence_loss: 3.3392 - neg_log_likelihood: 1120350006.9300 - val_loss: 16.5377 - val_squared_difference_loss: 13.2641 - val_KL_divergence_loss: 3.2736 - val_neg_log_likelihood: 10020701931591.7207\n",
      "Epoch 853/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.7529 - squared_difference_loss: 13.4200 - KL_divergence_loss: 3.3329 - neg_log_likelihood: 888771796.7073 - val_loss: 16.5909 - val_squared_difference_loss: 13.2933 - val_KL_divergence_loss: 3.2976 - val_neg_log_likelihood: 329994341934369.6875\n",
      "Epoch 854/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.7780 - squared_difference_loss: 13.4409 - KL_divergence_loss: 3.3371 - neg_log_likelihood: 4543326265.8300 - val_loss: 16.5943 - val_squared_difference_loss: 13.2897 - val_KL_divergence_loss: 3.3046 - val_neg_log_likelihood: 555928242984.5588\n",
      "Epoch 855/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.7496 - squared_difference_loss: 13.4072 - KL_divergence_loss: 3.3424 - neg_log_likelihood: 5161913329.9233 - val_loss: 16.5606 - val_squared_difference_loss: 13.2904 - val_KL_divergence_loss: 3.2702 - val_neg_log_likelihood: 23448278151179.0273\n",
      "Epoch 856/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.7451 - squared_difference_loss: 13.4122 - KL_divergence_loss: 3.3329 - neg_log_likelihood: 184829033.4391 - val_loss: 16.5040 - val_squared_difference_loss: 13.2305 - val_KL_divergence_loss: 3.2735 - val_neg_log_likelihood: 68216342326700.7969\n",
      "Epoch 857/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.7466 - squared_difference_loss: 13.3838 - KL_divergence_loss: 3.3629 - neg_log_likelihood: 3386008261.2597 - val_loss: 16.5600 - val_squared_difference_loss: 13.2755 - val_KL_divergence_loss: 3.2845 - val_neg_log_likelihood: 111806364523628.7344\n",
      "Epoch 858/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.7191 - squared_difference_loss: 13.3746 - KL_divergence_loss: 3.3445 - neg_log_likelihood: 3736647629.1868 - val_loss: 16.5456 - val_squared_difference_loss: 13.2986 - val_KL_divergence_loss: 3.2470 - val_neg_log_likelihood: 1426125873311321856.0000\n",
      "Epoch 859/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.7184 - squared_difference_loss: 13.3714 - KL_divergence_loss: 3.3470 - neg_log_likelihood: 539610770.6349 - val_loss: 16.9496 - val_squared_difference_loss: 13.6724 - val_KL_divergence_loss: 3.2772 - val_neg_log_likelihood: 1194354389713587011584.0000\n",
      "Epoch 860/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.7442 - squared_difference_loss: 13.3949 - KL_divergence_loss: 3.3494 - neg_log_likelihood: 377194131.1061 - val_loss: 16.6852 - val_squared_difference_loss: 13.4115 - val_KL_divergence_loss: 3.2737 - val_neg_log_likelihood: 159247702504004544.0000\n",
      "Epoch 861/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.7449 - squared_difference_loss: 13.3613 - KL_divergence_loss: 3.3836 - neg_log_likelihood: 164221842.2075 - val_loss: 16.6400 - val_squared_difference_loss: 13.3408 - val_KL_divergence_loss: 3.2991 - val_neg_log_likelihood: 24933069608383828.0000\n",
      "Epoch 862/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.6979 - squared_difference_loss: 13.3536 - KL_divergence_loss: 3.3443 - neg_log_likelihood: 1202838108.1429 - val_loss: 16.5216 - val_squared_difference_loss: 13.2418 - val_KL_divergence_loss: 3.2797 - val_neg_log_likelihood: 3512221762466005.5000\n",
      "Epoch 863/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.7143 - squared_difference_loss: 13.3456 - KL_divergence_loss: 3.3688 - neg_log_likelihood: 155515541.7845 - val_loss: 16.4953 - val_squared_difference_loss: 13.1906 - val_KL_divergence_loss: 3.3047 - val_neg_log_likelihood: 216588017240063311872.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 864/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.7233 - squared_difference_loss: 13.3676 - KL_divergence_loss: 3.3558 - neg_log_likelihood: 1646273404.6784 - val_loss: 16.5107 - val_squared_difference_loss: 13.1832 - val_KL_divergence_loss: 3.3275 - val_neg_log_likelihood: 1084216591878939.6250\n",
      "Epoch 865/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.6994 - squared_difference_loss: 13.3319 - KL_divergence_loss: 3.3675 - neg_log_likelihood: 2233062075.1033 - val_loss: 16.4962 - val_squared_difference_loss: 13.2050 - val_KL_divergence_loss: 3.2912 - val_neg_log_likelihood: 816278500761650069504.0000\n",
      "Epoch 866/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.7366 - squared_difference_loss: 13.3677 - KL_divergence_loss: 3.3689 - neg_log_likelihood: 6097196747.8244 - val_loss: 16.4835 - val_squared_difference_loss: 13.1814 - val_KL_divergence_loss: 3.3021 - val_neg_log_likelihood: 27145840578883067904.0000\n",
      "Epoch 867/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 16.6945 - squared_difference_loss: 13.3361 - KL_divergence_loss: 3.3584 - neg_log_likelihood: 1125198197.1791 - val_loss: 16.4471 - val_squared_difference_loss: 13.0973 - val_KL_divergence_loss: 3.3498 - val_neg_log_likelihood: 59727869903064104.0000\n",
      "Epoch 868/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 16.7380 - squared_difference_loss: 13.3650 - KL_divergence_loss: 3.3730 - neg_log_likelihood: 89721612.6902 - val_loss: 16.4545 - val_squared_difference_loss: 13.1365 - val_KL_divergence_loss: 3.3180 - val_neg_log_likelihood: 5096150530193216.0000\n",
      "Epoch 869/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.6940 - squared_difference_loss: 13.3099 - KL_divergence_loss: 3.3841 - neg_log_likelihood: 110734847.9413 - val_loss: 16.5959 - val_squared_difference_loss: 13.2062 - val_KL_divergence_loss: 3.3897 - val_neg_log_likelihood: 27125998751250356.0000\n",
      "Epoch 870/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.6829 - squared_difference_loss: 13.3028 - KL_divergence_loss: 3.3802 - neg_log_likelihood: 510619454.6392 - val_loss: 16.5153 - val_squared_difference_loss: 13.1513 - val_KL_divergence_loss: 3.3639 - val_neg_log_likelihood: 2715367117219597.5000\n",
      "Epoch 871/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.6519 - squared_difference_loss: 13.2776 - KL_divergence_loss: 3.3742 - neg_log_likelihood: 1498848417.9884 - val_loss: 16.4895 - val_squared_difference_loss: 13.1725 - val_KL_divergence_loss: 3.3170 - val_neg_log_likelihood: 2764615882651192797429760.0000\n",
      "Epoch 872/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.6799 - squared_difference_loss: 13.2973 - KL_divergence_loss: 3.3826 - neg_log_likelihood: 860899200.7378 - val_loss: 16.4390 - val_squared_difference_loss: 13.1221 - val_KL_divergence_loss: 3.3169 - val_neg_log_likelihood: 25447904391696.6914\n",
      "Epoch 873/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.6312 - squared_difference_loss: 13.2692 - KL_divergence_loss: 3.3620 - neg_log_likelihood: 15326730017.8435 - val_loss: 16.4970 - val_squared_difference_loss: 13.1824 - val_KL_divergence_loss: 3.3146 - val_neg_log_likelihood: 161766094021056672.0000\n",
      "Epoch 874/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.6726 - squared_difference_loss: 13.3089 - KL_divergence_loss: 3.3637 - neg_log_likelihood: 50080326.8386 - val_loss: 16.5766 - val_squared_difference_loss: 13.2739 - val_KL_divergence_loss: 3.3028 - val_neg_log_likelihood: 554064357466652416.0000\n",
      "Epoch 875/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.6248 - squared_difference_loss: 13.2474 - KL_divergence_loss: 3.3774 - neg_log_likelihood: 325722237.1518 - val_loss: 16.4479 - val_squared_difference_loss: 13.1691 - val_KL_divergence_loss: 3.2789 - val_neg_log_likelihood: 6590298298223645696.0000\n",
      "Epoch 876/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.6500 - squared_difference_loss: 13.2905 - KL_divergence_loss: 3.3594 - neg_log_likelihood: 15248775469.9598 - val_loss: 16.4641 - val_squared_difference_loss: 13.1907 - val_KL_divergence_loss: 3.2735 - val_neg_log_likelihood: 7202209978686.4639\n",
      "Epoch 877/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.6405 - squared_difference_loss: 13.2655 - KL_divergence_loss: 3.3750 - neg_log_likelihood: 683601879.2765 - val_loss: 16.4566 - val_squared_difference_loss: 13.1145 - val_KL_divergence_loss: 3.3421 - val_neg_log_likelihood: 3747061302212765.0000\n",
      "Epoch 878/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.6659 - squared_difference_loss: 13.2736 - KL_divergence_loss: 3.3922 - neg_log_likelihood: 296282068.7741 - val_loss: 16.5001 - val_squared_difference_loss: 13.1670 - val_KL_divergence_loss: 3.3331 - val_neg_log_likelihood: 37763387384513072.0000\n",
      "Epoch 879/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.6936 - squared_difference_loss: 13.3170 - KL_divergence_loss: 3.3766 - neg_log_likelihood: 249642899.4794 - val_loss: 16.5139 - val_squared_difference_loss: 13.1138 - val_KL_divergence_loss: 3.4001 - val_neg_log_likelihood: 325955926743729920.0000\n",
      "Epoch 880/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.6113 - squared_difference_loss: 13.2303 - KL_divergence_loss: 3.3811 - neg_log_likelihood: 308820637.9443 - val_loss: 16.4940 - val_squared_difference_loss: 13.1487 - val_KL_divergence_loss: 3.3453 - val_neg_log_likelihood: 86471844798511680.0000\n",
      "Epoch 881/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.6147 - squared_difference_loss: 13.2402 - KL_divergence_loss: 3.3745 - neg_log_likelihood: 616097256.8347 - val_loss: 16.6711 - val_squared_difference_loss: 13.3472 - val_KL_divergence_loss: 3.3239 - val_neg_log_likelihood: 3658664194937673728.0000\n",
      "Epoch 882/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.6052 - squared_difference_loss: 13.2188 - KL_divergence_loss: 3.3864 - neg_log_likelihood: 178024550.3156 - val_loss: 16.3779 - val_squared_difference_loss: 13.0250 - val_KL_divergence_loss: 3.3529 - val_neg_log_likelihood: 28848040167639016.0000\n",
      "Epoch 883/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.5766 - squared_difference_loss: 13.2000 - KL_divergence_loss: 3.3766 - neg_log_likelihood: 2280515189.5978 - val_loss: 16.3829 - val_squared_difference_loss: 13.0613 - val_KL_divergence_loss: 3.3216 - val_neg_log_likelihood: 10922971605661.3145\n",
      "Epoch 884/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.6311 - squared_difference_loss: 13.2492 - KL_divergence_loss: 3.3820 - neg_log_likelihood: 37836892.0199 - val_loss: 16.4231 - val_squared_difference_loss: 13.0728 - val_KL_divergence_loss: 3.3504 - val_neg_log_likelihood: 48681590509114968.0000\n",
      "Epoch 885/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.5983 - squared_difference_loss: 13.2067 - KL_divergence_loss: 3.3916 - neg_log_likelihood: 4671788554.2195 - val_loss: 16.3514 - val_squared_difference_loss: 12.9812 - val_KL_divergence_loss: 3.3702 - val_neg_log_likelihood: 6090485004288.1787\n",
      "Epoch 886/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.6290 - squared_difference_loss: 13.2232 - KL_divergence_loss: 3.4058 - neg_log_likelihood: 2836408527.5841 - val_loss: 16.3645 - val_squared_difference_loss: 13.0216 - val_KL_divergence_loss: 3.3429 - val_neg_log_likelihood: 11680360878933.2676\n",
      "Epoch 887/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.6252 - squared_difference_loss: 13.2272 - KL_divergence_loss: 3.3981 - neg_log_likelihood: 46551027958.6829 - val_loss: 16.3850 - val_squared_difference_loss: 13.0214 - val_KL_divergence_loss: 3.3636 - val_neg_log_likelihood: 63400029302148.3203\n",
      "Epoch 888/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.5925 - squared_difference_loss: 13.2046 - KL_divergence_loss: 3.3879 - neg_log_likelihood: 1200374392.3291 - val_loss: 16.3574 - val_squared_difference_loss: 12.9908 - val_KL_divergence_loss: 3.3666 - val_neg_log_likelihood: 34242314153868.6094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 889/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.5840 - squared_difference_loss: 13.1880 - KL_divergence_loss: 3.3960 - neg_log_likelihood: 575715373.4417 - val_loss: 16.3941 - val_squared_difference_loss: 13.0236 - val_KL_divergence_loss: 3.3705 - val_neg_log_likelihood: 23560167654124.6328\n",
      "Epoch 890/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.5884 - squared_difference_loss: 13.1771 - KL_divergence_loss: 3.4113 - neg_log_likelihood: 2649445863.5119 - val_loss: 16.3868 - val_squared_difference_loss: 13.0680 - val_KL_divergence_loss: 3.3188 - val_neg_log_likelihood: 341805750372593.6250\n",
      "Epoch 891/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 16.6091 - squared_difference_loss: 13.2211 - KL_divergence_loss: 3.3880 - neg_log_likelihood: 111550934.7270 - val_loss: 16.3525 - val_squared_difference_loss: 12.9977 - val_KL_divergence_loss: 3.3548 - val_neg_log_likelihood: 39610321151795.9531\n",
      "Epoch 892/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.5802 - squared_difference_loss: 13.1735 - KL_divergence_loss: 3.4066 - neg_log_likelihood: 18522679754.9340 - val_loss: 16.3406 - val_squared_difference_loss: 12.9748 - val_KL_divergence_loss: 3.3658 - val_neg_log_likelihood: 3849460285476017.0000\n",
      "Epoch 893/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.5498 - squared_difference_loss: 13.1436 - KL_divergence_loss: 3.4062 - neg_log_likelihood: 4041908756.3990 - val_loss: 16.3734 - val_squared_difference_loss: 13.0999 - val_KL_divergence_loss: 3.2735 - val_neg_log_likelihood: 73250740249709.6094\n",
      "Epoch 894/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 16.6065 - squared_difference_loss: 13.2091 - KL_divergence_loss: 3.3975 - neg_log_likelihood: 1528098336.2827 - val_loss: 16.3434 - val_squared_difference_loss: 12.9387 - val_KL_divergence_loss: 3.4047 - val_neg_log_likelihood: 40638562076857960.0000\n",
      "Epoch 895/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.5422 - squared_difference_loss: 13.1454 - KL_divergence_loss: 3.3968 - neg_log_likelihood: 1648065464.4226 - val_loss: 16.3505 - val_squared_difference_loss: 13.0217 - val_KL_divergence_loss: 3.3287 - val_neg_log_likelihood: 469935297741208.7500\n",
      "Epoch 896/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.5616 - squared_difference_loss: 13.1643 - KL_divergence_loss: 3.3973 - neg_log_likelihood: 395805248.4916 - val_loss: 16.4100 - val_squared_difference_loss: 13.0744 - val_KL_divergence_loss: 3.3356 - val_neg_log_likelihood: 60556252980065600.0000\n",
      "Epoch 897/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.5869 - squared_difference_loss: 13.1835 - KL_divergence_loss: 3.4034 - neg_log_likelihood: 14850267778.3655 - val_loss: 16.3235 - val_squared_difference_loss: 12.9653 - val_KL_divergence_loss: 3.3583 - val_neg_log_likelihood: 169973708650811.2500\n",
      "Epoch 898/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 16.5638 - squared_difference_loss: 13.1572 - KL_divergence_loss: 3.4067 - neg_log_likelihood: 3732629053.7021 - val_loss: 16.3627 - val_squared_difference_loss: 12.9914 - val_KL_divergence_loss: 3.3713 - val_neg_log_likelihood: 11062184722556814.0000\n",
      "Epoch 899/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.5586 - squared_difference_loss: 13.1531 - KL_divergence_loss: 3.4056 - neg_log_likelihood: 412037770.8326 - val_loss: 16.3141 - val_squared_difference_loss: 12.9515 - val_KL_divergence_loss: 3.3627 - val_neg_log_likelihood: 364256173974332.2500\n",
      "Epoch 900/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.5483 - squared_difference_loss: 13.1471 - KL_divergence_loss: 3.4012 - neg_log_likelihood: 2088147656.6098 - val_loss: 16.3313 - val_squared_difference_loss: 12.9627 - val_KL_divergence_loss: 3.3686 - val_neg_log_likelihood: 11096435062102546.0000\n",
      "Epoch 901/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.5672 - squared_difference_loss: 13.1519 - KL_divergence_loss: 3.4153 - neg_log_likelihood: 1060177340.7168 - val_loss: 16.3145 - val_squared_difference_loss: 12.9103 - val_KL_divergence_loss: 3.4041 - val_neg_log_likelihood: 87542250939620638720.0000\n",
      "Epoch 902/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.5422 - squared_difference_loss: 13.1323 - KL_divergence_loss: 3.4099 - neg_log_likelihood: 4405013223.2327 - val_loss: 16.2838 - val_squared_difference_loss: 12.9532 - val_KL_divergence_loss: 3.3306 - val_neg_log_likelihood: 75983802736413.4062\n",
      "Epoch 903/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.5598 - squared_difference_loss: 13.1469 - KL_divergence_loss: 3.4129 - neg_log_likelihood: 710823498.0617 - val_loss: 16.4055 - val_squared_difference_loss: 13.0356 - val_KL_divergence_loss: 3.3699 - val_neg_log_likelihood: 59885228803992760.0000\n",
      "Epoch 904/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.5294 - squared_difference_loss: 13.1227 - KL_divergence_loss: 3.4067 - neg_log_likelihood: 2108005585.5992 - val_loss: 16.2847 - val_squared_difference_loss: 12.8876 - val_KL_divergence_loss: 3.3971 - val_neg_log_likelihood: 44017734140002.0703\n",
      "Epoch 905/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.5194 - squared_difference_loss: 13.1007 - KL_divergence_loss: 3.4187 - neg_log_likelihood: 1555484492.9727 - val_loss: 16.2744 - val_squared_difference_loss: 12.8881 - val_KL_divergence_loss: 3.3863 - val_neg_log_likelihood: 88744608462714.6406\n",
      "Epoch 906/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.5314 - squared_difference_loss: 13.1303 - KL_divergence_loss: 3.4010 - neg_log_likelihood: 9083016927.5255 - val_loss: 16.3364 - val_squared_difference_loss: 12.9717 - val_KL_divergence_loss: 3.3647 - val_neg_log_likelihood: 160025984205525.0000\n",
      "Epoch 907/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.5167 - squared_difference_loss: 13.1170 - KL_divergence_loss: 3.3997 - neg_log_likelihood: 7628264078.5098 - val_loss: 16.3203 - val_squared_difference_loss: 12.9614 - val_KL_divergence_loss: 3.3590 - val_neg_log_likelihood: 24333272367781804.0000\n",
      "Epoch 908/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.5017 - squared_difference_loss: 13.0883 - KL_divergence_loss: 3.4134 - neg_log_likelihood: 361306064.5053 - val_loss: 16.3250 - val_squared_difference_loss: 12.9364 - val_KL_divergence_loss: 3.3886 - val_neg_log_likelihood: 87770871857616512.0000\n",
      "Epoch 909/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.5374 - squared_difference_loss: 13.1172 - KL_divergence_loss: 3.4202 - neg_log_likelihood: 3001335920.4061 - val_loss: 16.2979 - val_squared_difference_loss: 12.9701 - val_KL_divergence_loss: 3.3278 - val_neg_log_likelihood: 2034227661469935.5000\n",
      "Epoch 910/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.5335 - squared_difference_loss: 13.1170 - KL_divergence_loss: 3.4164 - neg_log_likelihood: 318199507.8983 - val_loss: 16.2637 - val_squared_difference_loss: 12.8759 - val_KL_divergence_loss: 3.3877 - val_neg_log_likelihood: 197569424854533376.0000\n",
      "Epoch 911/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.5075 - squared_difference_loss: 13.0895 - KL_divergence_loss: 3.4180 - neg_log_likelihood: 1915133795.6470 - val_loss: 16.2820 - val_squared_difference_loss: 12.9350 - val_KL_divergence_loss: 3.3470 - val_neg_log_likelihood: 370283193244108.3125\n",
      "Epoch 912/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.4863 - squared_difference_loss: 13.0684 - KL_divergence_loss: 3.4179 - neg_log_likelihood: 1630307988.6791 - val_loss: 16.3701 - val_squared_difference_loss: 13.0151 - val_KL_divergence_loss: 3.3549 - val_neg_log_likelihood: 141018158695824704.0000\n",
      "Epoch 913/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.5288 - squared_difference_loss: 13.1072 - KL_divergence_loss: 3.4215 - neg_log_likelihood: 88146537.4540 - val_loss: 16.3700 - val_squared_difference_loss: 13.0362 - val_KL_divergence_loss: 3.3337 - val_neg_log_likelihood: 2028165501117272.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 914/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.5305 - squared_difference_loss: 13.0975 - KL_divergence_loss: 3.4331 - neg_log_likelihood: 596851943.8053 - val_loss: 16.3567 - val_squared_difference_loss: 12.8819 - val_KL_divergence_loss: 3.4748 - val_neg_log_likelihood: 16942049208059.0449\n",
      "Epoch 915/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.5078 - squared_difference_loss: 13.0724 - KL_divergence_loss: 3.4355 - neg_log_likelihood: 77913663.1792 - val_loss: 16.3443 - val_squared_difference_loss: 12.9434 - val_KL_divergence_loss: 3.4009 - val_neg_log_likelihood: 28623641427163524104192.0000\n",
      "Epoch 916/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.5388 - squared_difference_loss: 13.1265 - KL_divergence_loss: 3.4123 - neg_log_likelihood: 76250223.5728 - val_loss: 16.3612 - val_squared_difference_loss: 12.9156 - val_KL_divergence_loss: 3.4456 - val_neg_log_likelihood: 597893767152779904.0000\n",
      "Epoch 917/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.4718 - squared_difference_loss: 13.0280 - KL_divergence_loss: 3.4438 - neg_log_likelihood: 136343939.3071 - val_loss: 16.3609 - val_squared_difference_loss: 12.9448 - val_KL_divergence_loss: 3.4160 - val_neg_log_likelihood: 404458008405502848.0000\n",
      "Epoch 918/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.5010 - squared_difference_loss: 13.0592 - KL_divergence_loss: 3.4418 - neg_log_likelihood: 154112614.5703 - val_loss: 16.2777 - val_squared_difference_loss: 12.8935 - val_KL_divergence_loss: 3.3842 - val_neg_log_likelihood: 41768186876908296.0000\n",
      "Epoch 919/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.5289 - squared_difference_loss: 13.0976 - KL_divergence_loss: 3.4313 - neg_log_likelihood: 35652283.6849 - val_loss: 16.2645 - val_squared_difference_loss: 12.8767 - val_KL_divergence_loss: 3.3878 - val_neg_log_likelihood: 3405559393830776.0000\n",
      "Epoch 920/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.4913 - squared_difference_loss: 13.0724 - KL_divergence_loss: 3.4188 - neg_log_likelihood: 100011060.8658 - val_loss: 16.3486 - val_squared_difference_loss: 12.9626 - val_KL_divergence_loss: 3.3860 - val_neg_log_likelihood: 223744356975232288.0000\n",
      "Epoch 921/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 16.4606 - squared_difference_loss: 13.0296 - KL_divergence_loss: 3.4310 - neg_log_likelihood: 83340267.9837 - val_loss: 16.2736 - val_squared_difference_loss: 12.9099 - val_KL_divergence_loss: 3.3637 - val_neg_log_likelihood: 543178599338919.5000\n",
      "Epoch 922/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.4559 - squared_difference_loss: 13.0181 - KL_divergence_loss: 3.4378 - neg_log_likelihood: 6161205032.0583 - val_loss: 16.3112 - val_squared_difference_loss: 12.9204 - val_KL_divergence_loss: 3.3908 - val_neg_log_likelihood: 563720098537545280.0000\n",
      "Epoch 923/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.4367 - squared_difference_loss: 13.0110 - KL_divergence_loss: 3.4257 - neg_log_likelihood: 5515899292.1785 - val_loss: 16.2583 - val_squared_difference_loss: 12.8984 - val_KL_divergence_loss: 3.3598 - val_neg_log_likelihood: 73124306725375.4375\n",
      "Epoch 924/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.4572 - squared_difference_loss: 13.0262 - KL_divergence_loss: 3.4311 - neg_log_likelihood: 769093990.9180 - val_loss: 16.2799 - val_squared_difference_loss: 12.9613 - val_KL_divergence_loss: 3.3186 - val_neg_log_likelihood: 297057957044627.5625\n",
      "Epoch 925/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 16.4238 - squared_difference_loss: 12.9835 - KL_divergence_loss: 3.4403 - neg_log_likelihood: 168956772.7635 - val_loss: 16.2192 - val_squared_difference_loss: 12.8498 - val_KL_divergence_loss: 3.3694 - val_neg_log_likelihood: 60692330841822.8125\n",
      "Epoch 926/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.4336 - squared_difference_loss: 12.9945 - KL_divergence_loss: 3.4391 - neg_log_likelihood: 16190174785.7267 - val_loss: 16.2124 - val_squared_difference_loss: 12.8461 - val_KL_divergence_loss: 3.3663 - val_neg_log_likelihood: 92944456261608.0000\n",
      "Epoch 927/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.4597 - squared_difference_loss: 13.0363 - KL_divergence_loss: 3.4234 - neg_log_likelihood: 1169686442.5426 - val_loss: 16.2172 - val_squared_difference_loss: 12.8500 - val_KL_divergence_loss: 3.3673 - val_neg_log_likelihood: 841745752478693.5000\n",
      "Epoch 928/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.4548 - squared_difference_loss: 12.9889 - KL_divergence_loss: 3.4658 - neg_log_likelihood: 330326830.1692 - val_loss: 16.2152 - val_squared_difference_loss: 12.8289 - val_KL_divergence_loss: 3.3863 - val_neg_log_likelihood: 1564652898144297.2500\n",
      "Epoch 929/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.4761 - squared_difference_loss: 13.0333 - KL_divergence_loss: 3.4428 - neg_log_likelihood: 348429924.1395 - val_loss: 16.2938 - val_squared_difference_loss: 12.9513 - val_KL_divergence_loss: 3.3425 - val_neg_log_likelihood: 4745996081410564096.0000\n",
      "Epoch 930/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.4420 - squared_difference_loss: 13.0107 - KL_divergence_loss: 3.4313 - neg_log_likelihood: 943774041.5877 - val_loss: 16.2203 - val_squared_difference_loss: 12.7730 - val_KL_divergence_loss: 3.4473 - val_neg_log_likelihood: 10457328153931600.0000\n",
      "Epoch 931/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.4359 - squared_difference_loss: 13.0004 - KL_divergence_loss: 3.4355 - neg_log_likelihood: 223856309.7652 - val_loss: 16.2551 - val_squared_difference_loss: 12.8106 - val_KL_divergence_loss: 3.4446 - val_neg_log_likelihood: 45989854312667792.0000\n",
      "Epoch 932/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.4392 - squared_difference_loss: 12.9840 - KL_divergence_loss: 3.4551 - neg_log_likelihood: 35385091.2090 - val_loss: 16.2064 - val_squared_difference_loss: 12.8088 - val_KL_divergence_loss: 3.3976 - val_neg_log_likelihood: 270957696899924512.0000\n",
      "Epoch 933/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.4290 - squared_difference_loss: 12.9839 - KL_divergence_loss: 3.4451 - neg_log_likelihood: 201612377.4386 - val_loss: 16.1976 - val_squared_difference_loss: 12.7895 - val_KL_divergence_loss: 3.4082 - val_neg_log_likelihood: 269444824065818.3750\n",
      "Epoch 934/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.4315 - squared_difference_loss: 12.9757 - KL_divergence_loss: 3.4558 - neg_log_likelihood: 1285963598.8708 - val_loss: 16.2505 - val_squared_difference_loss: 12.8472 - val_KL_divergence_loss: 3.4033 - val_neg_log_likelihood: 993897654904641536.0000\n",
      "Epoch 935/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.4291 - squared_difference_loss: 12.9711 - KL_divergence_loss: 3.4581 - neg_log_likelihood: 859977093.3759 - val_loss: 16.1741 - val_squared_difference_loss: 12.8061 - val_KL_divergence_loss: 3.3680 - val_neg_log_likelihood: 131640973914407.3750\n",
      "Epoch 936/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.4103 - squared_difference_loss: 12.9562 - KL_divergence_loss: 3.4541 - neg_log_likelihood: 450782522.7791 - val_loss: 16.2859 - val_squared_difference_loss: 12.9414 - val_KL_divergence_loss: 3.3445 - val_neg_log_likelihood: 644458892727987863552.0000\n",
      "Epoch 937/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.4615 - squared_difference_loss: 12.9772 - KL_divergence_loss: 3.4843 - neg_log_likelihood: 842412072.9622 - val_loss: 16.1768 - val_squared_difference_loss: 12.7643 - val_KL_divergence_loss: 3.4126 - val_neg_log_likelihood: 159316950845690.9062\n",
      "Epoch 938/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.4262 - squared_difference_loss: 12.9630 - KL_divergence_loss: 3.4632 - neg_log_likelihood: 914716752.7813 - val_loss: 16.2015 - val_squared_difference_loss: 12.8227 - val_KL_divergence_loss: 3.3788 - val_neg_log_likelihood: 992987772186155.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 939/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.4352 - squared_difference_loss: 12.9793 - KL_divergence_loss: 3.4559 - neg_log_likelihood: 519152329.8473 - val_loss: 16.1873 - val_squared_difference_loss: 12.7827 - val_KL_divergence_loss: 3.4046 - val_neg_log_likelihood: 2496588697793903.0000\n",
      "Epoch 940/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.4001 - squared_difference_loss: 12.9443 - KL_divergence_loss: 3.4559 - neg_log_likelihood: 197373976.1795 - val_loss: 16.1786 - val_squared_difference_loss: 12.7732 - val_KL_divergence_loss: 3.4054 - val_neg_log_likelihood: 20155625440756352.0000\n",
      "Epoch 941/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 16.4264 - squared_difference_loss: 12.9638 - KL_divergence_loss: 3.4626 - neg_log_likelihood: 98117346.8294 - val_loss: 16.1950 - val_squared_difference_loss: 12.7466 - val_KL_divergence_loss: 3.4485 - val_neg_log_likelihood: 695022322664298752.0000\n",
      "Epoch 942/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 16.4102 - squared_difference_loss: 12.9399 - KL_divergence_loss: 3.4703 - neg_log_likelihood: 1203469944.0748 - val_loss: 16.2123 - val_squared_difference_loss: 12.7787 - val_KL_divergence_loss: 3.4336 - val_neg_log_likelihood: 309107672493333888.0000\n",
      "Epoch 943/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.3667 - squared_difference_loss: 12.9062 - KL_divergence_loss: 3.4604 - neg_log_likelihood: 1053655696.6279 - val_loss: 16.1781 - val_squared_difference_loss: 12.8068 - val_KL_divergence_loss: 3.3714 - val_neg_log_likelihood: 68362289596206.2969\n",
      "Epoch 944/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 16.4041 - squared_difference_loss: 12.9362 - KL_divergence_loss: 3.4679 - neg_log_likelihood: 941298412.9780 - val_loss: 16.1386 - val_squared_difference_loss: 12.7150 - val_KL_divergence_loss: 3.4237 - val_neg_log_likelihood: 16476490657575210.0000\n",
      "Epoch 945/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 16.3999 - squared_difference_loss: 12.9142 - KL_divergence_loss: 3.4857 - neg_log_likelihood: 1458125125.2447 - val_loss: 16.1542 - val_squared_difference_loss: 12.7318 - val_KL_divergence_loss: 3.4224 - val_neg_log_likelihood: 209696565254326845440.0000\n",
      "Epoch 946/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.3878 - squared_difference_loss: 12.9028 - KL_divergence_loss: 3.4850 - neg_log_likelihood: 189061123.4572 - val_loss: 16.2230 - val_squared_difference_loss: 12.8298 - val_KL_divergence_loss: 3.3932 - val_neg_log_likelihood: 32092570777727688704.0000\n",
      "Epoch 947/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 16.4158 - squared_difference_loss: 12.9345 - KL_divergence_loss: 3.4813 - neg_log_likelihood: 146049667.8687 - val_loss: 16.1740 - val_squared_difference_loss: 12.7325 - val_KL_divergence_loss: 3.4414 - val_neg_log_likelihood: 39244233512398584.0000\n",
      "Epoch 948/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.3793 - squared_difference_loss: 12.9029 - KL_divergence_loss: 3.4764 - neg_log_likelihood: 311772340.6388 - val_loss: 16.1498 - val_squared_difference_loss: 12.7154 - val_KL_divergence_loss: 3.4344 - val_neg_log_likelihood: 245585703397711.7188\n",
      "Epoch 949/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.3898 - squared_difference_loss: 12.8970 - KL_divergence_loss: 3.4928 - neg_log_likelihood: 55684845.5440 - val_loss: 16.1550 - val_squared_difference_loss: 12.7591 - val_KL_divergence_loss: 3.3960 - val_neg_log_likelihood: 6952783187376576.0000\n",
      "Epoch 950/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 16.3956 - squared_difference_loss: 12.8979 - KL_divergence_loss: 3.4977 - neg_log_likelihood: 214432278.5091 - val_loss: 16.1401 - val_squared_difference_loss: 12.7115 - val_KL_divergence_loss: 3.4285 - val_neg_log_likelihood: 91705154083217.7812\n",
      "Epoch 951/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.3781 - squared_difference_loss: 12.8701 - KL_divergence_loss: 3.5080 - neg_log_likelihood: 147665050.5915 - val_loss: 16.1636 - val_squared_difference_loss: 12.7465 - val_KL_divergence_loss: 3.4171 - val_neg_log_likelihood: 348294765082998.0000\n",
      "Epoch 952/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.3740 - squared_difference_loss: 12.8820 - KL_divergence_loss: 3.4920 - neg_log_likelihood: 5571907359.0077 - val_loss: 16.1431 - val_squared_difference_loss: 12.7491 - val_KL_divergence_loss: 3.3939 - val_neg_log_likelihood: 11138283173582256.0000\n",
      "Epoch 953/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.3896 - squared_difference_loss: 12.8875 - KL_divergence_loss: 3.5022 - neg_log_likelihood: 235098747.2570 - val_loss: 16.1266 - val_squared_difference_loss: 12.6949 - val_KL_divergence_loss: 3.4316 - val_neg_log_likelihood: 54887634087163.5703\n",
      "Epoch 954/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.3383 - squared_difference_loss: 12.8429 - KL_divergence_loss: 3.4954 - neg_log_likelihood: 1958734673.9281 - val_loss: 16.1422 - val_squared_difference_loss: 12.7394 - val_KL_divergence_loss: 3.4028 - val_neg_log_likelihood: 16891890290928092.0000\n",
      "Epoch 955/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.3687 - squared_difference_loss: 12.8753 - KL_divergence_loss: 3.4933 - neg_log_likelihood: 146234144.2007 - val_loss: 16.1500 - val_squared_difference_loss: 12.7120 - val_KL_divergence_loss: 3.4380 - val_neg_log_likelihood: 123143531711772480.0000\n",
      "Epoch 956/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.3500 - squared_difference_loss: 12.8463 - KL_divergence_loss: 3.5037 - neg_log_likelihood: 2759875220.6959 - val_loss: 16.1174 - val_squared_difference_loss: 12.6583 - val_KL_divergence_loss: 3.4591 - val_neg_log_likelihood: 674068901278620.6250\n",
      "Epoch 957/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.3653 - squared_difference_loss: 12.8540 - KL_divergence_loss: 3.5113 - neg_log_likelihood: 141918459.7274 - val_loss: 16.1607 - val_squared_difference_loss: 12.7317 - val_KL_divergence_loss: 3.4291 - val_neg_log_likelihood: 9600770384554298.0000\n",
      "Epoch 958/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.3072 - squared_difference_loss: 12.8085 - KL_divergence_loss: 3.4987 - neg_log_likelihood: 57385076.0109 - val_loss: 16.0981 - val_squared_difference_loss: 12.6836 - val_KL_divergence_loss: 3.4145 - val_neg_log_likelihood: 50019705511275.0312\n",
      "Epoch 959/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.3473 - squared_difference_loss: 12.8732 - KL_divergence_loss: 3.4742 - neg_log_likelihood: 57601611.1869 - val_loss: 16.1529 - val_squared_difference_loss: 12.7728 - val_KL_divergence_loss: 3.3802 - val_neg_log_likelihood: 1199535742871263.0000\n",
      "Epoch 960/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.3428 - squared_difference_loss: 12.8452 - KL_divergence_loss: 3.4976 - neg_log_likelihood: 577600466.2562 - val_loss: 16.1356 - val_squared_difference_loss: 12.7875 - val_KL_divergence_loss: 3.3481 - val_neg_log_likelihood: 1792858543115793.0000\n",
      "Epoch 961/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.3479 - squared_difference_loss: 12.8478 - KL_divergence_loss: 3.5000 - neg_log_likelihood: 436682622.0866 - val_loss: 16.2141 - val_squared_difference_loss: 12.7850 - val_KL_divergence_loss: 3.4291 - val_neg_log_likelihood: 14912510938202707968.0000\n",
      "Epoch 962/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.3259 - squared_difference_loss: 12.8281 - KL_divergence_loss: 3.4979 - neg_log_likelihood: 147545839.4801 - val_loss: 16.1784 - val_squared_difference_loss: 12.7262 - val_KL_divergence_loss: 3.4522 - val_neg_log_likelihood: 244234682194001428480.0000\n",
      "Epoch 963/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.3135 - squared_difference_loss: 12.7918 - KL_divergence_loss: 3.5217 - neg_log_likelihood: 38905622.8528 - val_loss: 16.0577 - val_squared_difference_loss: 12.6071 - val_KL_divergence_loss: 3.4506 - val_neg_log_likelihood: 369678320554641.5625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 964/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.3374 - squared_difference_loss: 12.8313 - KL_divergence_loss: 3.5061 - neg_log_likelihood: 717843911.6635 - val_loss: 16.2794 - val_squared_difference_loss: 12.8390 - val_KL_divergence_loss: 3.4404 - val_neg_log_likelihood: 135939138156569556942848.0000\n",
      "Epoch 965/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 16.3059 - squared_difference_loss: 12.7928 - KL_divergence_loss: 3.5131 - neg_log_likelihood: 132286866.4515 - val_loss: 16.0834 - val_squared_difference_loss: 12.6283 - val_KL_divergence_loss: 3.4551 - val_neg_log_likelihood: 327561220826074.5000\n",
      "Epoch 966/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.3054 - squared_difference_loss: 12.7967 - KL_divergence_loss: 3.5087 - neg_log_likelihood: 188445429.6486 - val_loss: 16.2153 - val_squared_difference_loss: 12.7943 - val_KL_divergence_loss: 3.4210 - val_neg_log_likelihood: 2170759235209344843776.0000\n",
      "Epoch 967/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 16.3157 - squared_difference_loss: 12.8071 - KL_divergence_loss: 3.5086 - neg_log_likelihood: 546671314.9089 - val_loss: 16.0916 - val_squared_difference_loss: 12.6268 - val_KL_divergence_loss: 3.4648 - val_neg_log_likelihood: 1398044107373821.0000\n",
      "Epoch 968/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 16.3787 - squared_difference_loss: 12.8591 - KL_divergence_loss: 3.5197 - neg_log_likelihood: 65407928.7922 - val_loss: 16.0316 - val_squared_difference_loss: 12.5557 - val_KL_divergence_loss: 3.4760 - val_neg_log_likelihood: 104982755454098.7188\n",
      "Epoch 969/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.2913 - squared_difference_loss: 12.7689 - KL_divergence_loss: 3.5223 - neg_log_likelihood: 233081974.6550 - val_loss: 16.1595 - val_squared_difference_loss: 12.6506 - val_KL_divergence_loss: 3.5088 - val_neg_log_likelihood: 551601217095137820672.0000\n",
      "Epoch 970/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 16.2885 - squared_difference_loss: 12.7608 - KL_divergence_loss: 3.5277 - neg_log_likelihood: 1390796893.0041 - val_loss: 16.1022 - val_squared_difference_loss: 12.6210 - val_KL_divergence_loss: 3.4812 - val_neg_log_likelihood: 34626241276343528.0000\n",
      "Epoch 971/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.2752 - squared_difference_loss: 12.7660 - KL_divergence_loss: 3.5092 - neg_log_likelihood: 16805643.1284 - val_loss: 16.1513 - val_squared_difference_loss: 12.6700 - val_KL_divergence_loss: 3.4813 - val_neg_log_likelihood: 76108351017531932672.0000\n",
      "Epoch 972/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.3160 - squared_difference_loss: 12.7837 - KL_divergence_loss: 3.5322 - neg_log_likelihood: 24836338.5272 - val_loss: 16.0560 - val_squared_difference_loss: 12.5867 - val_KL_divergence_loss: 3.4693 - val_neg_log_likelihood: 167936908773934.6250\n",
      "Epoch 973/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.2894 - squared_difference_loss: 12.7820 - KL_divergence_loss: 3.5074 - neg_log_likelihood: 5038830087.3899 - val_loss: 16.0883 - val_squared_difference_loss: 12.6307 - val_KL_divergence_loss: 3.4576 - val_neg_log_likelihood: 43521002696100.0781\n",
      "Epoch 974/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 16.2906 - squared_difference_loss: 12.7503 - KL_divergence_loss: 3.5403 - neg_log_likelihood: 98948972.7518 - val_loss: 16.0457 - val_squared_difference_loss: 12.6202 - val_KL_divergence_loss: 3.4256 - val_neg_log_likelihood: 146595617113982.0000\n",
      "Epoch 975/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.3058 - squared_difference_loss: 12.7581 - KL_divergence_loss: 3.5477 - neg_log_likelihood: 510364829.1324 - val_loss: 16.2011 - val_squared_difference_loss: 12.7672 - val_KL_divergence_loss: 3.4339 - val_neg_log_likelihood: 59270051818738963972096.0000\n",
      "Epoch 976/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.2876 - squared_difference_loss: 12.7473 - KL_divergence_loss: 3.5403 - neg_log_likelihood: 34582854.9126 - val_loss: 16.0643 - val_squared_difference_loss: 12.5976 - val_KL_divergence_loss: 3.4667 - val_neg_log_likelihood: 22029243446957516.0000\n",
      "Epoch 977/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.2415 - squared_difference_loss: 12.7090 - KL_divergence_loss: 3.5324 - neg_log_likelihood: 118847406.3498 - val_loss: 16.0851 - val_squared_difference_loss: 12.6399 - val_KL_divergence_loss: 3.4452 - val_neg_log_likelihood: 3636146419225767936.0000\n",
      "Epoch 978/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.2558 - squared_difference_loss: 12.7298 - KL_divergence_loss: 3.5259 - neg_log_likelihood: 274102214.4887 - val_loss: 16.0183 - val_squared_difference_loss: 12.5428 - val_KL_divergence_loss: 3.4755 - val_neg_log_likelihood: 15108629578462292.0000\n",
      "Epoch 979/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.2594 - squared_difference_loss: 12.7253 - KL_divergence_loss: 3.5341 - neg_log_likelihood: 75475215.0018 - val_loss: 16.0460 - val_squared_difference_loss: 12.5915 - val_KL_divergence_loss: 3.4544 - val_neg_log_likelihood: 36995625368979256.0000\n",
      "Epoch 980/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 16.2515 - squared_difference_loss: 12.7173 - KL_divergence_loss: 3.5342 - neg_log_likelihood: 86041626.1803 - val_loss: 16.0425 - val_squared_difference_loss: 12.5818 - val_KL_divergence_loss: 3.4607 - val_neg_log_likelihood: 56181764974437120.0000\n",
      "Epoch 981/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.2660 - squared_difference_loss: 12.7388 - KL_divergence_loss: 3.5272 - neg_log_likelihood: 55185136.6540 - val_loss: 16.0157 - val_squared_difference_loss: 12.5229 - val_KL_divergence_loss: 3.4928 - val_neg_log_likelihood: 162401507131840096.0000\n",
      "Epoch 982/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.2468 - squared_difference_loss: 12.7148 - KL_divergence_loss: 3.5320 - neg_log_likelihood: 30928713.9935 - val_loss: 16.0159 - val_squared_difference_loss: 12.5324 - val_KL_divergence_loss: 3.4835 - val_neg_log_likelihood: 40286405845591.2812\n",
      "Epoch 983/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.2312 - squared_difference_loss: 12.6907 - KL_divergence_loss: 3.5404 - neg_log_likelihood: 23207396.1390 - val_loss: 16.0029 - val_squared_difference_loss: 12.5420 - val_KL_divergence_loss: 3.4609 - val_neg_log_likelihood: 323948664405220.6250\n",
      "Epoch 984/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.2318 - squared_difference_loss: 12.6950 - KL_divergence_loss: 3.5368 - neg_log_likelihood: 250431442.7565 - val_loss: 16.0212 - val_squared_difference_loss: 12.5352 - val_KL_divergence_loss: 3.4860 - val_neg_log_likelihood: 250804108359025.0000\n",
      "Epoch 985/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.2238 - squared_difference_loss: 12.6858 - KL_divergence_loss: 3.5380 - neg_log_likelihood: 502348304.2312 - val_loss: 16.0179 - val_squared_difference_loss: 12.5542 - val_KL_divergence_loss: 3.4637 - val_neg_log_likelihood: 1462115312110926.7500\n",
      "Epoch 986/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.2300 - squared_difference_loss: 12.6835 - KL_divergence_loss: 3.5465 - neg_log_likelihood: 1156693794.7018 - val_loss: 16.0616 - val_squared_difference_loss: 12.6318 - val_KL_divergence_loss: 3.4299 - val_neg_log_likelihood: 33202552307522604.0000\n",
      "Epoch 987/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.2102 - squared_difference_loss: 12.6743 - KL_divergence_loss: 3.5360 - neg_log_likelihood: 210641079.8729 - val_loss: 16.0748 - val_squared_difference_loss: 12.6271 - val_KL_divergence_loss: 3.4477 - val_neg_log_likelihood: 1030380649055394988032.0000\n",
      "Epoch 988/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.2536 - squared_difference_loss: 12.7247 - KL_divergence_loss: 3.5289 - neg_log_likelihood: 503740776.3475 - val_loss: 15.9983 - val_squared_difference_loss: 12.5260 - val_KL_divergence_loss: 3.4724 - val_neg_log_likelihood: 1077227443395635.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 989/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.2212 - squared_difference_loss: 12.6658 - KL_divergence_loss: 3.5554 - neg_log_likelihood: 1075939340.1341 - val_loss: 16.0285 - val_squared_difference_loss: 12.5442 - val_KL_divergence_loss: 3.4843 - val_neg_log_likelihood: 427159735700884.6250\n",
      "Epoch 990/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.2494 - squared_difference_loss: 12.6954 - KL_divergence_loss: 3.5540 - neg_log_likelihood: 52398057.7110 - val_loss: 16.0834 - val_squared_difference_loss: 12.5942 - val_KL_divergence_loss: 3.4892 - val_neg_log_likelihood: 36749629351514190381056.0000\n",
      "Epoch 991/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.2268 - squared_difference_loss: 12.6757 - KL_divergence_loss: 3.5511 - neg_log_likelihood: 244020350.8058 - val_loss: 15.9901 - val_squared_difference_loss: 12.5148 - val_KL_divergence_loss: 3.4753 - val_neg_log_likelihood: 36169975194420512.0000\n",
      "Epoch 992/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 16.2273 - squared_difference_loss: 12.6643 - KL_divergence_loss: 3.5629 - neg_log_likelihood: 221753926.2782 - val_loss: 15.9998 - val_squared_difference_loss: 12.4961 - val_KL_divergence_loss: 3.5036 - val_neg_log_likelihood: 583316353569717888.0000\n",
      "Epoch 993/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.1884 - squared_difference_loss: 12.6399 - KL_divergence_loss: 3.5485 - neg_log_likelihood: 98070005.6322 - val_loss: 16.0056 - val_squared_difference_loss: 12.5166 - val_KL_divergence_loss: 3.4890 - val_neg_log_likelihood: 17629875317540456.0000\n",
      "Epoch 994/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.2187 - squared_difference_loss: 12.6714 - KL_divergence_loss: 3.5473 - neg_log_likelihood: 393505370.6721 - val_loss: 16.0099 - val_squared_difference_loss: 12.5212 - val_KL_divergence_loss: 3.4887 - val_neg_log_likelihood: 9872095084074070016.0000\n",
      "Epoch 995/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.1953 - squared_difference_loss: 12.6306 - KL_divergence_loss: 3.5647 - neg_log_likelihood: 3590127068.5586 - val_loss: 15.9838 - val_squared_difference_loss: 12.4493 - val_KL_divergence_loss: 3.5344 - val_neg_log_likelihood: 20115942291556580.0000\n",
      "Epoch 996/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 16.2092 - squared_difference_loss: 12.6509 - KL_divergence_loss: 3.5583 - neg_log_likelihood: 158695224.5234 - val_loss: 16.0078 - val_squared_difference_loss: 12.5472 - val_KL_divergence_loss: 3.4606 - val_neg_log_likelihood: 189068752092312928.0000\n",
      "Epoch 997/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.1670 - squared_difference_loss: 12.5983 - KL_divergence_loss: 3.5687 - neg_log_likelihood: 9031731491.0945 - val_loss: 15.9739 - val_squared_difference_loss: 12.4621 - val_KL_divergence_loss: 3.5118 - val_neg_log_likelihood: 48078623001165808.0000\n",
      "Epoch 998/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.1757 - squared_difference_loss: 12.6217 - KL_divergence_loss: 3.5540 - neg_log_likelihood: 23700822.1492 - val_loss: 15.9631 - val_squared_difference_loss: 12.4047 - val_KL_divergence_loss: 3.5584 - val_neg_log_likelihood: 39981156093956136.0000\n",
      "Epoch 999/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.1951 - squared_difference_loss: 12.6524 - KL_divergence_loss: 3.5427 - neg_log_likelihood: 836830612.5967 - val_loss: 15.9843 - val_squared_difference_loss: 12.4849 - val_KL_divergence_loss: 3.4994 - val_neg_log_likelihood: 62186684085202.7812\n",
      "Epoch 1000/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.2211 - squared_difference_loss: 12.6636 - KL_divergence_loss: 3.5575 - neg_log_likelihood: 627109614.9515 - val_loss: 15.9326 - val_squared_difference_loss: 12.4289 - val_KL_divergence_loss: 3.5037 - val_neg_log_likelihood: 126093515081692160.0000\n",
      "Epoch 1001/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.1962 - squared_difference_loss: 12.6047 - KL_divergence_loss: 3.5915 - neg_log_likelihood: 631571745.0369 - val_loss: 15.9869 - val_squared_difference_loss: 12.4828 - val_KL_divergence_loss: 3.5042 - val_neg_log_likelihood: 9529712358836180992.0000\n",
      "Epoch 1002/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.1720 - squared_difference_loss: 12.6052 - KL_divergence_loss: 3.5667 - neg_log_likelihood: 442996831.7264 - val_loss: 15.9214 - val_squared_difference_loss: 12.4136 - val_KL_divergence_loss: 3.5078 - val_neg_log_likelihood: 1682134952774758.2500\n",
      "Epoch 1003/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.2044 - squared_difference_loss: 12.6426 - KL_divergence_loss: 3.5618 - neg_log_likelihood: 892585803.0495 - val_loss: 15.9888 - val_squared_difference_loss: 12.4617 - val_KL_divergence_loss: 3.5271 - val_neg_log_likelihood: 35574893959183248.0000\n",
      "Epoch 1004/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.2090 - squared_difference_loss: 12.6161 - KL_divergence_loss: 3.5929 - neg_log_likelihood: 713001649.3875 - val_loss: 15.9115 - val_squared_difference_loss: 12.3828 - val_KL_divergence_loss: 3.5287 - val_neg_log_likelihood: 3180053033894054912.0000\n",
      "Epoch 1005/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.1801 - squared_difference_loss: 12.6071 - KL_divergence_loss: 3.5730 - neg_log_likelihood: 126395559.8183 - val_loss: 15.9295 - val_squared_difference_loss: 12.4041 - val_KL_divergence_loss: 3.5254 - val_neg_log_likelihood: 6320538296321384.0000\n",
      "Epoch 1006/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.1858 - squared_difference_loss: 12.5839 - KL_divergence_loss: 3.6019 - neg_log_likelihood: 386855390.8482 - val_loss: 15.9459 - val_squared_difference_loss: 12.4029 - val_KL_divergence_loss: 3.5430 - val_neg_log_likelihood: 18972480624672604160.0000\n",
      "Epoch 1007/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.1497 - squared_difference_loss: 12.5739 - KL_divergence_loss: 3.5757 - neg_log_likelihood: 176519313.7462 - val_loss: 15.9404 - val_squared_difference_loss: 12.4342 - val_KL_divergence_loss: 3.5062 - val_neg_log_likelihood: 29296485681464942592.0000\n",
      "Epoch 1008/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.1495 - squared_difference_loss: 12.5796 - KL_divergence_loss: 3.5699 - neg_log_likelihood: 2534154081.1135 - val_loss: 15.9040 - val_squared_difference_loss: 12.4099 - val_KL_divergence_loss: 3.4941 - val_neg_log_likelihood: 6183412097949543.0000\n",
      "Epoch 1009/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.1506 - squared_difference_loss: 12.5664 - KL_divergence_loss: 3.5843 - neg_log_likelihood: 142193847.1978 - val_loss: 15.8978 - val_squared_difference_loss: 12.3994 - val_KL_divergence_loss: 3.4983 - val_neg_log_likelihood: 343595212913912.5000\n",
      "Epoch 1010/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.1373 - squared_difference_loss: 12.5656 - KL_divergence_loss: 3.5717 - neg_log_likelihood: 7068451409.8747 - val_loss: 15.9168 - val_squared_difference_loss: 12.4315 - val_KL_divergence_loss: 3.4853 - val_neg_log_likelihood: 665593983642649.5000\n",
      "Epoch 1011/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.1296 - squared_difference_loss: 12.5442 - KL_divergence_loss: 3.5854 - neg_log_likelihood: 731776408.2942 - val_loss: 15.8664 - val_squared_difference_loss: 12.3444 - val_KL_divergence_loss: 3.5220 - val_neg_log_likelihood: 90229407859756336.0000\n",
      "Epoch 1012/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.1191 - squared_difference_loss: 12.5472 - KL_divergence_loss: 3.5719 - neg_log_likelihood: 23536450451.8241 - val_loss: 15.9039 - val_squared_difference_loss: 12.3905 - val_KL_divergence_loss: 3.5133 - val_neg_log_likelihood: 36343505039812536.0000\n",
      "Epoch 1013/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.1279 - squared_difference_loss: 12.5508 - KL_divergence_loss: 3.5771 - neg_log_likelihood: 16069747423.0520 - val_loss: 15.8917 - val_squared_difference_loss: 12.3404 - val_KL_divergence_loss: 3.5514 - val_neg_log_likelihood: 489783142792569344.0000\n",
      "Epoch 1014/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.1526 - squared_difference_loss: 12.5655 - KL_divergence_loss: 3.5871 - neg_log_likelihood: 905838636.2545 - val_loss: 15.9187 - val_squared_difference_loss: 12.3529 - val_KL_divergence_loss: 3.5657 - val_neg_log_likelihood: 6600676066408645.0000\n",
      "Epoch 1015/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 16.0972 - squared_difference_loss: 12.5097 - KL_divergence_loss: 3.5875 - neg_log_likelihood: 114004062.7742 - val_loss: 15.9039 - val_squared_difference_loss: 12.3704 - val_KL_divergence_loss: 3.5335 - val_neg_log_likelihood: 57780993307535192.0000\n",
      "Epoch 1016/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.1330 - squared_difference_loss: 12.5500 - KL_divergence_loss: 3.5830 - neg_log_likelihood: 234971088.2948 - val_loss: 15.8896 - val_squared_difference_loss: 12.3674 - val_KL_divergence_loss: 3.5222 - val_neg_log_likelihood: 2778572535593932.5000\n",
      "Epoch 1017/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.0912 - squared_difference_loss: 12.4930 - KL_divergence_loss: 3.5982 - neg_log_likelihood: 3951811626.9401 - val_loss: 15.8681 - val_squared_difference_loss: 12.3497 - val_KL_divergence_loss: 3.5184 - val_neg_log_likelihood: 176088211653481248.0000\n",
      "Epoch 1018/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.0941 - squared_difference_loss: 12.5076 - KL_divergence_loss: 3.5864 - neg_log_likelihood: 4561351708.6429 - val_loss: 15.8750 - val_squared_difference_loss: 12.3517 - val_KL_divergence_loss: 3.5233 - val_neg_log_likelihood: 30864889241414184.0000\n",
      "Epoch 1019/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.1214 - squared_difference_loss: 12.5287 - KL_divergence_loss: 3.5927 - neg_log_likelihood: 185862930.1750 - val_loss: 15.9139 - val_squared_difference_loss: 12.3830 - val_KL_divergence_loss: 3.5308 - val_neg_log_likelihood: 15169185504151068672.0000\n",
      "Epoch 1020/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.1384 - squared_difference_loss: 12.5298 - KL_divergence_loss: 3.6087 - neg_log_likelihood: 82951537.4143 - val_loss: 15.9173 - val_squared_difference_loss: 12.3543 - val_KL_divergence_loss: 3.5631 - val_neg_log_likelihood: 1522552302422828032.0000\n",
      "Epoch 1021/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.1093 - squared_difference_loss: 12.4999 - KL_divergence_loss: 3.6094 - neg_log_likelihood: 274711630035.2862 - val_loss: 15.9017 - val_squared_difference_loss: 12.3591 - val_KL_divergence_loss: 3.5426 - val_neg_log_likelihood: 76723248673970080.0000\n",
      "Epoch 1022/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.0783 - squared_difference_loss: 12.4656 - KL_divergence_loss: 3.6127 - neg_log_likelihood: 2445837024.3315 - val_loss: 15.9179 - val_squared_difference_loss: 12.3788 - val_KL_divergence_loss: 3.5391 - val_neg_log_likelihood: 251809800016350752.0000\n",
      "Epoch 1023/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.1188 - squared_difference_loss: 12.5155 - KL_divergence_loss: 3.6033 - neg_log_likelihood: 2817315441.4907 - val_loss: 15.8785 - val_squared_difference_loss: 12.3525 - val_KL_divergence_loss: 3.5260 - val_neg_log_likelihood: 8958158276042279936.0000\n",
      "Epoch 1024/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.1252 - squared_difference_loss: 12.5079 - KL_divergence_loss: 3.6174 - neg_log_likelihood: 850889474.5892 - val_loss: 15.8951 - val_squared_difference_loss: 12.3666 - val_KL_divergence_loss: 3.5285 - val_neg_log_likelihood: 73471645862415632.0000\n",
      "Epoch 1025/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.0853 - squared_difference_loss: 12.4682 - KL_divergence_loss: 3.6171 - neg_log_likelihood: 646858533.2450 - val_loss: 15.8445 - val_squared_difference_loss: 12.3222 - val_KL_divergence_loss: 3.5223 - val_neg_log_likelihood: 1268011124959049984.0000\n",
      "Epoch 1026/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.0779 - squared_difference_loss: 12.4679 - KL_divergence_loss: 3.6100 - neg_log_likelihood: 4916716902.1328 - val_loss: 15.8927 - val_squared_difference_loss: 12.3561 - val_KL_divergence_loss: 3.5366 - val_neg_log_likelihood: 195733422029134336.0000\n",
      "Epoch 1027/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.0944 - squared_difference_loss: 12.4823 - KL_divergence_loss: 3.6121 - neg_log_likelihood: 959728094.8306 - val_loss: 15.8702 - val_squared_difference_loss: 12.3344 - val_KL_divergence_loss: 3.5358 - val_neg_log_likelihood: 22533320449283368.0000\n",
      "Epoch 1028/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 16.0930 - squared_difference_loss: 12.4780 - KL_divergence_loss: 3.6150 - neg_log_likelihood: 690137805.7035 - val_loss: 15.8245 - val_squared_difference_loss: 12.2881 - val_KL_divergence_loss: 3.5364 - val_neg_log_likelihood: 9489932080751560704.0000\n",
      "Epoch 1029/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.0839 - squared_difference_loss: 12.4451 - KL_divergence_loss: 3.6388 - neg_log_likelihood: 1179027208.1760 - val_loss: 15.8213 - val_squared_difference_loss: 12.2634 - val_KL_divergence_loss: 3.5579 - val_neg_log_likelihood: 47309234928267240.0000\n",
      "Epoch 1030/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.0798 - squared_difference_loss: 12.4512 - KL_divergence_loss: 3.6286 - neg_log_likelihood: 870442348.7420 - val_loss: 15.8277 - val_squared_difference_loss: 12.2756 - val_KL_divergence_loss: 3.5521 - val_neg_log_likelihood: 42978883206811000832.0000\n",
      "Epoch 1031/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.0733 - squared_difference_loss: 12.4519 - KL_divergence_loss: 3.6214 - neg_log_likelihood: 16675608509.2936 - val_loss: 15.8366 - val_squared_difference_loss: 12.2545 - val_KL_divergence_loss: 3.5821 - val_neg_log_likelihood: 227402331885931840.0000\n",
      "Epoch 1032/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.0638 - squared_difference_loss: 12.4261 - KL_divergence_loss: 3.6377 - neg_log_likelihood: 2354970290.1890 - val_loss: 15.8089 - val_squared_difference_loss: 12.2369 - val_KL_divergence_loss: 3.5721 - val_neg_log_likelihood: 9157486109730462720.0000\n",
      "Epoch 1033/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.0497 - squared_difference_loss: 12.4134 - KL_divergence_loss: 3.6363 - neg_log_likelihood: 2848007237.3481 - val_loss: 15.8140 - val_squared_difference_loss: 12.2630 - val_KL_divergence_loss: 3.5510 - val_neg_log_likelihood: 118509391086344096.0000\n",
      "Epoch 1034/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.0504 - squared_difference_loss: 12.4228 - KL_divergence_loss: 3.6276 - neg_log_likelihood: 2121622163.8546 - val_loss: 15.8199 - val_squared_difference_loss: 12.2499 - val_KL_divergence_loss: 3.5700 - val_neg_log_likelihood: 910750895282072832.0000\n",
      "Epoch 1035/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.0857 - squared_difference_loss: 12.4463 - KL_divergence_loss: 3.6394 - neg_log_likelihood: 12943152419.3695 - val_loss: 15.8208 - val_squared_difference_loss: 12.2010 - val_KL_divergence_loss: 3.6198 - val_neg_log_likelihood: 880463639386823808.0000\n",
      "Epoch 1036/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.0544 - squared_difference_loss: 12.4088 - KL_divergence_loss: 3.6456 - neg_log_likelihood: 4729497268.3843 - val_loss: 15.8213 - val_squared_difference_loss: 12.2322 - val_KL_divergence_loss: 3.5891 - val_neg_log_likelihood: 268068584286217696.0000\n",
      "Epoch 1037/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.0360 - squared_difference_loss: 12.3875 - KL_divergence_loss: 3.6486 - neg_log_likelihood: 4964464436.8955 - val_loss: 15.8106 - val_squared_difference_loss: 12.2653 - val_KL_divergence_loss: 3.5453 - val_neg_log_likelihood: 1976906977544525568.0000\n",
      "Epoch 1038/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.0494 - squared_difference_loss: 12.4231 - KL_divergence_loss: 3.6263 - neg_log_likelihood: 2498986983.6201 - val_loss: 15.8031 - val_squared_difference_loss: 12.2118 - val_KL_divergence_loss: 3.5913 - val_neg_log_likelihood: 3942407314906365952.0000\n",
      "Epoch 1039/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.0579 - squared_difference_loss: 12.4121 - KL_divergence_loss: 3.6458 - neg_log_likelihood: 340352528.3288 - val_loss: 15.8144 - val_squared_difference_loss: 12.2253 - val_KL_divergence_loss: 3.5892 - val_neg_log_likelihood: 76217623754981916672.0000\n",
      "Epoch 1040/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 16.0337 - squared_difference_loss: 12.3905 - KL_divergence_loss: 3.6432 - neg_log_likelihood: 3054058952.4567 - val_loss: 15.8369 - val_squared_difference_loss: 12.2697 - val_KL_divergence_loss: 3.5672 - val_neg_log_likelihood: 11314220377321220096.0000\n",
      "Epoch 1041/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 16.0546 - squared_difference_loss: 12.4190 - KL_divergence_loss: 3.6356 - neg_log_likelihood: 15668412776.0498 - val_loss: 15.7689 - val_squared_difference_loss: 12.1701 - val_KL_divergence_loss: 3.5989 - val_neg_log_likelihood: 8893313289494393856.0000\n",
      "Epoch 1042/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.0295 - squared_difference_loss: 12.3729 - KL_divergence_loss: 3.6566 - neg_log_likelihood: 24061824871.0314 - val_loss: 15.7873 - val_squared_difference_loss: 12.1625 - val_KL_divergence_loss: 3.6248 - val_neg_log_likelihood: 471933681134556480.0000\n",
      "Epoch 1043/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9831 - squared_difference_loss: 12.3266 - KL_divergence_loss: 3.6565 - neg_log_likelihood: 2833990515.2282 - val_loss: 15.7989 - val_squared_difference_loss: 12.2035 - val_KL_divergence_loss: 3.5954 - val_neg_log_likelihood: 788431827303485184.0000\n",
      "Epoch 1044/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 16.0082 - squared_difference_loss: 12.3619 - KL_divergence_loss: 3.6463 - neg_log_likelihood: 2974455858.9950 - val_loss: 15.7864 - val_squared_difference_loss: 12.2165 - val_KL_divergence_loss: 3.5699 - val_neg_log_likelihood: 7651127893691801600.0000\n",
      "Epoch 1045/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.0285 - squared_difference_loss: 12.3989 - KL_divergence_loss: 3.6296 - neg_log_likelihood: 375664460.2923 - val_loss: 15.7877 - val_squared_difference_loss: 12.2000 - val_KL_divergence_loss: 3.5878 - val_neg_log_likelihood: 79453322977784856576.0000\n",
      "Epoch 1046/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9973 - squared_difference_loss: 12.3636 - KL_divergence_loss: 3.6337 - neg_log_likelihood: 285517361.0924 - val_loss: 15.7828 - val_squared_difference_loss: 12.1853 - val_KL_divergence_loss: 3.5975 - val_neg_log_likelihood: 2385594252798477824.0000\n",
      "Epoch 1047/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 16.0139 - squared_difference_loss: 12.3602 - KL_divergence_loss: 3.6537 - neg_log_likelihood: 849808853.1056 - val_loss: 15.7569 - val_squared_difference_loss: 12.1713 - val_KL_divergence_loss: 3.5856 - val_neg_log_likelihood: 752758777786696448.0000\n",
      "Epoch 1048/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.9967 - squared_difference_loss: 12.3423 - KL_divergence_loss: 3.6544 - neg_log_likelihood: 319170064.3455 - val_loss: 15.7733 - val_squared_difference_loss: 12.1639 - val_KL_divergence_loss: 3.6094 - val_neg_log_likelihood: 6967048185272920064.0000\n",
      "Epoch 1049/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 16.0178 - squared_difference_loss: 12.3505 - KL_divergence_loss: 3.6674 - neg_log_likelihood: 4750684021.7646 - val_loss: 15.7956 - val_squared_difference_loss: 12.1660 - val_KL_divergence_loss: 3.6296 - val_neg_log_likelihood: 1867338853892089600.0000\n",
      "Epoch 1050/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9940 - squared_difference_loss: 12.3429 - KL_divergence_loss: 3.6510 - neg_log_likelihood: 3102048231.6690 - val_loss: 15.7589 - val_squared_difference_loss: 12.1603 - val_KL_divergence_loss: 3.5987 - val_neg_log_likelihood: 818726360382353024.0000\n",
      "Epoch 1051/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.0088 - squared_difference_loss: 12.3392 - KL_divergence_loss: 3.6697 - neg_log_likelihood: 2782265832.6488 - val_loss: 15.8184 - val_squared_difference_loss: 12.2068 - val_KL_divergence_loss: 3.6115 - val_neg_log_likelihood: 302462189076338704384.0000\n",
      "Epoch 1052/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.0111 - squared_difference_loss: 12.3438 - KL_divergence_loss: 3.6673 - neg_log_likelihood: 7646478659.9882 - val_loss: 15.7809 - val_squared_difference_loss: 12.2016 - val_KL_divergence_loss: 3.5793 - val_neg_log_likelihood: 4646269129499032576.0000\n",
      "Epoch 1053/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 16.0170 - squared_difference_loss: 12.3395 - KL_divergence_loss: 3.6775 - neg_log_likelihood: 853635404.9014 - val_loss: 15.8041 - val_squared_difference_loss: 12.1734 - val_KL_divergence_loss: 3.6307 - val_neg_log_likelihood: 3135065449873882624.0000\n",
      "Epoch 1054/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.0017 - squared_difference_loss: 12.3187 - KL_divergence_loss: 3.6830 - neg_log_likelihood: 1345757638.0832 - val_loss: 15.7794 - val_squared_difference_loss: 12.1504 - val_KL_divergence_loss: 3.6290 - val_neg_log_likelihood: 1385389885025078016.0000\n",
      "Epoch 1055/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9698 - squared_difference_loss: 12.3099 - KL_divergence_loss: 3.6599 - neg_log_likelihood: 29100453509.8036 - val_loss: 15.7494 - val_squared_difference_loss: 12.1554 - val_KL_divergence_loss: 3.5940 - val_neg_log_likelihood: 8949111962440380416.0000\n",
      "Epoch 1056/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.9911 - squared_difference_loss: 12.3285 - KL_divergence_loss: 3.6626 - neg_log_likelihood: 1667358070.2193 - val_loss: 15.7673 - val_squared_difference_loss: 12.1304 - val_KL_divergence_loss: 3.6369 - val_neg_log_likelihood: 1390693701728574464.0000\n",
      "Epoch 1057/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.9771 - squared_difference_loss: 12.3050 - KL_divergence_loss: 3.6721 - neg_log_likelihood: 417939986.1979 - val_loss: 15.7375 - val_squared_difference_loss: 12.1052 - val_KL_divergence_loss: 3.6323 - val_neg_log_likelihood: 2084651270186591744.0000\n",
      "Epoch 1058/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9808 - squared_difference_loss: 12.3063 - KL_divergence_loss: 3.6746 - neg_log_likelihood: 4662186890.9590 - val_loss: 15.7272 - val_squared_difference_loss: 12.0837 - val_KL_divergence_loss: 3.6435 - val_neg_log_likelihood: 27899907965149466624.0000\n",
      "Epoch 1059/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9862 - squared_difference_loss: 12.3005 - KL_divergence_loss: 3.6857 - neg_log_likelihood: 28306404.2553 - val_loss: 15.7506 - val_squared_difference_loss: 12.1084 - val_KL_divergence_loss: 3.6422 - val_neg_log_likelihood: 169703693933622525952.0000\n",
      "Epoch 1060/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9794 - squared_difference_loss: 12.3057 - KL_divergence_loss: 3.6737 - neg_log_likelihood: 4494698055.9492 - val_loss: 15.7366 - val_squared_difference_loss: 12.0954 - val_KL_divergence_loss: 3.6412 - val_neg_log_likelihood: 4716091696687915008.0000\n",
      "Epoch 1061/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9711 - squared_difference_loss: 12.3016 - KL_divergence_loss: 3.6695 - neg_log_likelihood: 3329870894.7095 - val_loss: 15.7559 - val_squared_difference_loss: 12.1205 - val_KL_divergence_loss: 3.6355 - val_neg_log_likelihood: 3425020805071270400.0000\n",
      "Epoch 1062/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9740 - squared_difference_loss: 12.2985 - KL_divergence_loss: 3.6755 - neg_log_likelihood: 5051533539.8522 - val_loss: 15.7554 - val_squared_difference_loss: 12.1112 - val_KL_divergence_loss: 3.6442 - val_neg_log_likelihood: 16849757488055459840.0000\n",
      "Epoch 1063/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9554 - squared_difference_loss: 12.2640 - KL_divergence_loss: 3.6914 - neg_log_likelihood: 3964008700.6799 - val_loss: 15.7473 - val_squared_difference_loss: 12.1079 - val_KL_divergence_loss: 3.6395 - val_neg_log_likelihood: 51982104143294038016.0000\n",
      "Epoch 1064/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 15.9810 - squared_difference_loss: 12.3087 - KL_divergence_loss: 3.6723 - neg_log_likelihood: 1004562888.2747 - val_loss: 15.7313 - val_squared_difference_loss: 12.0896 - val_KL_divergence_loss: 3.6417 - val_neg_log_likelihood: 2031471723688566784.0000\n",
      "Epoch 1065/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 16.0036 - squared_difference_loss: 12.3192 - KL_divergence_loss: 3.6844 - neg_log_likelihood: 2032504023.0666 - val_loss: 15.7341 - val_squared_difference_loss: 12.0610 - val_KL_divergence_loss: 3.6731 - val_neg_log_likelihood: 233725251867693613056.0000\n",
      "Epoch 1066/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9879 - squared_difference_loss: 12.2956 - KL_divergence_loss: 3.6924 - neg_log_likelihood: 3373671495.5373 - val_loss: 15.7544 - val_squared_difference_loss: 12.1053 - val_KL_divergence_loss: 3.6491 - val_neg_log_likelihood: 3868824621462906880.0000\n",
      "Epoch 1067/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.9657 - squared_difference_loss: 12.2894 - KL_divergence_loss: 3.6764 - neg_log_likelihood: 12689776007.6413 - val_loss: 15.7350 - val_squared_difference_loss: 12.0844 - val_KL_divergence_loss: 3.6506 - val_neg_log_likelihood: 1457648366221475072.0000\n",
      "Epoch 1068/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.9469 - squared_difference_loss: 12.2549 - KL_divergence_loss: 3.6921 - neg_log_likelihood: 9652431126.3499 - val_loss: 15.7176 - val_squared_difference_loss: 12.0497 - val_KL_divergence_loss: 3.6679 - val_neg_log_likelihood: 25023797805935742976.0000\n",
      "Epoch 1069/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 15.9510 - squared_difference_loss: 12.2700 - KL_divergence_loss: 3.6810 - neg_log_likelihood: 963307640.9891 - val_loss: 15.7304 - val_squared_difference_loss: 12.0957 - val_KL_divergence_loss: 3.6348 - val_neg_log_likelihood: 14699614513825390592.0000\n",
      "Epoch 1070/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9568 - squared_difference_loss: 12.2829 - KL_divergence_loss: 3.6738 - neg_log_likelihood: 3413962999.7196 - val_loss: 15.7154 - val_squared_difference_loss: 12.0750 - val_KL_divergence_loss: 3.6404 - val_neg_log_likelihood: 12826834789843001344.0000\n",
      "Epoch 1071/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.9377 - squared_difference_loss: 12.2610 - KL_divergence_loss: 3.6767 - neg_log_likelihood: 2524876722.7018 - val_loss: 15.6874 - val_squared_difference_loss: 12.0628 - val_KL_divergence_loss: 3.6246 - val_neg_log_likelihood: 18408655769601992704.0000\n",
      "Epoch 1072/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9358 - squared_difference_loss: 12.2559 - KL_divergence_loss: 3.6799 - neg_log_likelihood: 3197595031.8712 - val_loss: 15.7453 - val_squared_difference_loss: 12.0761 - val_KL_divergence_loss: 3.6692 - val_neg_log_likelihood: 770323624494349696.0000\n",
      "Epoch 1073/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9811 - squared_difference_loss: 12.2878 - KL_divergence_loss: 3.6933 - neg_log_likelihood: 383983249.3251 - val_loss: 15.7060 - val_squared_difference_loss: 12.0662 - val_KL_divergence_loss: 3.6398 - val_neg_log_likelihood: 20935239844590698496.0000\n",
      "Epoch 1074/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.9154 - squared_difference_loss: 12.2203 - KL_divergence_loss: 3.6952 - neg_log_likelihood: 132361024538.5408 - val_loss: 15.6988 - val_squared_difference_loss: 12.0295 - val_KL_divergence_loss: 3.6693 - val_neg_log_likelihood: 7748476083280418816.0000\n",
      "Epoch 1075/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.9306 - squared_difference_loss: 12.2695 - KL_divergence_loss: 3.6611 - neg_log_likelihood: 21587858643.5432 - val_loss: 15.6743 - val_squared_difference_loss: 12.0425 - val_KL_divergence_loss: 3.6317 - val_neg_log_likelihood: 156970239980065128448.0000\n",
      "Epoch 1076/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9197 - squared_difference_loss: 12.2392 - KL_divergence_loss: 3.6805 - neg_log_likelihood: 19665038461.7650 - val_loss: 15.7051 - val_squared_difference_loss: 12.0522 - val_KL_divergence_loss: 3.6529 - val_neg_log_likelihood: 10469232834185502720.0000\n",
      "Epoch 1077/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.9477 - squared_difference_loss: 12.2621 - KL_divergence_loss: 3.6856 - neg_log_likelihood: 3460218961.6282 - val_loss: 15.7023 - val_squared_difference_loss: 12.0374 - val_KL_divergence_loss: 3.6649 - val_neg_log_likelihood: 2887381760704819200.0000\n",
      "Epoch 1078/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9610 - squared_difference_loss: 12.2617 - KL_divergence_loss: 3.6993 - neg_log_likelihood: 1856263800.7853 - val_loss: 15.6902 - val_squared_difference_loss: 12.0323 - val_KL_divergence_loss: 3.6579 - val_neg_log_likelihood: 31342832412890124288.0000\n",
      "Epoch 1079/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9065 - squared_difference_loss: 12.2153 - KL_divergence_loss: 3.6912 - neg_log_likelihood: 2906564773.7130 - val_loss: 15.7133 - val_squared_difference_loss: 12.0598 - val_KL_divergence_loss: 3.6535 - val_neg_log_likelihood: 13898688061194924032.0000\n",
      "Epoch 1080/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.9148 - squared_difference_loss: 12.2167 - KL_divergence_loss: 3.6981 - neg_log_likelihood: 75209586729.9019 - val_loss: 15.6996 - val_squared_difference_loss: 12.0530 - val_KL_divergence_loss: 3.6466 - val_neg_log_likelihood: 40795307196052439040.0000\n",
      "Epoch 1081/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9249 - squared_difference_loss: 12.2236 - KL_divergence_loss: 3.7012 - neg_log_likelihood: 1733512761.8908 - val_loss: 15.6716 - val_squared_difference_loss: 12.0156 - val_KL_divergence_loss: 3.6560 - val_neg_log_likelihood: 4337897712676938240.0000\n",
      "Epoch 1082/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9272 - squared_difference_loss: 12.2197 - KL_divergence_loss: 3.7075 - neg_log_likelihood: 5945087004.4299 - val_loss: 15.6762 - val_squared_difference_loss: 12.0185 - val_KL_divergence_loss: 3.6576 - val_neg_log_likelihood: 13250698436246173696.0000\n",
      "Epoch 1083/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.9007 - squared_difference_loss: 12.2199 - KL_divergence_loss: 3.6808 - neg_log_likelihood: 26405069764.4004 - val_loss: 15.6869 - val_squared_difference_loss: 12.0011 - val_KL_divergence_loss: 3.6858 - val_neg_log_likelihood: 31019015035958263808.0000\n",
      "Epoch 1084/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9129 - squared_difference_loss: 12.2269 - KL_divergence_loss: 3.6860 - neg_log_likelihood: 51970787697.2512 - val_loss: 15.6743 - val_squared_difference_loss: 11.9990 - val_KL_divergence_loss: 3.6754 - val_neg_log_likelihood: 47000873981716799488.0000\n",
      "Epoch 1085/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9146 - squared_difference_loss: 12.2000 - KL_divergence_loss: 3.7146 - neg_log_likelihood: 6524808018.1077 - val_loss: 15.7201 - val_squared_difference_loss: 12.0298 - val_KL_divergence_loss: 3.6903 - val_neg_log_likelihood: 7923328499278713856.0000\n",
      "Epoch 1086/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.9182 - squared_difference_loss: 12.2162 - KL_divergence_loss: 3.7019 - neg_log_likelihood: 20153038360.9653 - val_loss: 15.6720 - val_squared_difference_loss: 11.9964 - val_KL_divergence_loss: 3.6756 - val_neg_log_likelihood: 5845714397534873600.0000\n",
      "Epoch 1087/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.9132 - squared_difference_loss: 12.2183 - KL_divergence_loss: 3.6950 - neg_log_likelihood: 31076925822.2029 - val_loss: 15.6485 - val_squared_difference_loss: 11.9959 - val_KL_divergence_loss: 3.6526 - val_neg_log_likelihood: 95681862309998542848.0000\n",
      "Epoch 1088/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.9005 - squared_difference_loss: 12.1890 - KL_divergence_loss: 3.7116 - neg_log_likelihood: 7359473516.3136 - val_loss: 15.7040 - val_squared_difference_loss: 12.0602 - val_KL_divergence_loss: 3.6438 - val_neg_log_likelihood: 28182707204288323584.0000\n",
      "Epoch 1089/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 15.9185 - squared_difference_loss: 12.2116 - KL_divergence_loss: 3.7069 - neg_log_likelihood: 7573278408.2452 - val_loss: 15.6481 - val_squared_difference_loss: 11.9647 - val_KL_divergence_loss: 3.6834 - val_neg_log_likelihood: 81424343350717054976.0000\n",
      "Epoch 1090/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9294 - squared_difference_loss: 12.2253 - KL_divergence_loss: 3.7041 - neg_log_likelihood: 3880332744.4898 - val_loss: 15.6579 - val_squared_difference_loss: 11.9883 - val_KL_divergence_loss: 3.6696 - val_neg_log_likelihood: 332362946427311816704.0000\n",
      "Epoch 1091/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9067 - squared_difference_loss: 12.2009 - KL_divergence_loss: 3.7058 - neg_log_likelihood: 10052474430.3121 - val_loss: 15.6360 - val_squared_difference_loss: 11.9807 - val_KL_divergence_loss: 3.6552 - val_neg_log_likelihood: 24952891963946045440.0000\n",
      "Epoch 1092/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8988 - squared_difference_loss: 12.1985 - KL_divergence_loss: 3.7002 - neg_log_likelihood: 1820981042.4152 - val_loss: 15.6763 - val_squared_difference_loss: 11.9908 - val_KL_divergence_loss: 3.6854 - val_neg_log_likelihood: 2124885750617632256.0000\n",
      "Epoch 1093/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9021 - squared_difference_loss: 12.1939 - KL_divergence_loss: 3.7082 - neg_log_likelihood: 4505551870.2492 - val_loss: 15.6709 - val_squared_difference_loss: 11.9864 - val_KL_divergence_loss: 3.6845 - val_neg_log_likelihood: 15526176324281892864.0000\n",
      "Epoch 1094/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.9322 - squared_difference_loss: 12.2251 - KL_divergence_loss: 3.7071 - neg_log_likelihood: 60177822558.7343 - val_loss: 15.6744 - val_squared_difference_loss: 12.0116 - val_KL_divergence_loss: 3.6629 - val_neg_log_likelihood: 101905993457559076864.0000\n",
      "Epoch 1095/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.8977 - squared_difference_loss: 12.1876 - KL_divergence_loss: 3.7102 - neg_log_likelihood: 130533307739.1631 - val_loss: 15.6808 - val_squared_difference_loss: 12.0218 - val_KL_divergence_loss: 3.6590 - val_neg_log_likelihood: 894536178310190464.0000\n",
      "Epoch 1096/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.9087 - squared_difference_loss: 12.2024 - KL_divergence_loss: 3.7063 - neg_log_likelihood: 6691501099.4754 - val_loss: 15.7186 - val_squared_difference_loss: 12.0553 - val_KL_divergence_loss: 3.6633 - val_neg_log_likelihood: 59839016274463252480.0000\n",
      "Epoch 1097/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.9074 - squared_difference_loss: 12.2039 - KL_divergence_loss: 3.7035 - neg_log_likelihood: 56812366688.8533 - val_loss: 15.6504 - val_squared_difference_loss: 11.9594 - val_KL_divergence_loss: 3.6910 - val_neg_log_likelihood: 7603075389987363840.0000\n",
      "Epoch 1098/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8892 - squared_difference_loss: 12.1845 - KL_divergence_loss: 3.7047 - neg_log_likelihood: 19209242915.0749 - val_loss: 15.6710 - val_squared_difference_loss: 11.9897 - val_KL_divergence_loss: 3.6813 - val_neg_log_likelihood: 15254899984185329664.0000\n",
      "Epoch 1099/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9038 - squared_difference_loss: 12.1974 - KL_divergence_loss: 3.7063 - neg_log_likelihood: 15824377676.3976 - val_loss: 15.6883 - val_squared_difference_loss: 11.9851 - val_KL_divergence_loss: 3.7033 - val_neg_log_likelihood: 536047382758017466368.0000\n",
      "Epoch 1100/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.8891 - squared_difference_loss: 12.1880 - KL_divergence_loss: 3.7011 - neg_log_likelihood: 10754800770.0565 - val_loss: 15.6652 - val_squared_difference_loss: 11.9646 - val_KL_divergence_loss: 3.7006 - val_neg_log_likelihood: 19812024538226946048.0000\n",
      "Epoch 1101/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8842 - squared_difference_loss: 12.1577 - KL_divergence_loss: 3.7265 - neg_log_likelihood: 5839641519.9817 - val_loss: 15.6345 - val_squared_difference_loss: 11.9316 - val_KL_divergence_loss: 3.7029 - val_neg_log_likelihood: 220699661825798209536.0000\n",
      "Epoch 1102/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.8932 - squared_difference_loss: 12.1963 - KL_divergence_loss: 3.6969 - neg_log_likelihood: 652490630.9150 - val_loss: 15.6998 - val_squared_difference_loss: 12.0121 - val_KL_divergence_loss: 3.6877 - val_neg_log_likelihood: 41005359104839671808.0000\n",
      "Epoch 1103/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.8875 - squared_difference_loss: 12.1649 - KL_divergence_loss: 3.7226 - neg_log_likelihood: 13637643847.1424 - val_loss: 15.6797 - val_squared_difference_loss: 11.9886 - val_KL_divergence_loss: 3.6911 - val_neg_log_likelihood: 297950844705178910720.0000\n",
      "Epoch 1104/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8886 - squared_difference_loss: 12.1759 - KL_divergence_loss: 3.7127 - neg_log_likelihood: 13755139320.8769 - val_loss: 15.6537 - val_squared_difference_loss: 11.9679 - val_KL_divergence_loss: 3.6859 - val_neg_log_likelihood: 17828159922270789632.0000\n",
      "Epoch 1105/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8810 - squared_difference_loss: 12.1678 - KL_divergence_loss: 3.7133 - neg_log_likelihood: 103740925251.1882 - val_loss: 15.6684 - val_squared_difference_loss: 11.9845 - val_KL_divergence_loss: 3.6839 - val_neg_log_likelihood: 111868843316519534592.0000\n",
      "Epoch 1106/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.9293 - squared_difference_loss: 12.2205 - KL_divergence_loss: 3.7088 - neg_log_likelihood: 399585895.3792 - val_loss: 15.6589 - val_squared_difference_loss: 11.9691 - val_KL_divergence_loss: 3.6898 - val_neg_log_likelihood: 98774003075876847616.0000\n",
      "Epoch 1107/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.8833 - squared_difference_loss: 12.1772 - KL_divergence_loss: 3.7061 - neg_log_likelihood: 87444552924.6023 - val_loss: 15.6709 - val_squared_difference_loss: 11.9794 - val_KL_divergence_loss: 3.6915 - val_neg_log_likelihood: 15595059270765291520.0000\n",
      "Epoch 1108/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8708 - squared_difference_loss: 12.1535 - KL_divergence_loss: 3.7172 - neg_log_likelihood: 139034657898.7234 - val_loss: 15.6489 - val_squared_difference_loss: 11.9690 - val_KL_divergence_loss: 3.6800 - val_neg_log_likelihood: 23180302994453757952.0000\n",
      "Epoch 1109/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.9020 - squared_difference_loss: 12.1795 - KL_divergence_loss: 3.7224 - neg_log_likelihood: 15545229906.8848 - val_loss: 15.6632 - val_squared_difference_loss: 11.9517 - val_KL_divergence_loss: 3.7115 - val_neg_log_likelihood: 17829711885433251840.0000\n",
      "Epoch 1110/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 15.8821 - squared_difference_loss: 12.1718 - KL_divergence_loss: 3.7103 - neg_log_likelihood: 21492126144.4188 - val_loss: 15.6450 - val_squared_difference_loss: 11.9340 - val_KL_divergence_loss: 3.7110 - val_neg_log_likelihood: 29822254177587654656.0000\n",
      "Epoch 1111/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.8852 - squared_difference_loss: 12.1704 - KL_divergence_loss: 3.7148 - neg_log_likelihood: 59068124193.0184 - val_loss: 15.6488 - val_squared_difference_loss: 11.9678 - val_KL_divergence_loss: 3.6810 - val_neg_log_likelihood: 99004477730305867776.0000\n",
      "Epoch 1112/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.8851 - squared_difference_loss: 12.1683 - KL_divergence_loss: 3.7167 - neg_log_likelihood: 3969996794.0410 - val_loss: 15.6551 - val_squared_difference_loss: 11.9656 - val_KL_divergence_loss: 3.6895 - val_neg_log_likelihood: 100077062787998433280.0000\n",
      "Epoch 1113/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8322 - squared_difference_loss: 12.1306 - KL_divergence_loss: 3.7016 - neg_log_likelihood: 10262333508.0815 - val_loss: 15.6463 - val_squared_difference_loss: 11.9641 - val_KL_divergence_loss: 3.6822 - val_neg_log_likelihood: 179874506371036348416.0000\n",
      "Epoch 1114/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8879 - squared_difference_loss: 12.1810 - KL_divergence_loss: 3.7069 - neg_log_likelihood: 464679244.4341 - val_loss: 15.6688 - val_squared_difference_loss: 11.9721 - val_KL_divergence_loss: 3.6967 - val_neg_log_likelihood: 64661771238807592960.0000\n",
      "Epoch 1115/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.8804 - squared_difference_loss: 12.1726 - KL_divergence_loss: 3.7078 - neg_log_likelihood: 37394515473.1963 - val_loss: 15.6617 - val_squared_difference_loss: 11.9607 - val_KL_divergence_loss: 3.7010 - val_neg_log_likelihood: 65983075160617410560.0000\n",
      "Epoch 1116/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.9119 - squared_difference_loss: 12.1798 - KL_divergence_loss: 3.7321 - neg_log_likelihood: 5371143827.3357 - val_loss: 15.6469 - val_squared_difference_loss: 11.9437 - val_KL_divergence_loss: 3.7032 - val_neg_log_likelihood: 22356950915886157824.0000\n",
      "Epoch 1117/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 15.8815 - squared_difference_loss: 12.1562 - KL_divergence_loss: 3.7253 - neg_log_likelihood: 23476554092.7211 - val_loss: 15.6551 - val_squared_difference_loss: 11.9668 - val_KL_divergence_loss: 3.6883 - val_neg_log_likelihood: 39698093044916994048.0000\n",
      "Epoch 1118/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.8507 - squared_difference_loss: 12.1365 - KL_divergence_loss: 3.7142 - neg_log_likelihood: 17990375680.2590 - val_loss: 15.6152 - val_squared_difference_loss: 11.9440 - val_KL_divergence_loss: 3.6712 - val_neg_log_likelihood: 67781459402840047616.0000\n",
      "Epoch 1119/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.8509 - squared_difference_loss: 12.1328 - KL_divergence_loss: 3.7182 - neg_log_likelihood: 13909408494.9799 - val_loss: 15.6567 - val_squared_difference_loss: 11.9488 - val_KL_divergence_loss: 3.7079 - val_neg_log_likelihood: 19697826470258806784.0000\n",
      "Epoch 1120/2000\n",
      "29507/29507 [==============================] - ETA: 0s - loss: 15.8402 - squared_difference_loss: 12.1121 - KL_divergence_loss: 3.7281 - neg_log_likelihood: 156017300440.83 - 0s 13us/step - loss: 15.8721 - squared_difference_loss: 12.1484 - KL_divergence_loss: 3.7237 - neg_log_likelihood: 137474939216.6493 - val_loss: 15.6617 - val_squared_difference_loss: 11.9807 - val_KL_divergence_loss: 3.6810 - val_neg_log_likelihood: 15040417928934836224.0000\n",
      "Epoch 1121/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8638 - squared_difference_loss: 12.1347 - KL_divergence_loss: 3.7290 - neg_log_likelihood: 28085628760.9553 - val_loss: 15.6645 - val_squared_difference_loss: 11.9558 - val_KL_divergence_loss: 3.7087 - val_neg_log_likelihood: 60431650734867578880.0000\n",
      "Epoch 1122/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.8579 - squared_difference_loss: 12.1534 - KL_divergence_loss: 3.7045 - neg_log_likelihood: 18441105924.7586 - val_loss: 15.6178 - val_squared_difference_loss: 11.8999 - val_KL_divergence_loss: 3.7179 - val_neg_log_likelihood: 500348734826390290432.0000\n",
      "Epoch 1123/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8540 - squared_difference_loss: 12.1409 - KL_divergence_loss: 3.7131 - neg_log_likelihood: 18595350701.0886 - val_loss: 15.6269 - val_squared_difference_loss: 11.9185 - val_KL_divergence_loss: 3.7084 - val_neg_log_likelihood: 27841265540791287808.0000\n",
      "Epoch 1124/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8565 - squared_difference_loss: 12.1275 - KL_divergence_loss: 3.7290 - neg_log_likelihood: 36648747782.1648 - val_loss: 15.6383 - val_squared_difference_loss: 11.9354 - val_KL_divergence_loss: 3.7029 - val_neg_log_likelihood: 76681283070396743680.0000\n",
      "Epoch 1125/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.9049 - squared_difference_loss: 12.1968 - KL_divergence_loss: 3.7082 - neg_log_likelihood: 4131349371.9424 - val_loss: 15.6476 - val_squared_difference_loss: 11.9344 - val_KL_divergence_loss: 3.7132 - val_neg_log_likelihood: 13171882551716792320.0000\n",
      "Epoch 1126/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8523 - squared_difference_loss: 12.1283 - KL_divergence_loss: 3.7240 - neg_log_likelihood: 2679192636.9386 - val_loss: 15.6233 - val_squared_difference_loss: 11.9104 - val_KL_divergence_loss: 3.7129 - val_neg_log_likelihood: 34991750022847873024.0000\n",
      "Epoch 1127/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8674 - squared_difference_loss: 12.1381 - KL_divergence_loss: 3.7293 - neg_log_likelihood: 19411950656.6926 - val_loss: 15.6804 - val_squared_difference_loss: 11.9831 - val_KL_divergence_loss: 3.6973 - val_neg_log_likelihood: 71696581229323509760.0000\n",
      "Epoch 1128/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 15.8718 - squared_difference_loss: 12.1619 - KL_divergence_loss: 3.7099 - neg_log_likelihood: 72862587160.6277 - val_loss: 15.6369 - val_squared_difference_loss: 11.9430 - val_KL_divergence_loss: 3.6939 - val_neg_log_likelihood: 157563580770547597312.0000\n",
      "Epoch 1129/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8582 - squared_difference_loss: 12.1270 - KL_divergence_loss: 3.7312 - neg_log_likelihood: 33612444634.5049 - val_loss: 15.5812 - val_squared_difference_loss: 11.8558 - val_KL_divergence_loss: 3.7255 - val_neg_log_likelihood: 17850712152651321344.0000\n",
      "Epoch 1130/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.8758 - squared_difference_loss: 12.1568 - KL_divergence_loss: 3.7190 - neg_log_likelihood: 51414544849.1832 - val_loss: 15.6442 - val_squared_difference_loss: 11.9223 - val_KL_divergence_loss: 3.7219 - val_neg_log_likelihood: 22538792634979090432.0000\n",
      "Epoch 1131/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.8693 - squared_difference_loss: 12.1367 - KL_divergence_loss: 3.7326 - neg_log_likelihood: 7432837588.4210 - val_loss: 15.6424 - val_squared_difference_loss: 11.9163 - val_KL_divergence_loss: 3.7261 - val_neg_log_likelihood: 14944895382325190656.0000\n",
      "Epoch 1132/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.8894 - squared_difference_loss: 12.1530 - KL_divergence_loss: 3.7363 - neg_log_likelihood: 16477465150.3962 - val_loss: 15.6295 - val_squared_difference_loss: 11.9101 - val_KL_divergence_loss: 3.7194 - val_neg_log_likelihood: 19627200586318819328.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1133/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.8691 - squared_difference_loss: 12.1289 - KL_divergence_loss: 3.7401 - neg_log_likelihood: 3080943255.6373 - val_loss: 15.6451 - val_squared_difference_loss: 11.9261 - val_KL_divergence_loss: 3.7191 - val_neg_log_likelihood: 116119156352959856640.0000\n",
      "Epoch 1134/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.8611 - squared_difference_loss: 12.1295 - KL_divergence_loss: 3.7317 - neg_log_likelihood: 2812611519.1220 - val_loss: 15.6604 - val_squared_difference_loss: 11.9625 - val_KL_divergence_loss: 3.6979 - val_neg_log_likelihood: 21803972820168417280.0000\n",
      "Epoch 1135/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8549 - squared_difference_loss: 12.1362 - KL_divergence_loss: 3.7186 - neg_log_likelihood: 13017790908.4204 - val_loss: 15.6642 - val_squared_difference_loss: 11.9694 - val_KL_divergence_loss: 3.6948 - val_neg_log_likelihood: 14287124158568286208.0000\n",
      "Epoch 1136/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8976 - squared_difference_loss: 12.1793 - KL_divergence_loss: 3.7183 - neg_log_likelihood: 4053619653.7082 - val_loss: 15.6454 - val_squared_difference_loss: 11.9230 - val_KL_divergence_loss: 3.7224 - val_neg_log_likelihood: 31502388111460712448.0000\n",
      "Epoch 1137/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.8462 - squared_difference_loss: 12.1193 - KL_divergence_loss: 3.7269 - neg_log_likelihood: 8290085480.7743 - val_loss: 15.6312 - val_squared_difference_loss: 11.9117 - val_KL_divergence_loss: 3.7195 - val_neg_log_likelihood: 119277019337268183040.0000\n",
      "Epoch 1138/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8368 - squared_difference_loss: 12.1068 - KL_divergence_loss: 3.7300 - neg_log_likelihood: 9164643123.1627 - val_loss: 15.6147 - val_squared_difference_loss: 11.9070 - val_KL_divergence_loss: 3.7077 - val_neg_log_likelihood: 39449749926711091200.0000\n",
      "Epoch 1139/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8309 - squared_difference_loss: 12.0918 - KL_divergence_loss: 3.7391 - neg_log_likelihood: 24565621671.9861 - val_loss: 15.6413 - val_squared_difference_loss: 11.9089 - val_KL_divergence_loss: 3.7324 - val_neg_log_likelihood: 74634185453032554496.0000\n",
      "Epoch 1140/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.8626 - squared_difference_loss: 12.1154 - KL_divergence_loss: 3.7472 - neg_log_likelihood: 64861845639.0153 - val_loss: 15.6445 - val_squared_difference_loss: 11.9391 - val_KL_divergence_loss: 3.7054 - val_neg_log_likelihood: 89577914913415315456.0000\n",
      "Epoch 1141/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.8196 - squared_difference_loss: 12.1064 - KL_divergence_loss: 3.7131 - neg_log_likelihood: 25991389280.3304 - val_loss: 15.6386 - val_squared_difference_loss: 11.9479 - val_KL_divergence_loss: 3.6906 - val_neg_log_likelihood: 134314421608034680832.0000\n",
      "Epoch 1142/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8522 - squared_difference_loss: 12.1288 - KL_divergence_loss: 3.7234 - neg_log_likelihood: 7863724381.9115 - val_loss: 15.6544 - val_squared_difference_loss: 11.9463 - val_KL_divergence_loss: 3.7081 - val_neg_log_likelihood: 134002754559306137600.0000\n",
      "Epoch 1143/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.8447 - squared_difference_loss: 12.1038 - KL_divergence_loss: 3.7409 - neg_log_likelihood: 888752904.6668 - val_loss: 15.5921 - val_squared_difference_loss: 11.8887 - val_KL_divergence_loss: 3.7034 - val_neg_log_likelihood: 21856889997039910912.0000\n",
      "Epoch 1144/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.8480 - squared_difference_loss: 12.1119 - KL_divergence_loss: 3.7361 - neg_log_likelihood: 10620367248.4868 - val_loss: 15.6150 - val_squared_difference_loss: 11.8944 - val_KL_divergence_loss: 3.7206 - val_neg_log_likelihood: 405610716977716854784.0000\n",
      "Epoch 1145/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8409 - squared_difference_loss: 12.0950 - KL_divergence_loss: 3.7459 - neg_log_likelihood: 75059490349.0278 - val_loss: 15.6000 - val_squared_difference_loss: 11.8641 - val_KL_divergence_loss: 3.7359 - val_neg_log_likelihood: 199465605659350925312.0000\n",
      "Epoch 1146/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8185 - squared_difference_loss: 12.0940 - KL_divergence_loss: 3.7245 - neg_log_likelihood: 140482127101.5196 - val_loss: 15.6279 - val_squared_difference_loss: 11.8974 - val_KL_divergence_loss: 3.7305 - val_neg_log_likelihood: 371569026506204577792.0000\n",
      "Epoch 1147/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.8185 - squared_difference_loss: 12.0908 - KL_divergence_loss: 3.7277 - neg_log_likelihood: 28966919911.4405 - val_loss: 15.5848 - val_squared_difference_loss: 11.8570 - val_KL_divergence_loss: 3.7278 - val_neg_log_likelihood: 187232895322279477248.0000\n",
      "Epoch 1148/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.8178 - squared_difference_loss: 12.0830 - KL_divergence_loss: 3.7348 - neg_log_likelihood: 4121021964.5918 - val_loss: 15.6433 - val_squared_difference_loss: 11.9285 - val_KL_divergence_loss: 3.7148 - val_neg_log_likelihood: 36182081728982061056.0000\n",
      "Epoch 1149/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8511 - squared_difference_loss: 12.1360 - KL_divergence_loss: 3.7151 - neg_log_likelihood: 39686296616.0894 - val_loss: 15.6285 - val_squared_difference_loss: 11.9002 - val_KL_divergence_loss: 3.7283 - val_neg_log_likelihood: 111274779281284726784.0000\n",
      "Epoch 1150/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.8295 - squared_difference_loss: 12.0843 - KL_divergence_loss: 3.7452 - neg_log_likelihood: 2057329133.1032 - val_loss: 15.6020 - val_squared_difference_loss: 11.8798 - val_KL_divergence_loss: 3.7223 - val_neg_log_likelihood: 275505380096627900416.0000\n",
      "Epoch 1151/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.8446 - squared_difference_loss: 12.1061 - KL_divergence_loss: 3.7385 - neg_log_likelihood: 1437397208.3754 - val_loss: 15.6538 - val_squared_difference_loss: 11.9113 - val_KL_divergence_loss: 3.7425 - val_neg_log_likelihood: 79216756440179556352.0000\n",
      "Epoch 1152/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 15.8085 - squared_difference_loss: 12.0825 - KL_divergence_loss: 3.7260 - neg_log_likelihood: 44350107207.6715 - val_loss: 15.6060 - val_squared_difference_loss: 11.8833 - val_KL_divergence_loss: 3.7226 - val_neg_log_likelihood: 676753894773888909312.0000\n",
      "Epoch 1153/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7976 - squared_difference_loss: 12.0562 - KL_divergence_loss: 3.7414 - neg_log_likelihood: 63073042372.2550 - val_loss: 15.6443 - val_squared_difference_loss: 11.9372 - val_KL_divergence_loss: 3.7072 - val_neg_log_likelihood: 156590102905459638272.0000\n",
      "Epoch 1154/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.8570 - squared_difference_loss: 12.1342 - KL_divergence_loss: 3.7227 - neg_log_likelihood: 589120768.4383 - val_loss: 15.6004 - val_squared_difference_loss: 11.8903 - val_KL_divergence_loss: 3.7102 - val_neg_log_likelihood: 214192731567475490816.0000\n",
      "Epoch 1155/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 15.8263 - squared_difference_loss: 12.0868 - KL_divergence_loss: 3.7395 - neg_log_likelihood: 18541667394.1227 - val_loss: 15.6050 - val_squared_difference_loss: 11.8684 - val_KL_divergence_loss: 3.7366 - val_neg_log_likelihood: 225135158357044396032.0000\n",
      "Epoch 1156/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.8006 - squared_difference_loss: 12.0710 - KL_divergence_loss: 3.7296 - neg_log_likelihood: 16124686270.4403 - val_loss: 15.6244 - val_squared_difference_loss: 11.9044 - val_KL_divergence_loss: 3.7199 - val_neg_log_likelihood: 129905198091174330368.0000\n",
      "Epoch 1157/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.8564 - squared_difference_loss: 12.0949 - KL_divergence_loss: 3.7616 - neg_log_likelihood: 85334677264.5225 - val_loss: 15.6219 - val_squared_difference_loss: 11.8707 - val_KL_divergence_loss: 3.7513 - val_neg_log_likelihood: 720044061271033249792.0000\n",
      "Epoch 1158/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.8016 - squared_difference_loss: 12.0452 - KL_divergence_loss: 3.7565 - neg_log_likelihood: 21560244530.1996 - val_loss: 15.6310 - val_squared_difference_loss: 11.8821 - val_KL_divergence_loss: 3.7490 - val_neg_log_likelihood: 563002746633151119360.0000\n",
      "Epoch 1159/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.8517 - squared_difference_loss: 12.1247 - KL_divergence_loss: 3.7270 - neg_log_likelihood: 12088155700.7882 - val_loss: 15.5934 - val_squared_difference_loss: 11.8456 - val_KL_divergence_loss: 3.7478 - val_neg_log_likelihood: 140761703633294786560.0000\n",
      "Epoch 1160/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8030 - squared_difference_loss: 12.0434 - KL_divergence_loss: 3.7596 - neg_log_likelihood: 177960604477.0936 - val_loss: 15.6045 - val_squared_difference_loss: 11.8682 - val_KL_divergence_loss: 3.7363 - val_neg_log_likelihood: 568271604809237069824.0000\n",
      "Epoch 1161/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8370 - squared_difference_loss: 12.0948 - KL_divergence_loss: 3.7421 - neg_log_likelihood: 20750932098.4776 - val_loss: 15.6104 - val_squared_difference_loss: 11.8754 - val_KL_divergence_loss: 3.7350 - val_neg_log_likelihood: 198055849645816578048.0000\n",
      "Epoch 1162/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.8533 - squared_difference_loss: 12.0962 - KL_divergence_loss: 3.7571 - neg_log_likelihood: 9142655077.0316 - val_loss: 15.6081 - val_squared_difference_loss: 11.8558 - val_KL_divergence_loss: 3.7522 - val_neg_log_likelihood: 234909108563549913088.0000\n",
      "Epoch 1163/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.8033 - squared_difference_loss: 12.0602 - KL_divergence_loss: 3.7430 - neg_log_likelihood: 9344334524.4963 - val_loss: 15.6404 - val_squared_difference_loss: 11.9103 - val_KL_divergence_loss: 3.7300 - val_neg_log_likelihood: 312551978004188430336.0000\n",
      "Epoch 1164/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8136 - squared_difference_loss: 12.0788 - KL_divergence_loss: 3.7348 - neg_log_likelihood: 138091621661.6511 - val_loss: 15.5977 - val_squared_difference_loss: 11.8686 - val_KL_divergence_loss: 3.7291 - val_neg_log_likelihood: 105995994047239716864.0000\n",
      "Epoch 1165/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.7712 - squared_difference_loss: 12.0478 - KL_divergence_loss: 3.7234 - neg_log_likelihood: 96646927201.5892 - val_loss: 15.6058 - val_squared_difference_loss: 11.8889 - val_KL_divergence_loss: 3.7169 - val_neg_log_likelihood: 126022503435074437120.0000\n",
      "Epoch 1166/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.8065 - squared_difference_loss: 12.0612 - KL_divergence_loss: 3.7453 - neg_log_likelihood: 15493683737.0699 - val_loss: 15.6606 - val_squared_difference_loss: 11.9018 - val_KL_divergence_loss: 3.7588 - val_neg_log_likelihood: 829769804710457638912.0000\n",
      "Epoch 1167/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.7983 - squared_difference_loss: 12.0431 - KL_divergence_loss: 3.7552 - neg_log_likelihood: 90996347568.6146 - val_loss: 15.5806 - val_squared_difference_loss: 11.8488 - val_KL_divergence_loss: 3.7318 - val_neg_log_likelihood: 745072610919922794496.0000\n",
      "Epoch 1168/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.8402 - squared_difference_loss: 12.0973 - KL_divergence_loss: 3.7429 - neg_log_likelihood: 12982171122.1740 - val_loss: 15.5799 - val_squared_difference_loss: 11.8263 - val_KL_divergence_loss: 3.7537 - val_neg_log_likelihood: 263457997006816083968.0000\n",
      "Epoch 1169/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.7895 - squared_difference_loss: 12.0394 - KL_divergence_loss: 3.7501 - neg_log_likelihood: 15688978785.8122 - val_loss: 15.6166 - val_squared_difference_loss: 11.8731 - val_KL_divergence_loss: 3.7435 - val_neg_log_likelihood: 318357547832489934848.0000\n",
      "Epoch 1170/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7953 - squared_difference_loss: 12.0621 - KL_divergence_loss: 3.7332 - neg_log_likelihood: 52542174143.8126 - val_loss: 15.6050 - val_squared_difference_loss: 11.8602 - val_KL_divergence_loss: 3.7448 - val_neg_log_likelihood: 187198754116633952256.0000\n",
      "Epoch 1171/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.8400 - squared_difference_loss: 12.0799 - KL_divergence_loss: 3.7601 - neg_log_likelihood: 38547254057.3986 - val_loss: 15.6034 - val_squared_difference_loss: 11.8680 - val_KL_divergence_loss: 3.7354 - val_neg_log_likelihood: 473606899507231916032.0000\n",
      "Epoch 1172/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7996 - squared_difference_loss: 12.0595 - KL_divergence_loss: 3.7400 - neg_log_likelihood: 2616628639.0669 - val_loss: 15.5847 - val_squared_difference_loss: 11.8486 - val_KL_divergence_loss: 3.7361 - val_neg_log_likelihood: 75906154185555591168.0000\n",
      "Epoch 1173/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7885 - squared_difference_loss: 12.0380 - KL_divergence_loss: 3.7505 - neg_log_likelihood: 288947270236.7078 - val_loss: 15.5700 - val_squared_difference_loss: 11.8468 - val_KL_divergence_loss: 3.7231 - val_neg_log_likelihood: 994253927712665239552.0000\n",
      "Epoch 1174/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.8251 - squared_difference_loss: 12.0762 - KL_divergence_loss: 3.7489 - neg_log_likelihood: 24463677688.6606 - val_loss: 15.5957 - val_squared_difference_loss: 11.8341 - val_KL_divergence_loss: 3.7616 - val_neg_log_likelihood: 547853530273499381760.0000\n",
      "Epoch 1175/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.8015 - squared_difference_loss: 12.0251 - KL_divergence_loss: 3.7764 - neg_log_likelihood: 5869540541.7491 - val_loss: 15.6062 - val_squared_difference_loss: 11.8800 - val_KL_divergence_loss: 3.7262 - val_neg_log_likelihood: 1023646706155744395264.0000\n",
      "Epoch 1176/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7830 - squared_difference_loss: 12.0567 - KL_divergence_loss: 3.7263 - neg_log_likelihood: 20944361364.2890 - val_loss: 15.6113 - val_squared_difference_loss: 11.8855 - val_KL_divergence_loss: 3.7258 - val_neg_log_likelihood: 386806577432368119808.0000\n",
      "Epoch 1177/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.8119 - squared_difference_loss: 12.0542 - KL_divergence_loss: 3.7578 - neg_log_likelihood: 30720135491.4247 - val_loss: 15.5874 - val_squared_difference_loss: 11.8474 - val_KL_divergence_loss: 3.7400 - val_neg_log_likelihood: 631118177431197188096.0000\n",
      "Epoch 1178/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7987 - squared_difference_loss: 12.0534 - KL_divergence_loss: 3.7453 - neg_log_likelihood: 21897124193.5439 - val_loss: 15.5967 - val_squared_difference_loss: 11.8714 - val_KL_divergence_loss: 3.7253 - val_neg_log_likelihood: 183411839544173953024.0000\n",
      "Epoch 1179/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.8045 - squared_difference_loss: 12.0307 - KL_divergence_loss: 3.7739 - neg_log_likelihood: 534038992857.7936 - val_loss: 15.6169 - val_squared_difference_loss: 11.8709 - val_KL_divergence_loss: 3.7460 - val_neg_log_likelihood: 1234800165604952375296.0000\n",
      "Epoch 1180/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.8217 - squared_difference_loss: 12.0712 - KL_divergence_loss: 3.7505 - neg_log_likelihood: 7503549381.9511 - val_loss: 15.5903 - val_squared_difference_loss: 11.8347 - val_KL_divergence_loss: 3.7556 - val_neg_log_likelihood: 1296276775492039999488.0000\n",
      "Epoch 1181/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.8176 - squared_difference_loss: 12.0459 - KL_divergence_loss: 3.7717 - neg_log_likelihood: 19501087250.8955 - val_loss: 15.6232 - val_squared_difference_loss: 11.8787 - val_KL_divergence_loss: 3.7445 - val_neg_log_likelihood: 538843839157996814336.0000\n",
      "Epoch 1182/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.8130 - squared_difference_loss: 12.0262 - KL_divergence_loss: 3.7868 - neg_log_likelihood: 17287778899.7106 - val_loss: 15.5767 - val_squared_difference_loss: 11.8297 - val_KL_divergence_loss: 3.7470 - val_neg_log_likelihood: 213596153374937546752.0000\n",
      "Epoch 1183/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7855 - squared_difference_loss: 12.0295 - KL_divergence_loss: 3.7560 - neg_log_likelihood: 28142730461.9738 - val_loss: 15.5802 - val_squared_difference_loss: 11.8414 - val_KL_divergence_loss: 3.7388 - val_neg_log_likelihood: 269325772431268544512.0000\n",
      "Epoch 1184/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7812 - squared_difference_loss: 12.0344 - KL_divergence_loss: 3.7467 - neg_log_likelihood: 296034276325.8420 - val_loss: 15.5495 - val_squared_difference_loss: 11.7958 - val_KL_divergence_loss: 3.7537 - val_neg_log_likelihood: 738735227557988139008.0000\n",
      "Epoch 1185/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7822 - squared_difference_loss: 12.0177 - KL_divergence_loss: 3.7645 - neg_log_likelihood: 2531051319258.1055 - val_loss: 15.5755 - val_squared_difference_loss: 11.8344 - val_KL_divergence_loss: 3.7411 - val_neg_log_likelihood: 247123345878816194560.0000\n",
      "Epoch 1186/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.7929 - squared_difference_loss: 12.0506 - KL_divergence_loss: 3.7424 - neg_log_likelihood: 60669589969.1419 - val_loss: 15.5876 - val_squared_difference_loss: 11.8278 - val_KL_divergence_loss: 3.7598 - val_neg_log_likelihood: 166105926640369958912.0000\n",
      "Epoch 1187/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.7653 - squared_difference_loss: 11.9931 - KL_divergence_loss: 3.7723 - neg_log_likelihood: 276585261252.8335 - val_loss: 15.5708 - val_squared_difference_loss: 11.8150 - val_KL_divergence_loss: 3.7558 - val_neg_log_likelihood: 1065117783057737318400.0000\n",
      "Epoch 1188/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.8123 - squared_difference_loss: 12.0381 - KL_divergence_loss: 3.7741 - neg_log_likelihood: 16225783069.1998 - val_loss: 15.5712 - val_squared_difference_loss: 11.8168 - val_KL_divergence_loss: 3.7544 - val_neg_log_likelihood: 659249563376260612096.0000\n",
      "Epoch 1189/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7930 - squared_difference_loss: 12.0281 - KL_divergence_loss: 3.7649 - neg_log_likelihood: 227192600590.6479 - val_loss: 15.5644 - val_squared_difference_loss: 11.8090 - val_KL_divergence_loss: 3.7555 - val_neg_log_likelihood: 272254297223617150976.0000\n",
      "Epoch 1190/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.7933 - squared_difference_loss: 12.0318 - KL_divergence_loss: 3.7615 - neg_log_likelihood: 105650322132.8561 - val_loss: 15.5570 - val_squared_difference_loss: 11.7903 - val_KL_divergence_loss: 3.7667 - val_neg_log_likelihood: 1053935611995201339392.0000\n",
      "Epoch 1191/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7793 - squared_difference_loss: 12.0205 - KL_divergence_loss: 3.7587 - neg_log_likelihood: 24149624541.6956 - val_loss: 15.5681 - val_squared_difference_loss: 11.8269 - val_KL_divergence_loss: 3.7412 - val_neg_log_likelihood: 437087617971400212480.0000\n",
      "Epoch 1192/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7739 - squared_difference_loss: 12.0131 - KL_divergence_loss: 3.7608 - neg_log_likelihood: 225258287830.8710 - val_loss: 15.5601 - val_squared_difference_loss: 11.8114 - val_KL_divergence_loss: 3.7487 - val_neg_log_likelihood: 326149576048845062144.0000\n",
      "Epoch 1193/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.8004 - squared_difference_loss: 12.0370 - KL_divergence_loss: 3.7635 - neg_log_likelihood: 106758547755.8545 - val_loss: 15.6005 - val_squared_difference_loss: 11.8531 - val_KL_divergence_loss: 3.7475 - val_neg_log_likelihood: 177517089818655686656.0000\n",
      "Epoch 1194/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7634 - squared_difference_loss: 12.0126 - KL_divergence_loss: 3.7508 - neg_log_likelihood: 164280808289.5299 - val_loss: 15.5716 - val_squared_difference_loss: 11.8192 - val_KL_divergence_loss: 3.7524 - val_neg_log_likelihood: 233304074643025854464.0000\n",
      "Epoch 1195/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.7712 - squared_difference_loss: 12.0061 - KL_divergence_loss: 3.7651 - neg_log_likelihood: 61949816873.1357 - val_loss: 15.5616 - val_squared_difference_loss: 11.8280 - val_KL_divergence_loss: 3.7336 - val_neg_log_likelihood: 72611903239497465856.0000\n",
      "Epoch 1196/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7764 - squared_difference_loss: 12.0181 - KL_divergence_loss: 3.7584 - neg_log_likelihood: 1502220852.4077 - val_loss: 15.5758 - val_squared_difference_loss: 11.8325 - val_KL_divergence_loss: 3.7433 - val_neg_log_likelihood: 247478288709962498048.0000\n",
      "Epoch 1197/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.7686 - squared_difference_loss: 11.9972 - KL_divergence_loss: 3.7714 - neg_log_likelihood: 169807784668.4343 - val_loss: 15.5720 - val_squared_difference_loss: 11.8165 - val_KL_divergence_loss: 3.7555 - val_neg_log_likelihood: 8697251752671431360512.0000\n",
      "Epoch 1198/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7819 - squared_difference_loss: 11.9850 - KL_divergence_loss: 3.7970 - neg_log_likelihood: 74318721359.1929 - val_loss: 15.6134 - val_squared_difference_loss: 11.8825 - val_KL_divergence_loss: 3.7309 - val_neg_log_likelihood: 308544227082488709120.0000\n",
      "Epoch 1199/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7676 - squared_difference_loss: 11.9876 - KL_divergence_loss: 3.7800 - neg_log_likelihood: 317327825690.2944 - val_loss: 15.5994 - val_squared_difference_loss: 11.8650 - val_KL_divergence_loss: 3.7343 - val_neg_log_likelihood: 1247976230609613225984.0000\n",
      "Epoch 1200/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.8171 - squared_difference_loss: 12.0519 - KL_divergence_loss: 3.7652 - neg_log_likelihood: 261258524.0068 - val_loss: 15.6152 - val_squared_difference_loss: 11.8717 - val_KL_divergence_loss: 3.7435 - val_neg_log_likelihood: 149720741058572517376.0000\n",
      "Epoch 1201/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7771 - squared_difference_loss: 12.0034 - KL_divergence_loss: 3.7737 - neg_log_likelihood: 265763059702.6448 - val_loss: 15.5577 - val_squared_difference_loss: 11.7720 - val_KL_divergence_loss: 3.7857 - val_neg_log_likelihood: 619949538938984857600.0000\n",
      "Epoch 1202/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7536 - squared_difference_loss: 11.9914 - KL_divergence_loss: 3.7622 - neg_log_likelihood: 1821194246081.8904 - val_loss: 15.5605 - val_squared_difference_loss: 11.8003 - val_KL_divergence_loss: 3.7602 - val_neg_log_likelihood: 732727327180232065024.0000\n",
      "Epoch 1203/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7553 - squared_difference_loss: 11.9936 - KL_divergence_loss: 3.7617 - neg_log_likelihood: 30693845900.4757 - val_loss: 15.5462 - val_squared_difference_loss: 11.7932 - val_KL_divergence_loss: 3.7530 - val_neg_log_likelihood: 549835761661211770880.0000\n",
      "Epoch 1204/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7852 - squared_difference_loss: 12.0203 - KL_divergence_loss: 3.7649 - neg_log_likelihood: 4832537870.2734 - val_loss: 15.5901 - val_squared_difference_loss: 11.8181 - val_KL_divergence_loss: 3.7720 - val_neg_log_likelihood: 801858311393863139328.0000\n",
      "Epoch 1205/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.7379 - squared_difference_loss: 11.9534 - KL_divergence_loss: 3.7845 - neg_log_likelihood: 348928148369.4427 - val_loss: 15.5805 - val_squared_difference_loss: 11.8218 - val_KL_divergence_loss: 3.7587 - val_neg_log_likelihood: 218075783690807017472.0000\n",
      "Epoch 1206/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.7719 - squared_difference_loss: 12.0011 - KL_divergence_loss: 3.7708 - neg_log_likelihood: 7944096133.8306 - val_loss: 15.5477 - val_squared_difference_loss: 11.7855 - val_KL_divergence_loss: 3.7622 - val_neg_log_likelihood: 644869832730747863040.0000\n",
      "Epoch 1207/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7593 - squared_difference_loss: 11.9775 - KL_divergence_loss: 3.7818 - neg_log_likelihood: 1455432601346.9587 - val_loss: 15.5776 - val_squared_difference_loss: 11.8084 - val_KL_divergence_loss: 3.7692 - val_neg_log_likelihood: 574167913597974347776.0000\n",
      "Epoch 1208/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7680 - squared_difference_loss: 11.9970 - KL_divergence_loss: 3.7710 - neg_log_likelihood: 316687553607.4094 - val_loss: 15.5450 - val_squared_difference_loss: 11.7518 - val_KL_divergence_loss: 3.7932 - val_neg_log_likelihood: 234435272332575211520.0000\n",
      "Epoch 1209/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7164 - squared_difference_loss: 11.9387 - KL_divergence_loss: 3.7778 - neg_log_likelihood: 424396374944.6657 - val_loss: 15.5565 - val_squared_difference_loss: 11.8062 - val_KL_divergence_loss: 3.7503 - val_neg_log_likelihood: 687056494488316280832.0000\n",
      "Epoch 1210/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7398 - squared_difference_loss: 11.9795 - KL_divergence_loss: 3.7604 - neg_log_likelihood: 254124708059.8726 - val_loss: 15.5698 - val_squared_difference_loss: 11.8017 - val_KL_divergence_loss: 3.7681 - val_neg_log_likelihood: 291045037251254878208.0000\n",
      "Epoch 1211/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7316 - squared_difference_loss: 11.9624 - KL_divergence_loss: 3.7693 - neg_log_likelihood: 146435134632.1174 - val_loss: 15.5945 - val_squared_difference_loss: 11.8246 - val_KL_divergence_loss: 3.7699 - val_neg_log_likelihood: 549968766086643122176.0000\n",
      "Epoch 1212/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7749 - squared_difference_loss: 11.9968 - KL_divergence_loss: 3.7781 - neg_log_likelihood: 8811773447.8422 - val_loss: 15.5634 - val_squared_difference_loss: 11.8027 - val_KL_divergence_loss: 3.7607 - val_neg_log_likelihood: 1160953169315295920128.0000\n",
      "Epoch 1213/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.7804 - squared_difference_loss: 12.0051 - KL_divergence_loss: 3.7753 - neg_log_likelihood: 42474228238.8797 - val_loss: 15.5548 - val_squared_difference_loss: 11.8073 - val_KL_divergence_loss: 3.7476 - val_neg_log_likelihood: 2797715713654819651584.0000\n",
      "Epoch 1214/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7545 - squared_difference_loss: 11.9829 - KL_divergence_loss: 3.7716 - neg_log_likelihood: 15687367916.5014 - val_loss: 15.5633 - val_squared_difference_loss: 11.8146 - val_KL_divergence_loss: 3.7487 - val_neg_log_likelihood: 547021505890194423808.0000\n",
      "Epoch 1215/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7558 - squared_difference_loss: 11.9936 - KL_divergence_loss: 3.7622 - neg_log_likelihood: 20224654841.1552 - val_loss: 15.5742 - val_squared_difference_loss: 11.8101 - val_KL_divergence_loss: 3.7641 - val_neg_log_likelihood: 606509158335077416960.0000\n",
      "Epoch 1216/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.7316 - squared_difference_loss: 11.9629 - KL_divergence_loss: 3.7687 - neg_log_likelihood: 378553117205.4808 - val_loss: 15.5514 - val_squared_difference_loss: 11.8128 - val_KL_divergence_loss: 3.7387 - val_neg_log_likelihood: 2213318198994232147968.0000\n",
      "Epoch 1217/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.7445 - squared_difference_loss: 11.9915 - KL_divergence_loss: 3.7530 - neg_log_likelihood: 25068249146.6894 - val_loss: 15.5277 - val_squared_difference_loss: 11.7962 - val_KL_divergence_loss: 3.7315 - val_neg_log_likelihood: 1960913999288671928320.0000\n",
      "Epoch 1218/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7651 - squared_difference_loss: 11.9633 - KL_divergence_loss: 3.8017 - neg_log_likelihood: 43709628246.2697 - val_loss: 15.5595 - val_squared_difference_loss: 11.7844 - val_KL_divergence_loss: 3.7751 - val_neg_log_likelihood: 339617865629240197120.0000\n",
      "Epoch 1219/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7184 - squared_difference_loss: 11.9388 - KL_divergence_loss: 3.7796 - neg_log_likelihood: 19326085467.6647 - val_loss: 15.5331 - val_squared_difference_loss: 11.7908 - val_KL_divergence_loss: 3.7423 - val_neg_log_likelihood: 1554084087008678379520.0000\n",
      "Epoch 1220/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7437 - squared_difference_loss: 11.9670 - KL_divergence_loss: 3.7766 - neg_log_likelihood: 208580296546.3627 - val_loss: 15.5429 - val_squared_difference_loss: 11.7834 - val_KL_divergence_loss: 3.7595 - val_neg_log_likelihood: 641573324869589663744.0000\n",
      "Epoch 1221/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7327 - squared_difference_loss: 11.9594 - KL_divergence_loss: 3.7732 - neg_log_likelihood: 837139528019.3215 - val_loss: 15.5476 - val_squared_difference_loss: 11.7866 - val_KL_divergence_loss: 3.7610 - val_neg_log_likelihood: 2970128940546689859584.0000\n",
      "Epoch 1222/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7509 - squared_difference_loss: 11.9696 - KL_divergence_loss: 3.7813 - neg_log_likelihood: 23924231590.2837 - val_loss: 15.5794 - val_squared_difference_loss: 11.8010 - val_KL_divergence_loss: 3.7784 - val_neg_log_likelihood: 2063652834440625258496.0000\n",
      "Epoch 1223/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7513 - squared_difference_loss: 11.9644 - KL_divergence_loss: 3.7869 - neg_log_likelihood: 32893338683.6742 - val_loss: 15.5507 - val_squared_difference_loss: 11.7916 - val_KL_divergence_loss: 3.7591 - val_neg_log_likelihood: 180368228987797733376.0000\n",
      "Epoch 1224/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7313 - squared_difference_loss: 11.9621 - KL_divergence_loss: 3.7692 - neg_log_likelihood: 173341707554.1417 - val_loss: 15.5920 - val_squared_difference_loss: 11.8416 - val_KL_divergence_loss: 3.7504 - val_neg_log_likelihood: 821932215629857947648.0000\n",
      "Epoch 1225/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7639 - squared_difference_loss: 11.9988 - KL_divergence_loss: 3.7651 - neg_log_likelihood: 70403087138.2809 - val_loss: 15.5476 - val_squared_difference_loss: 11.8133 - val_KL_divergence_loss: 3.7342 - val_neg_log_likelihood: 328778776258161606656.0000\n",
      "Epoch 1226/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7523 - squared_difference_loss: 11.9627 - KL_divergence_loss: 3.7896 - neg_log_likelihood: 65100634233.7335 - val_loss: 15.5782 - val_squared_difference_loss: 11.8024 - val_KL_divergence_loss: 3.7758 - val_neg_log_likelihood: 188662971447254745088.0000\n",
      "Epoch 1227/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.7235 - squared_difference_loss: 11.9335 - KL_divergence_loss: 3.7900 - neg_log_likelihood: 263082930924.4594 - val_loss: 15.5801 - val_squared_difference_loss: 11.8079 - val_KL_divergence_loss: 3.7722 - val_neg_log_likelihood: 1675539013341064724480.0000\n",
      "Epoch 1228/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7311 - squared_difference_loss: 11.9594 - KL_divergence_loss: 3.7716 - neg_log_likelihood: 91127573599.9376 - val_loss: 15.5644 - val_squared_difference_loss: 11.8062 - val_KL_divergence_loss: 3.7582 - val_neg_log_likelihood: 894507401803220385792.0000\n",
      "Epoch 1229/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7463 - squared_difference_loss: 11.9697 - KL_divergence_loss: 3.7766 - neg_log_likelihood: 302702588220.2236 - val_loss: 15.5359 - val_squared_difference_loss: 11.7774 - val_KL_divergence_loss: 3.7585 - val_neg_log_likelihood: 2034149931620623187968.0000\n",
      "Epoch 1230/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7548 - squared_difference_loss: 11.9653 - KL_divergence_loss: 3.7895 - neg_log_likelihood: 4465771022.1144 - val_loss: 15.5913 - val_squared_difference_loss: 11.8315 - val_KL_divergence_loss: 3.7598 - val_neg_log_likelihood: 390117819276286230528.0000\n",
      "Epoch 1231/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7345 - squared_difference_loss: 11.9581 - KL_divergence_loss: 3.7764 - neg_log_likelihood: 39461413589.1311 - val_loss: 15.5479 - val_squared_difference_loss: 11.7831 - val_KL_divergence_loss: 3.7648 - val_neg_log_likelihood: 1098574912156243329024.0000\n",
      "Epoch 1232/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7065 - squared_difference_loss: 11.9231 - KL_divergence_loss: 3.7834 - neg_log_likelihood: 233446468444.4254 - val_loss: 15.5643 - val_squared_difference_loss: 11.8007 - val_KL_divergence_loss: 3.7636 - val_neg_log_likelihood: 483120694995073433600.0000\n",
      "Epoch 1233/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6994 - squared_difference_loss: 11.9229 - KL_divergence_loss: 3.7766 - neg_log_likelihood: 271556396755.4483 - val_loss: 15.5531 - val_squared_difference_loss: 11.8065 - val_KL_divergence_loss: 3.7466 - val_neg_log_likelihood: 1112785360482455388160.0000\n",
      "Epoch 1234/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.7159 - squared_difference_loss: 11.9391 - KL_divergence_loss: 3.7768 - neg_log_likelihood: 83360430827.4145 - val_loss: 15.5437 - val_squared_difference_loss: 11.8080 - val_KL_divergence_loss: 3.7357 - val_neg_log_likelihood: 1101936053378923495424.0000\n",
      "Epoch 1235/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7132 - squared_difference_loss: 11.9406 - KL_divergence_loss: 3.7726 - neg_log_likelihood: 48922374646.4396 - val_loss: 15.5282 - val_squared_difference_loss: 11.7664 - val_KL_divergence_loss: 3.7618 - val_neg_log_likelihood: 2218119677164088459264.0000\n",
      "Epoch 1236/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.7406 - squared_difference_loss: 11.9786 - KL_divergence_loss: 3.7620 - neg_log_likelihood: 14138091787.2455 - val_loss: 15.5333 - val_squared_difference_loss: 11.8020 - val_KL_divergence_loss: 3.7313 - val_neg_log_likelihood: 1075207704173179961344.0000\n",
      "Epoch 1237/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7262 - squared_difference_loss: 11.9584 - KL_divergence_loss: 3.7678 - neg_log_likelihood: 56911523678.3430 - val_loss: 15.5274 - val_squared_difference_loss: 11.7611 - val_KL_divergence_loss: 3.7663 - val_neg_log_likelihood: 1523697340560581328896.0000\n",
      "Epoch 1238/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7234 - squared_difference_loss: 11.9412 - KL_divergence_loss: 3.7822 - neg_log_likelihood: 37003072508.1964 - val_loss: 15.5575 - val_squared_difference_loss: 11.7887 - val_KL_divergence_loss: 3.7689 - val_neg_log_likelihood: 266742465125404999680.0000\n",
      "Epoch 1239/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7134 - squared_difference_loss: 11.9463 - KL_divergence_loss: 3.7671 - neg_log_likelihood: 230624509357.6065 - val_loss: 15.5433 - val_squared_difference_loss: 11.7670 - val_KL_divergence_loss: 3.7763 - val_neg_log_likelihood: 1536748590869790588928.0000\n",
      "Epoch 1240/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7469 - squared_difference_loss: 11.9670 - KL_divergence_loss: 3.7798 - neg_log_likelihood: 32506855722.1603 - val_loss: 15.5266 - val_squared_difference_loss: 11.7418 - val_KL_divergence_loss: 3.7848 - val_neg_log_likelihood: 604111269764120313856.0000\n",
      "Epoch 1241/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6932 - squared_difference_loss: 11.9212 - KL_divergence_loss: 3.7721 - neg_log_likelihood: 105573239195.1399 - val_loss: 15.5656 - val_squared_difference_loss: 11.8006 - val_KL_divergence_loss: 3.7650 - val_neg_log_likelihood: 439663914671468904448.0000\n",
      "Epoch 1242/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7053 - squared_difference_loss: 11.9296 - KL_divergence_loss: 3.7757 - neg_log_likelihood: 56904597278.9383 - val_loss: 15.5941 - val_squared_difference_loss: 11.8389 - val_KL_divergence_loss: 3.7552 - val_neg_log_likelihood: 2349122364629729673216.0000\n",
      "Epoch 1243/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7243 - squared_difference_loss: 11.9485 - KL_divergence_loss: 3.7758 - neg_log_likelihood: 516266570597.0230 - val_loss: 15.5266 - val_squared_difference_loss: 11.7736 - val_KL_divergence_loss: 3.7530 - val_neg_log_likelihood: 270598363106982330368.0000\n",
      "Epoch 1244/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7521 - squared_difference_loss: 11.9725 - KL_divergence_loss: 3.7795 - neg_log_likelihood: 224171089645.8981 - val_loss: 15.5679 - val_squared_difference_loss: 11.7908 - val_KL_divergence_loss: 3.7771 - val_neg_log_likelihood: 720266578489341509632.0000\n",
      "Epoch 1245/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7281 - squared_difference_loss: 11.9344 - KL_divergence_loss: 3.7937 - neg_log_likelihood: 790292342560.6128 - val_loss: 15.5263 - val_squared_difference_loss: 11.7531 - val_KL_divergence_loss: 3.7733 - val_neg_log_likelihood: 1147986846033240129536.0000\n",
      "Epoch 1246/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7288 - squared_difference_loss: 11.9515 - KL_divergence_loss: 3.7774 - neg_log_likelihood: 59949765036.4370 - val_loss: 15.5093 - val_squared_difference_loss: 11.7324 - val_KL_divergence_loss: 3.7769 - val_neg_log_likelihood: 2269586844517738217472.0000\n",
      "Epoch 1247/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7028 - squared_difference_loss: 11.9226 - KL_divergence_loss: 3.7802 - neg_log_likelihood: 528628428835.4468 - val_loss: 15.5466 - val_squared_difference_loss: 11.7711 - val_KL_divergence_loss: 3.7756 - val_neg_log_likelihood: 1035856581055159730176.0000\n",
      "Epoch 1248/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7039 - squared_difference_loss: 11.9295 - KL_divergence_loss: 3.7744 - neg_log_likelihood: 68892537996.4662 - val_loss: 15.5280 - val_squared_difference_loss: 11.7837 - val_KL_divergence_loss: 3.7443 - val_neg_log_likelihood: 1897210338299544338432.0000\n",
      "Epoch 1249/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.7149 - squared_difference_loss: 11.9331 - KL_divergence_loss: 3.7818 - neg_log_likelihood: 163304976516.6902 - val_loss: 15.4970 - val_squared_difference_loss: 11.7348 - val_KL_divergence_loss: 3.7622 - val_neg_log_likelihood: 182447419938697412608.0000\n",
      "Epoch 1250/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7498 - squared_difference_loss: 11.9587 - KL_divergence_loss: 3.7911 - neg_log_likelihood: 67967218667.2960 - val_loss: 15.5182 - val_squared_difference_loss: 11.7593 - val_KL_divergence_loss: 3.7589 - val_neg_log_likelihood: 2016573177753949437952.0000\n",
      "Epoch 1251/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.7156 - squared_difference_loss: 11.9274 - KL_divergence_loss: 3.7882 - neg_log_likelihood: 83450047081.3405 - val_loss: 15.5424 - val_squared_difference_loss: 11.7783 - val_KL_divergence_loss: 3.7641 - val_neg_log_likelihood: 611044673331222806528.0000\n",
      "Epoch 1252/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7341 - squared_difference_loss: 11.9530 - KL_divergence_loss: 3.7811 - neg_log_likelihood: 47113703444.5490 - val_loss: 15.4877 - val_squared_difference_loss: 11.7133 - val_KL_divergence_loss: 3.7744 - val_neg_log_likelihood: 382947785414359449600.0000\n",
      "Epoch 1253/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.7057 - squared_difference_loss: 11.9225 - KL_divergence_loss: 3.7832 - neg_log_likelihood: 101677583501.3599 - val_loss: 15.5073 - val_squared_difference_loss: 11.7404 - val_KL_divergence_loss: 3.7669 - val_neg_log_likelihood: 2449620437503663669248.0000\n",
      "Epoch 1254/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.7212 - squared_difference_loss: 11.9342 - KL_divergence_loss: 3.7870 - neg_log_likelihood: 138495214599.7101 - val_loss: 15.5286 - val_squared_difference_loss: 11.7547 - val_KL_divergence_loss: 3.7739 - val_neg_log_likelihood: 196248841942633906176.0000\n",
      "Epoch 1255/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7104 - squared_difference_loss: 11.9095 - KL_divergence_loss: 3.8009 - neg_log_likelihood: 8741756320744.2100 - val_loss: 15.5488 - val_squared_difference_loss: 11.7677 - val_KL_divergence_loss: 3.7811 - val_neg_log_likelihood: 925173150649181143040.0000\n",
      "Epoch 1256/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.7420 - squared_difference_loss: 11.9666 - KL_divergence_loss: 3.7754 - neg_log_likelihood: 154012032109.2243 - val_loss: 15.4970 - val_squared_difference_loss: 11.7500 - val_KL_divergence_loss: 3.7471 - val_neg_log_likelihood: 5294358294763099127808.0000\n",
      "Epoch 1257/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.7345 - squared_difference_loss: 11.9354 - KL_divergence_loss: 3.7992 - neg_log_likelihood: 70580944637.5956 - val_loss: 15.5026 - val_squared_difference_loss: 11.7457 - val_KL_divergence_loss: 3.7569 - val_neg_log_likelihood: 2379476347733022343168.0000\n",
      "Epoch 1258/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6974 - squared_difference_loss: 11.9222 - KL_divergence_loss: 3.7752 - neg_log_likelihood: 194397886461.4057 - val_loss: 15.5245 - val_squared_difference_loss: 11.7320 - val_KL_divergence_loss: 3.7925 - val_neg_log_likelihood: 1667159618118094684160.0000\n",
      "Epoch 1259/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7263 - squared_difference_loss: 11.9366 - KL_divergence_loss: 3.7897 - neg_log_likelihood: 138347224389.2537 - val_loss: 15.5024 - val_squared_difference_loss: 11.7350 - val_KL_divergence_loss: 3.7674 - val_neg_log_likelihood: 666885818815176638464.0000\n",
      "Epoch 1260/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6996 - squared_difference_loss: 11.9074 - KL_divergence_loss: 3.7923 - neg_log_likelihood: 431488073389.8475 - val_loss: 15.5193 - val_squared_difference_loss: 11.7517 - val_KL_divergence_loss: 3.7676 - val_neg_log_likelihood: 653161850611681329152.0000\n",
      "Epoch 1261/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7032 - squared_difference_loss: 11.9360 - KL_divergence_loss: 3.7672 - neg_log_likelihood: 14988673620.3795 - val_loss: 15.5283 - val_squared_difference_loss: 11.7786 - val_KL_divergence_loss: 3.7497 - val_neg_log_likelihood: 2011874790687913017344.0000\n",
      "Epoch 1262/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7122 - squared_difference_loss: 11.9497 - KL_divergence_loss: 3.7625 - neg_log_likelihood: 109526422235.0230 - val_loss: 15.5291 - val_squared_difference_loss: 11.7451 - val_KL_divergence_loss: 3.7841 - val_neg_log_likelihood: 751241957767380992000.0000\n",
      "Epoch 1263/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.7064 - squared_difference_loss: 11.9220 - KL_divergence_loss: 3.7844 - neg_log_likelihood: 607056441808.7322 - val_loss: 15.5379 - val_squared_difference_loss: 11.7826 - val_KL_divergence_loss: 3.7553 - val_neg_log_likelihood: 476903363314007212032.0000\n",
      "Epoch 1264/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.7177 - squared_difference_loss: 11.9235 - KL_divergence_loss: 3.7941 - neg_log_likelihood: 262056530606.5926 - val_loss: 15.5019 - val_squared_difference_loss: 11.7246 - val_KL_divergence_loss: 3.7773 - val_neg_log_likelihood: 592316338780301688832.0000\n",
      "Epoch 1265/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7298 - squared_difference_loss: 11.9562 - KL_divergence_loss: 3.7737 - neg_log_likelihood: 8522838792.1092 - val_loss: 15.4596 - val_squared_difference_loss: 11.6889 - val_KL_divergence_loss: 3.7707 - val_neg_log_likelihood: 2040779624118005006336.0000\n",
      "Epoch 1266/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.7579 - squared_difference_loss: 11.9601 - KL_divergence_loss: 3.7978 - neg_log_likelihood: 7299269347.7806 - val_loss: 15.5474 - val_squared_difference_loss: 11.7479 - val_KL_divergence_loss: 3.7996 - val_neg_log_likelihood: 2527980827172919574528.0000\n",
      "Epoch 1267/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.7050 - squared_difference_loss: 11.9035 - KL_divergence_loss: 3.8014 - neg_log_likelihood: 70298130712.9848 - val_loss: 15.5235 - val_squared_difference_loss: 11.7576 - val_KL_divergence_loss: 3.7659 - val_neg_log_likelihood: 2526080498172919545856.0000\n",
      "Epoch 1268/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.6992 - squared_difference_loss: 11.9230 - KL_divergence_loss: 3.7761 - neg_log_likelihood: 93073252572.6001 - val_loss: 15.4961 - val_squared_difference_loss: 11.7153 - val_KL_divergence_loss: 3.7808 - val_neg_log_likelihood: 1192109356814533394432.0000\n",
      "Epoch 1269/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7123 - squared_difference_loss: 11.9201 - KL_divergence_loss: 3.7922 - neg_log_likelihood: 6860638549.2586 - val_loss: 15.4975 - val_squared_difference_loss: 11.7012 - val_KL_divergence_loss: 3.7963 - val_neg_log_likelihood: 1379838189075081461760.0000\n",
      "Epoch 1270/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.6941 - squared_difference_loss: 11.9127 - KL_divergence_loss: 3.7813 - neg_log_likelihood: 42421041904.7843 - val_loss: 15.5107 - val_squared_difference_loss: 11.7272 - val_KL_divergence_loss: 3.7836 - val_neg_log_likelihood: 2792133130916902469632.0000\n",
      "Epoch 1271/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6702 - squared_difference_loss: 11.8947 - KL_divergence_loss: 3.7756 - neg_log_likelihood: 394672666225.9860 - val_loss: 15.5186 - val_squared_difference_loss: 11.7480 - val_KL_divergence_loss: 3.7706 - val_neg_log_likelihood: 2984289800643361636352.0000\n",
      "Epoch 1272/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7018 - squared_difference_loss: 11.9109 - KL_divergence_loss: 3.7909 - neg_log_likelihood: 26871109061.8306 - val_loss: 15.4982 - val_squared_difference_loss: 11.7132 - val_KL_divergence_loss: 3.7850 - val_neg_log_likelihood: 9932210914796649840640.0000\n",
      "Epoch 1273/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6863 - squared_difference_loss: 11.8912 - KL_divergence_loss: 3.7951 - neg_log_likelihood: 33958932718.2154 - val_loss: 15.5232 - val_squared_difference_loss: 11.7505 - val_KL_divergence_loss: 3.7727 - val_neg_log_likelihood: 496831221438927077376.0000\n",
      "Epoch 1274/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7137 - squared_difference_loss: 11.9352 - KL_divergence_loss: 3.7784 - neg_log_likelihood: 65977320068.1511 - val_loss: 15.5003 - val_squared_difference_loss: 11.6819 - val_KL_divergence_loss: 3.8184 - val_neg_log_likelihood: 1508133267083376721920.0000\n",
      "Epoch 1275/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7229 - squared_difference_loss: 11.9271 - KL_divergence_loss: 3.7959 - neg_log_likelihood: 29138912895.0637 - val_loss: 15.4970 - val_squared_difference_loss: 11.7369 - val_KL_divergence_loss: 3.7601 - val_neg_log_likelihood: 1354751728007653883904.0000\n",
      "Epoch 1276/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7045 - squared_difference_loss: 11.9235 - KL_divergence_loss: 3.7810 - neg_log_likelihood: 71084748368.1020 - val_loss: 15.5166 - val_squared_difference_loss: 11.7321 - val_KL_divergence_loss: 3.7845 - val_neg_log_likelihood: 1065056265542487769088.0000\n",
      "Epoch 1277/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6962 - squared_difference_loss: 11.9251 - KL_divergence_loss: 3.7711 - neg_log_likelihood: 42683367314.0301 - val_loss: 15.5209 - val_squared_difference_loss: 11.7779 - val_KL_divergence_loss: 3.7430 - val_neg_log_likelihood: 885644066240061767680.0000\n",
      "Epoch 1278/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6939 - squared_difference_loss: 11.8932 - KL_divergence_loss: 3.8007 - neg_log_likelihood: 103473713767.5746 - val_loss: 15.5095 - val_squared_difference_loss: 11.7107 - val_KL_divergence_loss: 3.7989 - val_neg_log_likelihood: 678210563008275283968.0000\n",
      "Epoch 1279/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.7108 - squared_difference_loss: 11.9020 - KL_divergence_loss: 3.8087 - neg_log_likelihood: 8009151430.0692 - val_loss: 15.5379 - val_squared_difference_loss: 11.7662 - val_KL_divergence_loss: 3.7717 - val_neg_log_likelihood: 789791588431025930240.0000\n",
      "Epoch 1280/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6689 - squared_difference_loss: 11.8792 - KL_divergence_loss: 3.7897 - neg_log_likelihood: 271950212872.3479 - val_loss: 15.4776 - val_squared_difference_loss: 11.7239 - val_KL_divergence_loss: 3.7537 - val_neg_log_likelihood: 2423790350884550475776.0000\n",
      "Epoch 1281/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6545 - squared_difference_loss: 11.8743 - KL_divergence_loss: 3.7802 - neg_log_likelihood: 394224910718.6483 - val_loss: 15.5195 - val_squared_difference_loss: 11.7629 - val_KL_divergence_loss: 3.7566 - val_neg_log_likelihood: 636945623655840612352.0000\n",
      "Epoch 1282/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7145 - squared_difference_loss: 11.9277 - KL_divergence_loss: 3.7869 - neg_log_likelihood: 31363923390.6588 - val_loss: 15.5257 - val_squared_difference_loss: 11.7205 - val_KL_divergence_loss: 3.8053 - val_neg_log_likelihood: 6557884177109814870016.0000\n",
      "Epoch 1283/2000\n",
      "29507/29507 [==============================] - 1s 20us/step - loss: 15.6912 - squared_difference_loss: 11.9020 - KL_divergence_loss: 3.7892 - neg_log_likelihood: 85258034854.0570 - val_loss: 15.5102 - val_squared_difference_loss: 11.7373 - val_KL_divergence_loss: 3.7729 - val_neg_log_likelihood: 3617515422029965688832.0000\n",
      "Epoch 1284/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 15.6842 - squared_difference_loss: 11.9078 - KL_divergence_loss: 3.7764 - neg_log_likelihood: 34726559302.6305 - val_loss: 15.5260 - val_squared_difference_loss: 11.7441 - val_KL_divergence_loss: 3.7819 - val_neg_log_likelihood: 958219875558082609152.0000\n",
      "Epoch 1285/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.7032 - squared_difference_loss: 11.9214 - KL_divergence_loss: 3.7818 - neg_log_likelihood: 62635496751.9628 - val_loss: 15.5057 - val_squared_difference_loss: 11.7152 - val_KL_divergence_loss: 3.7905 - val_neg_log_likelihood: 2608973331888133898240.0000\n",
      "Epoch 1286/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 15.7198 - squared_difference_loss: 11.9055 - KL_divergence_loss: 3.8143 - neg_log_likelihood: 2276815128.9386 - val_loss: 15.4946 - val_squared_difference_loss: 11.6980 - val_KL_divergence_loss: 3.7966 - val_neg_log_likelihood: 1340037487415894474752.0000\n",
      "Epoch 1287/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6838 - squared_difference_loss: 11.9100 - KL_divergence_loss: 3.7738 - neg_log_likelihood: 1053071621329.2806 - val_loss: 15.5321 - val_squared_difference_loss: 11.7569 - val_KL_divergence_loss: 3.7752 - val_neg_log_likelihood: 1227886212236649693184.0000\n",
      "Epoch 1288/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 15.7104 - squared_difference_loss: 11.9229 - KL_divergence_loss: 3.7875 - neg_log_likelihood: 329792392455.6728 - val_loss: 15.5150 - val_squared_difference_loss: 11.7487 - val_KL_divergence_loss: 3.7663 - val_neg_log_likelihood: 3468070838156282822656.0000\n",
      "Epoch 1289/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7139 - squared_difference_loss: 11.9338 - KL_divergence_loss: 3.7802 - neg_log_likelihood: 134871260370.5618 - val_loss: 15.5324 - val_squared_difference_loss: 11.7417 - val_KL_divergence_loss: 3.7907 - val_neg_log_likelihood: 368076728286235328512.0000\n",
      "Epoch 1290/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.7025 - squared_difference_loss: 11.9144 - KL_divergence_loss: 3.7881 - neg_log_likelihood: 10992434389.5759 - val_loss: 15.4896 - val_squared_difference_loss: 11.7162 - val_KL_divergence_loss: 3.7734 - val_neg_log_likelihood: 408732603199938822144.0000\n",
      "Epoch 1291/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6757 - squared_difference_loss: 11.8961 - KL_divergence_loss: 3.7797 - neg_log_likelihood: 717911587749.0499 - val_loss: 15.4891 - val_squared_difference_loss: 11.7203 - val_KL_divergence_loss: 3.7688 - val_neg_log_likelihood: 6825031993704012840960.0000\n",
      "Epoch 1292/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6762 - squared_difference_loss: 11.8952 - KL_divergence_loss: 3.7810 - neg_log_likelihood: 83971646919.3685 - val_loss: 15.4942 - val_squared_difference_loss: 11.7237 - val_KL_divergence_loss: 3.7705 - val_neg_log_likelihood: 1375102766523221803008.0000\n",
      "Epoch 1293/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6632 - squared_difference_loss: 11.8648 - KL_divergence_loss: 3.7984 - neg_log_likelihood: 57917740473.0498 - val_loss: 15.5209 - val_squared_difference_loss: 11.7456 - val_KL_divergence_loss: 3.7753 - val_neg_log_likelihood: 4984582430239699763200.0000\n",
      "Epoch 1294/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6681 - squared_difference_loss: 11.9037 - KL_divergence_loss: 3.7644 - neg_log_likelihood: 760928097180.0488 - val_loss: 15.5392 - val_squared_difference_loss: 11.7790 - val_KL_divergence_loss: 3.7602 - val_neg_log_likelihood: 1737874535412170489856.0000\n",
      "Epoch 1295/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.6822 - squared_difference_loss: 11.9007 - KL_divergence_loss: 3.7815 - neg_log_likelihood: 162836616992.2764 - val_loss: 15.5027 - val_squared_difference_loss: 11.7253 - val_KL_divergence_loss: 3.7774 - val_neg_log_likelihood: 4123085521040775315456.0000\n",
      "Epoch 1296/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.7081 - squared_difference_loss: 11.9152 - KL_divergence_loss: 3.7929 - neg_log_likelihood: 43018264056.6662 - val_loss: 15.5248 - val_squared_difference_loss: 11.7433 - val_KL_divergence_loss: 3.7815 - val_neg_log_likelihood: 1534229715903604588544.0000\n",
      "Epoch 1297/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.6833 - squared_difference_loss: 11.8881 - KL_divergence_loss: 3.7953 - neg_log_likelihood: 803171284227.9210 - val_loss: 15.4960 - val_squared_difference_loss: 11.7279 - val_KL_divergence_loss: 3.7681 - val_neg_log_likelihood: 494000714129455841280.0000\n",
      "Epoch 1298/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6891 - squared_difference_loss: 11.8882 - KL_divergence_loss: 3.8009 - neg_log_likelihood: 759353141804.1790 - val_loss: 15.4825 - val_squared_difference_loss: 11.6703 - val_KL_divergence_loss: 3.8122 - val_neg_log_likelihood: 750476342951159529472.0000\n",
      "Epoch 1299/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6821 - squared_difference_loss: 11.8951 - KL_divergence_loss: 3.7870 - neg_log_likelihood: 187700782854.7039 - val_loss: 15.5188 - val_squared_difference_loss: 11.7300 - val_KL_divergence_loss: 3.7888 - val_neg_log_likelihood: 1342376443023274016768.0000\n",
      "Epoch 1300/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6740 - squared_difference_loss: 11.8831 - KL_divergence_loss: 3.7909 - neg_log_likelihood: 309702177743.0874 - val_loss: 15.4872 - val_squared_difference_loss: 11.7164 - val_KL_divergence_loss: 3.7708 - val_neg_log_likelihood: 308006091712084574208.0000\n",
      "Epoch 1301/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6847 - squared_difference_loss: 11.8855 - KL_divergence_loss: 3.7992 - neg_log_likelihood: 57871657110.9333 - val_loss: 15.5111 - val_squared_difference_loss: 11.7507 - val_KL_divergence_loss: 3.7603 - val_neg_log_likelihood: 1486429224987858305024.0000\n",
      "Epoch 1302/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6759 - squared_difference_loss: 11.9107 - KL_divergence_loss: 3.7651 - neg_log_likelihood: 16398965683.1677 - val_loss: 15.4971 - val_squared_difference_loss: 11.7341 - val_KL_divergence_loss: 3.7629 - val_neg_log_likelihood: 637767012824242585600.0000\n",
      "Epoch 1303/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6868 - squared_difference_loss: 11.8944 - KL_divergence_loss: 3.7924 - neg_log_likelihood: 6483165550.2258 - val_loss: 15.4794 - val_squared_difference_loss: 11.7105 - val_KL_divergence_loss: 3.7688 - val_neg_log_likelihood: 2981081871766913548288.0000\n",
      "Epoch 1304/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6892 - squared_difference_loss: 11.8911 - KL_divergence_loss: 3.7981 - neg_log_likelihood: 20767471742.2969 - val_loss: 15.5135 - val_squared_difference_loss: 11.7434 - val_KL_divergence_loss: 3.7701 - val_neg_log_likelihood: 791414960500513570816.0000\n",
      "Epoch 1305/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6698 - squared_difference_loss: 11.8924 - KL_divergence_loss: 3.7774 - neg_log_likelihood: 97212546365.3011 - val_loss: 15.4847 - val_squared_difference_loss: 11.7276 - val_KL_divergence_loss: 3.7571 - val_neg_log_likelihood: 965497941616749838336.0000\n",
      "Epoch 1306/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6737 - squared_difference_loss: 11.8927 - KL_divergence_loss: 3.7810 - neg_log_likelihood: 65931798618.4700 - val_loss: 15.4606 - val_squared_difference_loss: 11.6773 - val_KL_divergence_loss: 3.7833 - val_neg_log_likelihood: 1907847764059068039168.0000\n",
      "Epoch 1307/2000\n",
      "29507/29507 [==============================] - 1s 19us/step - loss: 15.6954 - squared_difference_loss: 11.8995 - KL_divergence_loss: 3.7959 - neg_log_likelihood: 400111766141.1227 - val_loss: 15.5015 - val_squared_difference_loss: 11.7292 - val_KL_divergence_loss: 3.7723 - val_neg_log_likelihood: 1936832364125980983296.0000\n",
      "Epoch 1308/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6543 - squared_difference_loss: 11.8857 - KL_divergence_loss: 3.7686 - neg_log_likelihood: 14146255372.2006 - val_loss: 15.5074 - val_squared_difference_loss: 11.7206 - val_KL_divergence_loss: 3.7869 - val_neg_log_likelihood: 2713870492483711926272.0000\n",
      "Epoch 1309/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.6588 - squared_difference_loss: 11.8705 - KL_divergence_loss: 3.7883 - neg_log_likelihood: 9750409358.0856 - val_loss: 15.5099 - val_squared_difference_loss: 11.7304 - val_KL_divergence_loss: 3.7795 - val_neg_log_likelihood: 3568694796114844975104.0000\n",
      "Epoch 1310/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.7116 - squared_difference_loss: 11.9407 - KL_divergence_loss: 3.7709 - neg_log_likelihood: 9681281029.9669 - val_loss: 15.5107 - val_squared_difference_loss: 11.7555 - val_KL_divergence_loss: 3.7552 - val_neg_log_likelihood: 3363708898751599345664.0000\n",
      "Epoch 1311/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6850 - squared_difference_loss: 11.9017 - KL_divergence_loss: 3.7833 - neg_log_likelihood: 2505073330.3001 - val_loss: 15.5029 - val_squared_difference_loss: 11.7241 - val_KL_divergence_loss: 3.7788 - val_neg_log_likelihood: 1390878629890774007808.0000\n",
      "Epoch 1312/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.7073 - squared_difference_loss: 11.9323 - KL_divergence_loss: 3.7751 - neg_log_likelihood: 5193120897.9095 - val_loss: 15.5171 - val_squared_difference_loss: 11.7388 - val_KL_divergence_loss: 3.7783 - val_neg_log_likelihood: 2812840179948010340352.0000\n",
      "Epoch 1313/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.6562 - squared_difference_loss: 11.8824 - KL_divergence_loss: 3.7738 - neg_log_likelihood: 124814423344.6104 - val_loss: 15.5075 - val_squared_difference_loss: 11.7093 - val_KL_divergence_loss: 3.7982 - val_neg_log_likelihood: 2167889423684149182464.0000\n",
      "Epoch 1314/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 15.6768 - squared_difference_loss: 11.8681 - KL_divergence_loss: 3.8087 - neg_log_likelihood: 9912342139.5150 - val_loss: 15.5009 - val_squared_difference_loss: 11.7371 - val_KL_divergence_loss: 3.7638 - val_neg_log_likelihood: 590779809856832274432.0000\n",
      "Epoch 1315/2000\n",
      "29507/29507 [==============================] - 1s 19us/step - loss: 15.6688 - squared_difference_loss: 11.8949 - KL_divergence_loss: 3.7739 - neg_log_likelihood: 16049664554.2813 - val_loss: 15.5075 - val_squared_difference_loss: 11.7296 - val_KL_divergence_loss: 3.7779 - val_neg_log_likelihood: 2008258414415475638272.0000\n",
      "Epoch 1316/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.6793 - squared_difference_loss: 11.9017 - KL_divergence_loss: 3.7777 - neg_log_likelihood: 141526593583.5363 - val_loss: 15.5103 - val_squared_difference_loss: 11.7168 - val_KL_divergence_loss: 3.7935 - val_neg_log_likelihood: 9430324673549928759296.0000\n",
      "Epoch 1317/2000\n",
      "29507/29507 [==============================] - 1s 19us/step - loss: 15.6608 - squared_difference_loss: 11.8672 - KL_divergence_loss: 3.7937 - neg_log_likelihood: 15515387501.6690 - val_loss: 15.5214 - val_squared_difference_loss: 11.7716 - val_KL_divergence_loss: 3.7498 - val_neg_log_likelihood: 6389062753374326226944.0000\n",
      "Epoch 1318/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 15.6569 - squared_difference_loss: 11.8762 - KL_divergence_loss: 3.7807 - neg_log_likelihood: 70230727432.1127 - val_loss: 15.4625 - val_squared_difference_loss: 11.6974 - val_KL_divergence_loss: 3.7651 - val_neg_log_likelihood: 393467832029260677120.0000\n",
      "Epoch 1319/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.6795 - squared_difference_loss: 11.8891 - KL_divergence_loss: 3.7904 - neg_log_likelihood: 51933301284.2980 - val_loss: 15.4973 - val_squared_difference_loss: 11.7116 - val_KL_divergence_loss: 3.7857 - val_neg_log_likelihood: 3000326417649400020992.0000\n",
      "Epoch 1320/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.6431 - squared_difference_loss: 11.8503 - KL_divergence_loss: 3.7928 - neg_log_likelihood: 35959536249.0244 - val_loss: 15.4846 - val_squared_difference_loss: 11.7038 - val_KL_divergence_loss: 3.7808 - val_neg_log_likelihood: 1641376359124874035200.0000\n",
      "Epoch 1321/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6784 - squared_difference_loss: 11.8989 - KL_divergence_loss: 3.7795 - neg_log_likelihood: 55270705422.1654 - val_loss: 15.4892 - val_squared_difference_loss: 11.6802 - val_KL_divergence_loss: 3.8090 - val_neg_log_likelihood: 1143454224300952780800.0000\n",
      "Epoch 1322/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6552 - squared_difference_loss: 11.8679 - KL_divergence_loss: 3.7873 - neg_log_likelihood: 78783963865.2158 - val_loss: 15.4911 - val_squared_difference_loss: 11.7201 - val_KL_divergence_loss: 3.7709 - val_neg_log_likelihood: 11908812195683297656832.0000\n",
      "Epoch 1323/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6223 - squared_difference_loss: 11.8439 - KL_divergence_loss: 3.7785 - neg_log_likelihood: 47548897142.0521 - val_loss: 15.4796 - val_squared_difference_loss: 11.7352 - val_KL_divergence_loss: 3.7445 - val_neg_log_likelihood: 2880750809454689648640.0000\n",
      "Epoch 1324/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6843 - squared_difference_loss: 11.9072 - KL_divergence_loss: 3.7771 - neg_log_likelihood: 1553686425392.6567 - val_loss: 15.4985 - val_squared_difference_loss: 11.7089 - val_KL_divergence_loss: 3.7895 - val_neg_log_likelihood: 8988140771351225958400.0000\n",
      "Epoch 1325/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6589 - squared_difference_loss: 11.8732 - KL_divergence_loss: 3.7857 - neg_log_likelihood: 288362002274.2010 - val_loss: 15.4748 - val_squared_difference_loss: 11.7287 - val_KL_divergence_loss: 3.7461 - val_neg_log_likelihood: 1605276163113410363392.0000\n",
      "Epoch 1326/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6537 - squared_difference_loss: 11.8700 - KL_divergence_loss: 3.7837 - neg_log_likelihood: 92393662541.6286 - val_loss: 15.4769 - val_squared_difference_loss: 11.6982 - val_KL_divergence_loss: 3.7787 - val_neg_log_likelihood: 6222030378096882876416.0000\n",
      "Epoch 1327/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6574 - squared_difference_loss: 11.8809 - KL_divergence_loss: 3.7765 - neg_log_likelihood: 1648851674455.1672 - val_loss: 15.4918 - val_squared_difference_loss: 11.6994 - val_KL_divergence_loss: 3.7925 - val_neg_log_likelihood: 6116402502965376581632.0000\n",
      "Epoch 1328/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6911 - squared_difference_loss: 11.8966 - KL_divergence_loss: 3.7945 - neg_log_likelihood: 9342213954.2302 - val_loss: 15.5018 - val_squared_difference_loss: 11.6799 - val_KL_divergence_loss: 3.8219 - val_neg_log_likelihood: 28095473565735917191168.0000\n",
      "Epoch 1329/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6764 - squared_difference_loss: 11.8810 - KL_divergence_loss: 3.7954 - neg_log_likelihood: 8366199854.1725 - val_loss: 15.4885 - val_squared_difference_loss: 11.7117 - val_KL_divergence_loss: 3.7767 - val_neg_log_likelihood: 2322256025545827155968.0000\n",
      "Epoch 1330/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6685 - squared_difference_loss: 11.8880 - KL_divergence_loss: 3.7804 - neg_log_likelihood: 505180789940.0562 - val_loss: 15.4825 - val_squared_difference_loss: 11.7092 - val_KL_divergence_loss: 3.7733 - val_neg_log_likelihood: 2110283446389058568192.0000\n",
      "Epoch 1331/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6619 - squared_difference_loss: 11.8728 - KL_divergence_loss: 3.7891 - neg_log_likelihood: 159790253267.9910 - val_loss: 15.4991 - val_squared_difference_loss: 11.7370 - val_KL_divergence_loss: 3.7621 - val_neg_log_likelihood: 2966301931121730387968.0000\n",
      "Epoch 1332/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6528 - squared_difference_loss: 11.8576 - KL_divergence_loss: 3.7951 - neg_log_likelihood: 42596460469.2170 - val_loss: 15.4506 - val_squared_difference_loss: 11.6750 - val_KL_divergence_loss: 3.7756 - val_neg_log_likelihood: 3286900571985795874816.0000\n",
      "Epoch 1333/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.6580 - squared_difference_loss: 11.8824 - KL_divergence_loss: 3.7756 - neg_log_likelihood: 846951112015.4778 - val_loss: 15.4716 - val_squared_difference_loss: 11.7012 - val_KL_divergence_loss: 3.7704 - val_neg_log_likelihood: 8762773480663349723136.0000\n",
      "Epoch 1334/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6843 - squared_difference_loss: 11.8826 - KL_divergence_loss: 3.8016 - neg_log_likelihood: 37047722343.6097 - val_loss: 15.4758 - val_squared_difference_loss: 11.6710 - val_KL_divergence_loss: 3.8048 - val_neg_log_likelihood: 4266809000021672329216.0000\n",
      "Epoch 1335/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6494 - squared_difference_loss: 11.8567 - KL_divergence_loss: 3.7927 - neg_log_likelihood: 29928851753.0475 - val_loss: 15.4818 - val_squared_difference_loss: 11.7202 - val_KL_divergence_loss: 3.7615 - val_neg_log_likelihood: 8879426931698462359552.0000\n",
      "Epoch 1336/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.6515 - squared_difference_loss: 11.8698 - KL_divergence_loss: 3.7817 - neg_log_likelihood: 16866129814.6244 - val_loss: 15.5070 - val_squared_difference_loss: 11.7137 - val_KL_divergence_loss: 3.7933 - val_neg_log_likelihood: 27644807355969658945536.0000\n",
      "Epoch 1337/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6803 - squared_difference_loss: 11.8765 - KL_divergence_loss: 3.8038 - neg_log_likelihood: 105026624240.4014 - val_loss: 15.4641 - val_squared_difference_loss: 11.6974 - val_KL_divergence_loss: 3.7667 - val_neg_log_likelihood: 855438398610980077568.0000\n",
      "Epoch 1338/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.7016 - squared_difference_loss: 11.9259 - KL_divergence_loss: 3.7757 - neg_log_likelihood: 7958782945.7186 - val_loss: 15.4744 - val_squared_difference_loss: 11.6861 - val_KL_divergence_loss: 3.7883 - val_neg_log_likelihood: 1526295980642748858368.0000\n",
      "Epoch 1339/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.6777 - squared_difference_loss: 11.8723 - KL_divergence_loss: 3.8054 - neg_log_likelihood: 17634417552.3369 - val_loss: 15.4680 - val_squared_difference_loss: 11.6750 - val_KL_divergence_loss: 3.7930 - val_neg_log_likelihood: 856839207859096387584.0000\n",
      "Epoch 1340/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6773 - squared_difference_loss: 11.8897 - KL_divergence_loss: 3.7876 - neg_log_likelihood: 91225716288.8511 - val_loss: 15.4817 - val_squared_difference_loss: 11.7208 - val_KL_divergence_loss: 3.7608 - val_neg_log_likelihood: 2145410062421025095680.0000\n",
      "Epoch 1341/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6600 - squared_difference_loss: 11.8675 - KL_divergence_loss: 3.7925 - neg_log_likelihood: 23596138553.3653 - val_loss: 15.4799 - val_squared_difference_loss: 11.6909 - val_KL_divergence_loss: 3.7891 - val_neg_log_likelihood: 8455949687700526727168.0000\n",
      "Epoch 1342/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6815 - squared_difference_loss: 11.9071 - KL_divergence_loss: 3.7744 - neg_log_likelihood: 19341273946.0068 - val_loss: 15.4832 - val_squared_difference_loss: 11.7195 - val_KL_divergence_loss: 3.7637 - val_neg_log_likelihood: 961793162855122206720.0000\n",
      "Epoch 1343/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6776 - squared_difference_loss: 11.8727 - KL_divergence_loss: 3.8049 - neg_log_likelihood: 47428351315.3787 - val_loss: 15.4820 - val_squared_difference_loss: 11.6965 - val_KL_divergence_loss: 3.7855 - val_neg_log_likelihood: 8487150477470396841984.0000\n",
      "Epoch 1344/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6762 - squared_difference_loss: 11.8826 - KL_divergence_loss: 3.7936 - neg_log_likelihood: 3362019409.3150 - val_loss: 15.5010 - val_squared_difference_loss: 11.7258 - val_KL_divergence_loss: 3.7752 - val_neg_log_likelihood: 828663043963984805888.0000\n",
      "Epoch 1345/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6859 - squared_difference_loss: 11.8967 - KL_divergence_loss: 3.7893 - neg_log_likelihood: 19139901560.0190 - val_loss: 15.5043 - val_squared_difference_loss: 11.7121 - val_KL_divergence_loss: 3.7922 - val_neg_log_likelihood: 1485345522140801925120.0000\n",
      "Epoch 1346/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6464 - squared_difference_loss: 11.8645 - KL_divergence_loss: 3.7818 - neg_log_likelihood: 19959489844.3943 - val_loss: 15.5150 - val_squared_difference_loss: 11.7403 - val_KL_divergence_loss: 3.7747 - val_neg_log_likelihood: 1082484789938695831552.0000\n",
      "Epoch 1347/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6862 - squared_difference_loss: 11.8952 - KL_divergence_loss: 3.7910 - neg_log_likelihood: 3338088914.0489 - val_loss: 15.4559 - val_squared_difference_loss: 11.6579 - val_KL_divergence_loss: 3.7980 - val_neg_log_likelihood: 348709104270320992256.0000\n",
      "Epoch 1348/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.6695 - squared_difference_loss: 11.8744 - KL_divergence_loss: 3.7951 - neg_log_likelihood: 17709339791.8847 - val_loss: 15.5005 - val_squared_difference_loss: 11.7168 - val_KL_divergence_loss: 3.7837 - val_neg_log_likelihood: 3014978873951089852416.0000\n",
      "Epoch 1349/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6639 - squared_difference_loss: 11.8644 - KL_divergence_loss: 3.7995 - neg_log_likelihood: 93966011174.6968 - val_loss: 15.4885 - val_squared_difference_loss: 11.7130 - val_KL_divergence_loss: 3.7755 - val_neg_log_likelihood: 781697607874739437568.0000\n",
      "Epoch 1350/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6506 - squared_difference_loss: 11.8524 - KL_divergence_loss: 3.7982 - neg_log_likelihood: 43953660735.4602 - val_loss: 15.4430 - val_squared_difference_loss: 11.6533 - val_KL_divergence_loss: 3.7896 - val_neg_log_likelihood: 711894261839539601408.0000\n",
      "Epoch 1351/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6403 - squared_difference_loss: 11.8486 - KL_divergence_loss: 3.7916 - neg_log_likelihood: 157913818290.8946 - val_loss: 15.4960 - val_squared_difference_loss: 11.6967 - val_KL_divergence_loss: 3.7992 - val_neg_log_likelihood: 909122466620935503872.0000\n",
      "Epoch 1352/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6429 - squared_difference_loss: 11.8565 - KL_divergence_loss: 3.7865 - neg_log_likelihood: 72797403190.3181 - val_loss: 15.4969 - val_squared_difference_loss: 11.7346 - val_KL_divergence_loss: 3.7623 - val_neg_log_likelihood: 1735236010781470621696.0000\n",
      "Epoch 1353/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6382 - squared_difference_loss: 11.8470 - KL_divergence_loss: 3.7912 - neg_log_likelihood: 33823738821.3474 - val_loss: 15.4954 - val_squared_difference_loss: 11.7158 - val_KL_divergence_loss: 3.7796 - val_neg_log_likelihood: 611148743259124662272.0000\n",
      "Epoch 1354/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6292 - squared_difference_loss: 11.8464 - KL_divergence_loss: 3.7828 - neg_log_likelihood: 17611924394.8422 - val_loss: 15.4641 - val_squared_difference_loss: 11.6729 - val_KL_divergence_loss: 3.7912 - val_neg_log_likelihood: 1870737490942928355328.0000\n",
      "Epoch 1355/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6495 - squared_difference_loss: 11.8535 - KL_divergence_loss: 3.7959 - neg_log_likelihood: 64433952604.2819 - val_loss: 15.4854 - val_squared_difference_loss: 11.7078 - val_KL_divergence_loss: 3.7776 - val_neg_log_likelihood: 9842346172442581401600.0000\n",
      "Epoch 1356/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.6426 - squared_difference_loss: 11.8569 - KL_divergence_loss: 3.7857 - neg_log_likelihood: 190742741723.2766 - val_loss: 15.4535 - val_squared_difference_loss: 11.6789 - val_KL_divergence_loss: 3.7746 - val_neg_log_likelihood: 1565787140075307925504.0000\n",
      "Epoch 1357/2000\n",
      "29507/29507 [==============================] - 1s 21us/step - loss: 15.6667 - squared_difference_loss: 11.8720 - KL_divergence_loss: 3.7947 - neg_log_likelihood: 301545925625.5753 - val_loss: 15.4869 - val_squared_difference_loss: 11.7055 - val_KL_divergence_loss: 3.7814 - val_neg_log_likelihood: 15104350267353155502080.0000\n",
      "Epoch 1358/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6364 - squared_difference_loss: 11.8575 - KL_divergence_loss: 3.7789 - neg_log_likelihood: 11180146573.7967 - val_loss: 15.4764 - val_squared_difference_loss: 11.7236 - val_KL_divergence_loss: 3.7528 - val_neg_log_likelihood: 1084518834582313369600.0000\n",
      "Epoch 1359/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6212 - squared_difference_loss: 11.8399 - KL_divergence_loss: 3.7813 - neg_log_likelihood: 19361566539.8081 - val_loss: 15.4956 - val_squared_difference_loss: 11.7203 - val_KL_divergence_loss: 3.7752 - val_neg_log_likelihood: 4279705524335486173184.0000\n",
      "Epoch 1360/2000\n",
      "29507/29507 [==============================] - 1s 19us/step - loss: 15.6682 - squared_difference_loss: 11.8903 - KL_divergence_loss: 3.7779 - neg_log_likelihood: 49221551154.7150 - val_loss: 15.4348 - val_squared_difference_loss: 11.6695 - val_KL_divergence_loss: 3.7653 - val_neg_log_likelihood: 3375015081605833162752.0000\n",
      "Epoch 1361/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6429 - squared_difference_loss: 11.8658 - KL_divergence_loss: 3.7771 - neg_log_likelihood: 3334896699.3321 - val_loss: 15.4733 - val_squared_difference_loss: 11.7116 - val_KL_divergence_loss: 3.7618 - val_neg_log_likelihood: 793538474299532509184.0000\n",
      "Epoch 1362/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6543 - squared_difference_loss: 11.8754 - KL_divergence_loss: 3.7790 - neg_log_likelihood: 37252322684.2086 - val_loss: 15.4796 - val_squared_difference_loss: 11.7200 - val_KL_divergence_loss: 3.7595 - val_neg_log_likelihood: 1505486551261673422848.0000\n",
      "Epoch 1363/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.6418 - squared_difference_loss: 11.8667 - KL_divergence_loss: 3.7752 - neg_log_likelihood: 4232644690.6232 - val_loss: 15.4686 - val_squared_difference_loss: 11.6686 - val_KL_divergence_loss: 3.8001 - val_neg_log_likelihood: 1591323621757151608832.0000\n",
      "Epoch 1364/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6425 - squared_difference_loss: 11.8491 - KL_divergence_loss: 3.7934 - neg_log_likelihood: 297602735628.4341 - val_loss: 15.4876 - val_squared_difference_loss: 11.7185 - val_KL_divergence_loss: 3.7690 - val_neg_log_likelihood: 789505015985085218816.0000\n",
      "Epoch 1365/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6799 - squared_difference_loss: 11.8923 - KL_divergence_loss: 3.7876 - neg_log_likelihood: 15520439288.8117 - val_loss: 15.4594 - val_squared_difference_loss: 11.6692 - val_KL_divergence_loss: 3.7902 - val_neg_log_likelihood: 5498258794142188437504.0000\n",
      "Epoch 1366/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.6677 - squared_difference_loss: 11.8830 - KL_divergence_loss: 3.7847 - neg_log_likelihood: 48560812182.5387 - val_loss: 15.4537 - val_squared_difference_loss: 11.6838 - val_KL_divergence_loss: 3.7700 - val_neg_log_likelihood: 2462040500979054936064.0000\n",
      "Epoch 1367/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6245 - squared_difference_loss: 11.8342 - KL_divergence_loss: 3.7902 - neg_log_likelihood: 498804826441.7256 - val_loss: 15.4532 - val_squared_difference_loss: 11.6981 - val_KL_divergence_loss: 3.7551 - val_neg_log_likelihood: 2642161873334238183424.0000\n",
      "Epoch 1368/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6688 - squared_difference_loss: 11.8710 - KL_divergence_loss: 3.7978 - neg_log_likelihood: 36933904404.1406 - val_loss: 15.4938 - val_squared_difference_loss: 11.6848 - val_KL_divergence_loss: 3.8090 - val_neg_log_likelihood: 1087833504582569689088.0000\n",
      "Epoch 1369/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.6359 - squared_difference_loss: 11.8469 - KL_divergence_loss: 3.7890 - neg_log_likelihood: 31653696934.1842 - val_loss: 15.4615 - val_squared_difference_loss: 11.6870 - val_KL_divergence_loss: 3.7745 - val_neg_log_likelihood: 2098291948127698550784.0000\n",
      "Epoch 1370/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6715 - squared_difference_loss: 11.8795 - KL_divergence_loss: 3.7920 - neg_log_likelihood: 23338268538.6378 - val_loss: 15.4852 - val_squared_difference_loss: 11.6802 - val_KL_divergence_loss: 3.8050 - val_neg_log_likelihood: 3895378651965687857152.0000\n",
      "Epoch 1371/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6292 - squared_difference_loss: 11.8331 - KL_divergence_loss: 3.7961 - neg_log_likelihood: 22127502749.1371 - val_loss: 15.4880 - val_squared_difference_loss: 11.6965 - val_KL_divergence_loss: 3.7915 - val_neg_log_likelihood: 1105569699669799337984.0000\n",
      "Epoch 1372/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6529 - squared_difference_loss: 11.8500 - KL_divergence_loss: 3.8029 - neg_log_likelihood: 32591776192.5478 - val_loss: 15.4964 - val_squared_difference_loss: 11.7061 - val_KL_divergence_loss: 3.7903 - val_neg_log_likelihood: 555151804095997411328.0000\n",
      "Epoch 1373/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6661 - squared_difference_loss: 11.8618 - KL_divergence_loss: 3.8043 - neg_log_likelihood: 3085748098.4574 - val_loss: 15.4770 - val_squared_difference_loss: 11.6840 - val_KL_divergence_loss: 3.7930 - val_neg_log_likelihood: 1039373693720848891904.0000\n",
      "Epoch 1374/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6127 - squared_difference_loss: 11.8315 - KL_divergence_loss: 3.7812 - neg_log_likelihood: 1572098161.7658 - val_loss: 15.4969 - val_squared_difference_loss: 11.7463 - val_KL_divergence_loss: 3.7506 - val_neg_log_likelihood: 484537038712125063168.0000\n",
      "Epoch 1375/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6312 - squared_difference_loss: 11.8547 - KL_divergence_loss: 3.7765 - neg_log_likelihood: 3642689059467.2300 - val_loss: 15.4624 - val_squared_difference_loss: 11.6839 - val_KL_divergence_loss: 3.7785 - val_neg_log_likelihood: 2118194924645020860416.0000\n",
      "Epoch 1376/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6233 - squared_difference_loss: 11.8391 - KL_divergence_loss: 3.7842 - neg_log_likelihood: 13301212275.8019 - val_loss: 15.4447 - val_squared_difference_loss: 11.6626 - val_KL_divergence_loss: 3.7821 - val_neg_log_likelihood: 5785015627682718679040.0000\n",
      "Epoch 1377/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6536 - squared_difference_loss: 11.8563 - KL_divergence_loss: 3.7973 - neg_log_likelihood: 501464412817.3478 - val_loss: 15.4796 - val_squared_difference_loss: 11.7017 - val_KL_divergence_loss: 3.7780 - val_neg_log_likelihood: 548204822233874628608.0000\n",
      "Epoch 1378/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6263 - squared_difference_loss: 11.8442 - KL_divergence_loss: 3.7821 - neg_log_likelihood: 8914521688.0494 - val_loss: 15.4767 - val_squared_difference_loss: 11.7234 - val_KL_divergence_loss: 3.7533 - val_neg_log_likelihood: 2474844618406872743936.0000\n",
      "Epoch 1379/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.6493 - squared_difference_loss: 11.8761 - KL_divergence_loss: 3.7733 - neg_log_likelihood: 54291359135.9562 - val_loss: 15.4783 - val_squared_difference_loss: 11.6970 - val_KL_divergence_loss: 3.7813 - val_neg_log_likelihood: 1556450370045738745856.0000\n",
      "Epoch 1380/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6541 - squared_difference_loss: 11.8748 - KL_divergence_loss: 3.7792 - neg_log_likelihood: 15684225945.9731 - val_loss: 15.4460 - val_squared_difference_loss: 11.6905 - val_KL_divergence_loss: 3.7555 - val_neg_log_likelihood: 4375626107015455571968.0000\n",
      "Epoch 1381/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6111 - squared_difference_loss: 11.8317 - KL_divergence_loss: 3.7794 - neg_log_likelihood: 278445618196.2684 - val_loss: 15.4735 - val_squared_difference_loss: 11.6881 - val_KL_divergence_loss: 3.7854 - val_neg_log_likelihood: 1919190624533065498624.0000\n",
      "Epoch 1382/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 15.6275 - squared_difference_loss: 11.8403 - KL_divergence_loss: 3.7872 - neg_log_likelihood: 7841065626.8853 - val_loss: 15.4619 - val_squared_difference_loss: 11.6861 - val_KL_divergence_loss: 3.7758 - val_neg_log_likelihood: 653042733451312889856.0000\n",
      "Epoch 1383/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6640 - squared_difference_loss: 11.8676 - KL_divergence_loss: 3.7965 - neg_log_likelihood: 27475925213.9130 - val_loss: 15.4448 - val_squared_difference_loss: 11.6741 - val_KL_divergence_loss: 3.7708 - val_neg_log_likelihood: 1453792282055068614656.0000\n",
      "Epoch 1384/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.6280 - squared_difference_loss: 11.8472 - KL_divergence_loss: 3.7808 - neg_log_likelihood: 44791988756.4532 - val_loss: 15.4570 - val_squared_difference_loss: 11.6912 - val_KL_divergence_loss: 3.7658 - val_neg_log_likelihood: 556031326811620048896.0000\n",
      "Epoch 1385/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6360 - squared_difference_loss: 11.8483 - KL_divergence_loss: 3.7877 - neg_log_likelihood: 63092716644.3089 - val_loss: 15.4994 - val_squared_difference_loss: 11.7284 - val_KL_divergence_loss: 3.7710 - val_neg_log_likelihood: 1316224709016677253120.0000\n",
      "Epoch 1386/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6400 - squared_difference_loss: 11.8572 - KL_divergence_loss: 3.7828 - neg_log_likelihood: 39247096043.1550 - val_loss: 15.4492 - val_squared_difference_loss: 11.6840 - val_KL_divergence_loss: 3.7653 - val_neg_log_likelihood: 2956035382927875899392.0000\n",
      "Epoch 1387/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6354 - squared_difference_loss: 11.8418 - KL_divergence_loss: 3.7936 - neg_log_likelihood: 73183165965.6833 - val_loss: 15.4387 - val_squared_difference_loss: 11.6288 - val_KL_divergence_loss: 3.8099 - val_neg_log_likelihood: 5338961628956008120320.0000\n",
      "Epoch 1388/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6480 - squared_difference_loss: 11.8582 - KL_divergence_loss: 3.7898 - neg_log_likelihood: 14572323132.6000 - val_loss: 15.4402 - val_squared_difference_loss: 11.6542 - val_KL_divergence_loss: 3.7860 - val_neg_log_likelihood: 2219084529573905301504.0000\n",
      "Epoch 1389/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.6219 - squared_difference_loss: 11.8453 - KL_divergence_loss: 3.7766 - neg_log_likelihood: 7735625772.2394 - val_loss: 15.4308 - val_squared_difference_loss: 11.6658 - val_KL_divergence_loss: 3.7650 - val_neg_log_likelihood: 2350483912588995067904.0000\n",
      "Epoch 1390/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6550 - squared_difference_loss: 11.8598 - KL_divergence_loss: 3.7952 - neg_log_likelihood: 15376032405.5574 - val_loss: 15.4615 - val_squared_difference_loss: 11.6879 - val_KL_divergence_loss: 3.7737 - val_neg_log_likelihood: 1651645220852343767040.0000\n",
      "Epoch 1391/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6381 - squared_difference_loss: 11.8466 - KL_divergence_loss: 3.7915 - neg_log_likelihood: 209649034014.9302 - val_loss: 15.4485 - val_squared_difference_loss: 11.6580 - val_KL_divergence_loss: 3.7906 - val_neg_log_likelihood: 2530263785108312424448.0000\n",
      "Epoch 1392/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6374 - squared_difference_loss: 11.8485 - KL_divergence_loss: 3.7889 - neg_log_likelihood: 8686054591.9214 - val_loss: 15.4962 - val_squared_difference_loss: 11.7120 - val_KL_divergence_loss: 3.7842 - val_neg_log_likelihood: 1153496606717106454528.0000\n",
      "Epoch 1393/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6259 - squared_difference_loss: 11.8249 - KL_divergence_loss: 3.8010 - neg_log_likelihood: 15965178569.7419 - val_loss: 15.4548 - val_squared_difference_loss: 11.6902 - val_KL_divergence_loss: 3.7646 - val_neg_log_likelihood: 1013776941769722560512.0000\n",
      "Epoch 1394/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6314 - squared_difference_loss: 11.8584 - KL_divergence_loss: 3.7731 - neg_log_likelihood: 13733695185.3707 - val_loss: 15.4917 - val_squared_difference_loss: 11.7284 - val_KL_divergence_loss: 3.7633 - val_neg_log_likelihood: 541078633707283611648.0000\n",
      "Epoch 1395/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6368 - squared_difference_loss: 11.8343 - KL_divergence_loss: 3.8024 - neg_log_likelihood: 269037733227.5154 - val_loss: 15.4416 - val_squared_difference_loss: 11.6615 - val_KL_divergence_loss: 3.7801 - val_neg_log_likelihood: 857207059122674597888.0000\n",
      "Epoch 1396/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6165 - squared_difference_loss: 11.8175 - KL_divergence_loss: 3.7990 - neg_log_likelihood: 658961724494.7738 - val_loss: 15.4834 - val_squared_difference_loss: 11.7166 - val_KL_divergence_loss: 3.7668 - val_neg_log_likelihood: 1967175130896534339584.0000\n",
      "Epoch 1397/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6218 - squared_difference_loss: 11.8320 - KL_divergence_loss: 3.7899 - neg_log_likelihood: 26082399512.3834 - val_loss: 15.4710 - val_squared_difference_loss: 11.7020 - val_KL_divergence_loss: 3.7691 - val_neg_log_likelihood: 700822081369518899200.0000\n",
      "Epoch 1398/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6198 - squared_difference_loss: 11.8241 - KL_divergence_loss: 3.7957 - neg_log_likelihood: 30243106345.0970 - val_loss: 15.3996 - val_squared_difference_loss: 11.6328 - val_KL_divergence_loss: 3.7667 - val_neg_log_likelihood: 529882130031271739392.0000\n",
      "Epoch 1399/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6250 - squared_difference_loss: 11.8509 - KL_divergence_loss: 3.7741 - neg_log_likelihood: 83443515630.2717 - val_loss: 15.4763 - val_squared_difference_loss: 11.6936 - val_KL_divergence_loss: 3.7827 - val_neg_log_likelihood: 3595974562599740112896.0000\n",
      "Epoch 1400/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6193 - squared_difference_loss: 11.8298 - KL_divergence_loss: 3.7895 - neg_log_likelihood: 16755640260.8896 - val_loss: 15.4349 - val_squared_difference_loss: 11.6476 - val_KL_divergence_loss: 3.7873 - val_neg_log_likelihood: 2373298186044583182336.0000\n",
      "Epoch 1401/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6289 - squared_difference_loss: 11.8289 - KL_divergence_loss: 3.8000 - neg_log_likelihood: 74105304346.6364 - val_loss: 15.4505 - val_squared_difference_loss: 11.6635 - val_KL_divergence_loss: 3.7870 - val_neg_log_likelihood: 2321461387568882909184.0000\n",
      "Epoch 1402/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6430 - squared_difference_loss: 11.8682 - KL_divergence_loss: 3.7748 - neg_log_likelihood: 12237228077.9688 - val_loss: 15.4733 - val_squared_difference_loss: 11.6764 - val_KL_divergence_loss: 3.7970 - val_neg_log_likelihood: 946470348014657994752.0000\n",
      "Epoch 1403/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6124 - squared_difference_loss: 11.8167 - KL_divergence_loss: 3.7957 - neg_log_likelihood: 44014559797.5034 - val_loss: 15.4549 - val_squared_difference_loss: 11.6752 - val_KL_divergence_loss: 3.7798 - val_neg_log_likelihood: 1137890335970225160192.0000\n",
      "Epoch 1404/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6266 - squared_difference_loss: 11.8362 - KL_divergence_loss: 3.7904 - neg_log_likelihood: 93248180439.6838 - val_loss: 15.4147 - val_squared_difference_loss: 11.6307 - val_KL_divergence_loss: 3.7840 - val_neg_log_likelihood: 406732120415675416576.0000\n",
      "Epoch 1405/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6491 - squared_difference_loss: 11.8530 - KL_divergence_loss: 3.7961 - neg_log_likelihood: 5781376737.6741 - val_loss: 15.4477 - val_squared_difference_loss: 11.6445 - val_KL_divergence_loss: 3.8031 - val_neg_log_likelihood: 1413545210451677675520.0000\n",
      "Epoch 1406/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6455 - squared_difference_loss: 11.8485 - KL_divergence_loss: 3.7971 - neg_log_likelihood: 53240200593.2229 - val_loss: 15.4455 - val_squared_difference_loss: 11.6478 - val_KL_divergence_loss: 3.7978 - val_neg_log_likelihood: 1405091569205393227776.0000\n",
      "Epoch 1407/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.6459 - squared_difference_loss: 11.8323 - KL_divergence_loss: 3.8136 - neg_log_likelihood: 7849675839.0953 - val_loss: 15.4822 - val_squared_difference_loss: 11.6647 - val_KL_divergence_loss: 3.8175 - val_neg_log_likelihood: 890232417872218030080.0000\n",
      "Epoch 1408/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6123 - squared_difference_loss: 11.8181 - KL_divergence_loss: 3.7942 - neg_log_likelihood: 59112933108.4098 - val_loss: 15.4321 - val_squared_difference_loss: 11.6367 - val_KL_divergence_loss: 3.7953 - val_neg_log_likelihood: 3855362956509288857600.0000\n",
      "Epoch 1409/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.6211 - squared_difference_loss: 11.8377 - KL_divergence_loss: 3.7834 - neg_log_likelihood: 110760801846.9787 - val_loss: 15.4201 - val_squared_difference_loss: 11.6458 - val_KL_divergence_loss: 3.7744 - val_neg_log_likelihood: 1063163681662099914752.0000\n",
      "Epoch 1410/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6563 - squared_difference_loss: 11.8511 - KL_divergence_loss: 3.8052 - neg_log_likelihood: 2042875752.4283 - val_loss: 15.4390 - val_squared_difference_loss: 11.6502 - val_KL_divergence_loss: 3.7887 - val_neg_log_likelihood: 8397804217497800409088.0000\n",
      "Epoch 1411/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6558 - squared_difference_loss: 11.8390 - KL_divergence_loss: 3.8168 - neg_log_likelihood: 281999739713.7570 - val_loss: 15.4599 - val_squared_difference_loss: 11.6484 - val_KL_divergence_loss: 3.8115 - val_neg_log_likelihood: 2974715688887597400064.0000\n",
      "Epoch 1412/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6248 - squared_difference_loss: 11.8240 - KL_divergence_loss: 3.8007 - neg_log_likelihood: 6807341444.3262 - val_loss: 15.3997 - val_squared_difference_loss: 11.6202 - val_KL_divergence_loss: 3.7795 - val_neg_log_likelihood: 2436956444578351677440.0000\n",
      "Epoch 1413/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6374 - squared_difference_loss: 11.8429 - KL_divergence_loss: 3.7945 - neg_log_likelihood: 70612524170.9533 - val_loss: 15.4500 - val_squared_difference_loss: 11.6687 - val_KL_divergence_loss: 3.7813 - val_neg_log_likelihood: 3037993987966165319680.0000\n",
      "Epoch 1414/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6139 - squared_difference_loss: 11.8328 - KL_divergence_loss: 3.7810 - neg_log_likelihood: 62416279620.6783 - val_loss: 15.4516 - val_squared_difference_loss: 11.6761 - val_KL_divergence_loss: 3.7755 - val_neg_log_likelihood: 3557730466098107121664.0000\n",
      "Epoch 1415/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6202 - squared_difference_loss: 11.8190 - KL_divergence_loss: 3.8012 - neg_log_likelihood: 12288171540.2099 - val_loss: 15.4366 - val_squared_difference_loss: 11.6494 - val_KL_divergence_loss: 3.7872 - val_neg_log_likelihood: 620695122606516994048.0000\n",
      "Epoch 1416/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6366 - squared_difference_loss: 11.8331 - KL_divergence_loss: 3.8035 - neg_log_likelihood: 10149707020.3298 - val_loss: 15.4181 - val_squared_difference_loss: 11.6594 - val_KL_divergence_loss: 3.7587 - val_neg_log_likelihood: 551957896093515055104.0000\n",
      "Epoch 1417/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6030 - squared_difference_loss: 11.8237 - KL_divergence_loss: 3.7794 - neg_log_likelihood: 185460352298.8980 - val_loss: 15.4151 - val_squared_difference_loss: 11.6373 - val_KL_divergence_loss: 3.7779 - val_neg_log_likelihood: 1098843055322632421376.0000\n",
      "Epoch 1418/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5967 - squared_difference_loss: 11.8154 - KL_divergence_loss: 3.7814 - neg_log_likelihood: 7212036802.1927 - val_loss: 15.4495 - val_squared_difference_loss: 11.6653 - val_KL_divergence_loss: 3.7842 - val_neg_log_likelihood: 1460748076586126278656.0000\n",
      "Epoch 1419/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6172 - squared_difference_loss: 11.8298 - KL_divergence_loss: 3.7874 - neg_log_likelihood: 9135010242.3538 - val_loss: 15.4044 - val_squared_difference_loss: 11.6188 - val_KL_divergence_loss: 3.7856 - val_neg_log_likelihood: 133710240023989092352.0000\n",
      "Epoch 1420/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6340 - squared_difference_loss: 11.8405 - KL_divergence_loss: 3.7936 - neg_log_likelihood: 1224376129.0149 - val_loss: 15.4440 - val_squared_difference_loss: 11.6627 - val_KL_divergence_loss: 3.7813 - val_neg_log_likelihood: 448866701015168122880.0000\n",
      "Epoch 1421/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6423 - squared_difference_loss: 11.8504 - KL_divergence_loss: 3.7920 - neg_log_likelihood: 32802096786.5299 - val_loss: 15.4288 - val_squared_difference_loss: 11.6478 - val_KL_divergence_loss: 3.7810 - val_neg_log_likelihood: 1822208506730573463552.0000\n",
      "Epoch 1422/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6128 - squared_difference_loss: 11.8105 - KL_divergence_loss: 3.8023 - neg_log_likelihood: 1501832130.7427 - val_loss: 15.4106 - val_squared_difference_loss: 11.6371 - val_KL_divergence_loss: 3.7735 - val_neg_log_likelihood: 1709279687019246649344.0000\n",
      "Epoch 1423/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6252 - squared_difference_loss: 11.8287 - KL_divergence_loss: 3.7964 - neg_log_likelihood: 20865547841.8133 - val_loss: 15.4669 - val_squared_difference_loss: 11.6940 - val_KL_divergence_loss: 3.7729 - val_neg_log_likelihood: 3563500002017093877760.0000\n",
      "Epoch 1424/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6298 - squared_difference_loss: 11.8273 - KL_divergence_loss: 3.8026 - neg_log_likelihood: 1043885401.3181 - val_loss: 15.4587 - val_squared_difference_loss: 11.7003 - val_KL_divergence_loss: 3.7584 - val_neg_log_likelihood: 1752074923137445396480.0000\n",
      "Epoch 1425/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6138 - squared_difference_loss: 11.8209 - KL_divergence_loss: 3.7929 - neg_log_likelihood: 22230558990.8097 - val_loss: 15.4177 - val_squared_difference_loss: 11.6268 - val_KL_divergence_loss: 3.7908 - val_neg_log_likelihood: 8368402444953048842240.0000\n",
      "Epoch 1426/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6076 - squared_difference_loss: 11.8173 - KL_divergence_loss: 3.7903 - neg_log_likelihood: 22265726228.7616 - val_loss: 15.4176 - val_squared_difference_loss: 11.6571 - val_KL_divergence_loss: 3.7605 - val_neg_log_likelihood: 1121063442641483726848.0000\n",
      "Epoch 1427/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6052 - squared_difference_loss: 11.8191 - KL_divergence_loss: 3.7861 - neg_log_likelihood: 6741105079.9151 - val_loss: 15.4458 - val_squared_difference_loss: 11.6718 - val_KL_divergence_loss: 3.7740 - val_neg_log_likelihood: 2730101359246515896320.0000\n",
      "Epoch 1428/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5962 - squared_difference_loss: 11.7924 - KL_divergence_loss: 3.8038 - neg_log_likelihood: 45188715299.1508 - val_loss: 15.4117 - val_squared_difference_loss: 11.6206 - val_KL_divergence_loss: 3.7910 - val_neg_log_likelihood: 780675599811252584448.0000\n",
      "Epoch 1429/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 15.6161 - squared_difference_loss: 11.8232 - KL_divergence_loss: 3.7929 - neg_log_likelihood: 35705671874.7848 - val_loss: 15.4198 - val_squared_difference_loss: 11.6369 - val_KL_divergence_loss: 3.7829 - val_neg_log_likelihood: 1703607366427348828160.0000\n",
      "Epoch 1430/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5987 - squared_difference_loss: 11.8044 - KL_divergence_loss: 3.7943 - neg_log_likelihood: 69929721964.0357 - val_loss: 15.4303 - val_squared_difference_loss: 11.6200 - val_KL_divergence_loss: 3.8103 - val_neg_log_likelihood: 1650302900933125210112.0000\n",
      "Epoch 1431/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6372 - squared_difference_loss: 11.8360 - KL_divergence_loss: 3.8012 - neg_log_likelihood: 296478484.1815 - val_loss: 15.4044 - val_squared_difference_loss: 11.6138 - val_KL_divergence_loss: 3.7905 - val_neg_log_likelihood: 1071586965683368230912.0000\n",
      "Epoch 1432/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.6114 - squared_difference_loss: 11.8189 - KL_divergence_loss: 3.7925 - neg_log_likelihood: 14546824346.8460 - val_loss: 15.4661 - val_squared_difference_loss: 11.6881 - val_KL_divergence_loss: 3.7780 - val_neg_log_likelihood: 1049403879607577346048.0000\n",
      "Epoch 1433/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6178 - squared_difference_loss: 11.8214 - KL_divergence_loss: 3.7964 - neg_log_likelihood: 67926711044.5696 - val_loss: 15.4374 - val_squared_difference_loss: 11.6389 - val_KL_divergence_loss: 3.7985 - val_neg_log_likelihood: 263147543967463931904.0000\n",
      "Epoch 1434/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5944 - squared_difference_loss: 11.7976 - KL_divergence_loss: 3.7969 - neg_log_likelihood: 15288741210.3478 - val_loss: 15.4207 - val_squared_difference_loss: 11.6195 - val_KL_divergence_loss: 3.8012 - val_neg_log_likelihood: 1677843692459740102656.0000\n",
      "Epoch 1435/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6181 - squared_difference_loss: 11.8119 - KL_divergence_loss: 3.8062 - neg_log_likelihood: 12192587468.3697 - val_loss: 15.4640 - val_squared_difference_loss: 11.6968 - val_KL_divergence_loss: 3.7671 - val_neg_log_likelihood: 439248923453315416064.0000\n",
      "Epoch 1436/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6156 - squared_difference_loss: 11.8235 - KL_divergence_loss: 3.7921 - neg_log_likelihood: 168039448389.9610 - val_loss: 15.4088 - val_squared_difference_loss: 11.6162 - val_KL_divergence_loss: 3.7926 - val_neg_log_likelihood: 2690699402809365233664.0000\n",
      "Epoch 1437/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6362 - squared_difference_loss: 11.8399 - KL_divergence_loss: 3.7963 - neg_log_likelihood: 28687749968.1578 - val_loss: 15.4507 - val_squared_difference_loss: 11.6785 - val_KL_divergence_loss: 3.7722 - val_neg_log_likelihood: 849740705575909588992.0000\n",
      "Epoch 1438/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6163 - squared_difference_loss: 11.8112 - KL_divergence_loss: 3.8050 - neg_log_likelihood: 7986862944.5664 - val_loss: 15.4705 - val_squared_difference_loss: 11.6822 - val_KL_divergence_loss: 3.7884 - val_neg_log_likelihood: 3815630717089618067456.0000\n",
      "Epoch 1439/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5995 - squared_difference_loss: 11.8115 - KL_divergence_loss: 3.7880 - neg_log_likelihood: 17481641664.5056 - val_loss: 15.4184 - val_squared_difference_loss: 11.6164 - val_KL_divergence_loss: 3.8021 - val_neg_log_likelihood: 3464933594453155250176.0000\n",
      "Epoch 1440/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.6308 - squared_difference_loss: 11.8197 - KL_divergence_loss: 3.8111 - neg_log_likelihood: 3032687167.6716 - val_loss: 15.4431 - val_squared_difference_loss: 11.6234 - val_KL_divergence_loss: 3.8197 - val_neg_log_likelihood: 849048090601080487936.0000\n",
      "Epoch 1441/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6074 - squared_difference_loss: 11.8090 - KL_divergence_loss: 3.7984 - neg_log_likelihood: 80611096037.0007 - val_loss: 15.4318 - val_squared_difference_loss: 11.6350 - val_KL_divergence_loss: 3.7968 - val_neg_log_likelihood: 6582593257792295927808.0000\n",
      "Epoch 1442/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6066 - squared_difference_loss: 11.8055 - KL_divergence_loss: 3.8011 - neg_log_likelihood: 16589363350.8089 - val_loss: 15.4365 - val_squared_difference_loss: 11.6222 - val_KL_divergence_loss: 3.8143 - val_neg_log_likelihood: 532362590675601915904.0000\n",
      "Epoch 1443/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5895 - squared_difference_loss: 11.7843 - KL_divergence_loss: 3.8052 - neg_log_likelihood: 10944907589.1474 - val_loss: 15.4134 - val_squared_difference_loss: 11.6294 - val_KL_divergence_loss: 3.7839 - val_neg_log_likelihood: 3116023738786382872576.0000\n",
      "Epoch 1444/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6088 - squared_difference_loss: 11.8195 - KL_divergence_loss: 3.7893 - neg_log_likelihood: 34061313505.3470 - val_loss: 15.4429 - val_squared_difference_loss: 11.6307 - val_KL_divergence_loss: 3.8122 - val_neg_log_likelihood: 1049307377431931912192.0000\n",
      "Epoch 1445/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6140 - squared_difference_loss: 11.8158 - KL_divergence_loss: 3.7982 - neg_log_likelihood: 2526609271.3842 - val_loss: 15.4198 - val_squared_difference_loss: 11.6270 - val_KL_divergence_loss: 3.7928 - val_neg_log_likelihood: 1349869236649117351936.0000\n",
      "Epoch 1446/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6240 - squared_difference_loss: 11.8224 - KL_divergence_loss: 3.8016 - neg_log_likelihood: 457285995.0420 - val_loss: 15.4334 - val_squared_difference_loss: 11.6175 - val_KL_divergence_loss: 3.8159 - val_neg_log_likelihood: 2289824374696707358720.0000\n",
      "Epoch 1447/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6175 - squared_difference_loss: 11.8066 - KL_divergence_loss: 3.8108 - neg_log_likelihood: 2445613884.0162 - val_loss: 15.4124 - val_squared_difference_loss: 11.5799 - val_KL_divergence_loss: 3.8325 - val_neg_log_likelihood: 5256437181456726360064.0000\n",
      "Epoch 1448/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6392 - squared_difference_loss: 11.8431 - KL_divergence_loss: 3.7961 - neg_log_likelihood: 207951199.3245 - val_loss: 15.4094 - val_squared_difference_loss: 11.6135 - val_KL_divergence_loss: 3.7960 - val_neg_log_likelihood: 1167753257815656890368.0000\n",
      "Epoch 1449/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5766 - squared_difference_loss: 11.7925 - KL_divergence_loss: 3.7841 - neg_log_likelihood: 157606376228.2055 - val_loss: 15.3807 - val_squared_difference_loss: 11.6159 - val_KL_divergence_loss: 3.7647 - val_neg_log_likelihood: 1583338074178127659008.0000\n",
      "Epoch 1450/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6060 - squared_difference_loss: 11.8103 - KL_divergence_loss: 3.7958 - neg_log_likelihood: 730243591.1465 - val_loss: 15.4425 - val_squared_difference_loss: 11.6476 - val_KL_divergence_loss: 3.7949 - val_neg_log_likelihood: 7712262841398413230080.0000\n",
      "Epoch 1451/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6113 - squared_difference_loss: 11.7908 - KL_divergence_loss: 3.8206 - neg_log_likelihood: 329482339817.7413 - val_loss: 15.3892 - val_squared_difference_loss: 11.5637 - val_KL_divergence_loss: 3.8255 - val_neg_log_likelihood: 1746542193049641680896.0000\n",
      "Epoch 1452/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6216 - squared_difference_loss: 11.8257 - KL_divergence_loss: 3.7959 - neg_log_likelihood: 47533018506.1765 - val_loss: 15.4220 - val_squared_difference_loss: 11.6271 - val_KL_divergence_loss: 3.7950 - val_neg_log_likelihood: 918239434001714774016.0000\n",
      "Epoch 1453/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6303 - squared_difference_loss: 11.8269 - KL_divergence_loss: 3.8034 - neg_log_likelihood: 7929245760.6627 - val_loss: 15.4333 - val_squared_difference_loss: 11.6185 - val_KL_divergence_loss: 3.8148 - val_neg_log_likelihood: 1304889415197886775296.0000\n",
      "Epoch 1454/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6037 - squared_difference_loss: 11.8029 - KL_divergence_loss: 3.8008 - neg_log_likelihood: 10964275551.0061 - val_loss: 15.4430 - val_squared_difference_loss: 11.6424 - val_KL_divergence_loss: 3.8007 - val_neg_log_likelihood: 694577107186770247680.0000\n",
      "Epoch 1455/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 15.6119 - squared_difference_loss: 11.7910 - KL_divergence_loss: 3.8209 - neg_log_likelihood: 42455061086.5572 - val_loss: 15.4216 - val_squared_difference_loss: 11.5952 - val_KL_divergence_loss: 3.8264 - val_neg_log_likelihood: 1306054396995754262528.0000\n",
      "Epoch 1456/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6120 - squared_difference_loss: 11.8162 - KL_divergence_loss: 3.7958 - neg_log_likelihood: 21508848375.7215 - val_loss: 15.4473 - val_squared_difference_loss: 11.6633 - val_KL_divergence_loss: 3.7840 - val_neg_log_likelihood: 651867914195434864640.0000\n",
      "Epoch 1457/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6150 - squared_difference_loss: 11.8080 - KL_divergence_loss: 3.8070 - neg_log_likelihood: 1473318244.9221 - val_loss: 15.4151 - val_squared_difference_loss: 11.5974 - val_KL_divergence_loss: 3.8176 - val_neg_log_likelihood: 1456777737043426148352.0000\n",
      "Epoch 1458/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.6363 - squared_difference_loss: 11.8185 - KL_divergence_loss: 3.8178 - neg_log_likelihood: 2592573715.4703 - val_loss: 15.4086 - val_squared_difference_loss: 11.5866 - val_KL_divergence_loss: 3.8221 - val_neg_log_likelihood: 182427522461577019392.0000\n",
      "Epoch 1459/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6321 - squared_difference_loss: 11.8056 - KL_divergence_loss: 3.8264 - neg_log_likelihood: 212446988529.6392 - val_loss: 15.4132 - val_squared_difference_loss: 11.5944 - val_KL_divergence_loss: 3.8188 - val_neg_log_likelihood: 1456390656310991912960.0000\n",
      "Epoch 1460/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5955 - squared_difference_loss: 11.7927 - KL_divergence_loss: 3.8028 - neg_log_likelihood: 5177566460.6728 - val_loss: 15.4075 - val_squared_difference_loss: 11.6297 - val_KL_divergence_loss: 3.7778 - val_neg_log_likelihood: 609723229359701098496.0000\n",
      "Epoch 1461/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5806 - squared_difference_loss: 11.7903 - KL_divergence_loss: 3.7904 - neg_log_likelihood: 15538126597.2617 - val_loss: 15.4142 - val_squared_difference_loss: 11.6305 - val_KL_divergence_loss: 3.7837 - val_neg_log_likelihood: 1211429930055964295168.0000\n",
      "Epoch 1462/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6067 - squared_difference_loss: 11.8037 - KL_divergence_loss: 3.8030 - neg_log_likelihood: 4691830322.2887 - val_loss: 15.4192 - val_squared_difference_loss: 11.6379 - val_KL_divergence_loss: 3.7813 - val_neg_log_likelihood: 311652312541015048192.0000\n",
      "Epoch 1463/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5830 - squared_difference_loss: 11.7689 - KL_divergence_loss: 3.8141 - neg_log_likelihood: 11777604381.2421 - val_loss: 15.4080 - val_squared_difference_loss: 11.6228 - val_KL_divergence_loss: 3.7852 - val_neg_log_likelihood: 208227651838727290880.0000\n",
      "Epoch 1464/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6004 - squared_difference_loss: 11.8057 - KL_divergence_loss: 3.7947 - neg_log_likelihood: 2931753429.8913 - val_loss: 15.4095 - val_squared_difference_loss: 11.6308 - val_KL_divergence_loss: 3.7787 - val_neg_log_likelihood: 1092507676112860479488.0000\n",
      "Epoch 1465/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5984 - squared_difference_loss: 11.8035 - KL_divergence_loss: 3.7949 - neg_log_likelihood: 7532155112.7228 - val_loss: 15.4345 - val_squared_difference_loss: 11.6469 - val_KL_divergence_loss: 3.7876 - val_neg_log_likelihood: 259915044046217773056.0000\n",
      "Epoch 1466/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5966 - squared_difference_loss: 11.7999 - KL_divergence_loss: 3.7967 - neg_log_likelihood: 2639749885.3975 - val_loss: 15.3933 - val_squared_difference_loss: 11.6072 - val_KL_divergence_loss: 3.7860 - val_neg_log_likelihood: 137551248234298720256.0000\n",
      "Epoch 1467/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5733 - squared_difference_loss: 11.7724 - KL_divergence_loss: 3.8009 - neg_log_likelihood: 20381441854.8291 - val_loss: 15.4011 - val_squared_difference_loss: 11.6129 - val_KL_divergence_loss: 3.7882 - val_neg_log_likelihood: 293002564547532423168.0000\n",
      "Epoch 1468/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5932 - squared_difference_loss: 11.7913 - KL_divergence_loss: 3.8019 - neg_log_likelihood: 91741358279.8974 - val_loss: 15.4186 - val_squared_difference_loss: 11.5876 - val_KL_divergence_loss: 3.8310 - val_neg_log_likelihood: 1293837844416677543936.0000\n",
      "Epoch 1469/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5948 - squared_difference_loss: 11.7711 - KL_divergence_loss: 3.8236 - neg_log_likelihood: 69818323348.6355 - val_loss: 15.4031 - val_squared_difference_loss: 11.5944 - val_KL_divergence_loss: 3.8087 - val_neg_log_likelihood: 1179860042204481454080.0000\n",
      "Epoch 1470/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5904 - squared_difference_loss: 11.7599 - KL_divergence_loss: 3.8305 - neg_log_likelihood: 6515199336.5487 - val_loss: 15.4296 - val_squared_difference_loss: 11.6113 - val_KL_divergence_loss: 3.8183 - val_neg_log_likelihood: 2445455132068309630976.0000\n",
      "Epoch 1471/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5697 - squared_difference_loss: 11.7840 - KL_divergence_loss: 3.7857 - neg_log_likelihood: 16815677264.4495 - val_loss: 15.3979 - val_squared_difference_loss: 11.6057 - val_KL_divergence_loss: 3.7922 - val_neg_log_likelihood: 525069212715020451840.0000\n",
      "Epoch 1472/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6168 - squared_difference_loss: 11.8091 - KL_divergence_loss: 3.8078 - neg_log_likelihood: 9631358189.0885 - val_loss: 15.4113 - val_squared_difference_loss: 11.5845 - val_KL_divergence_loss: 3.8268 - val_neg_log_likelihood: 2769152913034510336000.0000\n",
      "Epoch 1473/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6070 - squared_difference_loss: 11.8012 - KL_divergence_loss: 3.8058 - neg_log_likelihood: 7167941229.2895 - val_loss: 15.4200 - val_squared_difference_loss: 11.6128 - val_KL_divergence_loss: 3.8072 - val_neg_log_likelihood: 621297822145888124928.0000\n",
      "Epoch 1474/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6188 - squared_difference_loss: 11.8196 - KL_divergence_loss: 3.7992 - neg_log_likelihood: 13727215208.7028 - val_loss: 15.4185 - val_squared_difference_loss: 11.6193 - val_KL_divergence_loss: 3.7992 - val_neg_log_likelihood: 361893693061826215936.0000\n",
      "Epoch 1475/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.6142 - squared_difference_loss: 11.8131 - KL_divergence_loss: 3.8011 - neg_log_likelihood: 3058875778.3024 - val_loss: 15.4196 - val_squared_difference_loss: 11.6319 - val_KL_divergence_loss: 3.7876 - val_neg_log_likelihood: 280722915369755115520.0000\n",
      "Epoch 1476/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6217 - squared_difference_loss: 11.8137 - KL_divergence_loss: 3.8079 - neg_log_likelihood: 4297638990.0766 - val_loss: 15.4210 - val_squared_difference_loss: 11.6081 - val_KL_divergence_loss: 3.8129 - val_neg_log_likelihood: 858051817874492882944.0000\n",
      "Epoch 1477/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5950 - squared_difference_loss: 11.7876 - KL_divergence_loss: 3.8074 - neg_log_likelihood: 13599829411.9830 - val_loss: 15.4121 - val_squared_difference_loss: 11.6214 - val_KL_divergence_loss: 3.7907 - val_neg_log_likelihood: 761109138366067769344.0000\n",
      "Epoch 1478/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5910 - squared_difference_loss: 11.7939 - KL_divergence_loss: 3.7970 - neg_log_likelihood: 2546989268.8161 - val_loss: 15.3920 - val_squared_difference_loss: 11.6047 - val_KL_divergence_loss: 3.7873 - val_neg_log_likelihood: 951658105179657601024.0000\n",
      "Epoch 1479/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5965 - squared_difference_loss: 11.8071 - KL_divergence_loss: 3.7894 - neg_log_likelihood: 5691989234.7384 - val_loss: 15.4187 - val_squared_difference_loss: 11.6611 - val_KL_divergence_loss: 3.7576 - val_neg_log_likelihood: 911666802749699260416.0000\n",
      "Epoch 1480/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5921 - squared_difference_loss: 11.7873 - KL_divergence_loss: 3.8048 - neg_log_likelihood: 206083040635.7153 - val_loss: 15.4206 - val_squared_difference_loss: 11.6088 - val_KL_divergence_loss: 3.8118 - val_neg_log_likelihood: 2188525966100232667136.0000\n",
      "Epoch 1481/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6074 - squared_difference_loss: 11.8151 - KL_divergence_loss: 3.7923 - neg_log_likelihood: 6717889621.3026 - val_loss: 15.3924 - val_squared_difference_loss: 11.5975 - val_KL_divergence_loss: 3.7949 - val_neg_log_likelihood: 380548471141842026496.0000\n",
      "Epoch 1482/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6005 - squared_difference_loss: 11.7801 - KL_divergence_loss: 3.8204 - neg_log_likelihood: 14173278361.0047 - val_loss: 15.4049 - val_squared_difference_loss: 11.5847 - val_KL_divergence_loss: 3.8202 - val_neg_log_likelihood: 418190446520047960064.0000\n",
      "Epoch 1483/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5953 - squared_difference_loss: 11.7767 - KL_divergence_loss: 3.8186 - neg_log_likelihood: 147592332444.9189 - val_loss: 15.3776 - val_squared_difference_loss: 11.5906 - val_KL_divergence_loss: 3.7870 - val_neg_log_likelihood: 457179905586996445184.0000\n",
      "Epoch 1484/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5907 - squared_difference_loss: 11.7786 - KL_divergence_loss: 3.8122 - neg_log_likelihood: 81659031750.3324 - val_loss: 15.3995 - val_squared_difference_loss: 11.6057 - val_KL_divergence_loss: 3.7937 - val_neg_log_likelihood: 3112723757922975219712.0000\n",
      "Epoch 1485/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5734 - squared_difference_loss: 11.7742 - KL_divergence_loss: 3.7992 - neg_log_likelihood: 76007756935.5098 - val_loss: 15.4231 - val_squared_difference_loss: 11.6439 - val_KL_divergence_loss: 3.7792 - val_neg_log_likelihood: 926708654604064522240.0000\n",
      "Epoch 1486/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.6167 - squared_difference_loss: 11.8267 - KL_divergence_loss: 3.7900 - neg_log_likelihood: 6325351503.5679 - val_loss: 15.4128 - val_squared_difference_loss: 11.6020 - val_KL_divergence_loss: 3.8109 - val_neg_log_likelihood: 986489248275377553408.0000\n",
      "Epoch 1487/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6010 - squared_difference_loss: 11.7867 - KL_divergence_loss: 3.8143 - neg_log_likelihood: 1041946066.7198 - val_loss: 15.4307 - val_squared_difference_loss: 11.6233 - val_KL_divergence_loss: 3.8074 - val_neg_log_likelihood: 848710062350978646016.0000\n",
      "Epoch 1488/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6005 - squared_difference_loss: 11.8000 - KL_divergence_loss: 3.8005 - neg_log_likelihood: 2852692560.8578 - val_loss: 15.3984 - val_squared_difference_loss: 11.5923 - val_KL_divergence_loss: 3.8061 - val_neg_log_likelihood: 1463826741137109417984.0000\n",
      "Epoch 1489/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5974 - squared_difference_loss: 11.7907 - KL_divergence_loss: 3.8066 - neg_log_likelihood: 12538302051.3231 - val_loss: 15.3991 - val_squared_difference_loss: 11.6014 - val_KL_divergence_loss: 3.7977 - val_neg_log_likelihood: 546480762968312774656.0000\n",
      "Epoch 1490/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6067 - squared_difference_loss: 11.7917 - KL_divergence_loss: 3.8150 - neg_log_likelihood: 8679477467.6075 - val_loss: 15.4105 - val_squared_difference_loss: 11.5852 - val_KL_divergence_loss: 3.8253 - val_neg_log_likelihood: 4127889312498317262848.0000\n",
      "Epoch 1491/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5981 - squared_difference_loss: 11.7722 - KL_divergence_loss: 3.8259 - neg_log_likelihood: 10063222221.2664 - val_loss: 15.4510 - val_squared_difference_loss: 11.6403 - val_KL_divergence_loss: 3.8106 - val_neg_log_likelihood: 370686163881599762432.0000\n",
      "Epoch 1492/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5901 - squared_difference_loss: 11.7906 - KL_divergence_loss: 3.7995 - neg_log_likelihood: 23580130157.3522 - val_loss: 15.4068 - val_squared_difference_loss: 11.6034 - val_KL_divergence_loss: 3.8034 - val_neg_log_likelihood: 184660916349919068160.0000\n",
      "Epoch 1493/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.6205 - squared_difference_loss: 11.8161 - KL_divergence_loss: 3.8044 - neg_log_likelihood: 705962343.7482 - val_loss: 15.3943 - val_squared_difference_loss: 11.5877 - val_KL_divergence_loss: 3.8065 - val_neg_log_likelihood: 1809030483532639371264.0000\n",
      "Epoch 1494/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6178 - squared_difference_loss: 11.7675 - KL_divergence_loss: 3.8502 - neg_log_likelihood: 13925941324.9445 - val_loss: 15.3862 - val_squared_difference_loss: 11.5443 - val_KL_divergence_loss: 3.8419 - val_neg_log_likelihood: 641623266702017298432.0000\n",
      "Epoch 1495/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5864 - squared_difference_loss: 11.7653 - KL_divergence_loss: 3.8211 - neg_log_likelihood: 44671299607.4658 - val_loss: 15.4269 - val_squared_difference_loss: 11.6057 - val_KL_divergence_loss: 3.8212 - val_neg_log_likelihood: 963327598961660264448.0000\n",
      "Epoch 1496/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5797 - squared_difference_loss: 11.7716 - KL_divergence_loss: 3.8082 - neg_log_likelihood: 90243984935.7021 - val_loss: 15.4389 - val_squared_difference_loss: 11.6159 - val_KL_divergence_loss: 3.8229 - val_neg_log_likelihood: 1115140961635950395392.0000\n",
      "Epoch 1497/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5797 - squared_difference_loss: 11.7615 - KL_divergence_loss: 3.8182 - neg_log_likelihood: 21420299077.4754 - val_loss: 15.4237 - val_squared_difference_loss: 11.6312 - val_KL_divergence_loss: 3.7926 - val_neg_log_likelihood: 2314675007479919411200.0000\n",
      "Epoch 1498/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5376 - squared_difference_loss: 11.7446 - KL_divergence_loss: 3.7930 - neg_log_likelihood: 523556877727.5598 - val_loss: 15.3819 - val_squared_difference_loss: 11.5834 - val_KL_divergence_loss: 3.7985 - val_neg_log_likelihood: 2926988465026584543232.0000\n",
      "Epoch 1499/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5948 - squared_difference_loss: 11.7819 - KL_divergence_loss: 3.8129 - neg_log_likelihood: 19124996565.7521 - val_loss: 15.3954 - val_squared_difference_loss: 11.5943 - val_KL_divergence_loss: 3.8011 - val_neg_log_likelihood: 1286832195505352605696.0000\n",
      "Epoch 1500/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5742 - squared_difference_loss: 11.7679 - KL_divergence_loss: 3.8062 - neg_log_likelihood: 15220073981.9830 - val_loss: 15.4078 - val_squared_difference_loss: 11.6075 - val_KL_divergence_loss: 3.8003 - val_neg_log_likelihood: 600138034921534783488.0000\n",
      "Epoch 1501/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5814 - squared_difference_loss: 11.7720 - KL_divergence_loss: 3.8094 - neg_log_likelihood: 12798316217.9103 - val_loss: 15.4062 - val_squared_difference_loss: 11.6149 - val_KL_divergence_loss: 3.7913 - val_neg_log_likelihood: 364387396205856030720.0000\n",
      "Epoch 1502/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5949 - squared_difference_loss: 11.7935 - KL_divergence_loss: 3.8014 - neg_log_likelihood: 5465522346.2516 - val_loss: 15.3951 - val_squared_difference_loss: 11.5671 - val_KL_divergence_loss: 3.8280 - val_neg_log_likelihood: 578396379770024034304.0000\n",
      "Epoch 1503/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5642 - squared_difference_loss: 11.7601 - KL_divergence_loss: 3.8041 - neg_log_likelihood: 21147454412.1528 - val_loss: 15.3933 - val_squared_difference_loss: 11.6272 - val_KL_divergence_loss: 3.7660 - val_neg_log_likelihood: 196379640735034540032.0000\n",
      "Epoch 1504/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5623 - squared_difference_loss: 11.7611 - KL_divergence_loss: 3.8013 - neg_log_likelihood: 4184870177.4162 - val_loss: 15.3911 - val_squared_difference_loss: 11.5929 - val_KL_divergence_loss: 3.7982 - val_neg_log_likelihood: 284589518483791085568.0000\n",
      "Epoch 1505/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5661 - squared_difference_loss: 11.7600 - KL_divergence_loss: 3.8062 - neg_log_likelihood: 199282731435.3846 - val_loss: 15.3662 - val_squared_difference_loss: 11.5826 - val_KL_divergence_loss: 3.7835 - val_neg_log_likelihood: 451773191163618787328.0000\n",
      "Epoch 1506/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5599 - squared_difference_loss: 11.7743 - KL_divergence_loss: 3.7856 - neg_log_likelihood: 5547598978708.4932 - val_loss: 15.3848 - val_squared_difference_loss: 11.5953 - val_KL_divergence_loss: 3.7895 - val_neg_log_likelihood: 159640012015118286848.0000\n",
      "Epoch 1507/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5768 - squared_difference_loss: 11.7721 - KL_divergence_loss: 3.8047 - neg_log_likelihood: 4922316501.1396 - val_loss: 15.3396 - val_squared_difference_loss: 11.5402 - val_KL_divergence_loss: 3.7995 - val_neg_log_likelihood: 625279334283597316096.0000\n",
      "Epoch 1508/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5619 - squared_difference_loss: 11.7367 - KL_divergence_loss: 3.8252 - neg_log_likelihood: 41603007521.1376 - val_loss: 15.3744 - val_squared_difference_loss: 11.5774 - val_KL_divergence_loss: 3.7969 - val_neg_log_likelihood: 395257235690848256000.0000\n",
      "Epoch 1509/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5692 - squared_difference_loss: 11.7773 - KL_divergence_loss: 3.7919 - neg_log_likelihood: 4533714853.4390 - val_loss: 15.4010 - val_squared_difference_loss: 11.6427 - val_KL_divergence_loss: 3.7582 - val_neg_log_likelihood: 509149128936049606656.0000\n",
      "Epoch 1510/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5673 - squared_difference_loss: 11.7535 - KL_divergence_loss: 3.8137 - neg_log_likelihood: 15263724506.6887 - val_loss: 15.3955 - val_squared_difference_loss: 11.6114 - val_KL_divergence_loss: 3.7840 - val_neg_log_likelihood: 795231107627464523776.0000\n",
      "Epoch 1511/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5846 - squared_difference_loss: 11.7653 - KL_divergence_loss: 3.8193 - neg_log_likelihood: 133311125839.5541 - val_loss: 15.4066 - val_squared_difference_loss: 11.6023 - val_KL_divergence_loss: 3.8043 - val_neg_log_likelihood: 818379047045230886912.0000\n",
      "Epoch 1512/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.6010 - squared_difference_loss: 11.7796 - KL_divergence_loss: 3.8214 - neg_log_likelihood: 202977894332.1441 - val_loss: 15.3851 - val_squared_difference_loss: 11.5975 - val_KL_divergence_loss: 3.7876 - val_neg_log_likelihood: 377312454716880584704.0000\n",
      "Epoch 1513/2000\n",
      "29507/29507 [==============================] - ETA: 0s - loss: 15.5571 - squared_difference_loss: 11.7302 - KL_divergence_loss: 3.8269 - neg_log_likelihood: 542299422.945 - 0s 15us/step - loss: 15.5955 - squared_difference_loss: 11.7709 - KL_divergence_loss: 3.8246 - neg_log_likelihood: 490966131.0277 - val_loss: 15.4252 - val_squared_difference_loss: 11.6157 - val_KL_divergence_loss: 3.8094 - val_neg_log_likelihood: 65110251042531123200.0000\n",
      "Epoch 1514/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5636 - squared_difference_loss: 11.7585 - KL_divergence_loss: 3.8051 - neg_log_likelihood: 7595902926.6481 - val_loss: 15.3937 - val_squared_difference_loss: 11.5958 - val_KL_divergence_loss: 3.7979 - val_neg_log_likelihood: 61536039632594542592.0000\n",
      "Epoch 1515/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5599 - squared_difference_loss: 11.7307 - KL_divergence_loss: 3.8292 - neg_log_likelihood: 13728621420.7568 - val_loss: 15.3977 - val_squared_difference_loss: 11.5969 - val_KL_divergence_loss: 3.8008 - val_neg_log_likelihood: 203834955244923125760.0000\n",
      "Epoch 1516/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5697 - squared_difference_loss: 11.7556 - KL_divergence_loss: 3.8142 - neg_log_likelihood: 3942902131.0707 - val_loss: 15.3991 - val_squared_difference_loss: 11.6058 - val_KL_divergence_loss: 3.7933 - val_neg_log_likelihood: 519519479686477381632.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1517/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5704 - squared_difference_loss: 11.7622 - KL_divergence_loss: 3.8082 - neg_log_likelihood: 26623289218.5967 - val_loss: 15.3915 - val_squared_difference_loss: 11.6261 - val_KL_divergence_loss: 3.7655 - val_neg_log_likelihood: 270949054577615962112.0000\n",
      "Epoch 1518/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5750 - squared_difference_loss: 11.7768 - KL_divergence_loss: 3.7982 - neg_log_likelihood: 235045297.1119 - val_loss: 15.4107 - val_squared_difference_loss: 11.6197 - val_KL_divergence_loss: 3.7911 - val_neg_log_likelihood: 249548476697259671552.0000\n",
      "Epoch 1519/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5987 - squared_difference_loss: 11.7831 - KL_divergence_loss: 3.8156 - neg_log_likelihood: 2798027414.7800 - val_loss: 15.3897 - val_squared_difference_loss: 11.5571 - val_KL_divergence_loss: 3.8327 - val_neg_log_likelihood: 571793791851450335232.0000\n",
      "Epoch 1520/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5960 - squared_difference_loss: 11.7675 - KL_divergence_loss: 3.8285 - neg_log_likelihood: 1051816307.7225 - val_loss: 15.4501 - val_squared_difference_loss: 11.6490 - val_KL_divergence_loss: 3.8011 - val_neg_log_likelihood: 105792682730054303744.0000\n",
      "Epoch 1521/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5782 - squared_difference_loss: 11.7521 - KL_divergence_loss: 3.8261 - neg_log_likelihood: 9431724847.7424 - val_loss: 15.4015 - val_squared_difference_loss: 11.5929 - val_KL_divergence_loss: 3.8086 - val_neg_log_likelihood: 520917707169276362752.0000\n",
      "Epoch 1522/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5519 - squared_difference_loss: 11.7526 - KL_divergence_loss: 3.7993 - neg_log_likelihood: 63189336957.9595 - val_loss: 15.3935 - val_squared_difference_loss: 11.6115 - val_KL_divergence_loss: 3.7820 - val_neg_log_likelihood: 784440558461199712256.0000\n",
      "Epoch 1523/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5628 - squared_difference_loss: 11.7654 - KL_divergence_loss: 3.7974 - neg_log_likelihood: 9752463368.4951 - val_loss: 15.3912 - val_squared_difference_loss: 11.5924 - val_KL_divergence_loss: 3.7989 - val_neg_log_likelihood: 1007973932277368750080.0000\n",
      "Epoch 1524/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5800 - squared_difference_loss: 11.7494 - KL_divergence_loss: 3.8306 - neg_log_likelihood: 8464961532.1660 - val_loss: 15.3855 - val_squared_difference_loss: 11.5548 - val_KL_divergence_loss: 3.8306 - val_neg_log_likelihood: 193760345470194483200.0000\n",
      "Epoch 1525/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5749 - squared_difference_loss: 11.7723 - KL_divergence_loss: 3.8025 - neg_log_likelihood: 10778129975.2340 - val_loss: 15.3780 - val_squared_difference_loss: 11.5883 - val_KL_divergence_loss: 3.7897 - val_neg_log_likelihood: 305222522234159235072.0000\n",
      "Epoch 1526/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5681 - squared_difference_loss: 11.7463 - KL_divergence_loss: 3.8218 - neg_log_likelihood: 4271428782.0199 - val_loss: 15.3934 - val_squared_difference_loss: 11.5724 - val_KL_divergence_loss: 3.8210 - val_neg_log_likelihood: 623768312043097161728.0000\n",
      "Epoch 1527/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5541 - squared_difference_loss: 11.7262 - KL_divergence_loss: 3.8278 - neg_log_likelihood: 9688051108.2751 - val_loss: 15.3832 - val_squared_difference_loss: 11.5748 - val_KL_divergence_loss: 3.8084 - val_neg_log_likelihood: 300362021142494248960.0000\n",
      "Epoch 1528/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5909 - squared_difference_loss: 11.7658 - KL_divergence_loss: 3.8250 - neg_log_likelihood: 1084128290.8690 - val_loss: 15.4127 - val_squared_difference_loss: 11.6032 - val_KL_divergence_loss: 3.8095 - val_neg_log_likelihood: 563473954951444824064.0000\n",
      "Epoch 1529/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5521 - squared_difference_loss: 11.7351 - KL_divergence_loss: 3.8170 - neg_log_likelihood: 39868267358.7389 - val_loss: 15.3697 - val_squared_difference_loss: 11.5676 - val_KL_divergence_loss: 3.8020 - val_neg_log_likelihood: 256566455656826208256.0000\n",
      "Epoch 1530/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5689 - squared_difference_loss: 11.7530 - KL_divergence_loss: 3.8159 - neg_log_likelihood: 19143871417.7559 - val_loss: 15.3890 - val_squared_difference_loss: 11.5995 - val_KL_divergence_loss: 3.7895 - val_neg_log_likelihood: 618589368611498098688.0000\n",
      "Epoch 1531/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5583 - squared_difference_loss: 11.7543 - KL_divergence_loss: 3.8040 - neg_log_likelihood: 25642863782.1575 - val_loss: 15.3813 - val_squared_difference_loss: 11.6022 - val_KL_divergence_loss: 3.7790 - val_neg_log_likelihood: 48109953686282952704.0000\n",
      "Epoch 1532/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5849 - squared_difference_loss: 11.7665 - KL_divergence_loss: 3.8185 - neg_log_likelihood: 7998284096.0392 - val_loss: 15.3975 - val_squared_difference_loss: 11.5944 - val_KL_divergence_loss: 3.8030 - val_neg_log_likelihood: 138538013070882390016.0000\n",
      "Epoch 1533/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5574 - squared_difference_loss: 11.7476 - KL_divergence_loss: 3.8098 - neg_log_likelihood: 1728848005.6780 - val_loss: 15.3948 - val_squared_difference_loss: 11.6065 - val_KL_divergence_loss: 3.7884 - val_neg_log_likelihood: 66944528970045014016.0000\n",
      "Epoch 1534/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5462 - squared_difference_loss: 11.7291 - KL_divergence_loss: 3.8171 - neg_log_likelihood: 7722268137.0781 - val_loss: 15.3952 - val_squared_difference_loss: 11.5855 - val_KL_divergence_loss: 3.8097 - val_neg_log_likelihood: 128959617951251382272.0000\n",
      "Epoch 1535/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5526 - squared_difference_loss: 11.7462 - KL_divergence_loss: 3.8064 - neg_log_likelihood: 2277536384.2355 - val_loss: 15.3931 - val_squared_difference_loss: 11.5998 - val_KL_divergence_loss: 3.7933 - val_neg_log_likelihood: 138313603165525360640.0000\n",
      "Epoch 1536/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5577 - squared_difference_loss: 11.7615 - KL_divergence_loss: 3.7962 - neg_log_likelihood: 12812593725.6834 - val_loss: 15.3809 - val_squared_difference_loss: 11.5536 - val_KL_divergence_loss: 3.8273 - val_neg_log_likelihood: 143535868724003700736.0000\n",
      "Epoch 1537/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5948 - squared_difference_loss: 11.7797 - KL_divergence_loss: 3.8150 - neg_log_likelihood: 7742279184.7848 - val_loss: 15.3721 - val_squared_difference_loss: 11.5519 - val_KL_divergence_loss: 3.8202 - val_neg_log_likelihood: 188801115595385536512.0000\n",
      "Epoch 1538/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5639 - squared_difference_loss: 11.7301 - KL_divergence_loss: 3.8338 - neg_log_likelihood: 2468281960.4453 - val_loss: 15.3549 - val_squared_difference_loss: 11.5434 - val_KL_divergence_loss: 3.8115 - val_neg_log_likelihood: 440024509696638910464.0000\n",
      "Epoch 1539/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5446 - squared_difference_loss: 11.7512 - KL_divergence_loss: 3.7934 - neg_log_likelihood: 16731426461.2591 - val_loss: 15.4158 - val_squared_difference_loss: 11.6038 - val_KL_divergence_loss: 3.8120 - val_neg_log_likelihood: 239720599904754925568.0000\n",
      "Epoch 1540/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5660 - squared_difference_loss: 11.7516 - KL_divergence_loss: 3.8144 - neg_log_likelihood: 1430103075.8974 - val_loss: 15.4132 - val_squared_difference_loss: 11.6182 - val_KL_divergence_loss: 3.7951 - val_neg_log_likelihood: 478376326551398187008.0000\n",
      "Epoch 1541/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.6156 - squared_difference_loss: 11.7906 - KL_divergence_loss: 3.8251 - neg_log_likelihood: 162564908.5446 - val_loss: 15.3663 - val_squared_difference_loss: 11.5423 - val_KL_divergence_loss: 3.8239 - val_neg_log_likelihood: 150962962193315692544.0000\n",
      "Epoch 1542/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5729 - squared_difference_loss: 11.7286 - KL_divergence_loss: 3.8443 - neg_log_likelihood: 18058475893.1013 - val_loss: 15.4039 - val_squared_difference_loss: 11.5961 - val_KL_divergence_loss: 3.8078 - val_neg_log_likelihood: 90968658535508639744.0000\n",
      "Epoch 1543/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5895 - squared_difference_loss: 11.7647 - KL_divergence_loss: 3.8249 - neg_log_likelihood: 17650911946.4014 - val_loss: 15.3989 - val_squared_difference_loss: 11.5906 - val_KL_divergence_loss: 3.8082 - val_neg_log_likelihood: 560990111369595256832.0000\n",
      "Epoch 1544/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5767 - squared_difference_loss: 11.7667 - KL_divergence_loss: 3.8100 - neg_log_likelihood: 2925787912.3579 - val_loss: 15.3878 - val_squared_difference_loss: 11.5829 - val_KL_divergence_loss: 3.8049 - val_neg_log_likelihood: 235197169981839736832.0000\n",
      "Epoch 1545/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5701 - squared_difference_loss: 11.7553 - KL_divergence_loss: 3.8147 - neg_log_likelihood: 100691208889.2008 - val_loss: 15.3901 - val_squared_difference_loss: 11.5719 - val_KL_divergence_loss: 3.8182 - val_neg_log_likelihood: 227287760951701569536.0000\n",
      "Epoch 1546/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5886 - squared_difference_loss: 11.7730 - KL_divergence_loss: 3.8155 - neg_log_likelihood: 7636203700.4505 - val_loss: 15.3861 - val_squared_difference_loss: 11.5644 - val_KL_divergence_loss: 3.8218 - val_neg_log_likelihood: 91550899086169227264.0000\n",
      "Epoch 1547/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5541 - squared_difference_loss: 11.7478 - KL_divergence_loss: 3.8064 - neg_log_likelihood: 19460691193.7402 - val_loss: 15.3925 - val_squared_difference_loss: 11.5881 - val_KL_divergence_loss: 3.8045 - val_neg_log_likelihood: 45375935787493253120.0000\n",
      "Epoch 1548/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5849 - squared_difference_loss: 11.7675 - KL_divergence_loss: 3.8174 - neg_log_likelihood: 10284301058.5547 - val_loss: 15.3934 - val_squared_difference_loss: 11.5653 - val_KL_divergence_loss: 3.8281 - val_neg_log_likelihood: 72501267140677705728.0000\n",
      "Epoch 1549/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5652 - squared_difference_loss: 11.7359 - KL_divergence_loss: 3.8293 - neg_log_likelihood: 7558709868.0663 - val_loss: 15.3720 - val_squared_difference_loss: 11.5712 - val_KL_divergence_loss: 3.8008 - val_neg_log_likelihood: 193107769571826106368.0000\n",
      "Epoch 1550/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5558 - squared_difference_loss: 11.7464 - KL_divergence_loss: 3.8095 - neg_log_likelihood: 25909793899.3862 - val_loss: 15.3898 - val_squared_difference_loss: 11.5744 - val_KL_divergence_loss: 3.8154 - val_neg_log_likelihood: 285978420578500116480.0000\n",
      "Epoch 1551/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5557 - squared_difference_loss: 11.7344 - KL_divergence_loss: 3.8214 - neg_log_likelihood: 9625753526.5959 - val_loss: 15.3521 - val_squared_difference_loss: 11.5411 - val_KL_divergence_loss: 3.8110 - val_neg_log_likelihood: 621899409117988126720.0000\n",
      "Epoch 1552/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5481 - squared_difference_loss: 11.7426 - KL_divergence_loss: 3.8055 - neg_log_likelihood: 1529141049.0207 - val_loss: 15.3481 - val_squared_difference_loss: 11.5577 - val_KL_divergence_loss: 3.7904 - val_neg_log_likelihood: 510260384020623523840.0000\n",
      "Epoch 1553/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5437 - squared_difference_loss: 11.7472 - KL_divergence_loss: 3.7966 - neg_log_likelihood: 96397184121.3583 - val_loss: 15.3863 - val_squared_difference_loss: 11.6098 - val_KL_divergence_loss: 3.7765 - val_neg_log_likelihood: 85724303672347181056.0000\n",
      "Epoch 1554/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5652 - squared_difference_loss: 11.7552 - KL_divergence_loss: 3.8100 - neg_log_likelihood: 6394435892.7554 - val_loss: 15.3781 - val_squared_difference_loss: 11.5785 - val_KL_divergence_loss: 3.7997 - val_neg_log_likelihood: 359907610713057853440.0000\n",
      "Epoch 1555/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5794 - squared_difference_loss: 11.7732 - KL_divergence_loss: 3.8062 - neg_log_likelihood: 33364909237.8038 - val_loss: 15.4095 - val_squared_difference_loss: 11.5865 - val_KL_divergence_loss: 3.8230 - val_neg_log_likelihood: 31495176509728428032.0000\n",
      "Epoch 1556/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5726 - squared_difference_loss: 11.7281 - KL_divergence_loss: 3.8445 - neg_log_likelihood: 15878604836.9995 - val_loss: 15.3804 - val_squared_difference_loss: 11.5646 - val_KL_divergence_loss: 3.8158 - val_neg_log_likelihood: 308496441031600766976.0000\n",
      "Epoch 1557/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5458 - squared_difference_loss: 11.7199 - KL_divergence_loss: 3.8259 - neg_log_likelihood: 13430030291.6002 - val_loss: 15.3753 - val_squared_difference_loss: 11.5665 - val_KL_divergence_loss: 3.8089 - val_neg_log_likelihood: 88979988956175581184.0000\n",
      "Epoch 1558/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5447 - squared_difference_loss: 11.7218 - KL_divergence_loss: 3.8229 - neg_log_likelihood: 16904173817.8237 - val_loss: 15.3966 - val_squared_difference_loss: 11.5742 - val_KL_divergence_loss: 3.8225 - val_neg_log_likelihood: 75720891785271410688.0000\n",
      "Epoch 1559/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5810 - squared_difference_loss: 11.7566 - KL_divergence_loss: 3.8244 - neg_log_likelihood: 1131226116.4102 - val_loss: 15.3604 - val_squared_difference_loss: 11.5427 - val_KL_divergence_loss: 3.8176 - val_neg_log_likelihood: 97510525812178059264.0000\n",
      "Epoch 1560/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5823 - squared_difference_loss: 11.7700 - KL_divergence_loss: 3.8122 - neg_log_likelihood: 67667287481.9136 - val_loss: 15.4013 - val_squared_difference_loss: 11.5830 - val_KL_divergence_loss: 3.8184 - val_neg_log_likelihood: 99298761034598023168.0000\n",
      "Epoch 1561/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5679 - squared_difference_loss: 11.7588 - KL_divergence_loss: 3.8091 - neg_log_likelihood: 2003519688.6418 - val_loss: 15.3970 - val_squared_difference_loss: 11.5997 - val_KL_divergence_loss: 3.7973 - val_neg_log_likelihood: 60736900630433038336.0000\n",
      "Epoch 1562/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5669 - squared_difference_loss: 11.7341 - KL_divergence_loss: 3.8328 - neg_log_likelihood: 155116410686.2057 - val_loss: 15.3903 - val_squared_difference_loss: 11.5785 - val_KL_divergence_loss: 3.8117 - val_neg_log_likelihood: 96816453077829189632.0000\n",
      "Epoch 1563/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5469 - squared_difference_loss: 11.7256 - KL_divergence_loss: 3.8212 - neg_log_likelihood: 1340401909.1455 - val_loss: 15.4144 - val_squared_difference_loss: 11.5828 - val_KL_divergence_loss: 3.8315 - val_neg_log_likelihood: 82565332936775827456.0000\n",
      "Epoch 1564/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5562 - squared_difference_loss: 11.7437 - KL_divergence_loss: 3.8125 - neg_log_likelihood: 3552059369.1263 - val_loss: 15.3640 - val_squared_difference_loss: 11.5790 - val_KL_divergence_loss: 3.7850 - val_neg_log_likelihood: 311713272466434031616.0000\n",
      "Epoch 1565/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5617 - squared_difference_loss: 11.7470 - KL_divergence_loss: 3.8147 - neg_log_likelihood: 4005569751.1345 - val_loss: 15.4077 - val_squared_difference_loss: 11.5894 - val_KL_divergence_loss: 3.8183 - val_neg_log_likelihood: 88455637000806432768.0000\n",
      "Epoch 1566/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5769 - squared_difference_loss: 11.7600 - KL_divergence_loss: 3.8168 - neg_log_likelihood: 5530275186.1402 - val_loss: 15.4019 - val_squared_difference_loss: 11.6156 - val_KL_divergence_loss: 3.7863 - val_neg_log_likelihood: 68537342999190888448.0000\n",
      "Epoch 1567/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5409 - squared_difference_loss: 11.7484 - KL_divergence_loss: 3.7925 - neg_log_likelihood: 131409624731.0612 - val_loss: 15.3779 - val_squared_difference_loss: 11.5983 - val_KL_divergence_loss: 3.7796 - val_neg_log_likelihood: 153266452249911197696.0000\n",
      "Epoch 1568/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5748 - squared_difference_loss: 11.7607 - KL_divergence_loss: 3.8141 - neg_log_likelihood: 27765479630.9917 - val_loss: 15.3768 - val_squared_difference_loss: 11.5830 - val_KL_divergence_loss: 3.7938 - val_neg_log_likelihood: 130140780175110324224.0000\n",
      "Epoch 1569/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5900 - squared_difference_loss: 11.7578 - KL_divergence_loss: 3.8321 - neg_log_likelihood: 8004346626.4456 - val_loss: 15.3771 - val_squared_difference_loss: 11.5465 - val_KL_divergence_loss: 3.8306 - val_neg_log_likelihood: 68363677346951970816.0000\n",
      "Epoch 1570/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5335 - squared_difference_loss: 11.7213 - KL_divergence_loss: 3.8122 - neg_log_likelihood: 8401185019.9588 - val_loss: 15.3869 - val_squared_difference_loss: 11.5874 - val_KL_divergence_loss: 3.7995 - val_neg_log_likelihood: 74151491303142440960.0000\n",
      "Epoch 1571/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5442 - squared_difference_loss: 11.7345 - KL_divergence_loss: 3.8097 - neg_log_likelihood: 27858191773.4976 - val_loss: 15.3899 - val_squared_difference_loss: 11.5864 - val_KL_divergence_loss: 3.8035 - val_neg_log_likelihood: 69956446936223301632.0000\n",
      "Epoch 1572/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5377 - squared_difference_loss: 11.7316 - KL_divergence_loss: 3.8061 - neg_log_likelihood: 135751666653.0952 - val_loss: 15.3790 - val_squared_difference_loss: 11.5732 - val_KL_divergence_loss: 3.8059 - val_neg_log_likelihood: 116943115741164421120.0000\n",
      "Epoch 1573/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5470 - squared_difference_loss: 11.7428 - KL_divergence_loss: 3.8042 - neg_log_likelihood: 77103564677.6625 - val_loss: 15.3696 - val_squared_difference_loss: 11.5656 - val_KL_divergence_loss: 3.8040 - val_neg_log_likelihood: 106154324885750775808.0000\n",
      "Epoch 1574/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5719 - squared_difference_loss: 11.7532 - KL_divergence_loss: 3.8187 - neg_log_likelihood: 946393957.0095 - val_loss: 15.3464 - val_squared_difference_loss: 11.5296 - val_KL_divergence_loss: 3.8168 - val_neg_log_likelihood: 215438325529593249792.0000\n",
      "Epoch 1575/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5532 - squared_difference_loss: 11.7455 - KL_divergence_loss: 3.8077 - neg_log_likelihood: 4808687384.5972 - val_loss: 15.4097 - val_squared_difference_loss: 11.6357 - val_KL_divergence_loss: 3.7739 - val_neg_log_likelihood: 106085886799901376512.0000\n",
      "Epoch 1576/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5457 - squared_difference_loss: 11.7302 - KL_divergence_loss: 3.8155 - neg_log_likelihood: 2754786099.4875 - val_loss: 15.3774 - val_squared_difference_loss: 11.5915 - val_KL_divergence_loss: 3.7858 - val_neg_log_likelihood: 238593053050855522304.0000\n",
      "Epoch 1577/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5445 - squared_difference_loss: 11.7304 - KL_divergence_loss: 3.8142 - neg_log_likelihood: 34131434546.1495 - val_loss: 15.3969 - val_squared_difference_loss: 11.6080 - val_KL_divergence_loss: 3.7889 - val_neg_log_likelihood: 372248242096214310912.0000\n",
      "Epoch 1578/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5705 - squared_difference_loss: 11.7511 - KL_divergence_loss: 3.8194 - neg_log_likelihood: 5572114384.1006 - val_loss: 15.3526 - val_squared_difference_loss: 11.5549 - val_KL_divergence_loss: 3.7976 - val_neg_log_likelihood: 166375035835549777920.0000\n",
      "Epoch 1579/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5672 - squared_difference_loss: 11.7634 - KL_divergence_loss: 3.8037 - neg_log_likelihood: 125567779923.9292 - val_loss: 15.3671 - val_squared_difference_loss: 11.5705 - val_KL_divergence_loss: 3.7966 - val_neg_log_likelihood: 120912932251891023872.0000\n",
      "Epoch 1580/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5365 - squared_difference_loss: 11.7137 - KL_divergence_loss: 3.8228 - neg_log_likelihood: 21934004385.1059 - val_loss: 15.3933 - val_squared_difference_loss: 11.6068 - val_KL_divergence_loss: 3.7865 - val_neg_log_likelihood: 94480936346612072448.0000\n",
      "Epoch 1581/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5743 - squared_difference_loss: 11.7505 - KL_divergence_loss: 3.8238 - neg_log_likelihood: 8206637693.1728 - val_loss: 15.3795 - val_squared_difference_loss: 11.5652 - val_KL_divergence_loss: 3.8142 - val_neg_log_likelihood: 118807990435559292928.0000\n",
      "Epoch 1582/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5607 - squared_difference_loss: 11.7458 - KL_divergence_loss: 3.8149 - neg_log_likelihood: 4733400868.9103 - val_loss: 15.3999 - val_squared_difference_loss: 11.5932 - val_KL_divergence_loss: 3.8068 - val_neg_log_likelihood: 17423977473356630016.0000\n",
      "Epoch 1583/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5757 - squared_difference_loss: 11.7488 - KL_divergence_loss: 3.8269 - neg_log_likelihood: 1370474212.9744 - val_loss: 15.3765 - val_squared_difference_loss: 11.5596 - val_KL_divergence_loss: 3.8169 - val_neg_log_likelihood: 84539174255558328320.0000\n",
      "Epoch 1584/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5818 - squared_difference_loss: 11.7525 - KL_divergence_loss: 3.8293 - neg_log_likelihood: 2951383031.2660 - val_loss: 15.3865 - val_squared_difference_loss: 11.5698 - val_KL_divergence_loss: 3.8166 - val_neg_log_likelihood: 87121262604695257088.0000\n",
      "Epoch 1585/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5546 - squared_difference_loss: 11.7452 - KL_divergence_loss: 3.8094 - neg_log_likelihood: 2375143423.6948 - val_loss: 15.3560 - val_squared_difference_loss: 11.5760 - val_KL_divergence_loss: 3.7800 - val_neg_log_likelihood: 15320306925829937152.0000\n",
      "Epoch 1586/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5514 - squared_difference_loss: 11.7356 - KL_divergence_loss: 3.8158 - neg_log_likelihood: 6218063075.0179 - val_loss: 15.3773 - val_squared_difference_loss: 11.5588 - val_KL_divergence_loss: 3.8185 - val_neg_log_likelihood: 249966538365066575872.0000\n",
      "Epoch 1587/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5710 - squared_difference_loss: 11.7660 - KL_divergence_loss: 3.8049 - neg_log_likelihood: 8519887639.2038 - val_loss: 15.4142 - val_squared_difference_loss: 11.6441 - val_KL_divergence_loss: 3.7700 - val_neg_log_likelihood: 190922426926180761600.0000\n",
      "Epoch 1588/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5671 - squared_difference_loss: 11.7605 - KL_divergence_loss: 3.8066 - neg_log_likelihood: 2769896086.8675 - val_loss: 15.3642 - val_squared_difference_loss: 11.5493 - val_KL_divergence_loss: 3.8149 - val_neg_log_likelihood: 214917907191168106496.0000\n",
      "Epoch 1589/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 15.5654 - squared_difference_loss: 11.7621 - KL_divergence_loss: 3.8033 - neg_log_likelihood: 5223005506.0463 - val_loss: 15.3469 - val_squared_difference_loss: 11.5241 - val_KL_divergence_loss: 3.8229 - val_neg_log_likelihood: 84956034118098829312.0000\n",
      "Epoch 1590/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5583 - squared_difference_loss: 11.7407 - KL_divergence_loss: 3.8176 - neg_log_likelihood: 2311456958.2673 - val_loss: 15.4025 - val_squared_difference_loss: 11.6019 - val_KL_divergence_loss: 3.8006 - val_neg_log_likelihood: 210010601207779360768.0000\n",
      "Epoch 1591/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5575 - squared_difference_loss: 11.7365 - KL_divergence_loss: 3.8210 - neg_log_likelihood: 1189542196.8464 - val_loss: 15.3714 - val_squared_difference_loss: 11.5584 - val_KL_divergence_loss: 3.8130 - val_neg_log_likelihood: 39550742378965262336.0000\n",
      "Epoch 1592/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5769 - squared_difference_loss: 11.7701 - KL_divergence_loss: 3.8068 - neg_log_likelihood: 4722904524.0254 - val_loss: 15.3828 - val_squared_difference_loss: 11.5613 - val_KL_divergence_loss: 3.8215 - val_neg_log_likelihood: 142008476864560726016.0000\n",
      "Epoch 1593/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5546 - squared_difference_loss: 11.7173 - KL_divergence_loss: 3.8373 - neg_log_likelihood: 25543275361.7282 - val_loss: 15.3738 - val_squared_difference_loss: 11.5811 - val_KL_divergence_loss: 3.7927 - val_neg_log_likelihood: 58407782575517646848.0000\n",
      "Epoch 1594/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5548 - squared_difference_loss: 11.7505 - KL_divergence_loss: 3.8042 - neg_log_likelihood: 18943642827.6653 - val_loss: 15.3755 - val_squared_difference_loss: 11.5624 - val_KL_divergence_loss: 3.8132 - val_neg_log_likelihood: 51450585565012656128.0000\n",
      "Epoch 1595/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 15.5567 - squared_difference_loss: 11.7267 - KL_divergence_loss: 3.8301 - neg_log_likelihood: 6564790564.0989 - val_loss: 15.3776 - val_squared_difference_loss: 11.5511 - val_KL_divergence_loss: 3.8265 - val_neg_log_likelihood: 34955747429333086208.0000\n",
      "Epoch 1596/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5669 - squared_difference_loss: 11.7526 - KL_divergence_loss: 3.8143 - neg_log_likelihood: 16527352454.6734 - val_loss: 15.3888 - val_squared_difference_loss: 11.5656 - val_KL_divergence_loss: 3.8233 - val_neg_log_likelihood: 85879062575841312768.0000\n",
      "Epoch 1597/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5393 - squared_difference_loss: 11.7151 - KL_divergence_loss: 3.8242 - neg_log_likelihood: 13878735146.9501 - val_loss: 15.3583 - val_squared_difference_loss: 11.5375 - val_KL_divergence_loss: 3.8208 - val_neg_log_likelihood: 296397290198609821696.0000\n",
      "Epoch 1598/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5721 - squared_difference_loss: 11.7731 - KL_divergence_loss: 3.7990 - neg_log_likelihood: 396158139.1522 - val_loss: 15.3728 - val_squared_difference_loss: 11.5680 - val_KL_divergence_loss: 3.8048 - val_neg_log_likelihood: 190966627920978935808.0000\n",
      "Epoch 1599/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5547 - squared_difference_loss: 11.7258 - KL_divergence_loss: 3.8289 - neg_log_likelihood: 3574556923.0089 - val_loss: 15.3815 - val_squared_difference_loss: 11.5760 - val_KL_divergence_loss: 3.8055 - val_neg_log_likelihood: 83317054961548083200.0000\n",
      "Epoch 1600/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5565 - squared_difference_loss: 11.7532 - KL_divergence_loss: 3.8032 - neg_log_likelihood: 2224629911.0809 - val_loss: 15.3674 - val_squared_difference_loss: 11.5599 - val_KL_divergence_loss: 3.8075 - val_neg_log_likelihood: 28132889243261161472.0000\n",
      "Epoch 1601/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5801 - squared_difference_loss: 11.7609 - KL_divergence_loss: 3.8192 - neg_log_likelihood: 66698707.8342 - val_loss: 15.3530 - val_squared_difference_loss: 11.5453 - val_KL_divergence_loss: 3.8077 - val_neg_log_likelihood: 14889773396537335808.0000\n",
      "Epoch 1602/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5687 - squared_difference_loss: 11.7496 - KL_divergence_loss: 3.8191 - neg_log_likelihood: 4397000395.7767 - val_loss: 15.3353 - val_squared_difference_loss: 11.5347 - val_KL_divergence_loss: 3.8006 - val_neg_log_likelihood: 31378258791903793152.0000\n",
      "Epoch 1603/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5551 - squared_difference_loss: 11.7432 - KL_divergence_loss: 3.8119 - neg_log_likelihood: 503691694.8194 - val_loss: 15.3969 - val_squared_difference_loss: 11.5747 - val_KL_divergence_loss: 3.8222 - val_neg_log_likelihood: 47148694456473067520.0000\n",
      "Epoch 1604/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5627 - squared_difference_loss: 11.7361 - KL_divergence_loss: 3.8266 - neg_log_likelihood: 1738177918.8575 - val_loss: 15.3977 - val_squared_difference_loss: 11.5824 - val_KL_divergence_loss: 3.8152 - val_neg_log_likelihood: 27540641787830099968.0000\n",
      "Epoch 1605/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5571 - squared_difference_loss: 11.7364 - KL_divergence_loss: 3.8208 - neg_log_likelihood: 12743092283.7825 - val_loss: 15.3815 - val_squared_difference_loss: 11.5785 - val_KL_divergence_loss: 3.8031 - val_neg_log_likelihood: 43395595569679966208.0000\n",
      "Epoch 1606/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5821 - squared_difference_loss: 11.7769 - KL_divergence_loss: 3.8051 - neg_log_likelihood: 2222833808.3815 - val_loss: 15.3513 - val_squared_difference_loss: 11.5265 - val_KL_divergence_loss: 3.8248 - val_neg_log_likelihood: 62434246870460162048.0000\n",
      "Epoch 1607/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5931 - squared_difference_loss: 11.7517 - KL_divergence_loss: 3.8414 - neg_log_likelihood: 8870832089.9498 - val_loss: 15.3448 - val_squared_difference_loss: 11.5300 - val_KL_divergence_loss: 3.8148 - val_neg_log_likelihood: 13794943248752971776.0000\n",
      "Epoch 1608/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 15.5599 - squared_difference_loss: 11.7385 - KL_divergence_loss: 3.8214 - neg_log_likelihood: 178553292013.2040 - val_loss: 15.3602 - val_squared_difference_loss: 11.5518 - val_KL_divergence_loss: 3.8085 - val_neg_log_likelihood: 67487887793561190400.0000\n",
      "Epoch 1609/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5661 - squared_difference_loss: 11.7503 - KL_divergence_loss: 3.8158 - neg_log_likelihood: 27017280741.8114 - val_loss: 15.3338 - val_squared_difference_loss: 11.5173 - val_KL_divergence_loss: 3.8165 - val_neg_log_likelihood: 60028066450193760256.0000\n",
      "Epoch 1610/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5517 - squared_difference_loss: 11.7439 - KL_divergence_loss: 3.8079 - neg_log_likelihood: 221977229903.1379 - val_loss: 15.3791 - val_squared_difference_loss: 11.5561 - val_KL_divergence_loss: 3.8230 - val_neg_log_likelihood: 100188199257604194304.0000\n",
      "Epoch 1611/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5679 - squared_difference_loss: 11.7557 - KL_divergence_loss: 3.8122 - neg_log_likelihood: 4057557180.1270 - val_loss: 15.3728 - val_squared_difference_loss: 11.5519 - val_KL_divergence_loss: 3.8209 - val_neg_log_likelihood: 89108674668093030400.0000\n",
      "Epoch 1612/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5946 - squared_difference_loss: 11.7698 - KL_divergence_loss: 3.8248 - neg_log_likelihood: 4626250130.2543 - val_loss: 15.4109 - val_squared_difference_loss: 11.5978 - val_KL_divergence_loss: 3.8131 - val_neg_log_likelihood: 23657655236316672000.0000\n",
      "Epoch 1613/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5441 - squared_difference_loss: 11.7311 - KL_divergence_loss: 3.8129 - neg_log_likelihood: 23208642258.6453 - val_loss: 15.3368 - val_squared_difference_loss: 11.5209 - val_KL_divergence_loss: 3.8159 - val_neg_log_likelihood: 10291149255316731904.0000\n",
      "Epoch 1614/2000\n",
      "29507/29507 [==============================] - ETA: 0s - loss: 15.4903 - squared_difference_loss: 11.6894 - KL_divergence_loss: 3.8009 - neg_log_likelihood: 13916283051.610 - 0s 13us/step - loss: 15.5152 - squared_difference_loss: 11.7149 - KL_divergence_loss: 3.8003 - neg_log_likelihood: 12733918574.1880 - val_loss: 15.3817 - val_squared_difference_loss: 11.5916 - val_KL_divergence_loss: 3.7901 - val_neg_log_likelihood: 8453095524157893632.0000\n",
      "Epoch 1615/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5668 - squared_difference_loss: 11.7599 - KL_divergence_loss: 3.8069 - neg_log_likelihood: 91883948708.7250 - val_loss: 15.3617 - val_squared_difference_loss: 11.5598 - val_KL_divergence_loss: 3.8020 - val_neg_log_likelihood: 179025618975368675328.0000\n",
      "Epoch 1616/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5646 - squared_difference_loss: 11.7490 - KL_divergence_loss: 3.8156 - neg_log_likelihood: 344269769.4339 - val_loss: 15.3717 - val_squared_difference_loss: 11.5812 - val_KL_divergence_loss: 3.7904 - val_neg_log_likelihood: 59695819361335353344.0000\n",
      "Epoch 1617/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5604 - squared_difference_loss: 11.7554 - KL_divergence_loss: 3.8050 - neg_log_likelihood: 5330993287.4783 - val_loss: 15.3883 - val_squared_difference_loss: 11.6030 - val_KL_divergence_loss: 3.7852 - val_neg_log_likelihood: 41549558048158687232.0000\n",
      "Epoch 1618/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5956 - squared_difference_loss: 11.7901 - KL_divergence_loss: 3.8055 - neg_log_likelihood: 3009398620.7554 - val_loss: 15.3837 - val_squared_difference_loss: 11.5766 - val_KL_divergence_loss: 3.8070 - val_neg_log_likelihood: 80350211461565415424.0000\n",
      "Epoch 1619/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5775 - squared_difference_loss: 11.7649 - KL_divergence_loss: 3.8126 - neg_log_likelihood: 263705052.3065 - val_loss: 15.3757 - val_squared_difference_loss: 11.5511 - val_KL_divergence_loss: 3.8246 - val_neg_log_likelihood: 122508584044257411072.0000\n",
      "Epoch 1620/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5794 - squared_difference_loss: 11.7420 - KL_divergence_loss: 3.8374 - neg_log_likelihood: 1841994551.0212 - val_loss: 15.4315 - val_squared_difference_loss: 11.6372 - val_KL_divergence_loss: 3.7943 - val_neg_log_likelihood: 59111909572231184384.0000\n",
      "Epoch 1621/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5766 - squared_difference_loss: 11.7692 - KL_divergence_loss: 3.8074 - neg_log_likelihood: 1231098419.1083 - val_loss: 15.3851 - val_squared_difference_loss: 11.5733 - val_KL_divergence_loss: 3.8118 - val_neg_log_likelihood: 45853421623886553088.0000\n",
      "Epoch 1622/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5697 - squared_difference_loss: 11.7406 - KL_divergence_loss: 3.8292 - neg_log_likelihood: 76314718.3907 - val_loss: 15.3655 - val_squared_difference_loss: 11.5530 - val_KL_divergence_loss: 3.8125 - val_neg_log_likelihood: 78922527737507823616.0000\n",
      "Epoch 1623/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5600 - squared_difference_loss: 11.7456 - KL_divergence_loss: 3.8144 - neg_log_likelihood: 10749927573.9994 - val_loss: 15.3940 - val_squared_difference_loss: 11.5717 - val_KL_divergence_loss: 3.8223 - val_neg_log_likelihood: 49195519664339836928.0000\n",
      "Epoch 1624/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5342 - squared_difference_loss: 11.7010 - KL_divergence_loss: 3.8332 - neg_log_likelihood: 7007241116.7784 - val_loss: 15.3790 - val_squared_difference_loss: 11.5665 - val_KL_divergence_loss: 3.8125 - val_neg_log_likelihood: 95118700705070759936.0000\n",
      "Epoch 1625/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5516 - squared_difference_loss: 11.7407 - KL_divergence_loss: 3.8109 - neg_log_likelihood: 32504513166.5865 - val_loss: 15.3842 - val_squared_difference_loss: 11.5773 - val_KL_divergence_loss: 3.8069 - val_neg_log_likelihood: 33179138344610123776.0000\n",
      "Epoch 1626/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5428 - squared_difference_loss: 11.7198 - KL_divergence_loss: 3.8230 - neg_log_likelihood: 2883957101.5940 - val_loss: 15.3765 - val_squared_difference_loss: 11.5900 - val_KL_divergence_loss: 3.7865 - val_neg_log_likelihood: 56459458052201283584.0000\n",
      "Epoch 1627/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5647 - squared_difference_loss: 11.7664 - KL_divergence_loss: 3.7983 - neg_log_likelihood: 841471520.7325 - val_loss: 15.3783 - val_squared_difference_loss: 11.5551 - val_KL_divergence_loss: 3.8231 - val_neg_log_likelihood: 45967624097720885248.0000\n",
      "Epoch 1628/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5636 - squared_difference_loss: 11.7336 - KL_divergence_loss: 3.8299 - neg_log_likelihood: 216457699.2375 - val_loss: 15.4039 - val_squared_difference_loss: 11.5952 - val_KL_divergence_loss: 3.8087 - val_neg_log_likelihood: 19325981063689519104.0000\n",
      "Epoch 1629/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5542 - squared_difference_loss: 11.7336 - KL_divergence_loss: 3.8205 - neg_log_likelihood: 1935017779.1587 - val_loss: 15.3557 - val_squared_difference_loss: 11.5458 - val_KL_divergence_loss: 3.8099 - val_neg_log_likelihood: 17880141801521512448.0000\n",
      "Epoch 1630/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5484 - squared_difference_loss: 11.7302 - KL_divergence_loss: 3.8182 - neg_log_likelihood: 1127358305.5956 - val_loss: 15.3800 - val_squared_difference_loss: 11.5761 - val_KL_divergence_loss: 3.8039 - val_neg_log_likelihood: 113483835690447290368.0000\n",
      "Epoch 1631/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5913 - squared_difference_loss: 11.7780 - KL_divergence_loss: 3.8133 - neg_log_likelihood: 6434470840.7575 - val_loss: 15.3975 - val_squared_difference_loss: 11.5667 - val_KL_divergence_loss: 3.8308 - val_neg_log_likelihood: 76775382448242442240.0000\n",
      "Epoch 1632/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5544 - squared_difference_loss: 11.7499 - KL_divergence_loss: 3.8046 - neg_log_likelihood: 6376041264.1240 - val_loss: 15.3748 - val_squared_difference_loss: 11.5754 - val_KL_divergence_loss: 3.7994 - val_neg_log_likelihood: 61407609871425159168.0000\n",
      "Epoch 1633/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5590 - squared_difference_loss: 11.7485 - KL_divergence_loss: 3.8105 - neg_log_likelihood: 3666411647.5887 - val_loss: 15.3842 - val_squared_difference_loss: 11.5606 - val_KL_divergence_loss: 3.8235 - val_neg_log_likelihood: 40599012459078516736.0000\n",
      "Epoch 1634/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5582 - squared_difference_loss: 11.7424 - KL_divergence_loss: 3.8157 - neg_log_likelihood: 5595007691.2034 - val_loss: 15.3470 - val_squared_difference_loss: 11.5427 - val_KL_divergence_loss: 3.8043 - val_neg_log_likelihood: 63695587262185103360.0000\n",
      "Epoch 1635/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5399 - squared_difference_loss: 11.7368 - KL_divergence_loss: 3.8031 - neg_log_likelihood: 12761050781.3661 - val_loss: 15.3502 - val_squared_difference_loss: 11.5374 - val_KL_divergence_loss: 3.8128 - val_neg_log_likelihood: 61201071719762878464.0000\n",
      "Epoch 1636/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5810 - squared_difference_loss: 11.7595 - KL_divergence_loss: 3.8215 - neg_log_likelihood: 781291209.7828 - val_loss: 15.3661 - val_squared_difference_loss: 11.5428 - val_KL_divergence_loss: 3.8233 - val_neg_log_likelihood: 87226545869016858624.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1637/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5421 - squared_difference_loss: 11.7129 - KL_divergence_loss: 3.8292 - neg_log_likelihood: 4493284732.8903 - val_loss: 15.3776 - val_squared_difference_loss: 11.5596 - val_KL_divergence_loss: 3.8180 - val_neg_log_likelihood: 141617311925599961088.0000\n",
      "Epoch 1638/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5447 - squared_difference_loss: 11.7432 - KL_divergence_loss: 3.8016 - neg_log_likelihood: 22798692096.7003 - val_loss: 15.3578 - val_squared_difference_loss: 11.5627 - val_KL_divergence_loss: 3.7951 - val_neg_log_likelihood: 164166168409886883840.0000\n",
      "Epoch 1639/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5576 - squared_difference_loss: 11.7611 - KL_divergence_loss: 3.7965 - neg_log_likelihood: 2586010123.2929 - val_loss: 15.3656 - val_squared_difference_loss: 11.5511 - val_KL_divergence_loss: 3.8146 - val_neg_log_likelihood: 74074250938319847424.0000\n",
      "Epoch 1640/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5643 - squared_difference_loss: 11.7555 - KL_divergence_loss: 3.8088 - neg_log_likelihood: 1510665662.4268 - val_loss: 15.3801 - val_squared_difference_loss: 11.5719 - val_KL_divergence_loss: 3.8081 - val_neg_log_likelihood: 70706933780949286912.0000\n",
      "Epoch 1641/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5325 - squared_difference_loss: 11.7170 - KL_divergence_loss: 3.8155 - neg_log_likelihood: 2943404278.6999 - val_loss: 15.3597 - val_squared_difference_loss: 11.5531 - val_KL_divergence_loss: 3.8066 - val_neg_log_likelihood: 25413922110108487680.0000\n",
      "Epoch 1642/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5373 - squared_difference_loss: 11.7169 - KL_divergence_loss: 3.8204 - neg_log_likelihood: 9796493854.6480 - val_loss: 15.3419 - val_squared_difference_loss: 11.5083 - val_KL_divergence_loss: 3.8337 - val_neg_log_likelihood: 115326097989675745280.0000\n",
      "Epoch 1643/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5466 - squared_difference_loss: 11.7228 - KL_divergence_loss: 3.8238 - neg_log_likelihood: 14404622594.5458 - val_loss: 15.3596 - val_squared_difference_loss: 11.5313 - val_KL_divergence_loss: 3.8284 - val_neg_log_likelihood: 40786877607311425536.0000\n",
      "Epoch 1644/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5565 - squared_difference_loss: 11.7442 - KL_divergence_loss: 3.8123 - neg_log_likelihood: 1012546094.8305 - val_loss: 15.3741 - val_squared_difference_loss: 11.5469 - val_KL_divergence_loss: 3.8272 - val_neg_log_likelihood: 152180446617969033216.0000\n",
      "Epoch 1645/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 15.5682 - squared_difference_loss: 11.7595 - KL_divergence_loss: 3.8087 - neg_log_likelihood: 5369492868.4906 - val_loss: 15.3701 - val_squared_difference_loss: 11.5591 - val_KL_divergence_loss: 3.8110 - val_neg_log_likelihood: 38962692944226746368.0000\n",
      "Epoch 1646/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5537 - squared_difference_loss: 11.7424 - KL_divergence_loss: 3.8113 - neg_log_likelihood: 3392688298.0404 - val_loss: 15.3599 - val_squared_difference_loss: 11.5409 - val_KL_divergence_loss: 3.8191 - val_neg_log_likelihood: 30706773359483006976.0000\n",
      "Epoch 1647/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5555 - squared_difference_loss: 11.7457 - KL_divergence_loss: 3.8098 - neg_log_likelihood: 2448714493.7671 - val_loss: 15.3655 - val_squared_difference_loss: 11.5442 - val_KL_divergence_loss: 3.8213 - val_neg_log_likelihood: 8548552621229859840.0000\n",
      "Epoch 1648/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5247 - squared_difference_loss: 11.7203 - KL_divergence_loss: 3.8044 - neg_log_likelihood: 4010091324.6382 - val_loss: 15.3638 - val_squared_difference_loss: 11.5778 - val_KL_divergence_loss: 3.7860 - val_neg_log_likelihood: 148251359077904154624.0000\n",
      "Epoch 1649/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5517 - squared_difference_loss: 11.7551 - KL_divergence_loss: 3.7967 - neg_log_likelihood: 962205394.3193 - val_loss: 15.3425 - val_squared_difference_loss: 11.5449 - val_KL_divergence_loss: 3.7976 - val_neg_log_likelihood: 40028350782524489728.0000\n",
      "Epoch 1650/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 15.5311 - squared_difference_loss: 11.7214 - KL_divergence_loss: 3.8097 - neg_log_likelihood: 8992578319.6161 - val_loss: 15.3778 - val_squared_difference_loss: 11.5798 - val_KL_divergence_loss: 3.7980 - val_neg_log_likelihood: 18943440385721638912.0000\n",
      "Epoch 1651/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5701 - squared_difference_loss: 11.7628 - KL_divergence_loss: 3.8073 - neg_log_likelihood: 4742879563.7762 - val_loss: 15.3417 - val_squared_difference_loss: 11.5226 - val_KL_divergence_loss: 3.8191 - val_neg_log_likelihood: 47209643268785094656.0000\n",
      "Epoch 1652/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5589 - squared_difference_loss: 11.7273 - KL_divergence_loss: 3.8316 - neg_log_likelihood: 5639068541.8808 - val_loss: 15.3751 - val_squared_difference_loss: 11.5695 - val_KL_divergence_loss: 3.8056 - val_neg_log_likelihood: 17058903725893451776.0000\n",
      "Epoch 1653/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5208 - squared_difference_loss: 11.7163 - KL_divergence_loss: 3.8045 - neg_log_likelihood: 960880806.8149 - val_loss: 15.3472 - val_squared_difference_loss: 11.5645 - val_KL_divergence_loss: 3.7827 - val_neg_log_likelihood: 50719200230188662784.0000\n",
      "Epoch 1654/2000\n",
      "29507/29507 [==============================] - ETA: 0s - loss: 15.5009 - squared_difference_loss: 11.7163 - KL_divergence_loss: 3.7846 - neg_log_likelihood: 22433082143.067 - 0s 14us/step - loss: 15.5126 - squared_difference_loss: 11.7274 - KL_divergence_loss: 3.7853 - neg_log_likelihood: 21397350388.2002 - val_loss: 15.3713 - val_squared_difference_loss: 11.5838 - val_KL_divergence_loss: 3.7875 - val_neg_log_likelihood: 43099025264868646912.0000\n",
      "Epoch 1655/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5688 - squared_difference_loss: 11.7582 - KL_divergence_loss: 3.8106 - neg_log_likelihood: 521794125.7185 - val_loss: 15.3751 - val_squared_difference_loss: 11.5681 - val_KL_divergence_loss: 3.8070 - val_neg_log_likelihood: 107943016248346083328.0000\n",
      "Epoch 1656/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5594 - squared_difference_loss: 11.7448 - KL_divergence_loss: 3.8146 - neg_log_likelihood: 2559552936.9466 - val_loss: 15.3646 - val_squared_difference_loss: 11.5356 - val_KL_divergence_loss: 3.8290 - val_neg_log_likelihood: 165649403745845215232.0000\n",
      "Epoch 1657/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5164 - squared_difference_loss: 11.7130 - KL_divergence_loss: 3.8034 - neg_log_likelihood: 19393782477.5766 - val_loss: 15.3646 - val_squared_difference_loss: 11.5538 - val_KL_divergence_loss: 3.8108 - val_neg_log_likelihood: 88261056029771890688.0000\n",
      "Epoch 1658/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5633 - squared_difference_loss: 11.7502 - KL_divergence_loss: 3.8130 - neg_log_likelihood: 6225191092.0978 - val_loss: 15.3627 - val_squared_difference_loss: 11.5759 - val_KL_divergence_loss: 3.7868 - val_neg_log_likelihood: 23470799970345914368.0000\n",
      "Epoch 1659/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5523 - squared_difference_loss: 11.7400 - KL_divergence_loss: 3.8123 - neg_log_likelihood: 9620099166.8289 - val_loss: 15.3909 - val_squared_difference_loss: 11.5707 - val_KL_divergence_loss: 3.8203 - val_neg_log_likelihood: 89923031501998325760.0000\n",
      "Epoch 1660/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5668 - squared_difference_loss: 11.7256 - KL_divergence_loss: 3.8412 - neg_log_likelihood: 6376502472.6502 - val_loss: 15.3610 - val_squared_difference_loss: 11.5663 - val_KL_divergence_loss: 3.7948 - val_neg_log_likelihood: 60192979793261125632.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1661/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5869 - squared_difference_loss: 11.7687 - KL_divergence_loss: 3.8182 - neg_log_likelihood: 5986135145.3253 - val_loss: 15.3662 - val_squared_difference_loss: 11.5502 - val_KL_divergence_loss: 3.8161 - val_neg_log_likelihood: 119045164293973114880.0000\n",
      "Epoch 1662/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5476 - squared_difference_loss: 11.7352 - KL_divergence_loss: 3.8124 - neg_log_likelihood: 1369684617.0145 - val_loss: 15.3917 - val_squared_difference_loss: 11.5830 - val_KL_divergence_loss: 3.8087 - val_neg_log_likelihood: 84950714846749573120.0000\n",
      "Epoch 1663/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5520 - squared_difference_loss: 11.7261 - KL_divergence_loss: 3.8259 - neg_log_likelihood: 41035727632.7719 - val_loss: 15.3473 - val_squared_difference_loss: 11.5203 - val_KL_divergence_loss: 3.8270 - val_neg_log_likelihood: 84050137393335943168.0000\n",
      "Epoch 1664/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5495 - squared_difference_loss: 11.7303 - KL_divergence_loss: 3.8192 - neg_log_likelihood: 559419327.5687 - val_loss: 15.3682 - val_squared_difference_loss: 11.5630 - val_KL_divergence_loss: 3.8052 - val_neg_log_likelihood: 52696157410004869120.0000\n",
      "Epoch 1665/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5579 - squared_difference_loss: 11.7527 - KL_divergence_loss: 3.8052 - neg_log_likelihood: 3989268210.2324 - val_loss: 15.3584 - val_squared_difference_loss: 11.5420 - val_KL_divergence_loss: 3.8164 - val_neg_log_likelihood: 99992099334532775936.0000\n",
      "Epoch 1666/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5603 - squared_difference_loss: 11.7380 - KL_divergence_loss: 3.8223 - neg_log_likelihood: 67600731314.8121 - val_loss: 15.3563 - val_squared_difference_loss: 11.5501 - val_KL_divergence_loss: 3.8061 - val_neg_log_likelihood: 33817089101816295424.0000\n",
      "Epoch 1667/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5546 - squared_difference_loss: 11.7331 - KL_divergence_loss: 3.8215 - neg_log_likelihood: 11840737897.2781 - val_loss: 15.3863 - val_squared_difference_loss: 11.5808 - val_KL_divergence_loss: 3.8055 - val_neg_log_likelihood: 16488101480450297856.0000\n",
      "Epoch 1668/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5284 - squared_difference_loss: 11.7250 - KL_divergence_loss: 3.8034 - neg_log_likelihood: 2188071870.9912 - val_loss: 15.3630 - val_squared_difference_loss: 11.5620 - val_KL_divergence_loss: 3.8010 - val_neg_log_likelihood: 35770399081226637312.0000\n",
      "Epoch 1669/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5744 - squared_difference_loss: 11.7649 - KL_divergence_loss: 3.8094 - neg_log_likelihood: 5151289151.0670 - val_loss: 15.3532 - val_squared_difference_loss: 11.5310 - val_KL_divergence_loss: 3.8222 - val_neg_log_likelihood: 51284626179472490496.0000\n",
      "Epoch 1670/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5626 - squared_difference_loss: 11.7423 - KL_divergence_loss: 3.8203 - neg_log_likelihood: 11505086646.5878 - val_loss: 15.3621 - val_squared_difference_loss: 11.5512 - val_KL_divergence_loss: 3.8109 - val_neg_log_likelihood: 56943826737831993344.0000\n",
      "Epoch 1671/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5595 - squared_difference_loss: 11.7499 - KL_divergence_loss: 3.8096 - neg_log_likelihood: 1039687962.8959 - val_loss: 15.3584 - val_squared_difference_loss: 11.5408 - val_KL_divergence_loss: 3.8176 - val_neg_log_likelihood: 104822643554375122944.0000\n",
      "Epoch 1672/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5674 - squared_difference_loss: 11.7474 - KL_divergence_loss: 3.8200 - neg_log_likelihood: 147066177427.8701 - val_loss: 15.3727 - val_squared_difference_loss: 11.5697 - val_KL_divergence_loss: 3.8030 - val_neg_log_likelihood: 57910405136517922816.0000\n",
      "Epoch 1673/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5450 - squared_difference_loss: 11.7237 - KL_divergence_loss: 3.8213 - neg_log_likelihood: 3388732526.5499 - val_loss: 15.3667 - val_squared_difference_loss: 11.5431 - val_KL_divergence_loss: 3.8236 - val_neg_log_likelihood: 109648936685713506304.0000\n",
      "Epoch 1674/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5502 - squared_difference_loss: 11.7455 - KL_divergence_loss: 3.8047 - neg_log_likelihood: 14417436034.8079 - val_loss: 15.3655 - val_squared_difference_loss: 11.5460 - val_KL_divergence_loss: 3.8196 - val_neg_log_likelihood: 18655673858534940672.0000\n",
      "Epoch 1675/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5780 - squared_difference_loss: 11.7643 - KL_divergence_loss: 3.8137 - neg_log_likelihood: 34269628090.6591 - val_loss: 15.3429 - val_squared_difference_loss: 11.5407 - val_KL_divergence_loss: 3.8022 - val_neg_log_likelihood: 36617377940947300352.0000\n",
      "Epoch 1676/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5624 - squared_difference_loss: 11.7534 - KL_divergence_loss: 3.8091 - neg_log_likelihood: 25414641093.9155 - val_loss: 15.3446 - val_squared_difference_loss: 11.5490 - val_KL_divergence_loss: 3.7956 - val_neg_log_likelihood: 54588724491308187648.0000\n",
      "Epoch 1677/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5254 - squared_difference_loss: 11.7340 - KL_divergence_loss: 3.7914 - neg_log_likelihood: 6632400183.8661 - val_loss: 15.3681 - val_squared_difference_loss: 11.5801 - val_KL_divergence_loss: 3.7880 - val_neg_log_likelihood: 94002916281951371264.0000\n",
      "Epoch 1678/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5635 - squared_difference_loss: 11.7406 - KL_divergence_loss: 3.8229 - neg_log_likelihood: 1162319743.2915 - val_loss: 15.3528 - val_squared_difference_loss: 11.5498 - val_KL_divergence_loss: 3.8030 - val_neg_log_likelihood: 99481596214618112000.0000\n",
      "Epoch 1679/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5456 - squared_difference_loss: 11.7500 - KL_divergence_loss: 3.7956 - neg_log_likelihood: 13673480020.5760 - val_loss: 15.3277 - val_squared_difference_loss: 11.5421 - val_KL_divergence_loss: 3.7856 - val_neg_log_likelihood: 41559144941077094400.0000\n",
      "Epoch 1680/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.4958 - squared_difference_loss: 11.6985 - KL_divergence_loss: 3.7974 - neg_log_likelihood: 777869339688.4932 - val_loss: 15.3602 - val_squared_difference_loss: 11.5682 - val_KL_divergence_loss: 3.7920 - val_neg_log_likelihood: 25830381316477018112.0000\n",
      "Epoch 1681/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5328 - squared_difference_loss: 11.7342 - KL_divergence_loss: 3.7986 - neg_log_likelihood: 12823283930.9466 - val_loss: 15.3956 - val_squared_difference_loss: 11.5894 - val_KL_divergence_loss: 3.8061 - val_neg_log_likelihood: 27788534763695579136.0000\n",
      "Epoch 1682/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5510 - squared_difference_loss: 11.7571 - KL_divergence_loss: 3.7939 - neg_log_likelihood: 106920393903.0775 - val_loss: 15.3679 - val_squared_difference_loss: 11.5737 - val_KL_divergence_loss: 3.7943 - val_neg_log_likelihood: 17800202849923020800.0000\n",
      "Epoch 1683/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5852 - squared_difference_loss: 11.7575 - KL_divergence_loss: 3.8277 - neg_log_likelihood: 11585281020.0882 - val_loss: 15.3704 - val_squared_difference_loss: 11.5618 - val_KL_divergence_loss: 3.8087 - val_neg_log_likelihood: 17721905366237671424.0000\n",
      "Epoch 1684/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5839 - squared_difference_loss: 11.7484 - KL_divergence_loss: 3.8355 - neg_log_likelihood: 2744366472.7501 - val_loss: 15.4100 - val_squared_difference_loss: 11.5885 - val_KL_divergence_loss: 3.8214 - val_neg_log_likelihood: 73857986821091409920.0000\n",
      "Epoch 1685/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5435 - squared_difference_loss: 11.7214 - KL_divergence_loss: 3.8220 - neg_log_likelihood: 43703792733.3404 - val_loss: 15.3510 - val_squared_difference_loss: 11.5506 - val_KL_divergence_loss: 3.8004 - val_neg_log_likelihood: 24841560530089914368.0000\n",
      "Epoch 1686/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5462 - squared_difference_loss: 11.7317 - KL_divergence_loss: 3.8144 - neg_log_likelihood: 3870177044.5912 - val_loss: 15.3617 - val_squared_difference_loss: 11.5518 - val_KL_divergence_loss: 3.8099 - val_neg_log_likelihood: 39013662607768952832.0000\n",
      "Epoch 1687/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5324 - squared_difference_loss: 11.7099 - KL_divergence_loss: 3.8224 - neg_log_likelihood: 44094273890.7604 - val_loss: 15.3488 - val_squared_difference_loss: 11.5526 - val_KL_divergence_loss: 3.7963 - val_neg_log_likelihood: 36246518969455693824.0000\n",
      "Epoch 1688/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5580 - squared_difference_loss: 11.7395 - KL_divergence_loss: 3.8186 - neg_log_likelihood: 5577958068.1743 - val_loss: 15.4170 - val_squared_difference_loss: 11.6164 - val_KL_divergence_loss: 3.8005 - val_neg_log_likelihood: 50853255264129925120.0000\n",
      "Epoch 1689/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5225 - squared_difference_loss: 11.7105 - KL_divergence_loss: 3.8119 - neg_log_likelihood: 56784862191.6633 - val_loss: 15.3632 - val_squared_difference_loss: 11.5681 - val_KL_divergence_loss: 3.7951 - val_neg_log_likelihood: 38638374704771973120.0000\n",
      "Epoch 1690/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5617 - squared_difference_loss: 11.7475 - KL_divergence_loss: 3.8142 - neg_log_likelihood: 20098311867.9466 - val_loss: 15.3883 - val_squared_difference_loss: 11.5708 - val_KL_divergence_loss: 3.8174 - val_neg_log_likelihood: 27568003000303095808.0000\n",
      "Epoch 1691/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5258 - squared_difference_loss: 11.7185 - KL_divergence_loss: 3.8073 - neg_log_likelihood: 60509972775.8187 - val_loss: 15.3496 - val_squared_difference_loss: 11.5343 - val_KL_divergence_loss: 3.8153 - val_neg_log_likelihood: 40607186063824904192.0000\n",
      "Epoch 1692/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5462 - squared_difference_loss: 11.7381 - KL_divergence_loss: 3.8082 - neg_log_likelihood: 6910313016.7265 - val_loss: 15.3769 - val_squared_difference_loss: 11.5830 - val_KL_divergence_loss: 3.7939 - val_neg_log_likelihood: 50164206869203173376.0000\n",
      "Epoch 1693/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5577 - squared_difference_loss: 11.7464 - KL_divergence_loss: 3.8113 - neg_log_likelihood: 1028105365.9881 - val_loss: 15.3207 - val_squared_difference_loss: 11.5117 - val_KL_divergence_loss: 3.8090 - val_neg_log_likelihood: 24288150156830334976.0000\n",
      "Epoch 1694/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5721 - squared_difference_loss: 11.7692 - KL_divergence_loss: 3.8029 - neg_log_likelihood: 3077754541.3084 - val_loss: 15.3973 - val_squared_difference_loss: 11.6160 - val_KL_divergence_loss: 3.7813 - val_neg_log_likelihood: 21001047344475910144.0000\n",
      "Epoch 1695/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5846 - squared_difference_loss: 11.7713 - KL_divergence_loss: 3.8133 - neg_log_likelihood: 3895395115.4564 - val_loss: 15.3909 - val_squared_difference_loss: 11.5828 - val_KL_divergence_loss: 3.8081 - val_neg_log_likelihood: 33970935585557110784.0000\n",
      "Epoch 1696/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5382 - squared_difference_loss: 11.7206 - KL_divergence_loss: 3.8176 - neg_log_likelihood: 29098175328.5342 - val_loss: 15.3472 - val_squared_difference_loss: 11.5355 - val_KL_divergence_loss: 3.8117 - val_neg_log_likelihood: 41933442424107974656.0000\n",
      "Epoch 1697/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5405 - squared_difference_loss: 11.7241 - KL_divergence_loss: 3.8164 - neg_log_likelihood: 3183373947.7923 - val_loss: 15.3598 - val_squared_difference_loss: 11.5654 - val_KL_divergence_loss: 3.7944 - val_neg_log_likelihood: 25998761068175626240.0000\n",
      "Epoch 1698/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5571 - squared_difference_loss: 11.7663 - KL_divergence_loss: 3.7909 - neg_log_likelihood: 38009426678.1229 - val_loss: 15.3674 - val_squared_difference_loss: 11.5835 - val_KL_divergence_loss: 3.7839 - val_neg_log_likelihood: 18228994836675796992.0000\n",
      "Epoch 1699/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5501 - squared_difference_loss: 11.7391 - KL_divergence_loss: 3.8110 - neg_log_likelihood: 41834623940.8474 - val_loss: 15.3596 - val_squared_difference_loss: 11.5761 - val_KL_divergence_loss: 3.7835 - val_neg_log_likelihood: 12995961440524765184.0000\n",
      "Epoch 1700/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 15.5573 - squared_difference_loss: 11.7600 - KL_divergence_loss: 3.7973 - neg_log_likelihood: 2173275403.2779 - val_loss: 15.3595 - val_squared_difference_loss: 11.5543 - val_KL_divergence_loss: 3.8051 - val_neg_log_likelihood: 33479111037412560896.0000\n",
      "Epoch 1701/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5181 - squared_difference_loss: 11.7063 - KL_divergence_loss: 3.8117 - neg_log_likelihood: 17278932141.0576 - val_loss: 15.3769 - val_squared_difference_loss: 11.5719 - val_KL_divergence_loss: 3.8050 - val_neg_log_likelihood: 16538122459753990144.0000\n",
      "Epoch 1702/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5594 - squared_difference_loss: 11.7605 - KL_divergence_loss: 3.7989 - neg_log_likelihood: 28183773914.2960 - val_loss: 15.3602 - val_squared_difference_loss: 11.5467 - val_KL_divergence_loss: 3.8135 - val_neg_log_likelihood: 106873135373626228736.0000\n",
      "Epoch 1703/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5498 - squared_difference_loss: 11.7366 - KL_divergence_loss: 3.8132 - neg_log_likelihood: 20239372996.9021 - val_loss: 15.3587 - val_squared_difference_loss: 11.5294 - val_KL_divergence_loss: 3.8293 - val_neg_log_likelihood: 29044703363877294080.0000\n",
      "Epoch 1704/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5770 - squared_difference_loss: 11.7473 - KL_divergence_loss: 3.8297 - neg_log_likelihood: 89609851.6783 - val_loss: 15.3590 - val_squared_difference_loss: 11.5300 - val_KL_divergence_loss: 3.8290 - val_neg_log_likelihood: 19081690727730696192.0000\n",
      "Epoch 1705/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5627 - squared_difference_loss: 11.7374 - KL_divergence_loss: 3.8253 - neg_log_likelihood: 6129570525.3681 - val_loss: 15.3554 - val_squared_difference_loss: 11.5215 - val_KL_divergence_loss: 3.8339 - val_neg_log_likelihood: 33487134437505646592.0000\n",
      "Epoch 1706/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5597 - squared_difference_loss: 11.7372 - KL_divergence_loss: 3.8225 - neg_log_likelihood: 4269309430.2750 - val_loss: 15.3610 - val_squared_difference_loss: 11.5327 - val_KL_divergence_loss: 3.8284 - val_neg_log_likelihood: 17224776887958392832.0000\n",
      "Epoch 1707/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5466 - squared_difference_loss: 11.7443 - KL_divergence_loss: 3.8024 - neg_log_likelihood: 3451478289.4420 - val_loss: 15.3508 - val_squared_difference_loss: 11.5513 - val_KL_divergence_loss: 3.7995 - val_neg_log_likelihood: 31416297551282876416.0000\n",
      "Epoch 1708/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5876 - squared_difference_loss: 11.7656 - KL_divergence_loss: 3.8220 - neg_log_likelihood: 3689512389.0513 - val_loss: 15.3651 - val_squared_difference_loss: 11.5482 - val_KL_divergence_loss: 3.8170 - val_neg_log_likelihood: 19412118397061013504.0000\n",
      "Epoch 1709/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5453 - squared_difference_loss: 11.7305 - KL_divergence_loss: 3.8149 - neg_log_likelihood: 4017284748.3212 - val_loss: 15.3938 - val_squared_difference_loss: 11.5905 - val_KL_divergence_loss: 3.8033 - val_neg_log_likelihood: 63135847746583298048.0000\n",
      "Epoch 1710/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 15.5722 - squared_difference_loss: 11.7428 - KL_divergence_loss: 3.8294 - neg_log_likelihood: 5130908698.4156 - val_loss: 15.3657 - val_squared_difference_loss: 11.5474 - val_KL_divergence_loss: 3.8183 - val_neg_log_likelihood: 56389790361241133056.0000\n",
      "Epoch 1711/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 15.5468 - squared_difference_loss: 11.7361 - KL_divergence_loss: 3.8108 - neg_log_likelihood: 9864983022.5894 - val_loss: 15.3849 - val_squared_difference_loss: 11.5968 - val_KL_divergence_loss: 3.7881 - val_neg_log_likelihood: 42163702990221869056.0000\n",
      "Epoch 1712/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5462 - squared_difference_loss: 11.7348 - KL_divergence_loss: 3.8115 - neg_log_likelihood: 41713131097.9819 - val_loss: 15.3570 - val_squared_difference_loss: 11.5366 - val_KL_divergence_loss: 3.8205 - val_neg_log_likelihood: 6094637436759476224.0000\n",
      "Epoch 1713/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 15.5403 - squared_difference_loss: 11.7350 - KL_divergence_loss: 3.8053 - neg_log_likelihood: 36535188010.6096 - val_loss: 15.3626 - val_squared_difference_loss: 11.5722 - val_KL_divergence_loss: 3.7904 - val_neg_log_likelihood: 107518923121768349696.0000\n",
      "Epoch 1714/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 15.5592 - squared_difference_loss: 11.7684 - KL_divergence_loss: 3.7907 - neg_log_likelihood: 13270647559.8800 - val_loss: 15.3503 - val_squared_difference_loss: 11.5479 - val_KL_divergence_loss: 3.8024 - val_neg_log_likelihood: 18942619682609737728.0000\n",
      "Epoch 1715/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5622 - squared_difference_loss: 11.7300 - KL_divergence_loss: 3.8321 - neg_log_likelihood: 79314503.2009 - val_loss: 15.3647 - val_squared_difference_loss: 11.5550 - val_KL_divergence_loss: 3.8097 - val_neg_log_likelihood: 54593120036994162688.0000\n",
      "Epoch 1716/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5423 - squared_difference_loss: 11.7279 - KL_divergence_loss: 3.8145 - neg_log_likelihood: 7144899028.4748 - val_loss: 15.3726 - val_squared_difference_loss: 11.5527 - val_KL_divergence_loss: 3.8198 - val_neg_log_likelihood: 96625817039291957248.0000\n",
      "Epoch 1717/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 15.5407 - squared_difference_loss: 11.7319 - KL_divergence_loss: 3.8087 - neg_log_likelihood: 13572299781.2761 - val_loss: 15.3628 - val_squared_difference_loss: 11.5675 - val_KL_divergence_loss: 3.7952 - val_neg_log_likelihood: 37211083200290799616.0000\n",
      "Epoch 1718/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 15.5720 - squared_difference_loss: 11.7360 - KL_divergence_loss: 3.8360 - neg_log_likelihood: 12517279670.9109 - val_loss: 15.3600 - val_squared_difference_loss: 11.5433 - val_KL_divergence_loss: 3.8167 - val_neg_log_likelihood: 10873934433249056768.0000\n",
      "Epoch 1719/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5435 - squared_difference_loss: 11.7280 - KL_divergence_loss: 3.8155 - neg_log_likelihood: 6782244191.5951 - val_loss: 15.3631 - val_squared_difference_loss: 11.5598 - val_KL_divergence_loss: 3.8033 - val_neg_log_likelihood: 26671164568707100672.0000\n",
      "Epoch 1720/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5601 - squared_difference_loss: 11.7446 - KL_divergence_loss: 3.8154 - neg_log_likelihood: 6568815496.0603 - val_loss: 15.3694 - val_squared_difference_loss: 11.5724 - val_KL_divergence_loss: 3.7969 - val_neg_log_likelihood: 5703565274386657280.0000\n",
      "Epoch 1721/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 15.5695 - squared_difference_loss: 11.7497 - KL_divergence_loss: 3.8198 - neg_log_likelihood: 701988770.7926 - val_loss: 15.3609 - val_squared_difference_loss: 11.5610 - val_KL_divergence_loss: 3.7999 - val_neg_log_likelihood: 47585757418077962240.0000\n",
      "Epoch 1722/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5626 - squared_difference_loss: 11.7547 - KL_divergence_loss: 3.8079 - neg_log_likelihood: 4940792142.4586 - val_loss: 15.3918 - val_squared_difference_loss: 11.5740 - val_KL_divergence_loss: 3.8178 - val_neg_log_likelihood: 8647033815526279168.0000\n",
      "Epoch 1723/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5508 - squared_difference_loss: 11.7200 - KL_divergence_loss: 3.8308 - neg_log_likelihood: 1195762967.1327 - val_loss: 15.3597 - val_squared_difference_loss: 11.5515 - val_KL_divergence_loss: 3.8082 - val_neg_log_likelihood: 19453547021061423104.0000\n",
      "Epoch 1724/2000\n",
      "29507/29507 [==============================] - 0s 12us/step - loss: 15.5113 - squared_difference_loss: 11.7068 - KL_divergence_loss: 3.8045 - neg_log_likelihood: 15724589967.4800 - val_loss: 15.3609 - val_squared_difference_loss: 11.5768 - val_KL_divergence_loss: 3.7841 - val_neg_log_likelihood: 31780724389130379264.0000\n",
      "Epoch 1725/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5622 - squared_difference_loss: 11.7565 - KL_divergence_loss: 3.8057 - neg_log_likelihood: 1358960486.0168 - val_loss: 15.3556 - val_squared_difference_loss: 11.5587 - val_KL_divergence_loss: 3.7970 - val_neg_log_likelihood: 93658088859206696960.0000\n",
      "Epoch 1726/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5611 - squared_difference_loss: 11.7375 - KL_divergence_loss: 3.8235 - neg_log_likelihood: 2831796098.0127 - val_loss: 15.3542 - val_squared_difference_loss: 11.5306 - val_KL_divergence_loss: 3.8237 - val_neg_log_likelihood: 64024284461752934400.0000\n",
      "Epoch 1727/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5319 - squared_difference_loss: 11.7110 - KL_divergence_loss: 3.8208 - neg_log_likelihood: 27607293563.6501 - val_loss: 15.3446 - val_squared_difference_loss: 11.5381 - val_KL_divergence_loss: 3.8064 - val_neg_log_likelihood: 29792424819881193472.0000\n",
      "Epoch 1728/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5459 - squared_difference_loss: 11.7359 - KL_divergence_loss: 3.8100 - neg_log_likelihood: 21546413115.6086 - val_loss: 15.3686 - val_squared_difference_loss: 11.5674 - val_KL_divergence_loss: 3.8012 - val_neg_log_likelihood: 18949788995684429824.0000\n",
      "Epoch 1729/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5312 - squared_difference_loss: 11.7340 - KL_divergence_loss: 3.7972 - neg_log_likelihood: 8245750248.8256 - val_loss: 15.3615 - val_squared_difference_loss: 11.5535 - val_KL_divergence_loss: 3.8081 - val_neg_log_likelihood: 76180088553355362304.0000\n",
      "Epoch 1730/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5706 - squared_difference_loss: 11.7485 - KL_divergence_loss: 3.8221 - neg_log_likelihood: 31483777303.7174 - val_loss: 15.3555 - val_squared_difference_loss: 11.5153 - val_KL_divergence_loss: 3.8402 - val_neg_log_likelihood: 16254732035292518400.0000\n",
      "Epoch 1731/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5568 - squared_difference_loss: 11.7319 - KL_divergence_loss: 3.8249 - neg_log_likelihood: 233433257.6392 - val_loss: 15.3570 - val_squared_difference_loss: 11.5451 - val_KL_divergence_loss: 3.8119 - val_neg_log_likelihood: 34051795326846513152.0000\n",
      "Epoch 1732/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5539 - squared_difference_loss: 11.7501 - KL_divergence_loss: 3.8037 - neg_log_likelihood: 2288024639.4063 - val_loss: 15.3546 - val_squared_difference_loss: 11.5727 - val_KL_divergence_loss: 3.7818 - val_neg_log_likelihood: 25326048775447126016.0000\n",
      "Epoch 1733/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5708 - squared_difference_loss: 11.7564 - KL_divergence_loss: 3.8144 - neg_log_likelihood: 487036177.8264 - val_loss: 15.3522 - val_squared_difference_loss: 11.5404 - val_KL_divergence_loss: 3.8117 - val_neg_log_likelihood: 18433392193705005056.0000\n",
      "Epoch 1734/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5345 - squared_difference_loss: 11.7231 - KL_divergence_loss: 3.8114 - neg_log_likelihood: 30752122644.0042 - val_loss: 15.3559 - val_squared_difference_loss: 11.5539 - val_KL_divergence_loss: 3.8019 - val_neg_log_likelihood: 5370511100362570752.0000\n",
      "Epoch 1735/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5560 - squared_difference_loss: 11.7347 - KL_divergence_loss: 3.8213 - neg_log_likelihood: 4224692831.0147 - val_loss: 15.3467 - val_squared_difference_loss: 11.5175 - val_KL_divergence_loss: 3.8292 - val_neg_log_likelihood: 10296074200525721600.0000\n",
      "Epoch 1736/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5537 - squared_difference_loss: 11.7214 - KL_divergence_loss: 3.8323 - neg_log_likelihood: 10573738135.1090 - val_loss: 15.3679 - val_squared_difference_loss: 11.5656 - val_KL_divergence_loss: 3.8023 - val_neg_log_likelihood: 10230766622178445312.0000\n",
      "Epoch 1737/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5311 - squared_difference_loss: 11.7239 - KL_divergence_loss: 3.8072 - neg_log_likelihood: 4856643751.3657 - val_loss: 15.3462 - val_squared_difference_loss: 11.5506 - val_KL_divergence_loss: 3.7956 - val_neg_log_likelihood: 16616175133159526400.0000\n",
      "Epoch 1738/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5518 - squared_difference_loss: 11.7524 - KL_divergence_loss: 3.7994 - neg_log_likelihood: 376348168.1738 - val_loss: 15.3645 - val_squared_difference_loss: 11.5747 - val_KL_divergence_loss: 3.7897 - val_neg_log_likelihood: 4876874748336023552.0000\n",
      "Epoch 1739/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5697 - squared_difference_loss: 11.7458 - KL_divergence_loss: 3.8238 - neg_log_likelihood: 3484823761.6984 - val_loss: 15.3661 - val_squared_difference_loss: 11.5500 - val_KL_divergence_loss: 3.8161 - val_neg_log_likelihood: 10605074581359826944.0000\n",
      "Epoch 1740/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5653 - squared_difference_loss: 11.7519 - KL_divergence_loss: 3.8134 - neg_log_likelihood: 1149991310.9741 - val_loss: 15.3650 - val_squared_difference_loss: 11.5650 - val_KL_divergence_loss: 3.8000 - val_neg_log_likelihood: 6240185711022856192.0000\n",
      "Epoch 1741/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5647 - squared_difference_loss: 11.7656 - KL_divergence_loss: 3.7991 - neg_log_likelihood: 7058355178.7551 - val_loss: 15.3670 - val_squared_difference_loss: 11.5388 - val_KL_divergence_loss: 3.8282 - val_neg_log_likelihood: 40075675855262236672.0000\n",
      "Epoch 1742/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5642 - squared_difference_loss: 11.7189 - KL_divergence_loss: 3.8453 - neg_log_likelihood: 67565552539.5406 - val_loss: 15.3995 - val_squared_difference_loss: 11.5766 - val_KL_divergence_loss: 3.8229 - val_neg_log_likelihood: 5811178497592137728.0000\n",
      "Epoch 1743/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5274 - squared_difference_loss: 11.7082 - KL_divergence_loss: 3.8192 - neg_log_likelihood: 27108958829.4767 - val_loss: 15.3382 - val_squared_difference_loss: 11.5381 - val_KL_divergence_loss: 3.8002 - val_neg_log_likelihood: 20485307083369582592.0000\n",
      "Epoch 1744/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5569 - squared_difference_loss: 11.7440 - KL_divergence_loss: 3.8129 - neg_log_likelihood: 8929688693.9159 - val_loss: 15.3659 - val_squared_difference_loss: 11.5683 - val_KL_divergence_loss: 3.7976 - val_neg_log_likelihood: 96354257246439063552.0000\n",
      "Epoch 1745/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5444 - squared_difference_loss: 11.7303 - KL_divergence_loss: 3.8142 - neg_log_likelihood: 568267988.4438 - val_loss: 15.3553 - val_squared_difference_loss: 11.5232 - val_KL_divergence_loss: 3.8320 - val_neg_log_likelihood: 6321167209122952192.0000\n",
      "Epoch 1746/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5615 - squared_difference_loss: 11.7524 - KL_divergence_loss: 3.8091 - neg_log_likelihood: 7366460085.2388 - val_loss: 15.3810 - val_squared_difference_loss: 11.5802 - val_KL_divergence_loss: 3.8008 - val_neg_log_likelihood: 9683806400786501632.0000\n",
      "Epoch 1747/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5717 - squared_difference_loss: 11.7689 - KL_divergence_loss: 3.8028 - neg_log_likelihood: 8869757941.5652 - val_loss: 15.3723 - val_squared_difference_loss: 11.5705 - val_KL_divergence_loss: 3.8019 - val_neg_log_likelihood: 17032582895575410688.0000\n",
      "Epoch 1748/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5402 - squared_difference_loss: 11.7329 - KL_divergence_loss: 3.8074 - neg_log_likelihood: 9917483510.1401 - val_loss: 15.3904 - val_squared_difference_loss: 11.5739 - val_KL_divergence_loss: 3.8166 - val_neg_log_likelihood: 28780471408108244992.0000\n",
      "Epoch 1749/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5380 - squared_difference_loss: 11.7213 - KL_divergence_loss: 3.8167 - neg_log_likelihood: 39080033517.3642 - val_loss: 15.3761 - val_squared_difference_loss: 11.5887 - val_KL_divergence_loss: 3.7874 - val_neg_log_likelihood: 9234926751477712896.0000\n",
      "Epoch 1750/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5440 - squared_difference_loss: 11.7500 - KL_divergence_loss: 3.7940 - neg_log_likelihood: 4337034368.1025 - val_loss: 15.3712 - val_squared_difference_loss: 11.5877 - val_KL_divergence_loss: 3.7834 - val_neg_log_likelihood: 65585422320166256640.0000\n",
      "Epoch 1751/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5403 - squared_difference_loss: 11.7250 - KL_divergence_loss: 3.8153 - neg_log_likelihood: 9711564222.8961 - val_loss: 15.3891 - val_squared_difference_loss: 11.5740 - val_KL_divergence_loss: 3.8152 - val_neg_log_likelihood: 20598855786638671872.0000\n",
      "Epoch 1752/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5440 - squared_difference_loss: 11.7279 - KL_divergence_loss: 3.8161 - neg_log_likelihood: 981170240.3580 - val_loss: 15.3490 - val_squared_difference_loss: 11.5515 - val_KL_divergence_loss: 3.7976 - val_neg_log_likelihood: 23745325468870672384.0000\n",
      "Epoch 1753/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5251 - squared_difference_loss: 11.7157 - KL_divergence_loss: 3.8094 - neg_log_likelihood: 17489081473.7981 - val_loss: 15.3943 - val_squared_difference_loss: 11.5909 - val_KL_divergence_loss: 3.8034 - val_neg_log_likelihood: 14298987852936099840.0000\n",
      "Epoch 1754/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5286 - squared_difference_loss: 11.7298 - KL_divergence_loss: 3.7987 - neg_log_likelihood: 2378243796.5180 - val_loss: 15.3802 - val_squared_difference_loss: 11.5760 - val_KL_divergence_loss: 3.8042 - val_neg_log_likelihood: 71266233670265520128.0000\n",
      "Epoch 1755/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5511 - squared_difference_loss: 11.7436 - KL_divergence_loss: 3.8074 - neg_log_likelihood: 3257843191.3068 - val_loss: 15.3463 - val_squared_difference_loss: 11.5436 - val_KL_divergence_loss: 3.8027 - val_neg_log_likelihood: 20939567222956761088.0000\n",
      "Epoch 1756/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5236 - squared_difference_loss: 11.7077 - KL_divergence_loss: 3.8159 - neg_log_likelihood: 1594962567.6903 - val_loss: 15.3428 - val_squared_difference_loss: 11.5447 - val_KL_divergence_loss: 3.7981 - val_neg_log_likelihood: 8384850131897368576.0000\n",
      "Epoch 1757/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5471 - squared_difference_loss: 11.7534 - KL_divergence_loss: 3.7937 - neg_log_likelihood: 33690483236.6534 - val_loss: 15.3558 - val_squared_difference_loss: 11.5711 - val_KL_divergence_loss: 3.7847 - val_neg_log_likelihood: 8150744860232645632.0000\n",
      "Epoch 1758/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5531 - squared_difference_loss: 11.7601 - KL_divergence_loss: 3.7931 - neg_log_likelihood: 742218479.1782 - val_loss: 15.3430 - val_squared_difference_loss: 11.5362 - val_KL_divergence_loss: 3.8068 - val_neg_log_likelihood: 13237052427481038848.0000\n",
      "Epoch 1759/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5407 - squared_difference_loss: 11.7363 - KL_divergence_loss: 3.8045 - neg_log_likelihood: 3056878338.6403 - val_loss: 15.3585 - val_squared_difference_loss: 11.5670 - val_KL_divergence_loss: 3.7915 - val_neg_log_likelihood: 4757374266294628352.0000\n",
      "Epoch 1760/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5699 - squared_difference_loss: 11.7571 - KL_divergence_loss: 3.8128 - neg_log_likelihood: 2788522026.4616 - val_loss: 15.3446 - val_squared_difference_loss: 11.5146 - val_KL_divergence_loss: 3.8300 - val_neg_log_likelihood: 50547671247439634432.0000\n",
      "Epoch 1761/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5563 - squared_difference_loss: 11.7344 - KL_divergence_loss: 3.8219 - neg_log_likelihood: 4168548289.1789 - val_loss: 15.3956 - val_squared_difference_loss: 11.5621 - val_KL_divergence_loss: 3.8335 - val_neg_log_likelihood: 4378969789606248960.0000\n",
      "Epoch 1762/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5392 - squared_difference_loss: 11.7268 - KL_divergence_loss: 3.8123 - neg_log_likelihood: 9376032203.2009 - val_loss: 15.3507 - val_squared_difference_loss: 11.5609 - val_KL_divergence_loss: 3.7898 - val_neg_log_likelihood: 5663141627802385408.0000\n",
      "Epoch 1763/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 15.5581 - squared_difference_loss: 11.7590 - KL_divergence_loss: 3.7991 - neg_log_likelihood: 2485449635.0520 - val_loss: 15.3489 - val_squared_difference_loss: 11.5215 - val_KL_divergence_loss: 3.8274 - val_neg_log_likelihood: 10889064504854235136.0000\n",
      "Epoch 1764/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5812 - squared_difference_loss: 11.7612 - KL_divergence_loss: 3.8200 - neg_log_likelihood: 23951032102.4778 - val_loss: 15.3574 - val_squared_difference_loss: 11.5425 - val_KL_divergence_loss: 3.8149 - val_neg_log_likelihood: 31779628256423682048.0000\n",
      "Epoch 1765/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5479 - squared_difference_loss: 11.7373 - KL_divergence_loss: 3.8105 - neg_log_likelihood: 4309081861.9083 - val_loss: 15.3841 - val_squared_difference_loss: 11.5668 - val_KL_divergence_loss: 3.8173 - val_neg_log_likelihood: 16695801142244102144.0000\n",
      "Epoch 1766/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5345 - squared_difference_loss: 11.7186 - KL_divergence_loss: 3.8158 - neg_log_likelihood: 13137349604.6989 - val_loss: 15.3641 - val_squared_difference_loss: 11.5500 - val_KL_divergence_loss: 3.8140 - val_neg_log_likelihood: 4954924700507133952.0000\n",
      "Epoch 1767/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5415 - squared_difference_loss: 11.7308 - KL_divergence_loss: 3.8107 - neg_log_likelihood: 5317655042.4068 - val_loss: 15.3374 - val_squared_difference_loss: 11.5309 - val_KL_divergence_loss: 3.8065 - val_neg_log_likelihood: 109130165440685965312.0000\n",
      "Epoch 1768/2000\n",
      "29507/29507 [==============================] - 1s 19us/step - loss: 15.5322 - squared_difference_loss: 11.7189 - KL_divergence_loss: 3.8133 - neg_log_likelihood: 2528522362.9273 - val_loss: 15.3593 - val_squared_difference_loss: 11.5632 - val_KL_divergence_loss: 3.7961 - val_neg_log_likelihood: 15488386251200272384.0000\n",
      "Epoch 1769/2000\n",
      "29507/29507 [==============================] - 1s 19us/step - loss: 15.5171 - squared_difference_loss: 11.7220 - KL_divergence_loss: 3.7951 - neg_log_likelihood: 1751353312.0064 - val_loss: 15.3398 - val_squared_difference_loss: 11.5418 - val_KL_divergence_loss: 3.7980 - val_neg_log_likelihood: 7301681566728370176.0000\n",
      "Epoch 1770/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5600 - squared_difference_loss: 11.7536 - KL_divergence_loss: 3.8064 - neg_log_likelihood: 6279890811.5875 - val_loss: 15.3757 - val_squared_difference_loss: 11.5916 - val_KL_divergence_loss: 3.7842 - val_neg_log_likelihood: 13423388809784662016.0000\n",
      "Epoch 1771/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5447 - squared_difference_loss: 11.7366 - KL_divergence_loss: 3.8081 - neg_log_likelihood: 2260411477.0236 - val_loss: 15.3893 - val_squared_difference_loss: 11.5836 - val_KL_divergence_loss: 3.8057 - val_neg_log_likelihood: 47956507854525530112.0000\n",
      "Epoch 1772/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5271 - squared_difference_loss: 11.7090 - KL_divergence_loss: 3.8181 - neg_log_likelihood: 10475863278.3706 - val_loss: 15.3945 - val_squared_difference_loss: 11.5940 - val_KL_divergence_loss: 3.8005 - val_neg_log_likelihood: 35365732847432568832.0000\n",
      "Epoch 1773/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5295 - squared_difference_loss: 11.7292 - KL_divergence_loss: 3.8003 - neg_log_likelihood: 7225926744.3991 - val_loss: 15.3840 - val_squared_difference_loss: 11.5869 - val_KL_divergence_loss: 3.7971 - val_neg_log_likelihood: 38387947180588670976.0000\n",
      "Epoch 1774/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5594 - squared_difference_loss: 11.7428 - KL_divergence_loss: 3.8167 - neg_log_likelihood: 12959271417.8061 - val_loss: 15.3766 - val_squared_difference_loss: 11.5793 - val_KL_divergence_loss: 3.7973 - val_neg_log_likelihood: 17736791964969410560.0000\n",
      "Epoch 1775/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5500 - squared_difference_loss: 11.7262 - KL_divergence_loss: 3.8237 - neg_log_likelihood: 8302305227.8903 - val_loss: 15.3575 - val_squared_difference_loss: 11.5415 - val_KL_divergence_loss: 3.8160 - val_neg_log_likelihood: 21772448135491858432.0000\n",
      "Epoch 1776/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5173 - squared_difference_loss: 11.7130 - KL_divergence_loss: 3.8043 - neg_log_likelihood: 15537581017.6110 - val_loss: 15.3804 - val_squared_difference_loss: 11.5673 - val_KL_divergence_loss: 3.8131 - val_neg_log_likelihood: 52762380930497404928.0000\n",
      "Epoch 1777/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5409 - squared_difference_loss: 11.7158 - KL_divergence_loss: 3.8252 - neg_log_likelihood: 96589443.0994 - val_loss: 15.3747 - val_squared_difference_loss: 11.5732 - val_KL_divergence_loss: 3.8014 - val_neg_log_likelihood: 18167631539966793728.0000\n",
      "Epoch 1778/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5130 - squared_difference_loss: 11.7031 - KL_divergence_loss: 3.8099 - neg_log_likelihood: 13057321638.9625 - val_loss: 15.3701 - val_squared_difference_loss: 11.5840 - val_KL_divergence_loss: 3.7861 - val_neg_log_likelihood: 37563157832550187008.0000\n",
      "Epoch 1779/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5743 - squared_difference_loss: 11.7592 - KL_divergence_loss: 3.8151 - neg_log_likelihood: 1413736418.3075 - val_loss: 15.3495 - val_squared_difference_loss: 11.5415 - val_KL_divergence_loss: 3.8080 - val_neg_log_likelihood: 4171049358668902912.0000\n",
      "Epoch 1780/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5602 - squared_difference_loss: 11.7304 - KL_divergence_loss: 3.8298 - neg_log_likelihood: 1707903947.3773 - val_loss: 15.3701 - val_squared_difference_loss: 11.5511 - val_KL_divergence_loss: 3.8190 - val_neg_log_likelihood: 29420400222474031104.0000\n",
      "Epoch 1781/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5513 - squared_difference_loss: 11.7360 - KL_divergence_loss: 3.8153 - neg_log_likelihood: 24438767828.9556 - val_loss: 15.3916 - val_squared_difference_loss: 11.5944 - val_KL_divergence_loss: 3.7972 - val_neg_log_likelihood: 4151357761178260992.0000\n",
      "Epoch 1782/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5696 - squared_difference_loss: 11.7472 - KL_divergence_loss: 3.8223 - neg_log_likelihood: 22515424986.6137 - val_loss: 15.3384 - val_squared_difference_loss: 11.5391 - val_KL_divergence_loss: 3.7993 - val_neg_log_likelihood: 6540269734281600000.0000\n",
      "Epoch 1783/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5598 - squared_difference_loss: 11.7381 - KL_divergence_loss: 3.8217 - neg_log_likelihood: 6801795093.6772 - val_loss: 15.3375 - val_squared_difference_loss: 11.5311 - val_KL_divergence_loss: 3.8064 - val_neg_log_likelihood: 7991251570085316608.0000\n",
      "Epoch 1784/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5628 - squared_difference_loss: 11.7390 - KL_divergence_loss: 3.8238 - neg_log_likelihood: 74363728900.1145 - val_loss: 15.3957 - val_squared_difference_loss: 11.5786 - val_KL_divergence_loss: 3.8171 - val_neg_log_likelihood: 27865560927791697920.0000\n",
      "Epoch 1785/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5694 - squared_difference_loss: 11.7435 - KL_divergence_loss: 3.8258 - neg_log_likelihood: 346115505.8610 - val_loss: 15.3650 - val_squared_difference_loss: 11.5361 - val_KL_divergence_loss: 3.8288 - val_neg_log_likelihood: 11214313378535225344.0000\n",
      "Epoch 1786/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5257 - squared_difference_loss: 11.7198 - KL_divergence_loss: 3.8059 - neg_log_likelihood: 27567392198.2467 - val_loss: 15.3288 - val_squared_difference_loss: 11.5465 - val_KL_divergence_loss: 3.7823 - val_neg_log_likelihood: 15935048603715878912.0000\n",
      "Epoch 1787/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5422 - squared_difference_loss: 11.7524 - KL_divergence_loss: 3.7897 - neg_log_likelihood: 49016252024.6198 - val_loss: 15.3736 - val_squared_difference_loss: 11.5584 - val_KL_divergence_loss: 3.8152 - val_neg_log_likelihood: 22174410150744272896.0000\n",
      "Epoch 1788/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5758 - squared_difference_loss: 11.7642 - KL_divergence_loss: 3.8116 - neg_log_likelihood: 424499430.5872 - val_loss: 15.3533 - val_squared_difference_loss: 11.5207 - val_KL_divergence_loss: 3.8326 - val_neg_log_likelihood: 15554569407124385792.0000\n",
      "Epoch 1789/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5487 - squared_difference_loss: 11.7176 - KL_divergence_loss: 3.8310 - neg_log_likelihood: 140001971.9011 - val_loss: 15.3625 - val_squared_difference_loss: 11.5440 - val_KL_divergence_loss: 3.8185 - val_neg_log_likelihood: 11061017103477411840.0000\n",
      "Epoch 1790/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5521 - squared_difference_loss: 11.7321 - KL_divergence_loss: 3.8200 - neg_log_likelihood: 4307259342.3670 - val_loss: 15.3911 - val_squared_difference_loss: 11.5837 - val_KL_divergence_loss: 3.8074 - val_neg_log_likelihood: 34703080403219439616.0000\n",
      "Epoch 1791/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5589 - squared_difference_loss: 11.7363 - KL_divergence_loss: 3.8226 - neg_log_likelihood: 6828074888.1901 - val_loss: 15.3968 - val_squared_difference_loss: 11.5614 - val_KL_divergence_loss: 3.8354 - val_neg_log_likelihood: 13442753163062468608.0000\n",
      "Epoch 1792/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5307 - squared_difference_loss: 11.7183 - KL_divergence_loss: 3.8125 - neg_log_likelihood: 1009130108.1058 - val_loss: 15.3734 - val_squared_difference_loss: 11.5687 - val_KL_divergence_loss: 3.8047 - val_neg_log_likelihood: 24628501315887443968.0000\n",
      "Epoch 1793/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5314 - squared_difference_loss: 11.7381 - KL_divergence_loss: 3.7933 - neg_log_likelihood: 16850680524.2036 - val_loss: 15.3890 - val_squared_difference_loss: 11.6015 - val_KL_divergence_loss: 3.7875 - val_neg_log_likelihood: 44088043611446067200.0000\n",
      "Epoch 1794/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5403 - squared_difference_loss: 11.7479 - KL_divergence_loss: 3.7924 - neg_log_likelihood: 126301109.8622 - val_loss: 15.3569 - val_squared_difference_loss: 11.5605 - val_KL_divergence_loss: 3.7964 - val_neg_log_likelihood: 24283576510357643264.0000\n",
      "Epoch 1795/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5496 - squared_difference_loss: 11.7381 - KL_divergence_loss: 3.8115 - neg_log_likelihood: 8232517850.2675 - val_loss: 15.3866 - val_squared_difference_loss: 11.5735 - val_KL_divergence_loss: 3.8130 - val_neg_log_likelihood: 15384158748429361152.0000\n",
      "Epoch 1796/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 15.5495 - squared_difference_loss: 11.7510 - KL_divergence_loss: 3.7985 - neg_log_likelihood: 11014585310.0890 - val_loss: 15.3847 - val_squared_difference_loss: 11.5877 - val_KL_divergence_loss: 3.7970 - val_neg_log_likelihood: 21788340431384256512.0000\n",
      "Epoch 1797/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5290 - squared_difference_loss: 11.7125 - KL_divergence_loss: 3.8164 - neg_log_likelihood: 9496511341.9021 - val_loss: 15.3465 - val_squared_difference_loss: 11.5225 - val_KL_divergence_loss: 3.8240 - val_neg_log_likelihood: 13573429430527070208.0000\n",
      "Epoch 1798/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5302 - squared_difference_loss: 11.7094 - KL_divergence_loss: 3.8208 - neg_log_likelihood: 3581105612.1257 - val_loss: 15.3517 - val_squared_difference_loss: 11.5725 - val_KL_divergence_loss: 3.7792 - val_neg_log_likelihood: 20051876085071462400.0000\n",
      "Epoch 1799/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5392 - squared_difference_loss: 11.7222 - KL_divergence_loss: 3.8169 - neg_log_likelihood: 11033040025.7536 - val_loss: 15.3845 - val_squared_difference_loss: 11.5775 - val_KL_divergence_loss: 3.8071 - val_neg_log_likelihood: 2816978378497988608.0000\n",
      "Epoch 1800/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5521 - squared_difference_loss: 11.7347 - KL_divergence_loss: 3.8175 - neg_log_likelihood: 11421641154.1890 - val_loss: 15.3711 - val_squared_difference_loss: 11.5482 - val_KL_divergence_loss: 3.8229 - val_neg_log_likelihood: 10777022987478796288.0000\n",
      "Epoch 1801/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5312 - squared_difference_loss: 11.7199 - KL_divergence_loss: 3.8113 - neg_log_likelihood: 1298944018.4196 - val_loss: 15.3945 - val_squared_difference_loss: 11.5962 - val_KL_divergence_loss: 3.7984 - val_neg_log_likelihood: 8614390804853454848.0000\n",
      "Epoch 1802/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5330 - squared_difference_loss: 11.7287 - KL_divergence_loss: 3.8043 - neg_log_likelihood: 19506683154.9331 - val_loss: 15.3668 - val_squared_difference_loss: 11.5751 - val_KL_divergence_loss: 3.7917 - val_neg_log_likelihood: 9987671878069489664.0000\n",
      "Epoch 1803/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5200 - squared_difference_loss: 11.7299 - KL_divergence_loss: 3.7902 - neg_log_likelihood: 22072746314.0859 - val_loss: 15.3804 - val_squared_difference_loss: 11.5891 - val_KL_divergence_loss: 3.7913 - val_neg_log_likelihood: 11934835608649588736.0000\n",
      "Epoch 1804/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5924 - squared_difference_loss: 11.7731 - KL_divergence_loss: 3.8193 - neg_log_likelihood: 861735158.1989 - val_loss: 15.3577 - val_squared_difference_loss: 11.5421 - val_KL_divergence_loss: 3.8156 - val_neg_log_likelihood: 10483433642590572544.0000\n",
      "Epoch 1805/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5294 - squared_difference_loss: 11.7165 - KL_divergence_loss: 3.8128 - neg_log_likelihood: 28880338147.7024 - val_loss: 15.3793 - val_squared_difference_loss: 11.6063 - val_KL_divergence_loss: 3.7730 - val_neg_log_likelihood: 9073747580348413952.0000\n",
      "Epoch 1806/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5372 - squared_difference_loss: 11.7301 - KL_divergence_loss: 3.8071 - neg_log_likelihood: 1394622004.2936 - val_loss: 15.3551 - val_squared_difference_loss: 11.5513 - val_KL_divergence_loss: 3.8038 - val_neg_log_likelihood: 7858100011960048640.0000\n",
      "Epoch 1807/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5357 - squared_difference_loss: 11.7290 - KL_divergence_loss: 3.8066 - neg_log_likelihood: 6003012832.2210 - val_loss: 15.3849 - val_squared_difference_loss: 11.5862 - val_KL_divergence_loss: 3.7988 - val_neg_log_likelihood: 11629988062965372928.0000\n",
      "Epoch 1808/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5669 - squared_difference_loss: 11.7610 - KL_divergence_loss: 3.8058 - neg_log_likelihood: 11620288097.2624 - val_loss: 15.4044 - val_squared_difference_loss: 11.6192 - val_KL_divergence_loss: 3.7852 - val_neg_log_likelihood: 6496952068200983552.0000\n",
      "Epoch 1809/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5314 - squared_difference_loss: 11.7129 - KL_divergence_loss: 3.8185 - neg_log_likelihood: 6019338249.3646 - val_loss: 15.3672 - val_squared_difference_loss: 11.5648 - val_KL_divergence_loss: 3.8024 - val_neg_log_likelihood: 46331728202293207040.0000\n",
      "Epoch 1810/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5601 - squared_difference_loss: 11.7424 - KL_divergence_loss: 3.8177 - neg_log_likelihood: 701920135.0107 - val_loss: 15.3679 - val_squared_difference_loss: 11.5671 - val_KL_divergence_loss: 3.8008 - val_neg_log_likelihood: 9868707981449932800.0000\n",
      "Epoch 1811/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5586 - squared_difference_loss: 11.7407 - KL_divergence_loss: 3.8179 - neg_log_likelihood: 2887251036.1202 - val_loss: 15.3693 - val_squared_difference_loss: 11.5665 - val_KL_divergence_loss: 3.8028 - val_neg_log_likelihood: 25196164007495278592.0000\n",
      "Epoch 1812/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5440 - squared_difference_loss: 11.7254 - KL_divergence_loss: 3.8186 - neg_log_likelihood: 1714815962.2726 - val_loss: 15.3834 - val_squared_difference_loss: 11.5870 - val_KL_divergence_loss: 3.7964 - val_neg_log_likelihood: 50838421491264593920.0000\n",
      "Epoch 1813/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5517 - squared_difference_loss: 11.7474 - KL_divergence_loss: 3.8043 - neg_log_likelihood: 302146658.4735 - val_loss: 15.3510 - val_squared_difference_loss: 11.5610 - val_KL_divergence_loss: 3.7900 - val_neg_log_likelihood: 12009455286468657152.0000\n",
      "Epoch 1814/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 15.5677 - squared_difference_loss: 11.7532 - KL_divergence_loss: 3.8145 - neg_log_likelihood: 2683582227.8449 - val_loss: 15.3520 - val_squared_difference_loss: 11.5305 - val_KL_divergence_loss: 3.8215 - val_neg_log_likelihood: 4670801929785843712.0000\n",
      "Epoch 1815/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5316 - squared_difference_loss: 11.7331 - KL_divergence_loss: 3.7985 - neg_log_likelihood: 5632266660.1254 - val_loss: 15.3671 - val_squared_difference_loss: 11.5623 - val_KL_divergence_loss: 3.8048 - val_neg_log_likelihood: 4999938692029118464.0000\n",
      "Epoch 1816/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5402 - squared_difference_loss: 11.7167 - KL_divergence_loss: 3.8235 - neg_log_likelihood: 2645692064.0485 - val_loss: 15.3577 - val_squared_difference_loss: 11.5607 - val_KL_divergence_loss: 3.7970 - val_neg_log_likelihood: 9278108783790843904.0000\n",
      "Epoch 1817/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5164 - squared_difference_loss: 11.7265 - KL_divergence_loss: 3.7899 - neg_log_likelihood: 3876990232.8900 - val_loss: 15.3587 - val_squared_difference_loss: 11.6047 - val_KL_divergence_loss: 3.7540 - val_neg_log_likelihood: 6908131014422003712.0000\n",
      "Epoch 1818/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5409 - squared_difference_loss: 11.7394 - KL_divergence_loss: 3.8015 - neg_log_likelihood: 7386992345.1193 - val_loss: 15.3568 - val_squared_difference_loss: 11.5715 - val_KL_divergence_loss: 3.7853 - val_neg_log_likelihood: 3605555202889341440.0000\n",
      "Epoch 1819/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5336 - squared_difference_loss: 11.7425 - KL_divergence_loss: 3.7911 - neg_log_likelihood: 17276287544.1446 - val_loss: 15.3611 - val_squared_difference_loss: 11.5690 - val_KL_divergence_loss: 3.7921 - val_neg_log_likelihood: 5059238054235516928.0000\n",
      "Epoch 1820/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5686 - squared_difference_loss: 11.7372 - KL_divergence_loss: 3.8314 - neg_log_likelihood: 11895879100.9325 - val_loss: 15.3455 - val_squared_difference_loss: 11.5012 - val_KL_divergence_loss: 3.8443 - val_neg_log_likelihood: 6147083583747105792.0000\n",
      "Epoch 1821/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5623 - squared_difference_loss: 11.7317 - KL_divergence_loss: 3.8307 - neg_log_likelihood: 228306537.4028 - val_loss: 15.3521 - val_squared_difference_loss: 11.5413 - val_KL_divergence_loss: 3.8107 - val_neg_log_likelihood: 2862081400303769600.0000\n",
      "Epoch 1822/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5678 - squared_difference_loss: 11.7528 - KL_divergence_loss: 3.8150 - neg_log_likelihood: 2673232735.0236 - val_loss: 15.3443 - val_squared_difference_loss: 11.5228 - val_KL_divergence_loss: 3.8215 - val_neg_log_likelihood: 24258883189769175040.0000\n",
      "Epoch 1823/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5402 - squared_difference_loss: 11.7289 - KL_divergence_loss: 3.8113 - neg_log_likelihood: 7194989712.3320 - val_loss: 15.3581 - val_squared_difference_loss: 11.5343 - val_KL_divergence_loss: 3.8238 - val_neg_log_likelihood: 25212386070578352128.0000\n",
      "Epoch 1824/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5460 - squared_difference_loss: 11.7312 - KL_divergence_loss: 3.8147 - neg_log_likelihood: 1954603897.1779 - val_loss: 15.3713 - val_squared_difference_loss: 11.5596 - val_KL_divergence_loss: 3.8117 - val_neg_log_likelihood: 11528587846482294784.0000\n",
      "Epoch 1825/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5249 - squared_difference_loss: 11.7102 - KL_divergence_loss: 3.8147 - neg_log_likelihood: 3169457163.2435 - val_loss: 15.3667 - val_squared_difference_loss: 11.5724 - val_KL_divergence_loss: 3.7943 - val_neg_log_likelihood: 3985082932109890048.0000\n",
      "Epoch 1826/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 15.5404 - squared_difference_loss: 11.7349 - KL_divergence_loss: 3.8055 - neg_log_likelihood: 17111908945.9036 - val_loss: 15.3442 - val_squared_difference_loss: 11.5275 - val_KL_divergence_loss: 3.8167 - val_neg_log_likelihood: 13079482232920041472.0000\n",
      "Epoch 1827/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5420 - squared_difference_loss: 11.7126 - KL_divergence_loss: 3.8293 - neg_log_likelihood: 8877862016.9959 - val_loss: 15.3437 - val_squared_difference_loss: 11.5337 - val_KL_divergence_loss: 3.8100 - val_neg_log_likelihood: 18032053320303093760.0000\n",
      "Epoch 1828/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5454 - squared_difference_loss: 11.7305 - KL_divergence_loss: 3.8149 - neg_log_likelihood: 22618184568.5502 - val_loss: 15.3514 - val_squared_difference_loss: 11.5317 - val_KL_divergence_loss: 3.8197 - val_neg_log_likelihood: 19735083191596556288.0000\n",
      "Epoch 1829/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5472 - squared_difference_loss: 11.7290 - KL_divergence_loss: 3.8182 - neg_log_likelihood: 3394491980.0304 - val_loss: 15.3630 - val_squared_difference_loss: 11.5560 - val_KL_divergence_loss: 3.8070 - val_neg_log_likelihood: 4258507752462631936.0000\n",
      "Epoch 1830/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5363 - squared_difference_loss: 11.7181 - KL_divergence_loss: 3.8182 - neg_log_likelihood: 1635702996.5144 - val_loss: 15.3914 - val_squared_difference_loss: 11.5974 - val_KL_divergence_loss: 3.7940 - val_neg_log_likelihood: 7243439740316703744.0000\n",
      "Epoch 1831/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5409 - squared_difference_loss: 11.7458 - KL_divergence_loss: 3.7952 - neg_log_likelihood: 1469628592.8087 - val_loss: 15.3441 - val_squared_difference_loss: 11.5425 - val_KL_divergence_loss: 3.8016 - val_neg_log_likelihood: 5496875515230704640.0000\n",
      "Epoch 1832/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5673 - squared_difference_loss: 11.7534 - KL_divergence_loss: 3.8139 - neg_log_likelihood: 10482813034.9262 - val_loss: 15.3783 - val_squared_difference_loss: 11.5611 - val_KL_divergence_loss: 3.8171 - val_neg_log_likelihood: 27676741546330017792.0000\n",
      "Epoch 1833/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5621 - squared_difference_loss: 11.7394 - KL_divergence_loss: 3.8227 - neg_log_likelihood: 15731004704.6473 - val_loss: 15.3597 - val_squared_difference_loss: 11.5472 - val_KL_divergence_loss: 3.8124 - val_neg_log_likelihood: 14201097806338377728.0000\n",
      "Epoch 1834/2000\n",
      "29507/29507 [==============================] - 1s 23us/step - loss: 15.5337 - squared_difference_loss: 11.7231 - KL_divergence_loss: 3.8106 - neg_log_likelihood: 11262096871.5710 - val_loss: 15.3441 - val_squared_difference_loss: 11.5515 - val_KL_divergence_loss: 3.7926 - val_neg_log_likelihood: 10359904421534490624.0000\n",
      "Epoch 1835/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5191 - squared_difference_loss: 11.7206 - KL_divergence_loss: 3.7985 - neg_log_likelihood: 1608197479.3078 - val_loss: 15.3665 - val_squared_difference_loss: 11.5600 - val_KL_divergence_loss: 3.8065 - val_neg_log_likelihood: 8272617352781517824.0000\n",
      "Epoch 1836/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5538 - squared_difference_loss: 11.7428 - KL_divergence_loss: 3.8110 - neg_log_likelihood: 8023570149.6651 - val_loss: 15.3267 - val_squared_difference_loss: 11.5238 - val_KL_divergence_loss: 3.8029 - val_neg_log_likelihood: 8506029935281882112.0000\n",
      "Epoch 1837/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5594 - squared_difference_loss: 11.7447 - KL_divergence_loss: 3.8148 - neg_log_likelihood: 3376689411.3539 - val_loss: 15.3479 - val_squared_difference_loss: 11.5570 - val_KL_divergence_loss: 3.7909 - val_neg_log_likelihood: 5351863771511880704.0000\n",
      "Epoch 1838/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5554 - squared_difference_loss: 11.7537 - KL_divergence_loss: 3.8017 - neg_log_likelihood: 2800539175.6706 - val_loss: 15.3461 - val_squared_difference_loss: 11.5563 - val_KL_divergence_loss: 3.7898 - val_neg_log_likelihood: 4701199115663693824.0000\n",
      "Epoch 1839/2000\n",
      "29507/29507 [==============================] - 1s 19us/step - loss: 15.5303 - squared_difference_loss: 11.7156 - KL_divergence_loss: 3.8147 - neg_log_likelihood: 12147624639.7131 - val_loss: 15.3374 - val_squared_difference_loss: 11.5409 - val_KL_divergence_loss: 3.7964 - val_neg_log_likelihood: 14384912306064019456.0000\n",
      "Epoch 1840/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5272 - squared_difference_loss: 11.7296 - KL_divergence_loss: 3.7976 - neg_log_likelihood: 21535749066.3175 - val_loss: 15.3744 - val_squared_difference_loss: 11.5723 - val_KL_divergence_loss: 3.8020 - val_neg_log_likelihood: 6020540747967539200.0000\n",
      "Epoch 1841/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5482 - squared_difference_loss: 11.7219 - KL_divergence_loss: 3.8263 - neg_log_likelihood: 8907359012.8046 - val_loss: 15.3592 - val_squared_difference_loss: 11.5338 - val_KL_divergence_loss: 3.8254 - val_neg_log_likelihood: 21012221389580935168.0000\n",
      "Epoch 1842/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 15.5272 - squared_difference_loss: 11.6989 - KL_divergence_loss: 3.8283 - neg_log_likelihood: 1553785692.9587 - val_loss: 15.3613 - val_squared_difference_loss: 11.5620 - val_KL_divergence_loss: 3.7993 - val_neg_log_likelihood: 5564074127129739264.0000\n",
      "Epoch 1843/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5240 - squared_difference_loss: 11.7234 - KL_divergence_loss: 3.8005 - neg_log_likelihood: 3396961318.7076 - val_loss: 15.3710 - val_squared_difference_loss: 11.5883 - val_KL_divergence_loss: 3.7827 - val_neg_log_likelihood: 5139975452659511296.0000\n",
      "Epoch 1844/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5323 - squared_difference_loss: 11.7286 - KL_divergence_loss: 3.8037 - neg_log_likelihood: 2098678951.2957 - val_loss: 15.3604 - val_squared_difference_loss: 11.5546 - val_KL_divergence_loss: 3.8059 - val_neg_log_likelihood: 5718273538759355392.0000\n",
      "Epoch 1845/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5307 - squared_difference_loss: 11.7289 - KL_divergence_loss: 3.8018 - neg_log_likelihood: 82314482116.3525 - val_loss: 15.3930 - val_squared_difference_loss: 11.5913 - val_KL_divergence_loss: 3.8017 - val_neg_log_likelihood: 6702092953869301760.0000\n",
      "Epoch 1846/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5665 - squared_difference_loss: 11.7416 - KL_divergence_loss: 3.8250 - neg_log_likelihood: 15572960407.2278 - val_loss: 15.3642 - val_squared_difference_loss: 11.5666 - val_KL_divergence_loss: 3.7976 - val_neg_log_likelihood: 4556765334699325952.0000\n",
      "Epoch 1847/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 15.5404 - squared_difference_loss: 11.7220 - KL_divergence_loss: 3.8183 - neg_log_likelihood: 4844805050.7568 - val_loss: 15.3131 - val_squared_difference_loss: 11.4929 - val_KL_divergence_loss: 3.8201 - val_neg_log_likelihood: 8599826863368138752.0000\n",
      "Epoch 1848/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5720 - squared_difference_loss: 11.7791 - KL_divergence_loss: 3.7929 - neg_log_likelihood: 22570772381.3735 - val_loss: 15.3960 - val_squared_difference_loss: 11.6168 - val_KL_divergence_loss: 3.7792 - val_neg_log_likelihood: 4088192714168520704.0000\n",
      "Epoch 1849/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5147 - squared_difference_loss: 11.7077 - KL_divergence_loss: 3.8070 - neg_log_likelihood: 5574313210.9679 - val_loss: 15.3645 - val_squared_difference_loss: 11.5578 - val_KL_divergence_loss: 3.8067 - val_neg_log_likelihood: 4097752495734279168.0000\n",
      "Epoch 1850/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5381 - squared_difference_loss: 11.7399 - KL_divergence_loss: 3.7982 - neg_log_likelihood: 20260784164.3773 - val_loss: 15.3363 - val_squared_difference_loss: 11.5415 - val_KL_divergence_loss: 3.7949 - val_neg_log_likelihood: 10178520729479467008.0000\n",
      "Epoch 1851/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5444 - squared_difference_loss: 11.7364 - KL_divergence_loss: 3.8080 - neg_log_likelihood: 1206349092.5721 - val_loss: 15.3340 - val_squared_difference_loss: 11.5233 - val_KL_divergence_loss: 3.8107 - val_neg_log_likelihood: 5663464349333492736.0000\n",
      "Epoch 1852/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5294 - squared_difference_loss: 11.7089 - KL_divergence_loss: 3.8205 - neg_log_likelihood: 4201103368.7036 - val_loss: 15.3366 - val_squared_difference_loss: 11.5535 - val_KL_divergence_loss: 3.7832 - val_neg_log_likelihood: 6350663728612333568.0000\n",
      "Epoch 1853/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5361 - squared_difference_loss: 11.7356 - KL_divergence_loss: 3.8005 - neg_log_likelihood: 8071271524.1573 - val_loss: 15.3885 - val_squared_difference_loss: 11.5879 - val_KL_divergence_loss: 3.8006 - val_neg_log_likelihood: 1243915670716271616.0000\n",
      "Epoch 1854/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5443 - squared_difference_loss: 11.7210 - KL_divergence_loss: 3.8233 - neg_log_likelihood: 16304193308.3225 - val_loss: 15.3497 - val_squared_difference_loss: 11.5625 - val_KL_divergence_loss: 3.7872 - val_neg_log_likelihood: 19760694603547537408.0000\n",
      "Epoch 1855/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5711 - squared_difference_loss: 11.7697 - KL_divergence_loss: 3.8014 - neg_log_likelihood: 1713718690.6389 - val_loss: 15.3587 - val_squared_difference_loss: 11.5570 - val_KL_divergence_loss: 3.8018 - val_neg_log_likelihood: 5447027068307210240.0000\n",
      "Epoch 1856/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5432 - squared_difference_loss: 11.7157 - KL_divergence_loss: 3.8275 - neg_log_likelihood: 20707431008.1965 - val_loss: 15.3311 - val_squared_difference_loss: 11.5064 - val_KL_divergence_loss: 3.8247 - val_neg_log_likelihood: 9427522040212596736.0000\n",
      "Epoch 1857/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5991 - squared_difference_loss: 11.7754 - KL_divergence_loss: 3.8237 - neg_log_likelihood: 135939170.9404 - val_loss: 15.3414 - val_squared_difference_loss: 11.5250 - val_KL_divergence_loss: 3.8164 - val_neg_log_likelihood: 11206936855191699456.0000\n",
      "Epoch 1858/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5504 - squared_difference_loss: 11.7318 - KL_divergence_loss: 3.8185 - neg_log_likelihood: 2495085127.3758 - val_loss: 15.3173 - val_squared_difference_loss: 11.5106 - val_KL_divergence_loss: 3.8066 - val_neg_log_likelihood: 4605986802769714176.0000\n",
      "Epoch 1859/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5269 - squared_difference_loss: 11.7239 - KL_divergence_loss: 3.8030 - neg_log_likelihood: 6326265342.6921 - val_loss: 15.3548 - val_squared_difference_loss: 11.5623 - val_KL_divergence_loss: 3.7925 - val_neg_log_likelihood: 4964759874361893888.0000\n",
      "Epoch 1860/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5448 - squared_difference_loss: 11.7385 - KL_divergence_loss: 3.8063 - neg_log_likelihood: 2788445260.4569 - val_loss: 15.3339 - val_squared_difference_loss: 11.5163 - val_KL_divergence_loss: 3.8176 - val_neg_log_likelihood: 10256528941670633472.0000\n",
      "Epoch 1861/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5246 - squared_difference_loss: 11.7040 - KL_divergence_loss: 3.8205 - neg_log_likelihood: 8655684092.0549 - val_loss: 15.3361 - val_squared_difference_loss: 11.5418 - val_KL_divergence_loss: 3.7943 - val_neg_log_likelihood: 28991819690106658816.0000\n",
      "Epoch 1862/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5084 - squared_difference_loss: 11.7072 - KL_divergence_loss: 3.8012 - neg_log_likelihood: 54967923904.3652 - val_loss: 15.3579 - val_squared_difference_loss: 11.5661 - val_KL_divergence_loss: 3.7918 - val_neg_log_likelihood: 22120719678767292416.0000\n",
      "Epoch 1863/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5504 - squared_difference_loss: 11.7450 - KL_divergence_loss: 3.8055 - neg_log_likelihood: 1450476520.5539 - val_loss: 15.3584 - val_squared_difference_loss: 11.5664 - val_KL_divergence_loss: 3.7920 - val_neg_log_likelihood: 18957528605966639104.0000\n",
      "Epoch 1864/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5531 - squared_difference_loss: 11.7318 - KL_divergence_loss: 3.8213 - neg_log_likelihood: 8078820522.6344 - val_loss: 15.3540 - val_squared_difference_loss: 11.5435 - val_KL_divergence_loss: 3.8105 - val_neg_log_likelihood: 20681786789964419072.0000\n",
      "Epoch 1865/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 15.5149 - squared_difference_loss: 11.7039 - KL_divergence_loss: 3.8111 - neg_log_likelihood: 3707353139.6115 - val_loss: 15.3102 - val_squared_difference_loss: 11.5325 - val_KL_divergence_loss: 3.7777 - val_neg_log_likelihood: 14802871024740229120.0000\n",
      "Epoch 1866/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5410 - squared_difference_loss: 11.7350 - KL_divergence_loss: 3.8060 - neg_log_likelihood: 1724965168.2140 - val_loss: 15.3503 - val_squared_difference_loss: 11.5313 - val_KL_divergence_loss: 3.8190 - val_neg_log_likelihood: 11446137408210196480.0000\n",
      "Epoch 1867/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5149 - squared_difference_loss: 11.7141 - KL_divergence_loss: 3.8008 - neg_log_likelihood: 14835443991.3033 - val_loss: 15.3712 - val_squared_difference_loss: 11.5632 - val_KL_divergence_loss: 3.8080 - val_neg_log_likelihood: 16805187879014619136.0000\n",
      "Epoch 1868/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 15.5390 - squared_difference_loss: 11.7255 - KL_divergence_loss: 3.8136 - neg_log_likelihood: 42437095029.9720 - val_loss: 15.3540 - val_squared_difference_loss: 11.5608 - val_KL_divergence_loss: 3.7933 - val_neg_log_likelihood: 38791083248713752576.0000\n",
      "Epoch 1869/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5582 - squared_difference_loss: 11.7630 - KL_divergence_loss: 3.7952 - neg_log_likelihood: 13627571919.8275 - val_loss: 15.3329 - val_squared_difference_loss: 11.5355 - val_KL_divergence_loss: 3.7974 - val_neg_log_likelihood: 5785525705629324288.0000\n",
      "Epoch 1870/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5371 - squared_difference_loss: 11.7253 - KL_divergence_loss: 3.8118 - neg_log_likelihood: 38235674405.7000 - val_loss: 15.3333 - val_squared_difference_loss: 11.5079 - val_KL_divergence_loss: 3.8254 - val_neg_log_likelihood: 14217855457424623616.0000\n",
      "Epoch 1871/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5830 - squared_difference_loss: 11.7555 - KL_divergence_loss: 3.8275 - neg_log_likelihood: 2478195641.2269 - val_loss: 15.3701 - val_squared_difference_loss: 11.5303 - val_KL_divergence_loss: 3.8397 - val_neg_log_likelihood: 2725525990421203456.0000\n",
      "Epoch 1872/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5329 - squared_difference_loss: 11.7128 - KL_divergence_loss: 3.8202 - neg_log_likelihood: 3936524180.8851 - val_loss: 15.3625 - val_squared_difference_loss: 11.5675 - val_KL_divergence_loss: 3.7950 - val_neg_log_likelihood: 15991032839113367552.0000\n",
      "Epoch 1873/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5494 - squared_difference_loss: 11.7347 - KL_divergence_loss: 3.8147 - neg_log_likelihood: 7126987453.5499 - val_loss: 15.3802 - val_squared_difference_loss: 11.5823 - val_KL_divergence_loss: 3.7979 - val_neg_log_likelihood: 10070246803603658752.0000\n",
      "Epoch 1874/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5237 - squared_difference_loss: 11.7168 - KL_divergence_loss: 3.8069 - neg_log_likelihood: 5104962453.4594 - val_loss: 15.3638 - val_squared_difference_loss: 11.5690 - val_KL_divergence_loss: 3.7948 - val_neg_log_likelihood: 2256423562207111424.0000\n",
      "Epoch 1875/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5074 - squared_difference_loss: 11.6808 - KL_divergence_loss: 3.8266 - neg_log_likelihood: 18992789511.3949 - val_loss: 15.3839 - val_squared_difference_loss: 11.5577 - val_KL_divergence_loss: 3.8262 - val_neg_log_likelihood: 20405262433762189312.0000\n",
      "Epoch 1876/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5510 - squared_difference_loss: 11.7313 - KL_divergence_loss: 3.8197 - neg_log_likelihood: 4169309816.0850 - val_loss: 15.3478 - val_squared_difference_loss: 11.5438 - val_KL_divergence_loss: 3.8040 - val_neg_log_likelihood: 13768276048803028992.0000\n",
      "Epoch 1877/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5706 - squared_difference_loss: 11.7519 - KL_divergence_loss: 3.8187 - neg_log_likelihood: 1197750948.5416 - val_loss: 15.3697 - val_squared_difference_loss: 11.5364 - val_KL_divergence_loss: 3.8333 - val_neg_log_likelihood: 20084505159182352384.0000\n",
      "Epoch 1878/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5463 - squared_difference_loss: 11.7242 - KL_divergence_loss: 3.8221 - neg_log_likelihood: 43401320753.4568 - val_loss: 15.3435 - val_squared_difference_loss: 11.5227 - val_KL_divergence_loss: 3.8208 - val_neg_log_likelihood: 10252702952662767616.0000\n",
      "Epoch 1879/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5216 - squared_difference_loss: 11.7205 - KL_divergence_loss: 3.8011 - neg_log_likelihood: 7641116703.4257 - val_loss: 15.3345 - val_squared_difference_loss: 11.5296 - val_KL_divergence_loss: 3.8048 - val_neg_log_likelihood: 14350883854052218880.0000\n",
      "Epoch 1880/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5397 - squared_difference_loss: 11.7243 - KL_divergence_loss: 3.8153 - neg_log_likelihood: 96765627366.9813 - val_loss: 15.3368 - val_squared_difference_loss: 11.5234 - val_KL_divergence_loss: 3.8134 - val_neg_log_likelihood: 34842170968256180224.0000\n",
      "Epoch 1881/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5590 - squared_difference_loss: 11.7358 - KL_divergence_loss: 3.8232 - neg_log_likelihood: 3766873897.5601 - val_loss: 15.3613 - val_squared_difference_loss: 11.5506 - val_KL_divergence_loss: 3.8108 - val_neg_log_likelihood: 8007359546795272192.0000\n",
      "Epoch 1882/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5380 - squared_difference_loss: 11.7241 - KL_divergence_loss: 3.8139 - neg_log_likelihood: 2604067474.9913 - val_loss: 15.3781 - val_squared_difference_loss: 11.5955 - val_KL_divergence_loss: 3.7826 - val_neg_log_likelihood: 16321187827223478272.0000\n",
      "Epoch 1883/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5425 - squared_difference_loss: 11.7396 - KL_divergence_loss: 3.8029 - neg_log_likelihood: 2317239120.6020 - val_loss: 15.3442 - val_squared_difference_loss: 11.5378 - val_KL_divergence_loss: 3.8064 - val_neg_log_likelihood: 27938886949356220416.0000\n",
      "Epoch 1884/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5235 - squared_difference_loss: 11.7191 - KL_divergence_loss: 3.8044 - neg_log_likelihood: 29578074972.9679 - val_loss: 15.3603 - val_squared_difference_loss: 11.5573 - val_KL_divergence_loss: 3.8030 - val_neg_log_likelihood: 5071814947769749504.0000\n",
      "Epoch 1885/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5275 - squared_difference_loss: 11.7264 - KL_divergence_loss: 3.8011 - neg_log_likelihood: 19864510338.4364 - val_loss: 15.3606 - val_squared_difference_loss: 11.5424 - val_KL_divergence_loss: 3.8182 - val_neg_log_likelihood: 18836972001775878144.0000\n",
      "Epoch 1886/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5411 - squared_difference_loss: 11.7238 - KL_divergence_loss: 3.8174 - neg_log_likelihood: 11547093023.8087 - val_loss: 15.3462 - val_squared_difference_loss: 11.5344 - val_KL_divergence_loss: 3.8118 - val_neg_log_likelihood: 26212521366282018816.0000\n",
      "Epoch 1887/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5447 - squared_difference_loss: 11.7415 - KL_divergence_loss: 3.8032 - neg_log_likelihood: 42235000205.3248 - val_loss: 15.3603 - val_squared_difference_loss: 11.5491 - val_KL_divergence_loss: 3.8112 - val_neg_log_likelihood: 8611803535464605696.0000\n",
      "Epoch 1888/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 15.5456 - squared_difference_loss: 11.7122 - KL_divergence_loss: 3.8334 - neg_log_likelihood: 3683183090.5074 - val_loss: 15.3582 - val_squared_difference_loss: 11.5592 - val_KL_divergence_loss: 3.7990 - val_neg_log_likelihood: 3160972397607956480.0000\n",
      "Epoch 1889/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5693 - squared_difference_loss: 11.7672 - KL_divergence_loss: 3.8022 - neg_log_likelihood: 1613255827.9828 - val_loss: 15.3555 - val_squared_difference_loss: 11.5624 - val_KL_divergence_loss: 3.7930 - val_neg_log_likelihood: 22661194949510049792.0000\n",
      "Epoch 1890/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5610 - squared_difference_loss: 11.7490 - KL_divergence_loss: 3.8119 - neg_log_likelihood: 1234023784.6616 - val_loss: 15.3295 - val_squared_difference_loss: 11.5349 - val_KL_divergence_loss: 3.7947 - val_neg_log_likelihood: 8009506565700157440.0000\n",
      "Epoch 1891/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 15.5426 - squared_difference_loss: 11.7281 - KL_divergence_loss: 3.8146 - neg_log_likelihood: 1203407948.2478 - val_loss: 15.3297 - val_squared_difference_loss: 11.5351 - val_KL_divergence_loss: 3.7946 - val_neg_log_likelihood: 8387077836665018368.0000\n",
      "Epoch 1892/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5467 - squared_difference_loss: 11.7199 - KL_divergence_loss: 3.8267 - neg_log_likelihood: 1401911030.3598 - val_loss: 15.3406 - val_squared_difference_loss: 11.5252 - val_KL_divergence_loss: 3.8154 - val_neg_log_likelihood: 33889174375448743936.0000\n",
      "Epoch 1893/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5361 - squared_difference_loss: 11.7163 - KL_divergence_loss: 3.8198 - neg_log_likelihood: 2597815272.3563 - val_loss: 15.3649 - val_squared_difference_loss: 11.5422 - val_KL_divergence_loss: 3.8227 - val_neg_log_likelihood: 7408734876420356096.0000\n",
      "Epoch 1894/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5690 - squared_difference_loss: 11.7483 - KL_divergence_loss: 3.8206 - neg_log_likelihood: 21246391400.2005 - val_loss: 15.3701 - val_squared_difference_loss: 11.5470 - val_KL_divergence_loss: 3.8231 - val_neg_log_likelihood: 16871896865083191296.0000\n",
      "Epoch 1895/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5538 - squared_difference_loss: 11.7376 - KL_divergence_loss: 3.8162 - neg_log_likelihood: 300198690.7447 - val_loss: 15.3658 - val_squared_difference_loss: 11.5771 - val_KL_divergence_loss: 3.7886 - val_neg_log_likelihood: 1499085155831352832.0000\n",
      "Epoch 1896/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5847 - squared_difference_loss: 11.7560 - KL_divergence_loss: 3.8287 - neg_log_likelihood: 89704256518.6723 - val_loss: 15.3460 - val_squared_difference_loss: 11.5297 - val_KL_divergence_loss: 3.8163 - val_neg_log_likelihood: 20258237561642704896.0000\n",
      "Epoch 1897/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5382 - squared_difference_loss: 11.7154 - KL_divergence_loss: 3.8228 - neg_log_likelihood: 6416804707.5223 - val_loss: 15.4205 - val_squared_difference_loss: 11.6346 - val_KL_divergence_loss: 3.7859 - val_neg_log_likelihood: 29922462641444012032.0000\n",
      "Epoch 1898/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5262 - squared_difference_loss: 11.7293 - KL_divergence_loss: 3.7970 - neg_log_likelihood: 979722836.0233 - val_loss: 15.3816 - val_squared_difference_loss: 11.5891 - val_KL_divergence_loss: 3.7924 - val_neg_log_likelihood: 17117059322036695040.0000\n",
      "Epoch 1899/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5273 - squared_difference_loss: 11.7224 - KL_divergence_loss: 3.8050 - neg_log_likelihood: 1026300868.5450 - val_loss: 15.3377 - val_squared_difference_loss: 11.5489 - val_KL_divergence_loss: 3.7888 - val_neg_log_likelihood: 13753794192772276224.0000\n",
      "Epoch 1900/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 15.5118 - squared_difference_loss: 11.7059 - KL_divergence_loss: 3.8059 - neg_log_likelihood: 12755226683.8353 - val_loss: 15.3045 - val_squared_difference_loss: 11.5137 - val_KL_divergence_loss: 3.7908 - val_neg_log_likelihood: 14400416560095037440.0000\n",
      "Epoch 1901/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5485 - squared_difference_loss: 11.7492 - KL_divergence_loss: 3.7993 - neg_log_likelihood: 1900941904.9807 - val_loss: 15.3782 - val_squared_difference_loss: 11.5945 - val_KL_divergence_loss: 3.7837 - val_neg_log_likelihood: 9595012253843648512.0000\n",
      "Epoch 1902/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5230 - squared_difference_loss: 11.7063 - KL_divergence_loss: 3.8167 - neg_log_likelihood: 10833527113.7961 - val_loss: 15.3496 - val_squared_difference_loss: 11.5445 - val_KL_divergence_loss: 3.8051 - val_neg_log_likelihood: 2358831249707325440.0000\n",
      "Epoch 1903/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 15.5635 - squared_difference_loss: 11.7483 - KL_divergence_loss: 3.8152 - neg_log_likelihood: 3296033909.8614 - val_loss: 15.3330 - val_squared_difference_loss: 11.5173 - val_KL_divergence_loss: 3.8157 - val_neg_log_likelihood: 28950873748518076416.0000\n",
      "Epoch 1904/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5978 - squared_difference_loss: 11.7677 - KL_divergence_loss: 3.8301 - neg_log_likelihood: 110536408.6495 - val_loss: 15.3141 - val_squared_difference_loss: 11.5154 - val_KL_divergence_loss: 3.7988 - val_neg_log_likelihood: 31055620856695267328.0000\n",
      "Epoch 1905/2000\n",
      "29507/29507 [==============================] - 0s 13us/step - loss: 15.5302 - squared_difference_loss: 11.7267 - KL_divergence_loss: 3.8035 - neg_log_likelihood: 5793002564.1579 - val_loss: 15.3622 - val_squared_difference_loss: 11.5848 - val_KL_divergence_loss: 3.7773 - val_neg_log_likelihood: 16860034260153057280.0000\n",
      "Epoch 1906/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5361 - squared_difference_loss: 11.7253 - KL_divergence_loss: 3.8108 - neg_log_likelihood: 16278873321.7835 - val_loss: 15.3474 - val_squared_difference_loss: 11.5382 - val_KL_divergence_loss: 3.8092 - val_neg_log_likelihood: 11345171204766646272.0000\n",
      "Epoch 1907/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5484 - squared_difference_loss: 11.7432 - KL_divergence_loss: 3.8052 - neg_log_likelihood: 2190993934.8185 - val_loss: 15.3310 - val_squared_difference_loss: 11.5173 - val_KL_divergence_loss: 3.8137 - val_neg_log_likelihood: 9136864969257540608.0000\n",
      "Epoch 1908/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5012 - squared_difference_loss: 11.6899 - KL_divergence_loss: 3.8113 - neg_log_likelihood: 7239108454.7279 - val_loss: 15.3519 - val_squared_difference_loss: 11.5534 - val_KL_divergence_loss: 3.7985 - val_neg_log_likelihood: 15209844907351033856.0000\n",
      "Epoch 1909/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5419 - squared_difference_loss: 11.7307 - KL_divergence_loss: 3.8112 - neg_log_likelihood: 6972123505.3883 - val_loss: 15.3554 - val_squared_difference_loss: 11.5535 - val_KL_divergence_loss: 3.8019 - val_neg_log_likelihood: 16357404334584791040.0000\n",
      "Epoch 1910/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5209 - squared_difference_loss: 11.7029 - KL_divergence_loss: 3.8180 - neg_log_likelihood: 4626726719.3019 - val_loss: 15.3551 - val_squared_difference_loss: 11.5748 - val_KL_divergence_loss: 3.7804 - val_neg_log_likelihood: 33719258917872209920.0000\n",
      "Epoch 1911/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5159 - squared_difference_loss: 11.7218 - KL_divergence_loss: 3.7941 - neg_log_likelihood: 31206930358.7739 - val_loss: 15.4021 - val_squared_difference_loss: 11.6249 - val_KL_divergence_loss: 3.7771 - val_neg_log_likelihood: 9809036144870842368.0000\n",
      "Epoch 1912/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5665 - squared_difference_loss: 11.7691 - KL_divergence_loss: 3.7974 - neg_log_likelihood: 1821512808.1463 - val_loss: 15.3715 - val_squared_difference_loss: 11.5688 - val_KL_divergence_loss: 3.8027 - val_neg_log_likelihood: 47259029897592406016.0000\n",
      "Epoch 1913/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5653 - squared_difference_loss: 11.7360 - KL_divergence_loss: 3.8293 - neg_log_likelihood: 379310551.2089 - val_loss: 15.3410 - val_squared_difference_loss: 11.5192 - val_KL_divergence_loss: 3.8218 - val_neg_log_likelihood: 23809479111269675008.0000\n",
      "Epoch 1914/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5408 - squared_difference_loss: 11.7167 - KL_divergence_loss: 3.8241 - neg_log_likelihood: 4288174099.2346 - val_loss: 15.3677 - val_squared_difference_loss: 11.5834 - val_KL_divergence_loss: 3.7843 - val_neg_log_likelihood: 13663603478157457408.0000\n",
      "Epoch 1915/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5347 - squared_difference_loss: 11.7453 - KL_divergence_loss: 3.7894 - neg_log_likelihood: 9484645753.2252 - val_loss: 15.3335 - val_squared_difference_loss: 11.5376 - val_KL_divergence_loss: 3.7959 - val_neg_log_likelihood: 43173953753800400896.0000\n",
      "Epoch 1916/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5383 - squared_difference_loss: 11.7172 - KL_divergence_loss: 3.8211 - neg_log_likelihood: 12529197106.3651 - val_loss: 15.3725 - val_squared_difference_loss: 11.5871 - val_KL_divergence_loss: 3.7854 - val_neg_log_likelihood: 1189616559580502016.0000\n",
      "Epoch 1917/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5472 - squared_difference_loss: 11.7442 - KL_divergence_loss: 3.8030 - neg_log_likelihood: 13288632816.6932 - val_loss: 15.3344 - val_squared_difference_loss: 11.5326 - val_KL_divergence_loss: 3.8018 - val_neg_log_likelihood: 36328739149672038400.0000\n",
      "Epoch 1918/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 15.5406 - squared_difference_loss: 11.7373 - KL_divergence_loss: 3.8033 - neg_log_likelihood: 32579398731.3103 - val_loss: 15.3686 - val_squared_difference_loss: 11.5748 - val_KL_divergence_loss: 3.7938 - val_neg_log_likelihood: 7584802100655352832.0000\n",
      "Epoch 1919/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5470 - squared_difference_loss: 11.7471 - KL_divergence_loss: 3.7999 - neg_log_likelihood: 1427147245.9867 - val_loss: 15.3416 - val_squared_difference_loss: 11.5365 - val_KL_divergence_loss: 3.8051 - val_neg_log_likelihood: 15232340448176388096.0000\n",
      "Epoch 1920/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5611 - squared_difference_loss: 11.7575 - KL_divergence_loss: 3.8035 - neg_log_likelihood: 109978330.4887 - val_loss: 15.3312 - val_squared_difference_loss: 11.5204 - val_KL_divergence_loss: 3.8108 - val_neg_log_likelihood: 7992322658160214016.0000\n",
      "Epoch 1921/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 15.5643 - squared_difference_loss: 11.7486 - KL_divergence_loss: 3.8157 - neg_log_likelihood: 141915556.8863 - val_loss: 15.3644 - val_squared_difference_loss: 11.5801 - val_KL_divergence_loss: 3.7843 - val_neg_log_likelihood: 21353108072154353664.0000\n",
      "Epoch 1922/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5748 - squared_difference_loss: 11.7677 - KL_divergence_loss: 3.8071 - neg_log_likelihood: 8024672729.5850 - val_loss: 15.3629 - val_squared_difference_loss: 11.5633 - val_KL_divergence_loss: 3.7997 - val_neg_log_likelihood: 9720027096726044672.0000\n",
      "Epoch 1923/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5456 - squared_difference_loss: 11.7451 - KL_divergence_loss: 3.8005 - neg_log_likelihood: 8014707265.7111 - val_loss: 15.3756 - val_squared_difference_loss: 11.5905 - val_KL_divergence_loss: 3.7851 - val_neg_log_likelihood: 12867709690415923200.0000\n",
      "Epoch 1924/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5470 - squared_difference_loss: 11.7570 - KL_divergence_loss: 3.7900 - neg_log_likelihood: 11412633679.9574 - val_loss: 15.3902 - val_squared_difference_loss: 11.5967 - val_KL_divergence_loss: 3.7936 - val_neg_log_likelihood: 31887891062355869696.0000\n",
      "Epoch 1925/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5338 - squared_difference_loss: 11.7264 - KL_divergence_loss: 3.8074 - neg_log_likelihood: 2693390081.8353 - val_loss: 15.3510 - val_squared_difference_loss: 11.5566 - val_KL_divergence_loss: 3.7944 - val_neg_log_likelihood: 37315206362824114176.0000\n",
      "Epoch 1926/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5518 - squared_difference_loss: 11.7448 - KL_divergence_loss: 3.8070 - neg_log_likelihood: 5639082105.0933 - val_loss: 15.3509 - val_squared_difference_loss: 11.5414 - val_KL_divergence_loss: 3.8095 - val_neg_log_likelihood: 34045966960814755840.0000\n",
      "Epoch 1927/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5446 - squared_difference_loss: 11.7238 - KL_divergence_loss: 3.8209 - neg_log_likelihood: 758076061.9283 - val_loss: 15.3473 - val_squared_difference_loss: 11.5396 - val_KL_divergence_loss: 3.8077 - val_neg_log_likelihood: 34448538279877607424.0000\n",
      "Epoch 1928/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5590 - squared_difference_loss: 11.7481 - KL_divergence_loss: 3.8110 - neg_log_likelihood: 3819828762.3560 - val_loss: 15.3599 - val_squared_difference_loss: 11.5475 - val_KL_divergence_loss: 3.8124 - val_neg_log_likelihood: 15449752139430848512.0000\n",
      "Epoch 1929/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5359 - squared_difference_loss: 11.7159 - KL_divergence_loss: 3.8200 - neg_log_likelihood: 7787525366.2962 - val_loss: 15.3704 - val_squared_difference_loss: 11.5769 - val_KL_divergence_loss: 3.7935 - val_neg_log_likelihood: 10094536024164581376.0000\n",
      "Epoch 1930/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5532 - squared_difference_loss: 11.7431 - KL_divergence_loss: 3.8102 - neg_log_likelihood: 2293678626.4050 - val_loss: 15.3934 - val_squared_difference_loss: 11.6032 - val_KL_divergence_loss: 3.7903 - val_neg_log_likelihood: 6682168690251943936.0000\n",
      "Epoch 1931/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5550 - squared_difference_loss: 11.7400 - KL_divergence_loss: 3.8151 - neg_log_likelihood: 1791729645.2627 - val_loss: 15.3420 - val_squared_difference_loss: 11.5664 - val_KL_divergence_loss: 3.7755 - val_neg_log_likelihood: 7424167528459817984.0000\n",
      "Epoch 1932/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5392 - squared_difference_loss: 11.7253 - KL_divergence_loss: 3.8138 - neg_log_likelihood: 38587315787.7070 - val_loss: 15.3759 - val_squared_difference_loss: 11.5583 - val_KL_divergence_loss: 3.8176 - val_neg_log_likelihood: 11550478952144138240.0000\n",
      "Epoch 1933/2000\n",
      "29507/29507 [==============================] - 1s 19us/step - loss: 15.5369 - squared_difference_loss: 11.7252 - KL_divergence_loss: 3.8117 - neg_log_likelihood: 3848283782.5775 - val_loss: 15.3861 - val_squared_difference_loss: 11.5911 - val_KL_divergence_loss: 3.7950 - val_neg_log_likelihood: 15032850585587873792.0000\n",
      "Epoch 1934/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5322 - squared_difference_loss: 11.7374 - KL_divergence_loss: 3.7948 - neg_log_likelihood: 95639854.4370 - val_loss: 15.3571 - val_squared_difference_loss: 11.5726 - val_KL_divergence_loss: 3.7846 - val_neg_log_likelihood: 13230897151804964864.0000\n",
      "Epoch 1935/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5646 - squared_difference_loss: 11.7486 - KL_divergence_loss: 3.8160 - neg_log_likelihood: 3156141991.9516 - val_loss: 15.3846 - val_squared_difference_loss: 11.5788 - val_KL_divergence_loss: 3.8058 - val_neg_log_likelihood: 11469155246415235072.0000\n",
      "Epoch 1936/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5819 - squared_difference_loss: 11.7641 - KL_divergence_loss: 3.8178 - neg_log_likelihood: 459639704.7378 - val_loss: 15.3720 - val_squared_difference_loss: 11.5688 - val_KL_divergence_loss: 3.8033 - val_neg_log_likelihood: 7388924717647104000.0000\n",
      "Epoch 1937/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5454 - squared_difference_loss: 11.7409 - KL_divergence_loss: 3.8045 - neg_log_likelihood: 1491999530.4302 - val_loss: 15.3533 - val_squared_difference_loss: 11.5564 - val_KL_divergence_loss: 3.7969 - val_neg_log_likelihood: 4166865487229911040.0000\n",
      "Epoch 1938/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5390 - squared_difference_loss: 11.7247 - KL_divergence_loss: 3.8144 - neg_log_likelihood: 2211826759.2152 - val_loss: 15.3474 - val_squared_difference_loss: 11.5404 - val_KL_divergence_loss: 3.8070 - val_neg_log_likelihood: 18414226746446249984.0000\n",
      "Epoch 1939/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5295 - squared_difference_loss: 11.7253 - KL_divergence_loss: 3.8043 - neg_log_likelihood: 10725899602.6671 - val_loss: 15.3600 - val_squared_difference_loss: 11.5443 - val_KL_divergence_loss: 3.8157 - val_neg_log_likelihood: 27937109212032565248.0000\n",
      "Epoch 1940/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5481 - squared_difference_loss: 11.7292 - KL_divergence_loss: 3.8189 - neg_log_likelihood: 2302969399.0459 - val_loss: 15.3505 - val_squared_difference_loss: 11.5344 - val_KL_divergence_loss: 3.8160 - val_neg_log_likelihood: 25793622303840911360.0000\n",
      "Epoch 1941/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 15.5321 - squared_difference_loss: 11.7168 - KL_divergence_loss: 3.8153 - neg_log_likelihood: 24162346993.6864 - val_loss: 15.3474 - val_squared_difference_loss: 11.5429 - val_KL_divergence_loss: 3.8045 - val_neg_log_likelihood: 13600237086640683008.0000\n",
      "Epoch 1942/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5267 - squared_difference_loss: 11.7180 - KL_divergence_loss: 3.8087 - neg_log_likelihood: 20502171627.5692 - val_loss: 15.3519 - val_squared_difference_loss: 11.5398 - val_KL_divergence_loss: 3.8121 - val_neg_log_likelihood: 10090287170600087552.0000\n",
      "Epoch 1943/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5273 - squared_difference_loss: 11.7062 - KL_divergence_loss: 3.8211 - neg_log_likelihood: 1405296296.4174 - val_loss: 15.3556 - val_squared_difference_loss: 11.5788 - val_KL_divergence_loss: 3.7768 - val_neg_log_likelihood: 8009488491310262272.0000\n",
      "Epoch 1944/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5273 - squared_difference_loss: 11.7310 - KL_divergence_loss: 3.7962 - neg_log_likelihood: 75497968123.6939 - val_loss: 15.3567 - val_squared_difference_loss: 11.5841 - val_KL_divergence_loss: 3.7726 - val_neg_log_likelihood: 9406749296992378880.0000\n",
      "Epoch 1945/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5457 - squared_difference_loss: 11.7314 - KL_divergence_loss: 3.8143 - neg_log_likelihood: 2236459920.9689 - val_loss: 15.3394 - val_squared_difference_loss: 11.5440 - val_KL_divergence_loss: 3.7954 - val_neg_log_likelihood: 4245695099194129920.0000\n",
      "Epoch 1946/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5460 - squared_difference_loss: 11.7411 - KL_divergence_loss: 3.8049 - neg_log_likelihood: 2027975834.1797 - val_loss: 15.3536 - val_squared_difference_loss: 11.5577 - val_KL_divergence_loss: 3.7959 - val_neg_log_likelihood: 12754823142512613376.0000\n",
      "Epoch 1947/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 15.5295 - squared_difference_loss: 11.7265 - KL_divergence_loss: 3.8030 - neg_log_likelihood: 7047026746.9944 - val_loss: 15.3565 - val_squared_difference_loss: 11.5895 - val_KL_divergence_loss: 3.7671 - val_neg_log_likelihood: 9175019158796040192.0000\n",
      "Epoch 1948/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5464 - squared_difference_loss: 11.7397 - KL_divergence_loss: 3.8067 - neg_log_likelihood: 6292177552.7124 - val_loss: 15.3185 - val_squared_difference_loss: 11.4979 - val_KL_divergence_loss: 3.8206 - val_neg_log_likelihood: 7908370626718028800.0000\n",
      "Epoch 1949/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5400 - squared_difference_loss: 11.7432 - KL_divergence_loss: 3.7968 - neg_log_likelihood: 366331875.3347 - val_loss: 15.3643 - val_squared_difference_loss: 11.5948 - val_KL_divergence_loss: 3.7695 - val_neg_log_likelihood: 8308075772819316736.0000\n",
      "Epoch 1950/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5352 - squared_difference_loss: 11.7279 - KL_divergence_loss: 3.8074 - neg_log_likelihood: 2932274287.4046 - val_loss: 15.3565 - val_squared_difference_loss: 11.5571 - val_KL_divergence_loss: 3.7994 - val_neg_log_likelihood: 5893750281019689984.0000\n",
      "Epoch 1951/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5590 - squared_difference_loss: 11.7381 - KL_divergence_loss: 3.8208 - neg_log_likelihood: 1610622702.8628 - val_loss: 15.3607 - val_squared_difference_loss: 11.5507 - val_KL_divergence_loss: 3.8100 - val_neg_log_likelihood: 8765021205306123264.0000\n",
      "Epoch 1952/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5284 - squared_difference_loss: 11.7305 - KL_divergence_loss: 3.7979 - neg_log_likelihood: 5812476494.0462 - val_loss: 15.3149 - val_squared_difference_loss: 11.5201 - val_KL_divergence_loss: 3.7948 - val_neg_log_likelihood: 10391740626168377344.0000\n",
      "Epoch 1953/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5252 - squared_difference_loss: 11.7152 - KL_divergence_loss: 3.8100 - neg_log_likelihood: 6033584291.0384 - val_loss: 15.3580 - val_squared_difference_loss: 11.5354 - val_KL_divergence_loss: 3.8226 - val_neg_log_likelihood: 7986721028108248064.0000\n",
      "Epoch 1954/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5189 - squared_difference_loss: 11.7162 - KL_divergence_loss: 3.8026 - neg_log_likelihood: 5667076213.6160 - val_loss: 15.3782 - val_squared_difference_loss: 11.5841 - val_KL_divergence_loss: 3.7940 - val_neg_log_likelihood: 18830692934523248640.0000\n",
      "Epoch 1955/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5312 - squared_difference_loss: 11.7244 - KL_divergence_loss: 3.8067 - neg_log_likelihood: 3629461444.8969 - val_loss: 15.3673 - val_squared_difference_loss: 11.5755 - val_KL_divergence_loss: 3.7919 - val_neg_log_likelihood: 8018090548059234304.0000\n",
      "Epoch 1956/2000\n",
      "29507/29507 [==============================] - 1s 19us/step - loss: 15.5674 - squared_difference_loss: 11.7619 - KL_divergence_loss: 3.8055 - neg_log_likelihood: 471459050.5035 - val_loss: 15.3335 - val_squared_difference_loss: 11.5142 - val_KL_divergence_loss: 3.8194 - val_neg_log_likelihood: 10427782560562337792.0000\n",
      "Epoch 1957/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5324 - squared_difference_loss: 11.7222 - KL_divergence_loss: 3.8102 - neg_log_likelihood: 2721020906.6247 - val_loss: 15.3269 - val_squared_difference_loss: 11.5235 - val_KL_divergence_loss: 3.8033 - val_neg_log_likelihood: 8010137410554609664.0000\n",
      "Epoch 1958/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5383 - squared_difference_loss: 11.7199 - KL_divergence_loss: 3.8184 - neg_log_likelihood: 6343520595.3869 - val_loss: 15.3723 - val_squared_difference_loss: 11.5812 - val_KL_divergence_loss: 3.7911 - val_neg_log_likelihood: 11787475469014587392.0000\n",
      "Epoch 1959/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5295 - squared_difference_loss: 11.7341 - KL_divergence_loss: 3.7954 - neg_log_likelihood: 5265902114.9557 - val_loss: 15.3372 - val_squared_difference_loss: 11.5656 - val_KL_divergence_loss: 3.7716 - val_neg_log_likelihood: 6922261643290444800.0000\n",
      "Epoch 1960/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5447 - squared_difference_loss: 11.7436 - KL_divergence_loss: 3.8011 - neg_log_likelihood: 13534973215.0109 - val_loss: 15.3638 - val_squared_difference_loss: 11.5573 - val_KL_divergence_loss: 3.8065 - val_neg_log_likelihood: 10606199908778129408.0000\n",
      "Epoch 1961/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5740 - squared_difference_loss: 11.7704 - KL_divergence_loss: 3.8035 - neg_log_likelihood: 1677065077.5747 - val_loss: 15.3822 - val_squared_difference_loss: 11.5715 - val_KL_divergence_loss: 3.8107 - val_neg_log_likelihood: 12232625817960554496.0000\n",
      "Epoch 1962/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5327 - squared_difference_loss: 11.7325 - KL_divergence_loss: 3.8002 - neg_log_likelihood: 928644879.7638 - val_loss: 15.3559 - val_squared_difference_loss: 11.5684 - val_KL_divergence_loss: 3.7875 - val_neg_log_likelihood: 10712863768900585472.0000\n",
      "Epoch 1963/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5468 - squared_difference_loss: 11.7362 - KL_divergence_loss: 3.8106 - neg_log_likelihood: 504187577.4145 - val_loss: 15.3459 - val_squared_difference_loss: 11.5520 - val_KL_divergence_loss: 3.7939 - val_neg_log_likelihood: 10660800079318085632.0000\n",
      "Epoch 1964/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5373 - squared_difference_loss: 11.7358 - KL_divergence_loss: 3.8015 - neg_log_likelihood: 272221127.1533 - val_loss: 15.3755 - val_squared_difference_loss: 11.5826 - val_KL_divergence_loss: 3.7929 - val_neg_log_likelihood: 36863212227371433984.0000\n",
      "Epoch 1965/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5161 - squared_difference_loss: 11.7081 - KL_divergence_loss: 3.8081 - neg_log_likelihood: 20033407789.0832 - val_loss: 15.3244 - val_squared_difference_loss: 11.5119 - val_KL_divergence_loss: 3.8126 - val_neg_log_likelihood: 35570721422459432960.0000\n",
      "Epoch 1966/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5358 - squared_difference_loss: 11.7385 - KL_divergence_loss: 3.7973 - neg_log_likelihood: 8429263972.4733 - val_loss: 15.3600 - val_squared_difference_loss: 11.5679 - val_KL_divergence_loss: 3.7921 - val_neg_log_likelihood: 19987574970792181760.0000\n",
      "Epoch 1967/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5187 - squared_difference_loss: 11.6988 - KL_divergence_loss: 3.8199 - neg_log_likelihood: 7818114475.1456 - val_loss: 15.3142 - val_squared_difference_loss: 11.5122 - val_KL_divergence_loss: 3.8020 - val_neg_log_likelihood: 7443803814940697600.0000\n",
      "Epoch 1968/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5500 - squared_difference_loss: 11.7214 - KL_divergence_loss: 3.8286 - neg_log_likelihood: 9797988694.8499 - val_loss: 15.3396 - val_squared_difference_loss: 11.5373 - val_KL_divergence_loss: 3.8023 - val_neg_log_likelihood: 12535497401784870912.0000\n",
      "Epoch 1969/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5175 - squared_difference_loss: 11.7068 - KL_divergence_loss: 3.8107 - neg_log_likelihood: 8661673220.2583 - val_loss: 15.3586 - val_squared_difference_loss: 11.5711 - val_KL_divergence_loss: 3.7875 - val_neg_log_likelihood: 5457080958938458112.0000\n",
      "Epoch 1970/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5263 - squared_difference_loss: 11.7250 - KL_divergence_loss: 3.8014 - neg_log_likelihood: 21973765897.5303 - val_loss: 15.3671 - val_squared_difference_loss: 11.5754 - val_KL_divergence_loss: 3.7917 - val_neg_log_likelihood: 11816991452216903680.0000\n",
      "Epoch 1971/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5465 - squared_difference_loss: 11.7326 - KL_divergence_loss: 3.8140 - neg_log_likelihood: 861423545.0474 - val_loss: 15.3416 - val_squared_difference_loss: 11.5431 - val_KL_divergence_loss: 3.7984 - val_neg_log_likelihood: 15858638687089901568.0000\n",
      "Epoch 1972/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5373 - squared_difference_loss: 11.7167 - KL_divergence_loss: 3.8206 - neg_log_likelihood: 4389451089.0236 - val_loss: 15.3533 - val_squared_difference_loss: 11.5413 - val_KL_divergence_loss: 3.8120 - val_neg_log_likelihood: 5169083852322933760.0000\n",
      "Epoch 1973/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5298 - squared_difference_loss: 11.7181 - KL_divergence_loss: 3.8117 - neg_log_likelihood: 3332239889.6062 - val_loss: 15.3441 - val_squared_difference_loss: 11.5540 - val_KL_divergence_loss: 3.7901 - val_neg_log_likelihood: 8500222437619365888.0000\n",
      "Epoch 1974/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5785 - squared_difference_loss: 11.7779 - KL_divergence_loss: 3.8006 - neg_log_likelihood: 2719829527.8479 - val_loss: 15.3689 - val_squared_difference_loss: 11.5747 - val_KL_divergence_loss: 3.7942 - val_neg_log_likelihood: 4281101343205242368.0000\n",
      "Epoch 1975/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 15.5310 - squared_difference_loss: 11.7308 - KL_divergence_loss: 3.8002 - neg_log_likelihood: 1636710814.6676 - val_loss: 15.3514 - val_squared_difference_loss: 11.5653 - val_KL_divergence_loss: 3.7861 - val_neg_log_likelihood: 6841205700604944384.0000\n",
      "Epoch 1976/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5409 - squared_difference_loss: 11.7194 - KL_divergence_loss: 3.8215 - neg_log_likelihood: 28476987292.8824 - val_loss: 15.3787 - val_squared_difference_loss: 11.5662 - val_KL_divergence_loss: 3.8125 - val_neg_log_likelihood: 2697219313789693952.0000\n",
      "Epoch 1977/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5366 - squared_difference_loss: 11.7271 - KL_divergence_loss: 3.8094 - neg_log_likelihood: 7439195692.2000 - val_loss: 15.3658 - val_squared_difference_loss: 11.5684 - val_KL_divergence_loss: 3.7974 - val_neg_log_likelihood: 6649593865582909440.0000\n",
      "Epoch 1978/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5179 - squared_difference_loss: 11.7008 - KL_divergence_loss: 3.8171 - neg_log_likelihood: 987286935.3653 - val_loss: 15.3260 - val_squared_difference_loss: 11.5360 - val_KL_divergence_loss: 3.7900 - val_neg_log_likelihood: 6467805395207995392.0000\n",
      "Epoch 1979/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5488 - squared_difference_loss: 11.7339 - KL_divergence_loss: 3.8148 - neg_log_likelihood: 2157324335.7228 - val_loss: 15.3392 - val_squared_difference_loss: 11.5351 - val_KL_divergence_loss: 3.8041 - val_neg_log_likelihood: 15015657634700183552.0000\n",
      "Epoch 1980/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5470 - squared_difference_loss: 11.7388 - KL_divergence_loss: 3.8081 - neg_log_likelihood: 6805297690.9166 - val_loss: 15.3132 - val_squared_difference_loss: 11.5170 - val_KL_divergence_loss: 3.7963 - val_neg_log_likelihood: 4454349314342963712.0000\n",
      "Epoch 1981/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5410 - squared_difference_loss: 11.7309 - KL_divergence_loss: 3.8100 - neg_log_likelihood: 2378341711.0651 - val_loss: 15.3543 - val_squared_difference_loss: 11.5621 - val_KL_divergence_loss: 3.7922 - val_neg_log_likelihood: 5663239353612570624.0000\n",
      "Epoch 1982/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5243 - squared_difference_loss: 11.7089 - KL_divergence_loss: 3.8154 - neg_log_likelihood: 286516618.2613 - val_loss: 15.3475 - val_squared_difference_loss: 11.5370 - val_KL_divergence_loss: 3.8104 - val_neg_log_likelihood: 3785431035443737600.0000\n",
      "Epoch 1983/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5247 - squared_difference_loss: 11.7184 - KL_divergence_loss: 3.8062 - neg_log_likelihood: 3037777951.7753 - val_loss: 15.3489 - val_squared_difference_loss: 11.5698 - val_KL_divergence_loss: 3.7791 - val_neg_log_likelihood: 2657459371156182016.0000\n",
      "Epoch 1984/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 15.5492 - squared_difference_loss: 11.7339 - KL_divergence_loss: 3.8153 - neg_log_likelihood: 4725412530.7535 - val_loss: 15.3359 - val_squared_difference_loss: 11.5464 - val_KL_divergence_loss: 3.7895 - val_neg_log_likelihood: 6282332814219622400.0000\n",
      "Epoch 1985/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5553 - squared_difference_loss: 11.7633 - KL_divergence_loss: 3.7920 - neg_log_likelihood: 4752533448.3857 - val_loss: 15.3550 - val_squared_difference_loss: 11.5768 - val_KL_divergence_loss: 3.7781 - val_neg_log_likelihood: 10984041717390198784.0000\n",
      "Epoch 1986/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5690 - squared_difference_loss: 11.7428 - KL_divergence_loss: 3.8262 - neg_log_likelihood: 1019393118.9968 - val_loss: 15.3601 - val_squared_difference_loss: 11.5423 - val_KL_divergence_loss: 3.8178 - val_neg_log_likelihood: 8457460487571240960.0000\n",
      "Epoch 1987/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 15.5211 - squared_difference_loss: 11.7071 - KL_divergence_loss: 3.8140 - neg_log_likelihood: 2227888592.0982 - val_loss: 15.3563 - val_squared_difference_loss: 11.5752 - val_KL_divergence_loss: 3.7811 - val_neg_log_likelihood: 13271438367341285376.0000\n",
      "Epoch 1988/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5275 - squared_difference_loss: 11.7299 - KL_divergence_loss: 3.7975 - neg_log_likelihood: 3603912314.2030 - val_loss: 15.3849 - val_squared_difference_loss: 11.5969 - val_KL_divergence_loss: 3.7880 - val_neg_log_likelihood: 6542761022248231936.0000\n",
      "Epoch 1989/2000\n",
      "29507/29507 [==============================] - 1s 17us/step - loss: 15.5426 - squared_difference_loss: 11.7433 - KL_divergence_loss: 3.7993 - neg_log_likelihood: 4026115117.1574 - val_loss: 15.3758 - val_squared_difference_loss: 11.5834 - val_KL_divergence_loss: 3.7924 - val_neg_log_likelihood: 5789526275964388352.0000\n",
      "Epoch 1990/2000\n",
      "29507/29507 [==============================] - 1s 18us/step - loss: 15.5356 - squared_difference_loss: 11.7270 - KL_divergence_loss: 3.8086 - neg_log_likelihood: 1645558870.8150 - val_loss: 15.3761 - val_squared_difference_loss: 11.5652 - val_KL_divergence_loss: 3.8109 - val_neg_log_likelihood: 15605996701682001920.0000\n",
      "Epoch 1991/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5448 - squared_difference_loss: 11.7258 - KL_divergence_loss: 3.8190 - neg_log_likelihood: 1054078400.6150 - val_loss: 15.3535 - val_squared_difference_loss: 11.5614 - val_KL_divergence_loss: 3.7921 - val_neg_log_likelihood: 3834745333031415808.0000\n",
      "Epoch 1992/2000\n",
      "29507/29507 [==============================] - 0s 17us/step - loss: 15.5182 - squared_difference_loss: 11.7163 - KL_divergence_loss: 3.8019 - neg_log_likelihood: 2050985777.5399 - val_loss: 15.3348 - val_squared_difference_loss: 11.5714 - val_KL_divergence_loss: 3.7634 - val_neg_log_likelihood: 4411070612409776128.0000\n",
      "Epoch 1993/2000\n",
      "29507/29507 [==============================] - 0s 14us/step - loss: 15.5325 - squared_difference_loss: 11.7523 - KL_divergence_loss: 3.7803 - neg_log_likelihood: 1199315461.1683 - val_loss: 15.3518 - val_squared_difference_loss: 11.5720 - val_KL_divergence_loss: 3.7798 - val_neg_log_likelihood: 12341706534223697920.0000\n",
      "Epoch 1994/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5275 - squared_difference_loss: 11.7297 - KL_divergence_loss: 3.7979 - neg_log_likelihood: 2479296761.5338 - val_loss: 15.3848 - val_squared_difference_loss: 11.6054 - val_KL_divergence_loss: 3.7794 - val_neg_log_likelihood: 6387305884859150336.0000\n",
      "Epoch 1995/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5505 - squared_difference_loss: 11.7499 - KL_divergence_loss: 3.8006 - neg_log_likelihood: 1737463315.0750 - val_loss: 15.3619 - val_squared_difference_loss: 11.5592 - val_KL_divergence_loss: 3.8028 - val_neg_log_likelihood: 60754967174882295808.0000\n",
      "Epoch 1996/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5227 - squared_difference_loss: 11.7200 - KL_divergence_loss: 3.8027 - neg_log_likelihood: 34517941145.9206 - val_loss: 15.3608 - val_squared_difference_loss: 11.5587 - val_KL_divergence_loss: 3.8021 - val_neg_log_likelihood: 8618198718906894336.0000\n",
      "Epoch 1997/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5547 - squared_difference_loss: 11.7370 - KL_divergence_loss: 3.8177 - neg_log_likelihood: 175689924.4103 - val_loss: 15.3180 - val_squared_difference_loss: 11.5130 - val_KL_divergence_loss: 3.8050 - val_neg_log_likelihood: 10807626734334810112.0000\n",
      "Epoch 1998/2000\n",
      "29507/29507 [==============================] - 0s 16us/step - loss: 15.5332 - squared_difference_loss: 11.7217 - KL_divergence_loss: 3.8115 - neg_log_likelihood: 752695877.0076 - val_loss: 15.3533 - val_squared_difference_loss: 11.5586 - val_KL_divergence_loss: 3.7946 - val_neg_log_likelihood: 3242919266792761856.0000\n",
      "Epoch 1999/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5505 - squared_difference_loss: 11.7316 - KL_divergence_loss: 3.8190 - neg_log_likelihood: 30094246929.7723 - val_loss: 15.3352 - val_squared_difference_loss: 11.5298 - val_KL_divergence_loss: 3.8054 - val_neg_log_likelihood: 5645254201490518016.0000\n",
      "Epoch 2000/2000\n",
      "29507/29507 [==============================] - 0s 15us/step - loss: 15.5446 - squared_difference_loss: 11.7313 - KL_divergence_loss: 3.8133 - neg_log_likelihood: 2655731927.7660 - val_loss: 15.3491 - val_squared_difference_loss: 11.5557 - val_KL_divergence_loss: 3.7934 - val_neg_log_likelihood: 6221091924336828416.0000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +=: 'float' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-582d65992afa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m                                             \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                                             \u001b[0mlatent_dimensions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlat_var_num\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                                             intermediate_dimensions=hid_var_num)\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mfold_num\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +=: 'float' and 'tuple'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "X_mat = np.array(X_model_input)\n",
    "\n",
    "n_folds = 5\n",
    "\n",
    "num_latent_vars = [10, 20, 30, 40, 50, 60]\n",
    "num_hidden_vars = [10, 25, 50, 100, 250, 1000, 2500, 5000]\n",
    "# num_latent_vars = [5, 10, 15, 20, 25, 30, 50, 75, 100, 150, 250, 500, 1000]\n",
    "# num_hidden_vars = [10, 25, 50, 100, 250, 500, 750, 1000, 1500, 2500, 5000]\n",
    "cv_results = pd.DataFrame(0,\n",
    "                           index=num_latent_vars,\n",
    "                           columns=num_hidden_vars)\n",
    "\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "kf.get_n_splits(X_mat)\n",
    "\n",
    "i = 1\n",
    "for lat_var_num in num_latent_vars:\n",
    "    for hid_var_num in num_hidden_vars:\n",
    "        print(\"Latent Var Num = {}\".format(lat_var_num))\n",
    "        print(\"Hidden Var Num = {}\".format(hid_var_num))\n",
    "        fold_num = 1\n",
    "        total_nll = 0.\n",
    "        \n",
    "        print('Simulation #{}: VAE with {} Latent Variable(s) and {} Hidden Variable(s)...'.format(i, lat_var_num, hid_var_num))\n",
    "        \n",
    "        for train_index, test_index in kf.split(X_mat):\n",
    "            X_train, X_test = X_mat[train_index], X_mat[test_index]\n",
    "            print(\"\\tEvaluating model on Fold {}\".format(fold_num))\n",
    "            total_nll += evaluate_vae_model(X_train, \n",
    "                                            X_test, \n",
    "                                            latent_dimensions=lat_var_num, \n",
    "                                            intermediate_dimensions=hid_var_num)\n",
    "            fold_num += 1\n",
    "            if fold_num > 1:\n",
    "                break\n",
    "\n",
    "        cv_results.loc[lat_var_num, hid_var_num] = total_nll / n_folds\n",
    "        print('\\tAvgerage Validation Squared Error = {}'.format(total_nll / n_folds))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>25</th>\n",
       "      <th>50</th>\n",
       "      <th>100</th>\n",
       "      <th>250</th>\n",
       "      <th>1000</th>\n",
       "      <th>2500</th>\n",
       "      <th>5000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      10    25    50    100   250   1000  2500  5000\n",
       "5        0     0     0     0     0     0     0     0\n",
       "10       0     0     0     0     0     0     0     0\n",
       "25       0     0     0     0     0     0     0     0\n",
       "50       0     0     0     0     0     0     0     0\n",
       "100      0     0     0     0     0     0     0     0\n",
       "250      0     0     0     0     0     0     0     0\n",
       "1000     0     0     0     0     0     0     0     0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(-my_cv_results)\n",
    "plt.xlabel('# Hidden Layer Variables')\n",
    "plt.ylabel('# Latent Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PCA and FA scores...\n",
      "Running PCA/FA for 5 Components...\n"
     ]
    }
   ],
   "source": [
    "# http://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_vs_fa_model_selection.html#sphx-glr-auto-examples-decomposition-plot-pca-vs-fa-model-selection-py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.covariance import ShrunkCovariance, LedoitWolf\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# #############################################################################\n",
    "# Fit the models\n",
    "\n",
    "n_components = np.arange(5, 50, 5)  # options for n_components\n",
    "\n",
    "def compute_scores(X):\n",
    "    pca = PCA(svd_solver='full')\n",
    "    fa = FactorAnalysis()\n",
    "\n",
    "    pca_scores, fa_scores = [], []\n",
    "    for n in n_components:\n",
    "        if n % 1 == 0:\n",
    "            print (\"Running PCA/FA for {} Components...\".format(n))\n",
    "        pca.n_components = n\n",
    "        fa.n_components = n\n",
    "        pca_scores.append(np.mean(cross_val_score(pca, X))) # Return the average log-likelihood of all samples.\n",
    "        fa_scores.append(np.mean(cross_val_score(fa, X))) # Return the average log-likelihood of all samples.\n",
    "    \n",
    "    return pca_scores, fa_scores\n",
    "\n",
    "def shrunk_cov_score(X):\n",
    "    shrinkages = np.logspace(-2, 0, 30)\n",
    "    cv = GridSearchCV(ShrunkCovariance(), {'shrinkage': shrinkages})\n",
    "    return np.mean(cross_val_score(cv.fit(X).best_estimator_, X))\n",
    "\n",
    "def lw_score(X):\n",
    "    return np.mean(cross_val_score(LedoitWolf(), X))\n",
    "\n",
    "print(\"Computing PCA and FA scores...\")\n",
    "pca_scores, fa_scores = compute_scores(X)\n",
    "n_components_pca = n_components[np.argmax(pca_scores)]\n",
    "n_components_fa = n_components[np.argmax(fa_scores)]\n",
    "\n",
    "pca = PCA(svd_solver='full', n_components='mle')\n",
    "pca.fit(X)\n",
    "n_components_pca_mle = pca.n_components_\n",
    "\n",
    "print(\"best n_components by PCA CV = %d\" % n_components_pca)\n",
    "print(\"best n_components by FactorAnalysis CV = %d\" % n_components_fa)\n",
    "print(\"best n_components by PCA MLE = %d\" % n_components_pca_mle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-347.84223695035411,\n",
       " -115.89896769655316,\n",
       " -112.67750997972912,\n",
       " -110.48183722108551,\n",
       " -108.67955504119895,\n",
       " -107.03236610284353,\n",
       " -105.39105114774401,\n",
       " -103.97962315929954,\n",
       " -102.66271691659124,\n",
       " -101.38721593865922,\n",
       " -100.13794689574883,\n",
       " -98.92299302234396,\n",
       " -97.752391801209569,\n",
       " -96.76292486127852,\n",
       " -95.534976780412038,\n",
       " -94.386431072794423,\n",
       " -93.41496395056555,\n",
       " -92.481518970189356,\n",
       " -91.584637251708571,\n",
       " -90.576231158887936,\n",
       " -89.848806159746744,\n",
       " -89.099105875251951,\n",
       " -88.310906036879331,\n",
       " -87.655443740083001,\n",
       " -87.023676564274638,\n",
       " -86.394045904128845,\n",
       " -85.851240469953026,\n",
       " -85.216656861828668,\n",
       " -84.56159005305669]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEKCAYAAADTgGjXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1377b9790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "#plt.plot(num_latent_vars[:6], -cv_results.loc[num_latent_vars[:6],150], 'g', label='VAE scores')\n",
    "\n",
    "plt.plot(n_components, pca_scores, 'b', label='PCA scores')\n",
    "plt.axvline(n_components_pca, color='b',\n",
    "            label='PCA CV: %d' % n_components_pca, linestyle='--')\n",
    "\n",
    "plt.plot(n_components, fa_scores, 'r', label='FA scores')\n",
    "plt.axvline(n_components_fa, color='r',\n",
    "            label='FactorAnalysis CV: %d' % n_components_fa,\n",
    "            linestyle='--')\n",
    "\n",
    "\n",
    "plt.axhline(lw_score(X), color='orange',\n",
    "            label='LedoitWolf MLE' % n_components_pca_mle, linestyle='-.')\n",
    "\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Log-Likelihood')\n",
    "# plt.ylabel('CV scores')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
