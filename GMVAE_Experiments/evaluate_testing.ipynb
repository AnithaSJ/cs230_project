{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import calinski_harabaz_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import sys\n",
    "from gmvae_model import GMVAE\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "n_x = 10\n",
    "n_z = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1350, 10)\n"
     ]
    }
   ],
   "source": [
    "true_clusters = 3\n",
    "dataset = load_and_mix_data('generated_from_cluster',true_clusters,True)\n",
    "print(dataset.train.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph written\n"
     ]
    }
   ],
   "source": [
    "model = GMVAE(k=k, n_x=n_x, n_z=n_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_z(sess, X, model, multiplier, k, n_z):\n",
    "    '''\n",
    "        For each datapoint in X, sample its latent representation 'multiplier' times\n",
    "        Returns: z - all latent vectors, ordered in [z1,z2,...,ZM,another z1,another z2,...], \n",
    "                    which makes it easy to divide into 'multiplier' \"batches\"\n",
    "                 category - for each latent vector, an indicator showing which cluster it belongs to\n",
    "    '''\n",
    "    M = len(X)\n",
    "    all_z = np.zeros((M*multiplier, k, n_z))\n",
    "    for i in range(k):\n",
    "        for j in range(multiplier):\n",
    "            all_z[M*j:M*(j+1), i] = sess.run(model.z[i],\n",
    "                                    feed_dict={'x:0': X})\n",
    "\n",
    "    qy = sess.run(model.qy, feed_dict={'x:0': X})\n",
    "    category = qy.argmax(axis=1)\n",
    "    category = np.concatenate([category for j in range(multiplier)])\n",
    "    y_pred = one_hot(category, depth=k).astype(bool)\n",
    "\n",
    "    z = all_z[y_pred]\n",
    "    return z, category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(X, n_z):\n",
    "    '''\n",
    "        Performs dimensionality reduction of dataset X, down to n_z dimensions\n",
    "        Returns: x - a reduced dimensionality representation of X\n",
    "    '''\n",
    "    pca_solver = PCA(n_components = n_z)\n",
    "    x = pca_solver.fit_transform(X)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gm(X, k):\n",
    "    '''\n",
    "        Clusters all data points in X into k clusters \n",
    "        Returns: labels - for each data point, an indicator showing which cluster it belongs to\n",
    "    '''\n",
    "    gm_solver = GaussianMixture(n_components = k)\n",
    "    gm_solver.fit(X)\n",
    "    labels = gm_solver.predict(X)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_pca_and_cluster(X, k, n_z):\n",
    "    '''\n",
    "        Performs PCA dimensionality reduction on X and clusters the result into k clusters\n",
    "        Returns: X_reducted - a reduced dimensionality representation of X\n",
    "                 X_labels - for each data point in X_reducted, an indicator showing which cluster it belongs to\n",
    "    '''\n",
    "    X_reducted = pca(X, n_z)\n",
    "    X_labels = gm(X_reducted, k)\n",
    "    return X_reducted, X_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pairwise_stability(sess, model, X, k, n_z):\n",
    "    '''\n",
    "        Computes pairwise stability for data set X and the given model\n",
    "        Looking at the clustering achieved by the model, for each pair of data points that are assigned to the same\n",
    "        cluster, see if they also are assigned to the same cluster using PCA + GMM clustering\n",
    "        Returns: Score indicating how close the clustering achieved by the model is to simpler PCA + GMM clustering\n",
    "    '''\n",
    "    X_reducted, X_labels = perform_pca_and_cluster(X, k, n_z)\n",
    "    z, category = sample_z(sess,\n",
    "                           X,\n",
    "                           model,\n",
    "                           multiplier = 1, \n",
    "                           k = k, \n",
    "                           n_z = n_z)\n",
    "    total_pairs = 0\n",
    "    stable_pairs = 0\n",
    "    for i in range(len(category)):\n",
    "        for j in range(i,len(category)):\n",
    "            if category[i] == category[j]:\n",
    "                total_pairs += 1\n",
    "                if X_labels[i] == X_labels[j]:\n",
    "                    stable_pairs += 1\n",
    "    return 1.*stable_pairs/total_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_and_compute_calinski_harabaz(sess, X, model, multiplier, k, n_z):\n",
    "    '''\n",
    "        For each datapoint in X, sample its latent representation 'multiplier' times\n",
    "        For each batch of samples ('multiplier' batches), compute the calinski harabasz index\n",
    "        Returns: A list containing the calinski harabasz index for each batch of samples\n",
    "    '''\n",
    "    z, categories = sample_z(sess,\n",
    "                           X,\n",
    "                           model,\n",
    "                           multiplier,\n",
    "                           k,\n",
    "                           n_z)\n",
    "    if np.unique(categories).shape[0] == 1:\n",
    "        print('All variables assigned to one cluster! Returning a score of 0.')\n",
    "        return np.zeros(multiplier)\n",
    "    output = np.zeros(multiplier)\n",
    "    M = X.shape[0]\n",
    "    for i in range(multiplier):\n",
    "        output[i] = calinski_harabaz_score(z[M*i:M*(i+1)], categories[M*i:M*(i+1)])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_plot(scores, clusters):\n",
    "    '''\n",
    "        Creates a boxplot of the Calinski Harabasz Index, for each number of clusters\n",
    "    '''\n",
    "    K = len(scores)\n",
    "    plt.figure()\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Calinski Harabasz Index')\n",
    "    plt.boxplot(scores, sym = '', positions = clusters)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(scores, clusters):\n",
    "    '''\n",
    "        Creates a plot of the Pairwise Stability Score, for each number of clusters\n",
    "    '''\n",
    "    K = len(scores)\n",
    "    plt.figure()\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Pairwise Stability Score')\n",
    "    plt.plot(clusters, scores)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph written\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  6.93e-01,  1.83e+00,  6.93e-01,  1.84e+00,  3.73e-01,         1\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  6.93e-01,  1.78e+00,  6.93e-01,  1.82e+00,  3.73e-01,         2\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  6.93e-01,  1.80e+00,  6.93e-01,  1.81e+00,  3.73e-01,         3\n",
      "All variables assigned to one cluster! Returning a score of 0.\n",
      "graph written\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  1.10e+00,  1.38e+00,  1.10e+00,  1.41e+00,  3.93e-01,         1\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  1.10e+00,  1.38e+00,  1.10e+00,  1.40e+00,  3.80e-01,         2\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  1.10e+00,  1.40e+00,  1.10e+00,  1.40e+00,  3.80e-01,         3\n",
      "graph written\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  1.39e+00,  1.06e+00,  1.39e+00,  1.16e+00,  4.33e-01,         1\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  1.39e+00,  1.13e+00,  1.39e+00,  1.13e+00,  4.13e-01,         2\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  1.39e+00,  1.13e+00,  1.39e+00,  1.12e+00,  4.00e-01,         3\n",
      "graph written\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  1.61e+00,  9.29e-01,  1.61e+00,  9.32e-01,  4.93e-01,         1\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  1.61e+00,  8.47e-01,  1.61e+00,  8.95e-01,  5.47e-01,         2\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  1.61e+00,  9.12e-01,  1.61e+00,  8.91e-01,  5.47e-01,         3\n",
      "graph written\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  1.79e+00,  7.68e-01,  1.79e+00,  7.63e-01,  5.27e-01,         1\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  1.79e+00,  7.17e-01,  1.79e+00,  7.11e-01,  6.27e-01,         2\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  1.79e+00,  6.95e-01,  1.79e+00,  7.09e-01,  4.73e-01,         3\n",
      "graph written\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  1.95e+00,  5.58e-01,  1.95e+00,  5.80e-01,  5.33e-01,         1\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  1.95e+00,  5.25e-01,  1.95e+00,  5.53e-01,  4.53e-01,         2\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  1.95e+00,  5.80e-01,  1.95e+00,  5.52e-01,  4.13e-01,         3\n",
      "graph written\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  2.08e+00,  3.62e-01,  2.08e+00,  4.28e-01,  5.93e-01,         1\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  2.08e+00,  4.36e-01,  2.08e+00,  4.21e-01,  4.00e-01,         2\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  2.08e+00,  4.29e-01,  2.08e+00,  4.20e-01,  3.87e-01,         3\n",
      "graph written\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  2.20e+00,  2.84e-01,  2.20e+00,  3.16e-01,  6.07e-01,         1\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  2.20e+00,  2.96e-01,  2.20e+00,  3.04e-01,  4.73e-01,         2\n",
      "    tr_ent,   tr_loss,     t_ent,    t_loss,     t_acc,     epoch                                   \n",
      "  2.20e+00,  3.17e-01,  2.20e+00,  3.02e-01,  4.20e-01,         3\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver(keep_checkpoint_every_n_hours=4)\n",
    "CH_scores = []\n",
    "stability_scores = []\n",
    "clusters = range(2,10)\n",
    "for k in clusters:\n",
    "    model = GMVAE(k=k, n_x=n_x, n_z=n_z)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        # TRAINING\n",
    "        sess_info = (sess, saver)\n",
    "        # For some reason we can't save when running on jupyter notebook, hence the last parameter\n",
    "        # When we want to save our parameters, maybe just run a python script from a terminal instead?\n",
    "        history = model.train('logs/gmvae_k={:d}.log'.format(k), dataset, sess_info, epochs=3, save_parameters = False)\n",
    "\n",
    "        multiplier = 10 # How many z:s we sample from one data point\n",
    "        CH = sample_and_compute_calinski_harabaz(sess,\n",
    "                               dataset.test.data,\n",
    "                               model,\n",
    "                               multiplier,\n",
    "                               k,\n",
    "                               n_z)\n",
    "        CH_scores.append(CH)\n",
    "        stability_score = compute_pairwise_stability(sess, model, dataset.test.data, k, n_z)\n",
    "        stability_scores.append(stability_score)\n",
    "box_plot(CH_scores, clusters)\n",
    "plot(stability_scores, clusters)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
